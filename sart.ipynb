{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All Imports\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "from numba import cuda\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import glob\n",
    "from skimage import filters\n",
    "from skimage.filters import unsharp_mask, threshold_local, threshold_minimum\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "\n",
    "\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "\n",
    "from skimage.measure import label\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#import pylidc as pl\n",
    "\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import pymrt as mrt\n",
    "#import pymrt.geometry\n",
    "import ipyvolume as ipv\n",
    "import copy\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import uuid\n",
    "import numpy as np\n",
    "from ipdb import set_trace as bp\n",
    "\n",
    "\n",
    "\n",
    "#from image_gen import ImageDataGenerator\n",
    "#from load_data import loadDataMontgomery, loadDataJSRT\n",
    "#from build_model import build_UNet2D_4L\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "import functools\n",
    "import pickle\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     6,
     19,
     35,
     45,
     70,
     89,
     287,
     518,
     751,
     975,
     1204,
     1214,
     1225,
     1238,
     1255,
     1269,
     1285,
     1297,
     1421,
     1519,
     1529,
     1536,
     1543,
     1588,
     1627,
     1641,
     1680,
     1719,
     1833,
     1954,
     1981,
     2045,
     2090,
     2115,
     2141,
     2157
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ray Tracing Code\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def x_y_flip(host_prjbuf_temp):\n",
    "    host_prjbuf_temp_gpu  = np.copy(host_prjbuf_temp)\n",
    "    host_prjbuf_1view_gpu = np.copy(host_prjbuf_temp)\n",
    "    \n",
    "    for i in prange(BINSx):\n",
    "        for j in prange(BINSy):\n",
    "            bin_ind_temp = j*BINSx+i\n",
    "            bin_ind      = i*BINSy+j\n",
    "            host_prjbuf_1view_gpu[bin_ind] = host_prjbuf_temp_gpu[bin_ind_temp]\n",
    "    \n",
    "    return host_prjbuf_1view_gpu\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_yry(host_prj_allangle, host_scat_allangle):\n",
    "    all_b_size        =  ANGLES*BINSx*BINSy\n",
    "    host_yry_allangle =  np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    for i in prange(all_b_size):\n",
    "        if (host_prj_allangle[i] == 0):\n",
    "            host_yry_allangle[i] = 0\n",
    "        else:\n",
    "            dif = host_prj_allangle[i] - host_scat_allangle[i]\n",
    "            if (dif <= 0):\n",
    "                dif = host_prj_allangle[i]\n",
    "            host_yry_allangle[i] = (dif*dif)/host_prj_allangle[i]\n",
    "    \n",
    "    return host_yry_allangle\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_gamma_yry(host_yry_allangle, host_gamma_allangle):\n",
    "    all_b_size              = ANGLES*BINSx*BINSy\n",
    "    host_gamma_yry_allangle = np.zeros(all_b_size)\n",
    "    \n",
    "    for i in prange(all_b_size):\n",
    "        host_gamma_yry_allangle[i] = host_yry_allangle[i]*host_gamma_allangle[i]\n",
    "    \n",
    "    return host_gamma_yry_allangle\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_h(host_prj_sub, host_blank_sub, host_line_sub, host_scat_sub):\n",
    "    ANGLES_per_sub  = int(ANGLES/subset_num)\n",
    "    sub_b_size      = int(ANGLES_per_sub*BINSx*BINSy)\n",
    "    \n",
    "    host_sub = np.zeros(sub_b_size)\n",
    "    \n",
    "    for i in prange(sub_b_size):\n",
    "        y_tmp       = host_blank_sub[i]*np.exp(-host_line_sub[i])\n",
    "        host_sub[i] = (host_prj_sub[i]/(y_tmp+host_scat_sub[i])-1)*y_tmp\n",
    "    \n",
    "    return host_sub\n",
    "\n",
    "@njit(parallel=True)\n",
    "def update_est(host_est, host_capL, host_RD, host_d, host_RDD):\n",
    "    f_size    = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "    host_est1 = np.zeros(f_size)\n",
    "    \n",
    "    for i in prange(f_size):\n",
    "        host_est1[i] = host_est[i]-(host_capL[i]+beta*host_RD[i])/(host_d[i]+2*beta*host_RDD[i])\n",
    "        if (host_est1[i] < 0):\n",
    "            host_est1[i] = 0\n",
    "    \n",
    "    return host_est1\n",
    "\n",
    "@njit(parallel=True)\n",
    "def regroup_prj(host_uponregroup_allangle):\n",
    "    all_b_size     = int(ANGLES*BINSx*BINSy)\n",
    "    ANGLES_per_sub = int(ANGLES/subset_num)\n",
    "    b_size         = int(BINSx*BINSy)\n",
    "    \n",
    "    host_allangle_tmp = np.zeros(host_uponregroup_allangle.shape)\n",
    "    flag              = 0\n",
    "    \n",
    "    for i in range(subset_num):\n",
    "        for j in range(ANGLES_per_sub):\n",
    "            for k in range(b_size):\n",
    "                host_allangle_tmp[flag] = host_uponregroup_allangle[int((j*subset_num+i)*b_size+k)]\n",
    "                flag = flag +1\n",
    "    \n",
    "    return host_allangle_tmp\n",
    "\n",
    "import math\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def rayTrace3D_GPU_direct_notexturememory_normprj(d_normprj, x0, y0, z0, x1, y1, z1, status, sum_norm, bin_ind):\n",
    "    # Perform Ray Tracing\n",
    "    sum_norm = 0\n",
    "    dx     = x1-x0\n",
    "    dy     = y1-y0\n",
    "    dz     = z1-z0\n",
    "    Length = math.sqrt( dx*dx+dy*dy+dz*dz )\n",
    "\n",
    "\n",
    "    if (x1 != x0):\n",
    "        min_lx = (x_p0-x0)/dx\n",
    "        max_lx = min_lx+IMGSIZx*Vsize_x/dx\n",
    "\n",
    "        if (min_lx > max_lx):\n",
    "            #SWAP(min_lx, max_lx);\n",
    "            s_temp = min_lx\n",
    "            min_lx = max_lx\n",
    "            max_lx = s_temp\n",
    "    else:\n",
    "        # the line perpendicular to x axis\n",
    "        if (x0 >= IMGSIZx*Vsize_x+x_p0 or x0<=x_p0):\n",
    "            status = -1\n",
    "            return\n",
    "        min_lx = -1e3\n",
    "        max_lx = 1e3\n",
    "    \n",
    "    \n",
    "    if (y0 != y1):\n",
    "        min_ly = (y_p0-y0)/dy\n",
    "        max_ly = min_ly+IMGSIZy*Vsize_y/dy\n",
    "\n",
    "        if (min_ly > max_ly):\n",
    "            #SWAP(min_ly, max_ly);\n",
    "            s_temp = min_ly\n",
    "            min_ly = max_ly\n",
    "            max_ly = s_temp\n",
    "    else:\n",
    "        # the line perpendicular to y axis\n",
    "        if (y0 >= IMGSIZy*Vsize_y+y_p0 or y0 <= y_p0):\n",
    "            status = -1\n",
    "            return\n",
    "        min_ly = -1e3\n",
    "        max_ly = 1e3\n",
    "\n",
    "    \n",
    "    if (z0 != z1):\n",
    "        min_lz = (z_p0-z0)/dz\n",
    "        max_lz = min_lz+IMGSIZz*Vsize_z/dz\n",
    "        if (min_lz > max_lz):\n",
    "            #SWAP(min_lz, max_lz);\n",
    "            s_temp = min_lz\n",
    "            min_lz = max_lz\n",
    "            max_lz = s_temp\n",
    "    else:\n",
    "        # the line perpendicular to z axis\n",
    "        if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "            status = -1\n",
    "            return\n",
    "        min_lz = -1e3\n",
    "        max_lz = 1e3\n",
    "    \n",
    "    \n",
    "    max_l = max_lx\n",
    "    if (max_l > max_ly):\n",
    "        max_l=max_ly\n",
    "    if (max_l > max_lz):\n",
    "        max_l = max_lz\n",
    "\n",
    "    min_l = min_lx\n",
    "    if (min_l < min_ly):\n",
    "        min_l = min_ly\n",
    "    if (min_l < min_lz):\n",
    "        min_l = min_lz\n",
    "\n",
    "    if (min_l >= max_l):\n",
    "        status = -1\n",
    "        return\n",
    "    \n",
    "    if (min_lx != min_l):\n",
    "        prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "\n",
    "        if (x0 < x1):\n",
    "            min_lx= ((prev_x+1)*Vsize_x+x_p0-x0)/ dx\n",
    "        else:\n",
    "            if (x0 == x1):\n",
    "                min_lx = 1e3\n",
    "            else:\n",
    "                min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "    else:\n",
    "        if (x0 < x1):\n",
    "            prev_x = 0\n",
    "            min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "        else:\n",
    "            prev_x = IMGSIZx-1\n",
    "            min_lx = ( prev_x*Vsize_x+x_p0-x0 )/ dx\n",
    "    \n",
    "    if (min_ly != min_l):\n",
    "        prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/Vsize_y ))\n",
    "        if (y0 < y1):\n",
    "            min_ly = ( (prev_y+1)*Vsize_y+y_p0-y0)/ dy\n",
    "        else:\n",
    "            if (y0==y1):\n",
    "                min_ly = 1e3\n",
    "            else:\n",
    "                min_ly = (prev_y*Vsize_y+y_p0-y0)/ dy\n",
    "    else:\n",
    "        if (y0<y1):\n",
    "            prev_y = 0\n",
    "            min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "        else:\n",
    "            prev_y = IMGSIZy-1\n",
    "            min_ly = ( prev_y*Vsize_y+y_p0-y0 )/ dy\n",
    "    \n",
    "    if (min_lz != min_l):\n",
    "        prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/Vsize_z ))\n",
    "        if (z0 < z1):\n",
    "            min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "        else:\n",
    "            if (z0 == z1):\n",
    "                min_lz = 1e3\n",
    "            else:\n",
    "                min_lz = (prev_z*Vsize_z+z_p0-z0)/ dz\n",
    "    else:\n",
    "        if (z0 < z1):\n",
    "            prev_z = 0\n",
    "            min_lz = ( Vsize_z+z_p0-z0 )/ dz\n",
    "        else:\n",
    "            prev_z = (int)(IMGSIZz-1)\n",
    "            min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "    \n",
    "    \n",
    "    min_l_new = min_lx\n",
    "    if (min_l_new > min_ly):\n",
    "        min_l_new = min_ly\n",
    "    if (min_l_new > min_lz):\n",
    "        min_l_new = min_lz\n",
    "    \n",
    "    incx = Vsize_x/dx\n",
    "    incy = Vsize_y/dy\n",
    "    incz = Vsize_z/dz\n",
    "\n",
    "    ind = 0\n",
    "    \n",
    "    while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "        tmp_length = (min_l_new-min_l)*Length; #<-a_ij\n",
    "        if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "            sum_norm = sum_norm + 1*tmp_length\n",
    "        \n",
    "        ind = ind + 1\n",
    "        if (min_l_new == min_lx):\n",
    "            if (x0 < x1):\n",
    "                prev_x = prev_x + 1\n",
    "                min_lx = min_lx + incx; #Vsize_x/dx\n",
    "            else:\n",
    "                prev_x = prev_x - 1\n",
    "                min_lx = min_lx - incx; #Vsize_x/dx;\n",
    "        else:\n",
    "            prev_x = prev_x\n",
    "\n",
    "\n",
    "        if (min_l_new == min_ly):\n",
    "            if (y0 < y1):\n",
    "                prev_y = prev_y + 1\n",
    "                min_ly = min_ly + incy; #Vsize_y / dy;\n",
    "            else:\n",
    "                prev_y = prev_y - 1\n",
    "                min_ly = min_ly- incy; #Vsize_y/dy;\n",
    "        else:\n",
    "            prev_y = prev_y\n",
    "\n",
    "\n",
    "        if (min_l_new == min_lz):\n",
    "            if (z0 < z1):\n",
    "                prev_z = prev_z + 1\n",
    "                min_lz = min_lz + incz #Vsize_z/dz;\n",
    "            else:\n",
    "                prev_z = prev_z - 1\n",
    "                min_lz = min_lz - incz; #Vsize_z/dz\n",
    "        else:\n",
    "            prev_z = prev_z\n",
    "\n",
    "        min_l     = min_l_new\n",
    "        min_l_new = min_lx\n",
    "\n",
    "        if (min_l_new > min_ly):\n",
    "            min_l_new = min_ly\n",
    "\n",
    "        if (min_l_new>min_lz):\n",
    "            min_l_new=min_lz\n",
    "        \n",
    "        \n",
    "        tmp_length = (max_l-min_l)*Length\n",
    "        if ((prev_x>=0) and (prev_x<IMGSIZx) and (prev_y>=0) and (prev_y<IMGSIZy) and (prev_z>=0) and (prev_z<IMGSIZz)):\n",
    "            sum_norm = sum_norm + 1*tmp_length\n",
    "        \n",
    "        d_normprj[bin_ind] = sum_norm\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def rayTrace3D_GPU_direct_notexturememory(d_normprj, d_prjbuf, d_objbuf, x0, y0, z0, x1, y1, z1, status):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    status   = 0\n",
    "    #sum_norm = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "        \n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        fsum_norm = 0.0\n",
    "        fsum      = 0.0\n",
    "        \n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        \n",
    "        d_normprj[bin_ind] = 0\n",
    "        d_prjbuf[bin_ind]  = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "            \n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "            \n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                    fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "                \n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "            status2 = 100\n",
    "        \n",
    "        if status2 == 100:\n",
    "            d_normprj[bin_ind] = fsum_norm\n",
    "            d_prjbuf[bin_ind]  = fsum\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "    \n",
    "@cuda.jit\n",
    "def ray_trace_gpu_manyangles_direct_notexturememory_normprj(d_normprj, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    status   = 0\n",
    "    #sum_norm = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        #print(a)\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "\n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        sum_norm = 0.0\n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        d_normprj[bin_ind] = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "\n",
    "\n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "\n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    sum_norm = sum_norm + 1*tmp_length\n",
    "\n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                sum_norm = sum_norm + 1*tmp_length\n",
    "            status2 = 100\n",
    "        if status2 == 100:\n",
    "            d_normprj[bin_ind] = sum_norm\n",
    "        #else:\n",
    "        #    d_normprj[bin_ind] = sum_norm\n",
    "#         elif status == 10:\n",
    "#             d_normprj[bin_ind] = 100000\n",
    "#         elif status == -1:\n",
    "#             d_normprj[bin_ind] = 50000\n",
    "#         else:\n",
    "#             d_normprj[bin_ind] = 200000\n",
    "#         d_normprj[bin_ind] = Length\n",
    "        cuda.syncthreads()\n",
    "\n",
    "@cuda.jit\n",
    "def ray_trace_gpu_manyangles_direct_notexturememory_OSTR_cos(d_objbuf, d_prjbuf, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    status   = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        #print(a)\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "        \n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        sum_norm = 0.0\n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        #d_prjbuf[bin_ind] = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "\n",
    "\n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "\n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    sum_norm = sum_norm + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "\n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                sum_norm = sum_norm + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "            status2 = 100\n",
    "        \n",
    "        if status2 == 100:\n",
    "            d_prjbuf[bin_ind] = sum_norm*cos_theta\n",
    "        cuda.syncthreads()\n",
    "\n",
    "@cuda.jit\n",
    "def ray_trace_gpu_manyangles_direct_notexturememory_cos(d_objbuf, d_prjbuf, d_normprj, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    status   = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        #print(a)\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "        \n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        fsum_norm = 0.0\n",
    "        fsum      = 0.0\n",
    "        \n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        #d_prjbuf[bin_ind] = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        \n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "\n",
    "\n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "\n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                    fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "\n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "            \n",
    "            status2 = 100\n",
    "        if status2 == 100:\n",
    "            d_normprj[bin_ind] = fsum_norm\n",
    "            d_prjbuf[bin_ind]  = fsum*cos_theta\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "    \n",
    "def fprojectCB_1R_GPU_OSTR_normprj(d_normprj, d_angles, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            ray_trace_gpu_manyangles_direct_notexturememory_normprj[PRJ_GRID, PRJ_THREAD](d_normprj, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY)\n",
    "            #cuda.synchronize()\n",
    "    return\n",
    "\n",
    "def fprojectCB_1R_GPU_OSTR_cos(estbuf, prj_est, d_angles, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            ray_trace_gpu_manyangles_direct_notexturememory_OSTR_cos[PRJ_GRID, PRJ_THREAD](estbuf, prj_est, d_angles, d_index, \n",
    "                                                                                           angleStart, angleEnd, nbBinsX, nbBinsY)\n",
    "            cuda.synchronize()\n",
    "    return\n",
    "\n",
    "def fprojectCB_1R_GPU_SART_cos(estbuf, prj_est, d_normprj, d_angles, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            ray_trace_gpu_manyangles_direct_notexturememory_cos[PRJ_GRID, PRJ_THREAD](estbuf, prj_est, d_normprj, d_angles, \n",
    "                                                                                      d_index, angleStart, angleEnd, \n",
    "                                                                                      nbBinsX, nbBinsY)\n",
    "            cuda.synchronize()\n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def SART_prj_diff_kernel(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    # calculate bin index\n",
    "    for a in range(angleStart, angleEnd):\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "        \n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        if normprj[bin_ind] != 0:\n",
    "            diff_line[bin_ind] = prjbuf[bin_ind]#bin_ind#(prjbuf[bin_ind] - prj_est[bin_ind])/normprj[bin_ind]\n",
    "        else:\n",
    "            diff_line[bin_ind] = bin_ind#1\n",
    "    return\n",
    "\n",
    "@njit(parallel=True)\n",
    "def SART_prj_diff(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd):\n",
    "    result_diff_line = np.zeros(prjbuf.shape)\n",
    "    \n",
    "    #for nbBinsX in prange(nBatchBINSx):\n",
    "    #    for nbBinsY in prange(nBatchBINSy):\n",
    "    for bin_ind in prange(prjbuf.shape[0]):\n",
    "        if normprj[bin_ind] != 0:\n",
    "            result_diff_line[bin_ind] = (prjbuf[bin_ind] - prj_est[bin_ind])/normprj[bin_ind]\n",
    "        else:\n",
    "            result_diff_line[bin_ind] = 0.0#prjbuf[bin_ind]#bin_ind\n",
    "    \n",
    "    return result_diff_line\n",
    "\n",
    "#@njit(parallel=True)\n",
    "def SART_prj_diff_old(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            SART_prj_diff_kernel[PRJ_GRID, PRJ_THREAD](diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd, nbBinsX, nbBinsY)\n",
    "            cuda.synchronize()\n",
    "    return\n",
    "#SART_prj_diff_kernel<<<PRJ_GRID,PRJ_THREAD>>>(diff_line,prjbuf,prj_est,normprj,d_index,angleStart,angleEnd,nbBinsX,nbBinsY);\n",
    "#CUT_CHECK_ERROR(\"Kernel execution failed\");\n",
    "#cudaThreadSynchronize()\n",
    "\n",
    "#def SART_prj_diff(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd):\n",
    "\n",
    "#@cuda.jit\n",
    "def bprojectCB_4B_GPU_R_SART(d_objbuf, d_prjbuf, d_prior, d_index, \n",
    "                                   d_angles, angleStart, angleEnd, lambda_parameter, beta):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    for nbatchIDx in range(nBatchXdim):\n",
    "        backprj_OSSART_gpu_manyviews_R[BACKPRJ_GRID, BACKPRJ_THREAD](d_objbuf, d_prjbuf, d_prior, d_index, \n",
    "                                                                            d_angles, angleStart, angleEnd , nbatchIDx, lambda_parameter, beta)\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def backprj_OSSART_gpu_manyviews_R(d_objbuf, d_prjbuf, d_prior, d_index, d_angles, \n",
    "                                          angleStart, angleEnd, nbatchIDx, lambda_parameter, beta):\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    tid = tx\n",
    "    \n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel = (ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x\n",
    "    \n",
    "    total_sum         = 0.0\n",
    "    total_sensitivity = 0.0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        u_term    = 0.0\n",
    "        \n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        \n",
    "        #(x0,y0,z0) - source position\n",
    "        x0 = sourceR*sin_theta\n",
    "        z0 = sourceR*cos_theta\n",
    "        y0 = sourceY\n",
    "        \n",
    "        #(x1,y1,z1) - center of voxel\n",
    "        x1 = (ind_x+0.5)*Vsize_x + x_p0\n",
    "        y1 = (ind_y+0.5)*Vsize_y + y_p0\n",
    "        z1 = (ind_z+0.5)*Vsize_z + z_p0\n",
    "        \n",
    "        #Check FDK paper for this weight factor. This weight can be set to 1, in a simple case\n",
    "        depth_weight = (x0*x0+y0*y0+z0*z0)/((x0-x1)*(x0-x1) + (y0-y1)*(y0-y1)+(z0-z1)*(z0-z1))\n",
    "        \n",
    "        #Do NOT Rotate (x0,y0,z0)  -theta  around the y-axis\n",
    "        y0r =y0\n",
    "        x0r =x0\n",
    "        z0r =z0\n",
    "        \n",
    "        #Do NOT Rotate (x1,y1,z1)  -theta around the y-axis\n",
    "        y1r = y1\n",
    "        z1r = z1\n",
    "        x1r = x1\n",
    "        \n",
    "        if (z1r != z0r):\n",
    "            t = (-detectorR - z0r) / (z1r - z0r)\n",
    "            x2 = x0r + (x1r - x0r) * t\n",
    "            y2 = y0r + (y1r - y0r) * t\n",
    "            \n",
    "            weight = 1.0\n",
    "            \n",
    "            # BACKPROJECTION USING INTERPOLATION\n",
    "            # Calculate the continuous position (in bin_index coordinate) of the projection of voxel in the detector plane.\n",
    "            imb = ((float)(x2 - x_d0)/Bsize_x)\n",
    "            jmb = ((float)(y2 - y_d0)/Bsize_y)\n",
    "            \n",
    "            ilb = (float)(math.floor(imb))\n",
    "            if (imb < (ilb+0.5)):\n",
    "                ilb = ilb - 1\n",
    "            \n",
    "            jlb = (float)(math.floor(jmb))\n",
    "            if ( jmb < (jlb+0.5)):\n",
    "                jlb = jlb - 1\n",
    "            \n",
    "            fracI = imb - (ilb+0.5)\n",
    "            fracJ = jmb - (jlb+0.5)\n",
    "            \n",
    "            d1 = 0\n",
    "            d2 = 0\n",
    "            d1_sen = 0\n",
    "            d2_sen = 0\n",
    "        \n",
    "            # Interpolation\n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = ilb*BINSy + jlb\n",
    "                d1      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d1_sen  = (1-fracI) \n",
    "\n",
    "            if ((ilb < BINSx-1) and (ilb >= -1) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = (ilb + 1)* BINSy+ jlb\n",
    "                d1      = d1 + fracI * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d1_sen  = d1_sen + fracI \n",
    "\n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy-1) and (jlb >= -1)):\n",
    "                bin_ind = ilb* BINSy + jlb + 1\n",
    "                d2      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d2_sen   =  1-fracI \n",
    "\n",
    "            if ((ilb<BINSx-1) and (ilb>=-1) and (jlb<BINSy-1) and (jlb>=-1)):\n",
    "                bin_ind = (ilb + 1) * BINSy +  jlb + 1\n",
    "                d2 = d2 + fracI  * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d2_sen = d2_sen + fracI\n",
    "            \n",
    "            u_term    = (1 - fracJ) * d1 + fracJ * d2\n",
    "            u_term    = u_term*Vsize_z*depth_weight\n",
    "            \n",
    "            u_sensitivity = ((1-fracJ)*d1_sen+fracJ*d2_sen)\n",
    "            u_sensitivity = u_sensitivity *Vsize_z*depth_weight\n",
    "            \n",
    "            total_sum         = total_sum + (u_term*weight)\n",
    "            total_sensitivity = total_sensitivity+(u_sensitivity*weight)\n",
    "    \n",
    "    u_term    = 0\n",
    "    beta_term = 0\n",
    "    \n",
    "    if(total_sensitivity != 0):\n",
    "        u_term    = (total_sum/total_sensitivity)\n",
    "        beta_term = (beta*d_prior[ind_voxel])/total_sensitivity\n",
    "    \n",
    "    d_objbuf[ind_voxel] = d_objbuf[ind_voxel]+lambda_parameter*(u_term+beta_term)\n",
    "    if(d_objbuf[ind_voxel] < 0):\n",
    "        d_objbuf[ind_voxel] = 0\n",
    "    #if(d_objbuf[ind_voxel] > 0.1):\n",
    "    #    d_objbuf[ind_voxel] = 0\n",
    "    \n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def backprj_gpu_manyviews_SBP(d_objbuf, d_prjbuf, d_index, d_angles, angleStart, angleEnd , nbatchIDx):\n",
    "    # Block id in a 1D grid\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    tid = tx\n",
    "    \n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel = (ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x\n",
    "    \n",
    "    total_sum = 0.0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        u_term    = 0.0\n",
    "        \n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        \n",
    "        #(x0,y0,z0) - source position\n",
    "        x0 = sourceR*sin_theta\n",
    "        z0 = sourceR*cos_theta\n",
    "        y0 = sourceY\n",
    "        \n",
    "        #(x1,y1,z1) - center of voxel\n",
    "        x1 = (ind_x+0.5)*Vsize_x + x_p0\n",
    "        y1 = (ind_y+0.5)*Vsize_y + y_p0\n",
    "        z1 = (ind_z+0.5)*Vsize_z + z_p0\n",
    "        \n",
    "        #Check FDK paper for this weight factor. This weight can be set to 1, in a simple case\n",
    "        depth_weight = (x0*x0 + y0*y0 + z0*z0)/((x0-x1)*(x0-x1) + (y0-y1)*(y0-y1)+(z0-z1)*(z0-z1))\n",
    "        \n",
    "        y0r = y0\n",
    "        x0r = x0\n",
    "        z0r = z0\n",
    "        \n",
    "        y1r = y1\n",
    "        z1r = z1\n",
    "        x1r = x1\n",
    "        \n",
    "        if (z1r != z0r):\n",
    "            t = (-detectorR - z0r) / (z1r - z0r)\n",
    "            x2 = x0r + (x1r - x0r) * t\n",
    "            y2 = y0r + (y1r - y0r) * t\n",
    "            \n",
    "            weight = 1.0\n",
    "            \n",
    "            # BACKPROJECTION USING INTERPOLATION\n",
    "            # Calculate the continuous position (in bin_index coordinate) of the projection of voxel in the detector plane.\n",
    "            imb = ((float)(x2 - x_d0)/Bsize_x)\n",
    "            jmb = ((float)(y2 - y_d0)/Bsize_y)\n",
    "            \n",
    "            ilb = (float)(math.floor(imb))\n",
    "            if (imb < (ilb+0.5)):\n",
    "                ilb = ilb - 1\n",
    "            \n",
    "            jlb = (float)(math.floor(jmb))\n",
    "            if ( jmb < (jlb+0.5)):\n",
    "                jlb = jlb - 1\n",
    "\n",
    "            fracI = imb - (ilb+0.5)\n",
    "            fracJ = jmb - (jlb+0.5)\n",
    "            \n",
    "            d1 = 0\n",
    "            d2 = 0\n",
    "            \n",
    "            # Interpolation\n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = ilb*BINSy + jlb\n",
    "                d1      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            if ((ilb < BINSx-1) and (ilb >= -1) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = (ilb + 1)* BINSy+ jlb\n",
    "                d1      = d1 + fracI * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy-1) and (jlb >= -1)):\n",
    "                bin_ind = ilb* BINSy + jlb + 1\n",
    "                d2      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            if ((ilb<BINSx-1) and (ilb>=-1) and (jlb<BINSy-1) and (jlb>=-1)):\n",
    "                bin_ind = (ilb + 1) * BINSy +  jlb + 1\n",
    "                d2 = d2 + fracI  * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            u_term    = (1 - fracJ) * d1 + fracJ * d2\n",
    "            u_term    = u_term*Vsize_z*depth_weight\n",
    "            total_sum = total_sum + (u_term*weight)\n",
    "        \n",
    "    d_objbuf[ind_voxel] = d_objbuf[ind_voxel]+total_sum        \n",
    "    return\n",
    "\n",
    "\n",
    "def bprojectCB_GPU_SBP(d_objbuf, d_prjbuf, d_index, d_angles, angleStart, angleEnd):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    for nbatchIDx in range(nBatchXdim):\n",
    "        backprj_gpu_manyviews_SBP[BACKPRJ_GRID, BACKPRJ_THREAD](d_objbuf, d_prjbuf, d_index, d_angles, angleStart, angleEnd , nbatchIDx)\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "@njit(parallel=True)\n",
    "def temp_fun1(angleStart, b_size, sub_b_size, host_prj_allangle):\n",
    "    host_prj_sub = np.zeros(sub_b_size)\n",
    "    for i in prange(sub_b_size):\n",
    "        host_prj_sub[i]   = host_prj_allangle[angleStart*b_size+i]\n",
    "    return host_prj_sub\n",
    "\n",
    "@njit(parallel=True)\n",
    "def temp_fun2(subset_num, f_size, host_capL):\n",
    "    temp = np.zeros(f_size)\n",
    "    for i in prange(f_size):\n",
    "        temp[i] = subset_num*host_capL[i]\n",
    "    return temp\n",
    "\n",
    "@cuda.jit\n",
    "def G_Fessler_prior(RDD, RD, estbuf, delta, z_xy_ratio, nbatchIDx):\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    # Thread index\n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    cent = 1\n",
    "    tid  = tx\n",
    "    \n",
    "    # Calculate the index of the voxel being considered\n",
    "    # ind_x = nbatchIDx*((int)(IMGSIZx/h_nBatchXdim))+ tid\n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel=int((ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x)  #(if prj is scanner data, need x_y_flip)\n",
    "    #ind_voxel=(ind_z*IMGSIZx+ind_x)*IMGSIZy+ind_y;\n",
    "    \n",
    "    for ind_nr_z  in range(ind_z-1, ind_z+2):\n",
    "        for ind_nr_y in range(ind_y-1, ind_y+2):\n",
    "            for ind_nr_x in range(ind_x-1, ind_x+2):\n",
    "                distance = math.sqrt(float((ind_nr_x-ind_x)*(ind_nr_x-ind_x)+(ind_nr_y-ind_y)*(ind_nr_y-ind_y)+(ind_nr_z-ind_z)*(ind_nr_z-ind_z)*z_xy_ratio*z_xy_ratio))\n",
    "                \n",
    "                if (distance == 0.0):\n",
    "                    distance = 1.0\n",
    "                    cent     = 0\n",
    "                \n",
    "                if ( ind_nr_x<0  or ind_nr_y<0 or ind_nr_z<0 or ind_nr_x>(IMGSIZx-1) or ind_nr_y>(IMGSIZy-1) or ind_nr_z>(IMGSIZz-1) ):\n",
    "                    ind_nr = int(ind_voxel)\n",
    "                else:\n",
    "                    ind_nr = int(ind_nr_x + ind_nr_y*IMGSIZx + ind_nr_z*IMGSIZx*IMGSIZy)\n",
    "                \n",
    "                diff        = estbuf[ind_voxel]-estbuf[ind_nr]\n",
    "                denominator = 1.0+abs(diff/delta)\n",
    "                RDD_tmp     = cent*(1.0/distance)/denominator\n",
    "                \n",
    "                RDD[ind_voxel] = RDD[ind_voxel] + RDD_tmp\n",
    "                RD[ind_voxel]  = RD[ind_voxel]  + RDD_tmp*diff\n",
    "                \n",
    "                cent = 1 # reset cent\n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def G_Huber_prior_sart(priorbuf, estbuf, delta, nbatchIDx):\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    # Thread index\n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    cent = 1\n",
    "    tid  = tx\n",
    "    \n",
    "    # Calculate the index of the voxel being considered\n",
    "    # ind_x = nbatchIDx*((int)(IMGSIZx/h_nBatchXdim))+ tid\n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel = int((ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x)  #(if prj is scanner data, need x_y_flip)\n",
    "    #ind_voxel=(ind_z*IMGSIZx+ind_x)*IMGSIZy+ind_y;\n",
    "    \n",
    "    for ind_nr_z  in range(ind_z-1, ind_z+2):\n",
    "        for ind_nr_y in range(ind_y-1, ind_y+2):\n",
    "            for ind_nr_x in range(ind_x-1, ind_x+2):\n",
    "                distance = math.sqrt(float((ind_nr_x-ind_x)*(ind_nr_x-ind_x)+(ind_nr_y-ind_y)*(ind_nr_y-ind_y)+(ind_nr_z-ind_z)*(ind_nr_z-ind_z)))\n",
    "                \n",
    "                if (distance == 0.0):\n",
    "                    distance = 1.0\n",
    "                \n",
    "                if ( ind_nr_x<0  or ind_nr_y<0 or ind_nr_z<0 or ind_nr_x>(IMGSIZx-1) or ind_nr_y>(IMGSIZy-1) or ind_nr_z>(IMGSIZz-1) ):\n",
    "                    ind_nr = int(ind_voxel)\n",
    "                else:\n",
    "                    ind_nr = int(ind_nr_x + ind_nr_y*IMGSIZx + ind_nr_z*IMGSIZx*IMGSIZy)\n",
    "                \n",
    "                diff        = estbuf[ind_voxel]-estbuf[ind_nr]\n",
    "                denominator = math.sqrt(1.0+(diff/delta)*(diff/delta))\n",
    "                \n",
    "                priorbuf[ind_voxel] = priorbuf[ind_voxel] + (1.0/distance)*diff/denominator\n",
    "    return    \n",
    "\n",
    "def prior_GPU_SART(d_prior, d_est, delta):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    if (delta == 0):\n",
    "        print(\"delta cannot be ZERO !!\")\n",
    "        exit(1)\n",
    "    \n",
    "    for nbatchIDx in range(0, nBatchXdim):\n",
    "        G_Huber_prior_sart[BACKPRJ_GRID, BACKPRJ_THREAD](d_prior, d_est, delta, nbatchIDx)\n",
    "        # Check out the content of this kernel in file ConebeamCT_kernel.cu\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "def prior_GPU_OSTR(d_RDD, d_RD, d_est, delta, z_xy_ratio):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    if (delta == 0):\n",
    "        print(\"delta cannot be ZERO !!\")\n",
    "        exit(1)\n",
    "    \n",
    "    for nbatchIDx in range(0, nBatchXdim):\n",
    "        G_Fessler_prior[BACKPRJ_GRID, BACKPRJ_THREAD](d_RDD, d_RD, d_est, delta, z_xy_ratio, nbatchIDx)\n",
    "        # Check out the content of this kernel in file ConebeamCT_kernel.cu\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This module contains a Python and NumPy implementation of the HaarPSI perceptual similarity index algorithm,\n",
    "as described in \"A Haar Wavelet-Based Perceptual Similarity Index for Image Quality Assessment\" by\n",
    "R. Reisenhofer, S. Bosse, G. Kutyniok and T. Wiegand.\n",
    "\n",
    "Converted by David Neumann from the original MATLAB implementation written by Rafael Reisenhofer.\n",
    "\n",
    "Last updated on 08/01/2018 by David Neumann.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy\n",
    "from scipy import signal\n",
    "\n",
    "try:\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "    import tensorflow as tf\n",
    "    is_tensorflow_available = True\n",
    "except ImportError:\n",
    "    is_tensorflow_available = False\n",
    "\n",
    "def haar_psi(reference_image, distorted_image, preprocess_with_subsampling = True):\n",
    "    \"\"\"\n",
    "    Calculates the HaarPSI perceptual similarity index between the two specified images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        reference_image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The reference image, which can be in RGB or grayscale. The values must be in the range [0, 255].\n",
    "            The image must be a NumPy array or TensorFlow tensor of the shape (width, height, 3) in the case\n",
    "            of RGB, or a NumPy array or TensorFlow tensor in the shape (width, height) for grayscale.\n",
    "        distorted_image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The distorted image, which is to be compared to the reference image. The image can be in RGB or\n",
    "            grayscale. The values must be in the range [0, 255]. The image must be a NumPy array or a\n",
    "            TensorFlow tensor of the shape (width, height, 3) in the case of RGB, or a NumPy array or\n",
    "            TensorFlow tensor in the shape (width, height) for grayscale.\n",
    "        preprocess_with_subsampling: boolean\n",
    "            An optional parameter, which determines whether a preprocessing step is to be performed, which\n",
    "            accommodates for the viewing distance in psychophysical experiments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        (float, numpy.ndarray | tensorflow.Tensor | tensorflow.Variable, numpy.ndarray | tensorflow.Tensor\n",
    "        | tensorflow.Variable): Returns a three-tuple containing the similarity score, the similarity maps\n",
    "        and the weight maps. The similarity score is the Haar wavelet-based perceptual similarity index,\n",
    "        measured in the interval [0,1]. The similarity maps are maps of horizontal and vertical local\n",
    "        similarities. For RGB images, this variable also includes a similarity map with respect to the two\n",
    "        color channels in the YIQ space. The weight maps are maps that measure the importance of the local\n",
    "        similarities in the similarity maps.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(reference_image) and is_numpy(distorted_image):\n",
    "        return haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling)\n",
    "    elif is_tensorflow(reference_image) and is_tensorflow(distorted_image):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        return haar_psi_tensorflow(reference_image, distorted_image, preprocess_with_subsampling)\n",
    "    else:\n",
    "        raise ValueError(\"The reference or the distorted image is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "def haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True):\n",
    "    \"\"\"\n",
    "    Calculates the HaarPSI perceptual similarity index between the two specified images. This implementation uses NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        reference_image: numpy.ndarray\n",
    "            The reference image, which can be in RGB or grayscale. The values must be in the range [0, 255].\n",
    "            The image must be a NumPy array of the shape (width, height, 3) in the case of RGB or a NumPy\n",
    "            array in the shape (width, height) for grayscale.\n",
    "        distorted_image: numpy.ndarray\n",
    "            The distorted image, which is to be compared to the reference image. The image can be in RGB or\n",
    "            grayscale. The values must be in the range [0, 255]. The image must be a NumPy array of the\n",
    "            shape (width, height, 3) in the case of RGB or a NumPy array in the shape (width, height) for\n",
    "            grayscale.\n",
    "        preprocess_with_subsampling: boolean\n",
    "            An optional parameter, which determines whether a preprocessing step is to be performed, which\n",
    "            accommodates for the viewing distance in psychophysical experiments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        (float, numpy.ndarray, numpy.ndarray): Returns a three-tuple containing the similarity score, the\n",
    "        similarity maps and the weight maps. The similarity score is the Haar wavelet-based perceptual\n",
    "        similarity index, measured in the interval [0,1]. The similarity maps are maps of horizontal and\n",
    "        vertical local similarities. For RGB images, this variable also includes a similarity map with\n",
    "        respect to the two color channels in the YIQ space. The weight maps are maps that measure the\n",
    "        importance of the local similarities in the similarity maps.\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if the image is a grayscale or an RGB image\n",
    "    if reference_image.shape != distorted_image.shape:\n",
    "        raise ValueError(\"The shapes of the reference image and the distorted image do not match.\")\n",
    "    if len(reference_image.shape) == 2:\n",
    "        is_color_image = False\n",
    "    elif reference_image.shape[2] == 1:\n",
    "        is_color_image = False\n",
    "    else:\n",
    "        is_color_image = True\n",
    "\n",
    "    # Converts the image values to double precision floating point numbers\n",
    "    reference_image = reference_image.astype(numpy.float64)\n",
    "    distorted_image = distorted_image.astype(numpy.float64)\n",
    "\n",
    "    # The HaarPSI algorithm requires two constants, C and alpha, that have been experimentally determined\n",
    "    # to be C = 30 and alpha = 4.2\n",
    "    C     = 30.0\n",
    "    alpha = 4.2\n",
    "\n",
    "    # If the images are in RGB, then they are transformed to the YIQ color space\n",
    "    if is_color_image:\n",
    "        reference_image_y = 0.299 * reference_image[:, :, 0] + 0.587 * reference_image[:, :, 1] + 0.114 * reference_image[:, :, 2]\n",
    "        distorted_image_y = 0.299 * distorted_image[:, :, 0] + 0.587 * distorted_image[:, :, 1] + 0.114 * distorted_image[:, :, 2]\n",
    "        reference_image_i = 0.596 * reference_image[:, :, 0] - 0.274 * reference_image[:, :, 1] - 0.322 * reference_image[:, :, 2]\n",
    "        distorted_image_i = 0.596 * distorted_image[:, :, 0] - 0.274 * distorted_image[:, :, 1] - 0.322 * distorted_image[:, :, 2]\n",
    "        reference_image_q = 0.211 * reference_image[:, :, 0] - 0.523 * reference_image[:, :, 1] + 0.312 * reference_image[:, :, 2]\n",
    "        distorted_image_q = 0.211 * distorted_image[:, :, 0] - 0.523 * distorted_image[:, :, 1] + 0.312 * distorted_image[:, :, 2]\n",
    "    else:\n",
    "        reference_image_y = reference_image\n",
    "        distorted_image_y = distorted_image\n",
    "\n",
    "    # Subsamples the images, which simulates the typical distance between an image and its viewer\n",
    "    if preprocess_with_subsampling:\n",
    "        reference_image_y = subsample(reference_image_y)\n",
    "        distorted_image_y = subsample(distorted_image_y)\n",
    "        if is_color_image:\n",
    "            reference_image_i = subsample(reference_image_i)\n",
    "            distorted_image_i = subsample(distorted_image_i)\n",
    "            reference_image_q = subsample(reference_image_q)\n",
    "            distorted_image_q = subsample(distorted_image_q)\n",
    "\n",
    "    # Performs the Haar wavelet decomposition\n",
    "    number_of_scales = 3\n",
    "    coefficients_reference_image_y = haar_wavelet_decompose(reference_image_y, number_of_scales)\n",
    "    coefficients_distorted_image_y = haar_wavelet_decompose(distorted_image_y, number_of_scales)\n",
    "    if is_color_image:\n",
    "        coefficients_reference_image_i = numpy.abs(convolve2d(reference_image_i, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_i = numpy.abs(convolve2d(distorted_image_i, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_reference_image_q = numpy.abs(convolve2d(reference_image_q, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_q = numpy.abs(convolve2d(distorted_image_q, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "\n",
    "    # Pre-allocates the variables for the local similarities and the weights\n",
    "    if is_color_image:\n",
    "        local_similarities = numpy.zeros(sum([reference_image_y.shape, (3, )], ()))\n",
    "        weights = numpy.zeros(sum([reference_image_y.shape, (3, )], ()))\n",
    "    else:\n",
    "        local_similarities = numpy.zeros(sum([reference_image_y.shape, (2, )], ()))\n",
    "        weights = numpy.zeros(sum([reference_image_y.shape, (2, )], ()))\n",
    "\n",
    "    # Computes the weights and similarities for each orientation\n",
    "    for orientation in range(2):\n",
    "        weights[:, :, orientation] = numpy.maximum(\n",
    "            numpy.abs(coefficients_reference_image_y[:, :, 2 + orientation * number_of_scales]),\n",
    "            numpy.abs(coefficients_distorted_image_y[:, :, 2 + orientation * number_of_scales])\n",
    "        )\n",
    "        coefficients_reference_image_y_magnitude = numpy.abs(coefficients_reference_image_y[:, :, (orientation * number_of_scales, 1 + orientation * number_of_scales)])\n",
    "        coefficients_distorted_image_y_magnitude = numpy.abs(coefficients_distorted_image_y[:, :, (orientation * number_of_scales, 1 + orientation * number_of_scales)])\n",
    "        local_similarities[:, :, orientation] = numpy.sum(\n",
    "            (2 * coefficients_reference_image_y_magnitude * coefficients_distorted_image_y_magnitude + C) / (coefficients_reference_image_y_magnitude**2 + coefficients_distorted_image_y_magnitude**2 + C),\n",
    "            axis = 2\n",
    "        ) / 2\n",
    "\n",
    "    # Computes the similarities for color channels\n",
    "    if is_color_image:\n",
    "        similarity_i = (2 * coefficients_reference_image_i * coefficients_distorted_image_i + C) / (coefficients_reference_image_i**2 + coefficients_distorted_image_i**2 + C)\n",
    "        similarity_q = (2 * coefficients_reference_image_q * coefficients_distorted_image_q + C) / (coefficients_reference_image_q**2 + coefficients_distorted_image_q**2 + C)\n",
    "        local_similarities[:, :, 2] = (similarity_i + similarity_q) / 2\n",
    "        weights[:, :, 2] = (weights[:, :, 0] + weights[:, :, 1]) / 2\n",
    "\n",
    "    # Calculates the final score\n",
    "    similarity = logit(numpy.sum(sigmoid(local_similarities[:], alpha) * weights[:]) / numpy.sum(weights[:]), alpha)**2\n",
    "\n",
    "    # Returns the result\n",
    "    return similarity, local_similarities, weights\n",
    "\n",
    "def haar_psi_tensorflow(reference_image, distorted_image, preprocess_with_subsampling = True):\n",
    "    \"\"\"\n",
    "    Calculates the HaarPSI perceptual similarity index between the two specified images. This implementation uses TensorFlow.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        reference_image: tensorflow.Tensor | tensorflow.Variable\n",
    "            The reference image, which can be in RGB or grayscale. The values must be in the range [0, 255].\n",
    "            The image must be a TensorFlow Tensor of the shape (width, height, 3) in the case of RGB or a\n",
    "            TensorFlow tensor in the shape (width, height) for grayscale.\n",
    "        distorted_image: tensorflow.Tensor | tensorflow.Variable\n",
    "            The distorted image, which is to be compared to the reference image. The image can be in RGB or\n",
    "            grayscale. The values must be in the range [0, 255]. The image must be a TensorFlow tensor of\n",
    "            the shape (width, height, 3) in the case of RGB or a TensorFlow tensor in the shape\n",
    "            (width, height) for grayscale.\n",
    "        preprocess_with_subsampling: boolean\n",
    "            An optional parameter, which determines whether a preprocessing step is to be performed, which\n",
    "            accommodates for the viewing distance in psychophysical experiments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        (float, tensorflow.Tensor, tensorflow.Tensor): Returns a three-tuple containing the similarity score,\n",
    "        the similarity maps and the weight maps. The similarity score is the Haar wavelet-based perceptual\n",
    "        similarity index, measured in the interval [0,1]. The similarity maps are maps of horizontal and\n",
    "        vertical local similarities. For RGB images, this variable also includes a similarity map with\n",
    "        respect to the two color channels in the YIQ space. The weight maps are maps that measure the\n",
    "        importance of the local similarities in the similarity maps.\n",
    "    \"\"\"\n",
    "\n",
    "    if not is_tensorflow_available:\n",
    "        raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "    # Checks if the images are both single precision floats\n",
    "    if reference_image.dtype != tf.float32:\n",
    "        raise ValueError(\"The reference image has to be single precision float.\")\n",
    "    if distorted_image.dtype != tf.float32:\n",
    "        raise ValueError(\"The distorted image has to be single precision float.\")\n",
    "\n",
    "    # Checks if the image is a grayscale or an RGB image\n",
    "    if reference_image.get_shape().as_list() != distorted_image.get_shape().as_list():\n",
    "        raise ValueError(\"The shapes of the reference image and the distorted image do not match.\")\n",
    "    if len(reference_image.get_shape().as_list()) == 2:\n",
    "        is_color_image = False\n",
    "    elif reference_image.get_shape().as_list()[2] == 1:\n",
    "        is_color_image = False\n",
    "    else:\n",
    "        is_color_image = True\n",
    "\n",
    "    # The HaarPSI algorithm requires two constants, C and alpha, that have been experimentally determined\n",
    "    # to be C = 30 and alpha = 4.2\n",
    "    C = tf.constant(30.0, dtype = tf.float32)\n",
    "    alpha = tf.constant(4.2, dtype = tf.float32)\n",
    "\n",
    "    # If the images are in RGB, then they are transformed to the YIQ color space\n",
    "    if is_color_image:\n",
    "        reference_image_y = 0.299 * reference_image[:, :, 0] + 0.587 * reference_image[:, :, 1] + 0.114 * reference_image[:, :, 2]\n",
    "        distorted_image_y = 0.299 * distorted_image[:, :, 0] + 0.587 * distorted_image[:, :, 1] + 0.114 * distorted_image[:, :, 2]\n",
    "        reference_image_i = 0.596 * reference_image[:, :, 0] - 0.274 * reference_image[:, :, 1] - 0.322 * reference_image[:, :, 2]\n",
    "        distorted_image_i = 0.596 * distorted_image[:, :, 0] - 0.274 * distorted_image[:, :, 1] - 0.322 * distorted_image[:, :, 2]\n",
    "        reference_image_q = 0.211 * reference_image[:, :, 0] - 0.523 * reference_image[:, :, 1] + 0.312 * reference_image[:, :, 2]\n",
    "        distorted_image_q = 0.211 * distorted_image[:, :, 0] - 0.523 * distorted_image[:, :, 1] + 0.312 * distorted_image[:, :, 2]\n",
    "    else:\n",
    "        reference_image_y = reference_image\n",
    "        distorted_image_y = distorted_image\n",
    "\n",
    "    # Subsamples the images, which simulates the typical distance between an image and its viewer\n",
    "    if preprocess_with_subsampling:\n",
    "        reference_image_y = subsample(reference_image_y)\n",
    "        distorted_image_y = subsample(distorted_image_y)\n",
    "        if is_color_image:\n",
    "            reference_image_i = subsample(reference_image_i)\n",
    "            distorted_image_i = subsample(distorted_image_i)\n",
    "            reference_image_q = subsample(reference_image_q)\n",
    "            distorted_image_q = subsample(distorted_image_q)\n",
    "\n",
    "    # Performs the Haar wavelet decomposition\n",
    "    number_of_scales = 3\n",
    "    coefficients_reference_image_y = haar_wavelet_decompose(reference_image_y, number_of_scales)\n",
    "    coefficients_distorted_image_y = haar_wavelet_decompose(distorted_image_y, number_of_scales)\n",
    "    if is_color_image:\n",
    "        coefficients_reference_image_i = tf.abs(convolve2d(reference_image_i, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_i = tf.abs(convolve2d(distorted_image_i, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_reference_image_q = tf.abs(convolve2d(reference_image_q, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_q = tf.abs(convolve2d(distorted_image_q, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "\n",
    "    # Pre-allocates the variables for the local similarities and the weights\n",
    "    if is_color_image:\n",
    "        local_similarities = [tf.zeros_like(reference_image_y)] * 3\n",
    "        weights = [tf.zeros_like(reference_image_y)] * 3\n",
    "    else:\n",
    "        local_similarities = [tf.zeros_like(reference_image_y)] * 2\n",
    "        weights = [tf.zeros_like(reference_image_y)] * 2\n",
    "\n",
    "    # Computes the weights and similarities for each orientation\n",
    "    for orientation in range(2):\n",
    "        weights[orientation] = tf.maximum(\n",
    "            tf.abs(coefficients_reference_image_y[:, :, 2 + orientation * number_of_scales]),\n",
    "            tf.abs(coefficients_distorted_image_y[:, :, 2 + orientation * number_of_scales])\n",
    "        )\n",
    "        coefficients_reference_image_y_magnitude = tf.abs(coefficients_reference_image_y[:, :, orientation * number_of_scales:2 + orientation * number_of_scales])\n",
    "        coefficients_distorted_image_y_magnitude = tf.abs(coefficients_distorted_image_y[:, :, orientation * number_of_scales:2 + orientation * number_of_scales])\n",
    "        local_similarities[orientation] = tf.reduce_sum(\n",
    "            (2 * coefficients_reference_image_y_magnitude * coefficients_distorted_image_y_magnitude + C) / (coefficients_reference_image_y_magnitude**2 + coefficients_distorted_image_y_magnitude**2 + C),\n",
    "            axis = 2\n",
    "        ) / 2\n",
    "    weights = tf.stack(weights, axis = -1)\n",
    "    local_similarities = tf.stack(local_similarities, axis = -1)\n",
    "\n",
    "    # Computes the similarities for color channels\n",
    "    if is_color_image:\n",
    "        similarity_i = (2 * coefficients_reference_image_i * coefficients_distorted_image_i + C) / (coefficients_reference_image_i**2 + coefficients_distorted_image_i**2 + C)\n",
    "        similarity_q = (2 * coefficients_reference_image_q * coefficients_distorted_image_q + C) / (coefficients_reference_image_q**2 + coefficients_distorted_image_q**2 + C)\n",
    "        local_similarities = tf.concat([local_similarities[:, :, slice(0, 2)], tf.expand_dims((similarity_i + similarity_q) / 2, axis = 2)], axis = 2)\n",
    "        weights = tf.concat([weights[:, :, slice(0, 2)], tf.expand_dims((weights[:, :, 0] + weights[:, :, 1]) / 2, axis = 2)], axis = 2)\n",
    "\n",
    "    # Calculates the final score\n",
    "    similarity = logit(tf.reduce_sum(sigmoid(local_similarities[:], alpha) * weights[:]) / tf.reduce_sum(weights[:]), alpha)**2\n",
    "\n",
    "    # Returns the result\n",
    "    return similarity, local_similarities, weights\n",
    "\n",
    "def subsample(image):\n",
    "    \"\"\"\n",
    "    Convolves the specified image with a 2x2 mean filter and performs a dyadic subsampling step. This\n",
    "    simulates the typical distance between an image and its viewer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The image that is to be subsampled.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.ndarray | tensorflow.Tensor: Returns the subsampled image.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(image):\n",
    "        subsampled_image = convolve2d(image, numpy.ones((2, 2)) / 4.0, mode = \"same\")\n",
    "    elif is_tensorflow(image):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        subsampled_image = convolve2d(image, tf.ones((2, 2)) / 4.0, mode = \"same\")\n",
    "    else:\n",
    "        raise ValueError(\"The image is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "    subsampled_image = subsampled_image[::2, ::2]\n",
    "    return subsampled_image\n",
    "\n",
    "def convolve2d(data, kernel, mode = \"same\"):\n",
    "    \"\"\"\n",
    "    Convolves the first input array with the second one in the same way MATLAB does. Due to an\n",
    "    implementation detail, the SciPy and MATLAB implementations yield different results. This method\n",
    "    rectifies this shortcoming of the SciPy implementation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        data: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The first input array.\n",
    "        kernel: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The second input array with which the fist input array is being convolved.\n",
    "        mode: str\n",
    "            A string indicating the size of the output.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.ndarray | tensorflow.Tensor: Returns a 2-dimensional array containing a subset of the discrete\n",
    "        linear convolution of the first input array with the second input array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if the NumPy or the TensorFlow implementation is to be used\n",
    "    if is_numpy(data) and is_numpy(kernel):\n",
    "\n",
    "        # Due to an implementation detail of MATLAB, the input arrays have to be rotated by 90 degrees to\n",
    "        # retrieve a similar result as compared to MATLAB\n",
    "        rotated_data = numpy.rot90(data, 2)\n",
    "        rotated_kernel = numpy.rot90(kernel, 2)\n",
    "\n",
    "        # The convolution result has to be rotated again by 90 degrees to get the same result as in MATLAB\n",
    "        result = signal.convolve2d(\n",
    "            rotated_data,\n",
    "            rotated_kernel,\n",
    "            mode = mode\n",
    "        )\n",
    "        result = numpy.rot90(result, 2)\n",
    "\n",
    "    elif is_tensorflow(data) and is_tensorflow(kernel):\n",
    "\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "        # TensorFlow requires a 4D Tensor for convolution, the data has to be shaped [batch_size, width, height, number_of_channels]\n",
    "        # and the kernel has to be shaped [width, height, number_of_channels_in, number_of_channels_out]\n",
    "        data_shape = data.get_shape().as_list()\n",
    "        data = tf.reshape(data, [1, data_shape[0], data_shape[1], 1])\n",
    "        kernel_shape = kernel.get_shape().as_list()\n",
    "        kernel = tf.reshape(kernel, [kernel_shape[0], kernel_shape[1], 1, 1])\n",
    "\n",
    "        # Calculates the convolution, for some reason that I do not fully understand, the result has to be negated\n",
    "        result = tf.nn.conv2d(\n",
    "            data,\n",
    "            kernel,\n",
    "            padding = mode.upper(),\n",
    "            strides = [1, 1, 1, 1]\n",
    "        )\n",
    "        result = tf.negative(tf.squeeze(result))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either the data or the kernel is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "    # Returns the result of the convolution\n",
    "    return result\n",
    "\n",
    "def haar_wavelet_decompose(image, number_of_scales):\n",
    "    \"\"\"\n",
    "    Performs the Haar wavelet decomposition.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The image that is to be decomposed.\n",
    "        number_of_scales: int\n",
    "            The number different filter scales that is to be used.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.ndarray | tensorflow.Tensor: Returns the coefficients that were determined by the Haar wavelet\n",
    "        decomposition.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(image):\n",
    "\n",
    "        coefficients = numpy.zeros(sum([image.shape, (2 * number_of_scales, )], ()))\n",
    "        for scale in range(1, number_of_scales + 1):\n",
    "            haar_filter = 2**(-scale) * numpy.ones((2**scale, 2**scale))\n",
    "            haar_filter[:haar_filter.shape[0] // 2, :] = -haar_filter[:haar_filter.shape[0] // 2, :]\n",
    "            coefficients[:, :, scale - 1] = convolve2d(image, haar_filter, mode = \"same\")\n",
    "            coefficients[:, :, scale + number_of_scales - 1] = convolve2d(image, numpy.transpose(haar_filter), mode = \"same\")\n",
    "\n",
    "    elif is_tensorflow(image):\n",
    "\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "        coefficients = [None] * (2 * number_of_scales)\n",
    "        for scale in range(1, number_of_scales + 1):\n",
    "            upper_part = -2**(-scale) * tf.ones((2**scale // 2, 2**scale))\n",
    "            lower_part = 2**(-scale) * tf.ones((2**scale // 2, 2**scale))\n",
    "            haar_filter = tf.concat([upper_part, lower_part], axis = 0)\n",
    "            coefficients[scale - 1] = convolve2d(image, haar_filter, mode = \"same\")\n",
    "            coefficients[scale + number_of_scales - 1] = convolve2d(image, tf.transpose(haar_filter), mode = \"same\")\n",
    "        coefficients = tf.stack(coefficients, axis = -1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"The image is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "    return coefficients\n",
    "\n",
    "def sigmoid(value, alpha):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid (logistic) function to the specified value.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value: int | float | numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The value to which the sigmoid function is to be applied.\n",
    "        alpha: float\n",
    "            The steepness of the \"S\"-shaped curve produced by the sigmoid function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        int | float | numpy.ndarray | tensorflow.Tensor: Returns the result of the sigmoid function.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(value):\n",
    "        return 1.0 / (1.0 + numpy.exp(-alpha * value))\n",
    "    elif is_tensorflow(value):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        return 1.0 / (1.0 + tf.exp(-alpha * value))\n",
    "    else:\n",
    "        raise ValueError(\"The value is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "def logit(value, alpha):\n",
    "    \"\"\"\n",
    "    Applies the logit function to the specified value, which is the reverse of the sigmoid\n",
    "    (logistic) function.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value: int | float | numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The value to which the logit function is to be applied.\n",
    "        alpha: float\n",
    "            The steepness of the \"S\"-shaped curve produced by the logit function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        int | float | tensorflow.Tensor: Returns the result of the logit function.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(value):\n",
    "        return numpy.log(value / (1 - value)) / alpha\n",
    "    elif is_tensorflow(value):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        return tf.log(value / (1 - value)) / alpha\n",
    "    else:\n",
    "        raise ValueError(\"The value is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "def is_numpy(value):\n",
    "    \"\"\"\n",
    "    Determines whether the specified value is a NumPy value, i.e. an numpy.ndarray or a NumPy scalar, etc.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value:\n",
    "            The value for which is to be determined if it is a NumPy value or not.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        boolean: Returns True if the value is a NumPy value and False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    return type(value).__module__.split(\".\")[0] == \"numpy\"\n",
    "\n",
    "def is_tensorflow(value):\n",
    "    \"\"\"\n",
    "    Determines whether the specified value is a TensorFlow value, i.e. an tensorflow.Variable or a\n",
    "    tensorflow.Tensor, etc.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value:\n",
    "            The value for which is to be determined if it is a TensorFlow value or not.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        boolean: Returns True if the value is a TensorFlow value and False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    if not is_tensorflow_available:\n",
    "        raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "    return type(value).__module__.split(\".\")[0] == \"tensorflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     2,
     32,
     91,
     138,
     143,
     172
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# File Reading Code\n",
    "\n",
    "def get_duke_proj(index, lesion):\n",
    "    if lesion:\n",
    "        a       = sio.loadmat(\"/media/dril/My Passport/CHO-DATA/WITH-LESION-MAT/LE/\"+str(index)+\".mat\")[\"head\"]\n",
    "    else:\n",
    "        a       = sio.loadmat(\"/media/dril/My Passport/CHO-DATA/NO-LESION-MAT/LE/\"+str(index)+\".mat\")[\"head\"]\n",
    "    testvol = np.rollaxis(a, 2, 0)\n",
    "    testvol = np.moveaxis(testvol, [0, 1, 2], [0, 2, 1])\n",
    "    \n",
    "    testvol[testvol == 0.80] = 0.81\n",
    "    print(np.unique(testvol.flatten()))\n",
    "    \n",
    "    testvol = testvol/65\n",
    "    proj_arr         = W*testvol\n",
    "    \n",
    "    # All Flags\n",
    "    insert_noise     = 1\n",
    "    if insert_noise:\n",
    "        I0        = 1000\n",
    "        proj      = I0*np.exp(-proj_arr)\n",
    "        proj_noi  = np.random.poisson(proj)\n",
    "        proj_noi[proj_noi == 0] = 1\n",
    "        g_noi                   = np.log(I0) - np.log(proj_noi) # convert back to line integrals \n",
    "        g_noi[g_noi < 0]        = 0\n",
    "        proj_arr = g_noi\n",
    "    \n",
    "    temp_proj = np.reshape(proj_arr, [detCols, num_angles, detRows])\n",
    "    temp_proj = np.rollaxis(temp_proj, 0, 2)\n",
    "    #print(temp_proj.shape)\n",
    "    return temp_proj\n",
    "\n",
    "def load_prj_raw(breast_type):\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    print(BINSx*BINSy, ANGLES, prj_allangle.shape)\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    start_angle = -21.30\n",
    "    \n",
    "    proj_paths = glob.glob(\"/media/dril/Windows/mcgpu1/projections_without_fsm\"+projection_name+\"/*.raw\")\n",
    "    proj_paths.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "    \n",
    "    for p in proj_paths:\n",
    "        print(p)\n",
    "        \n",
    "        if '.0000.' in p:\n",
    "            continue\n",
    "        \n",
    "        a    = np.fromfile(p, dtype='float32')#pydicom.dcmread(p)\n",
    "        a    = np.reshape(a, [2, 1504, 3000])\n",
    "        temp = a[0, :, :]#.pixel_array.T\n",
    "        temp = np.log(10000000)-np.log(temp)\n",
    "        \n",
    "        if(0):\n",
    "            # Sharpening filter\n",
    "            temp = unsharp_mask(temp, radius=3, amount=1, preserve_range=True)\n",
    "            thresh_min      = threshold_minimum(temp)\n",
    "            binary_adaptive = temp > thresh_min\n",
    "            temp = np.multiply(temp, binary_adaptive)\n",
    "            \n",
    "        if breast_type == \"right\":\n",
    "            temp = np.fliplr(temp)\n",
    "            temp = temp[-BINSy:]\n",
    "        else:\n",
    "            temp = temp[:BINSy]\n",
    "            temp = np.flipud(temp)\n",
    "            print(temp.shape)\n",
    "        \n",
    "        temp = temp.flatten()\n",
    "        temp = x_y_flip(temp)\n",
    "        \n",
    "        x.append(temp)\n",
    "        y.append(start_angle)\n",
    "        start_angle = start_angle + 1.92\n",
    "    \n",
    "    y = np.array(y)*np.pi/180\n",
    "    \n",
    "    print(\"length x \", len(x), \" \", len(y))\n",
    "    y, x = zip(*sorted(zip(y, x)))\n",
    "    for j in range(len(x)):\n",
    "        print(\"Proj \", j)\n",
    "        flag2 = j\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = x[j][i]\n",
    "    \n",
    "    return prj_allangle, y\n",
    "\n",
    "def load_prj_ima(breast_type):\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    print(BINSx*BINSy, ANGLES, prj_allangle.shape)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    proj_paths = glob.glob(\"/media/dril/ubuntudata/DBT_recon_data/\"+projection_name+\"/CE*.IMA\")\n",
    "    for p in proj_paths:\n",
    "        if '.0000.' in p:\n",
    "            continue\n",
    "        \n",
    "        a    = pydicom.dcmread(p)\n",
    "        temp = a.pixel_array.T\n",
    "        temp = np.log(10000)-np.log(temp)\n",
    "        # Sharpening filter\n",
    "        temp = unsharp_mask(temp, radius=3, amount=1, preserve_range=True)\n",
    "        thresh_min      = threshold_minimum(temp)\n",
    "        binary_adaptive = temp > thresh_min\n",
    "        temp = np.multiply(temp, binary_adaptive)\n",
    "            \n",
    "        if breast_type == \"right\":\n",
    "            temp = np.fliplr(temp)\n",
    "            temp = temp[-BINSy:]\n",
    "        else:\n",
    "            temp = temp[:BINSy]\n",
    "            temp = np.flipud(temp)\n",
    "        \n",
    "        temp = temp.flatten()\n",
    "        temp = x_y_flip(temp)\n",
    "        \n",
    "        x.append(temp)\n",
    "        y.append(float(a[0x00181530].value))\n",
    "    y = np.array(y)*np.pi/180\n",
    "    \n",
    "    print(\"length x \", len(x), \" \", len(y))\n",
    "    y, x = zip(*sorted(zip(y, x)))\n",
    "    for j in range(len(x)):\n",
    "        print(\"Proj \", j)\n",
    "        flag2 = j\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = x[j][i]\n",
    "    \n",
    "    return prj_allangle, y\n",
    "\n",
    "def import_param():\n",
    "    for i in range(ANGLES):\n",
    "        index[i] = i\n",
    "    return index\n",
    "\n",
    "def load_prj():\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    \n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    scat_allangle = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    for viewangle in range(ANGLES):\n",
    "        s        = viewangle + 1\n",
    "        filename = basepath + filepath+str(s).zfill(4)#+'.raw'\n",
    "        \n",
    "        with open(filename, 'rb') as f:\n",
    "            primary_plus_scatter  = np.fromfile(f, dtype=np.float32)\n",
    "            host_prj_temp1        = primary_plus_scatter[:b_size]\n",
    "            host_prj_temp2        = primary_plus_scatter[b_size:]\n",
    "        \n",
    "        host_prj_1view_temp = x_y_flip(host_prj_temp1)\n",
    "        host_sct_1view_temp = x_y_flip(host_prj_temp2)\n",
    "        \n",
    "        print(host_prj_1view_temp.shape)\n",
    "        \n",
    "        # all angle together\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = host_prj_1view_temp[i]\n",
    "            scat_allangle[flag2*BINSx*BINSy + i] = host_sct_1view_temp[i]\n",
    "        \n",
    "        flag2 = flag2+1\n",
    "    return prj_allangle, scat_allangle\n",
    "    \n",
    "def load_prj_std(data_type):\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    \n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    #scat_allangle = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    for viewangle in range(ANGLES):\n",
    "        s        = viewangle + 1\n",
    "        \n",
    "        if data_type   == 0:\n",
    "            #filename = basepath + 'OSTR_prelog/'+projection_name+str(s).zfill(4)#+\".raw\"\n",
    "            filename = basepath + 'Projections_Renamed_Seg/'+projection_name+str(s).zfill(4)#+\".raw\"\n",
    "        elif data_type == 1:\n",
    "            filename = basepath + 'OSTR_scatter/'+scatter_name+str(s).zfill(4)#+\".raw\"\n",
    "        else:\n",
    "            filename = basepath + 'OSTR_blank/'+blank_name+str(s).zfill(4)#+\".raw\"\n",
    "        \n",
    "        #print(filename)\n",
    "        with open(filename, 'rb') as f:\n",
    "            #data  = np.load(f)\n",
    "            data  = np.fromfile(f, dtype=np.float32)\n",
    "            # If doign SART\n",
    "            #data  = np.log(10000) - np.log(data)\n",
    "            \n",
    "            #print(data.shape)\n",
    "            #data  = np.reshape(data, (1400, 3584))\n",
    "            #data  = data[:1400, :]\n",
    "            #data  = np.flip(data, 0)\n",
    "            #data  = data.flatten()\n",
    "            #print(data.shape)\n",
    "                #data  = np.fromfile(f, dtype=np.float32)\n",
    "        #np.save(filename+'.npy', data)\n",
    "        proj = x_y_flip(data)\n",
    "        \n",
    "        # all angle together\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = proj[i]\n",
    "        \n",
    "        flag2 = flag2+1\n",
    "    \n",
    "    return prj_allangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All settings\n",
    "# CE18 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE05 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE08 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE11 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE24 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE07 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE14 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE25 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE28 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE03 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE06 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE20 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE12 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE22 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings Hash\n",
    "\n",
    "train_list = ['CE18', 'CE05', 'CE28', 'CE25', 'CE14', 'CE24', 'CE11',  'CE20', 'CE12', 'CE22']\n",
    "x_p0_list  = [-116.25, -116.25, ]\n",
    "\n",
    "# CE18 right\n",
    "# x_p0    = \n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE05 right\n",
    "# x_p0    = \n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE08 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE11 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE24 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE07 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE14 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE25 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE28 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE03 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE06 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE20 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE12 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE22 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings Part for Monte Carlo Data\n",
    "\n",
    "projection_name = \"1\"#\"CE26.3584x1000.\"#\"OSTR_LE.3584x1400.\"\n",
    "\n",
    "IMGSIZx = 2600\n",
    "IMGSIZy = 1200\n",
    "IMGSIZz = 48\n",
    "f_size  = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "\n",
    "BINSx   = 3000#3584\n",
    "#BINSy   = 2816\n",
    "BINSy   = 1500#1600\n",
    "\n",
    "Vsize_x = 0.085\n",
    "Vsize_y = 0.085\n",
    "Vsize_z = 1\n",
    "\n",
    "x_p0    = -IMGSIZx*Vsize_x*0.5#-116.25\n",
    "y_p0    = -IMGSIZy*Vsize_y\n",
    "z_p0    = -30\n",
    "\n",
    "x_d0    = -BINSx*0.085*0.5\n",
    "y_d0    = -BINSy*0.085\n",
    "\n",
    "Bsize_x = 0.085\n",
    "Bsize_y = 0.085\n",
    "b_size  = BINSx*BINSy\n",
    "\n",
    "ANGLES  = 25\n",
    "index   = []\n",
    "angles  = []\n",
    "\n",
    "\n",
    "detectorR = 47.0\n",
    "sourceR   = 608.5\n",
    "sourceY   = 0.0\n",
    "\n",
    "# Tuning Parameters\n",
    "beta  = 1000\n",
    "delta = 0.03\n",
    "#####################\n",
    "\n",
    "iter_num   = 5\n",
    "subset_num = 5\n",
    "\n",
    "IO_Iter = 0\n",
    "method  = 0\n",
    "\n",
    "\n",
    "BACKPRJ_ThreX = 390\n",
    "BACKPRJ_ThreY = 1\n",
    "BACKPRJ_GridX = 1000\n",
    "BACKPRJ_GridY = 48\n",
    "nBatchXdim    = 8\n",
    "\n",
    "nBatchBINSx = 1\n",
    "nBatchBINSy = 1\n",
    "\n",
    "PRJ_ThreX = 15\n",
    "PRJ_ThreY = 15\n",
    "PRJ_GridX = 200\n",
    "PRJ_GridY = 100\n",
    "\n",
    "\n",
    "f_size     = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "all_b_size = ANGLES*BINSx*BINSy\n",
    "sub_b_size = BINSx*BINSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Settings Part for Real Data\n",
    "\n",
    "projection_name = \"CE18\"#\"CE26.3584x1000.\"#\"OSTR_LE.3584x1400.\"\n",
    "\n",
    "IMGSIZx = 2600\n",
    "IMGSIZy = 1200\n",
    "IMGSIZz = 48\n",
    "f_size  = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "\n",
    "BINSx   = 3584\n",
    "#BINSy   = 2816\n",
    "BINSy   = 1600\n",
    "\n",
    "Vsize_x = 0.085\n",
    "Vsize_y = 0.085\n",
    "Vsize_z = 1\n",
    "\n",
    "x_p0    = -116.25\n",
    "y_p0    = -115.1\n",
    "z_p0    = -30.0\n",
    "\n",
    "x_d0    = -152.32\n",
    "y_d0    = -137.7\n",
    "\n",
    "Bsize_x = 0.085\n",
    "Bsize_y = 0.085\n",
    "b_size  = BINSx*BINSy\n",
    "\n",
    "ANGLES  = 25\n",
    "index   = []\n",
    "angles  = []\n",
    "\n",
    "\n",
    "detectorR = 47.0\n",
    "sourceR   = 608.5\n",
    "sourceY   = 0.0\n",
    "\n",
    "# Tuning Parameters\n",
    "beta  = 1000\n",
    "delta = 0.03\n",
    "#####################\n",
    "\n",
    "iter_num   = 5\n",
    "subset_num = 5\n",
    "\n",
    "IO_Iter = 0\n",
    "method  = 0\n",
    "\n",
    "\n",
    "BACKPRJ_ThreX = 390\n",
    "BACKPRJ_ThreY = 1\n",
    "BACKPRJ_GridX = 1000\n",
    "BACKPRJ_GridY = 48\n",
    "nBatchXdim    = 8\n",
    "\n",
    "nBatchBINSx = 1\n",
    "nBatchBINSy = 1\n",
    "\n",
    "PRJ_ThreX = 16\n",
    "PRJ_ThreY = 16\n",
    "PRJ_GridX = 224\n",
    "PRJ_GridY = 100\n",
    "\n",
    "\n",
    "f_size     = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "all_b_size = ANGLES*BINSx*BINSy\n",
    "sub_b_size = BINSx*BINSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code for doing SART Recon\n",
    "#h_angles\n",
    "#host_prj_allangle_backup, h_angles   = load_prj_ima(\"right\")\n",
    "projection_name = \"1\"\n",
    "host_prj_allangle_backup, h_angles   = load_prj_raw(\"left\")\n",
    "h_angles = list(h_angles)\n",
    "\n",
    "h_index   = np.array(list(range(0, 25)))\n",
    "\n",
    "d_angles = cuda.to_device(h_angles)\n",
    "d_index  = cuda.to_device(h_index)\n",
    "\n",
    "angleStart = 0\n",
    "angleEnd   = 25\n",
    "\n",
    "\n",
    "host_prj_allangle   = copy.deepcopy(host_prj_allangle_backup) #load_prj_std(0) # Load prelog  data\n",
    "\n",
    "host_prj_allangle   = regroup_prj(host_prj_allangle)\n",
    "\n",
    "index_tmp = np.zeros(ANGLES)\n",
    "for i in range(0, ANGLES):\n",
    "    index_tmp[i] = h_index[i]\n",
    "\n",
    "flag           = 0\n",
    "ANGLES_per_sub = int(ANGLES/subset_num)\n",
    "h_index        = np.zeros(ANGLES, dtype=int)\n",
    "\n",
    "for i in range(0, subset_num):\n",
    "    for j in range(0, ANGLES_per_sub):\n",
    "        h_index[flag] = index_tmp[j*subset_num+i]\n",
    "        flag          = flag + 1\n",
    "        \n",
    "\n",
    "\n",
    "sub_b_size     = ANGLES_per_sub*b_size\n",
    "\n",
    "print('sub_b_size is ', sub_b_size)\n",
    "print('delta is ',      delta)\n",
    "print(\"Indexes are \",   h_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     42
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recon Loop\n",
    "\n",
    "delta_array      = [0.0005]#[0.0001, 0.0002, 0.0003, 0.0005, 0.0006, 0.0007, 0.001]\n",
    "beta_array       = []\n",
    "beta_array.append(0)\n",
    "# for i in range(6):\n",
    "#     beta_array.append(np.random.uniform(0.11, 0.69))\n",
    "beta_array       = -1*np.around(beta_array, decimals=3)\n",
    "print(\"BETA array\")\n",
    "print(beta_array)\n",
    "\n",
    "#0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0]#[-0.7, -0.5, -0.3, -0.1, 0]\n",
    "lambda_parameter = 0.9\n",
    "\n",
    "for delta in delta_array:\n",
    "    for beta in beta_array:\n",
    "        print(\"Reconstructing \", beta, delta)\n",
    "        \n",
    "        d_line_sub     = cuda.device_array(int(sub_b_size))\n",
    "        d_normprj      = cuda.device_array(int(sub_b_size))\n",
    "\n",
    "        d_index        = cuda.to_device(h_index)\n",
    "\n",
    "        host_est      = np.zeros(f_size, np.float32)\n",
    "        d_est         = cuda.to_device(host_est)\n",
    "\n",
    "        host_prj_est  = np.zeros(f_size, np.float32)\n",
    "        prj_est       = cuda.to_device(host_prj_est)\n",
    "\n",
    "        host_prj_est  = np.zeros(f_size, np.float32)\n",
    "        prj_est       = cuda.to_device(host_prj_est)\n",
    "\n",
    "        d_prior       = np.zeros(f_size, np.float32)\n",
    "        d_prior       = cuda.to_device(d_prior)\n",
    "\n",
    "        d_diff_line_sub = cuda.device_array(int(sub_b_size))\n",
    "        d_normprj_sub   = cuda.device_array(int(sub_b_size))\n",
    "        d_prj_est_sub   = cuda.device_array(int(sub_b_size))\n",
    "        #d_prj_buf_sub   = cuda.device_array(int(sub_b_size))\n",
    "\n",
    "        for i in range(0, 5):\n",
    "            #print(\"Iteration \", i)\n",
    "            for a in range(0, 5):\n",
    "                angleStart = a*ANGLES_per_sub\n",
    "                angleEnd   = (a+1)*ANGLES_per_sub\n",
    "\n",
    "                host_prj_sub  = temp_fun1(angleStart, b_size, sub_b_size, host_prj_allangle)\n",
    "                d_prj_buf_sub = cuda.to_device(host_prj_sub)\n",
    "\n",
    "                d_prior       = np.zeros(f_size, np.float32)\n",
    "                d_prior       = cuda.to_device(d_prior)\n",
    "\n",
    "                prior_GPU_SART(d_prior, d_est, delta)\n",
    "\n",
    "                fprojectCB_1R_GPU_SART_cos(\n",
    "                    d_est,\n",
    "                    d_prj_est_sub,\n",
    "                    d_normprj_sub,\n",
    "                    d_angles,\n",
    "                    d_index,\n",
    "                    angleStart,\n",
    "                    angleEnd)\n",
    "\n",
    "                #d_normprj_sub\n",
    "                h_diff_line_sub  = d_diff_line_sub.copy_to_host()\n",
    "                h_normprj_sub    = d_normprj_sub.copy_to_host()\n",
    "                h_prj_est_sub    = d_prj_est_sub.copy_to_host()\n",
    "\n",
    "                #h_normprj_sub[h_normprj_sub  < 0.5] = 10000\n",
    "\n",
    "                result_diff = SART_prj_diff(h_diff_line_sub,\n",
    "                    host_prj_sub,\n",
    "                    h_prj_est_sub,\n",
    "                    h_normprj_sub,\n",
    "                    h_index,\n",
    "                    angleStart,\n",
    "                    angleEnd)\n",
    "\n",
    "                #result_diff[result_diff > 0.5] = 0\n",
    "                #result_diff[result_diff > 100] = 0\n",
    "                #result_diff = np.nan_to_num(np.divide(host_prj_sub - h_prj_est_sub, h_normprj_sub))\n",
    "\n",
    "                d_diff_line_sub = cuda.to_device(result_diff)\n",
    "\n",
    "                bprojectCB_4B_GPU_R_SART (d_est, d_diff_line_sub, d_prior,\n",
    "                                          d_index,\n",
    "                                          d_angles,\n",
    "                                          angleStart,\n",
    "                                          angleEnd,\n",
    "                                          lambda_parameter, beta)\n",
    "\n",
    "                d_prj_est_sub = np.zeros(d_prj_est_sub.shape)\n",
    "                d_prj_est_sub = cuda.to_device(d_prj_est_sub)\n",
    "\n",
    "                d_normprj_sub = np.zeros(d_normprj_sub.shape)\n",
    "                d_normprj_sub = cuda.to_device(d_normprj_sub)\n",
    "\n",
    "                d_prj_buf_sub = np.zeros(d_prj_buf_sub.shape)\n",
    "                d_prj_buf_sub = cuda.to_device(d_prj_buf_sub)\n",
    "                \n",
    "        host_est = d_est.copy_to_host()\n",
    "        host_est.astype('float32').tofile('/media/dril/My Passport/'+projection_name+'_'+str(IMGSIZx)+'x'+str(IMGSIZy)+'x'+str(IMGSIZz)+'.'+str(i)+'_'+str(delta)+'_'+str(beta)+'.raw')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     55,
     161,
     261,
     371,
     479,
     584,
     686,
     727,
     754
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [STAR] CNN Models\n",
    "\n",
    "def rating_cnn(input_size = (256, 256, 1)):\n",
    "    filter1 = 4\n",
    "    filter2 = 4\n",
    "    filter3 = 4\n",
    "    filter4 = 4\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same',kernel_initializer = 'glorot_normal')(input1)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #conv1 = Dropout(0.2)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filter3, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #conv3 = Dropout(0.2)(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(filter4, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    out1 = Flatten()(conv4)\n",
    "    #out1 = Dropout(0.3)(out1)\n",
    "    \n",
    "    #out2 = Dense(64, kernel_initializer = 'glorot_normal')(out1)\n",
    "    #out2 = LeakyReLU()(out2)\n",
    "    #out2 = Dropout(0.3)(out2)\n",
    "    \n",
    "    #out3 = Dense(32,  kernel_initializer = 'glorot_normal')(out2)\n",
    "    #out3 = LeakyReLU()(out3)\n",
    "    \n",
    "    out3 = Dense(1, activation=\"sigmoid\")(out1)\n",
    "    \n",
    "    model  = Model(input = input1, output = out3)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def unet_double(pretrained_weights = None, input_size = (128, 128, 5), ):\n",
    "    filter1 = 64\n",
    "    filter2 = 128\n",
    "    filter3 = 256\n",
    "    filter4 = 512\n",
    "    filter5 = 1024\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    input3 = Input((1, ))\n",
    "    \n",
    "    hash_val1 = Dense(128, activation='relu')(input2)\n",
    "    hash_val1 = Dense(1, activation='relu')(hash_val1)\n",
    "    \n",
    "    hash_val2 = Dense(128, activation='relu')(input3)\n",
    "    hash_val2 = Dense(1, activation='relu')(hash_val2)\n",
    "    \n",
    "    hash_val = Multiply()([hash_val1, hash_val2])\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(hash_val)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2, input3], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_vanilla(pretrained_weights = None, input_size = (128, 128, 1), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    #input2 = Input((1, ))\n",
    "    \n",
    "    #hash_val = Dense(128, activation='relu')(input2)\n",
    "    #hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    #hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    #input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    #conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    #conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    #conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.1)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    #pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.1)(conv5)\n",
    "    #drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    #conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    #conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    #conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = input1, output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_two(pretrained_weights = None, input_size = (128, 128, 1), ):\n",
    "    filter1 = 64\n",
    "    filter2 = 128\n",
    "    filter3 = 256\n",
    "    filter4 = 512\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(input2)\n",
    "    hash_val = Dropout(0.3)(hash_val)\n",
    "    hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    hash_val1 = Dense(128, activation='relu')(input2)\n",
    "    hash_val1 = Dropout(0.3)(hash_val1)\n",
    "    hash_val1 = Dense(32, activation='relu')(hash_val1)\n",
    "    hash_val1 = Dense(1, activation='relu')(hash_val1)\n",
    "    \n",
    "    input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Dropout(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val1, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Dropout(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val1, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Dropout(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val1, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet(pretrained_weights = None, input_size = (256, 256, 1), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(input2)\n",
    "    hash_val = Dropout(0.3)(hash_val)\n",
    "    hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4, up6], axis = 3)\n",
    "    \n",
    "    \n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Dropout(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Dropout(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Dropout(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_no_dense(pretrained_weights = None, input_size = (256, 256, 1), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    \n",
    "    #hash_val = Dense(128, activation='relu')(input2)\n",
    "    #hash_val = Dropout(0.3)(hash_val)\n",
    "    #hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    hash_val = input2#Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Dropout(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Dropout(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Dropout(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_lstm(pretrained_weights = None, input_size = (128, 128, 2), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    single_input = Input(input_size)\n",
    "    \n",
    "    input1 = Lambda(lambda x: x[:, :, :, 0])(single_input)\n",
    "    input1 = Reshape([128, 128, 1])(input1)\n",
    "    \n",
    "    input2 = Lambda(lambda x: x[:, :, :, 1])(single_input)\n",
    "    input2 = Flatten()(input2)\n",
    "    input2 = Reshape([1, 128*128])(input2) \n",
    "    input2 = Lambda(lambda x: x[:, :, 0])(input2)\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(input2)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "        \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #conv10 = Subtract()([input1, conv9])\n",
    "    \n",
    "    model  = Model(input = single_input, output = conv9)\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def lstm_model():\n",
    "    input_size = (5, 128, 128, 1)\n",
    "    \n",
    "    input1     = Input(input_size)\n",
    "    input2     = Input((1, ))\n",
    "    \n",
    "    cnn_model  = unet()\n",
    "    \n",
    "    #time2       = TimeDistributed(cnn_model)(input1)\n",
    "    \n",
    "    lstm_out1   = ConvLSTM2D(filters=32, kernel_size=(3, 3), input_shape=(5, 128, 128, 1),\n",
    "                             padding='same', activation=LeakyReLU(alpha=0.2), return_sequences=True)(input1)\n",
    "    \n",
    "    lstm_out2   = ConvLSTM2D(filters=1, kernel_size=(3, 3), padding='same', activation=LeakyReLU(alpha=0.2),\n",
    "                            return_sequences=False)(lstm_out1)\n",
    "    \n",
    "    input_one = Lambda(lambda x: x[:, 4, :, :, :])(input1)\n",
    "    input_one = Reshape([128, 128, 1])(input_one)\n",
    "    \n",
    "    cnn_out1   = cnn_model([lstm_out2, input2])\n",
    "    \n",
    "    final_out = Subtract()([input_one, cnn_out1])\n",
    "    #lstm_out1   = ConvLSTM2D(filters=40, kernel_size=(3, 3), input_shape=(5, 128, 128, 1),\n",
    "    #                         padding='same', activation=LeakyReLU(alpha=0.2), return_sequences=True)(lstm_out1)\n",
    "    #lstm_out1   = ConvLSTM2D(filters=40, kernel_size=(3, 3), input_shape=(5, 128, 128, 1),\n",
    "    #                         padding='same', activation=LeakyReLU(alpha=0.2), return_sequences=True)(lstm_out1)\n",
    "    #lstm_out2   = ConvLSTM2D(filters=1, kernel_size=(3, 3), padding='same', activation=LeakyReLU(alpha=0.2),\n",
    "    #                         return_sequences=False)(lstm_out1)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, 4, :, :, 0])(input1)\n",
    "    #input_last  = Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    #conv10      = Subtract()([input1, lstm_out2])\n",
    "    \n",
    "    time_model  = Model(input = [input1, input2], output = final_out)\n",
    "    time_model.compile(optimizer = Adam(lr = 1e-4), \n",
    "                  loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    \n",
    "    return time_model\n",
    "\n",
    "def conv_lstm_model():\n",
    "    seq = Sequential()\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                       input_shape=(5, 128, 128, 1),\n",
    "                       padding='same', return_sequences=True))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=True))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=True))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=1, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=False))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "    #               activation='sigmoid',\n",
    "    #               padding='same', data_format='channels_last'))\n",
    "    \n",
    "    seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def unet_combined(pretrained_weights = None, input_size = (128, 128, 1)):\n",
    "    base_model  = unet()\n",
    "    base_model.load_weights(\"all-data-0-to-7-0.0005-5.h5\")\n",
    "\n",
    "    filter1 = 32\n",
    "    filter2 = 32\n",
    "    filter3 = 32\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input(input_size)\n",
    "    \n",
    "    input1_1 = Input((1, ))\n",
    "    input1_2 = Input((1, ))\n",
    "    input1_3 = Input((1, ))\n",
    "    input1_4 = Input((1, ))\n",
    "    input1_5 = Input((1, ))\n",
    "    input1_6 = Input((1, ))\n",
    "    input1_7 = Input((1, ))\n",
    "    \n",
    "    for t in base_model.layers:\n",
    "        t.trainable = False\n",
    "    \n",
    "    w1    = Concatenate()([input1, input2])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(w1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter3, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    \n",
    "    layer_output = base_model.layers[-4].output\n",
    "    \n",
    "    new_model    = Model(base_model.input, layer_output)\n",
    "    \n",
    "    r1 = new_model([input1, input1_1])\n",
    "    r2 = new_model([input1, input1_2])\n",
    "    r3 = new_model([input1, input1_3])\n",
    "    r4 = new_model([input1, input1_4])\n",
    "    r5 = new_model([input1, input1_5])\n",
    "    r6 = new_model([input1, input1_6])\n",
    "    r7 = new_model([input1, input1_7])\n",
    "    \n",
    "#     c1 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 0])(conv1))\n",
    "#     c2 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 1])(conv1))\n",
    "#     c3 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 2])(conv1))\n",
    "#     c4 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 3])(conv1))\n",
    "#     c5 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 4])(conv1))\n",
    "#     c6 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 5])(conv1))\n",
    "#     c7 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 6])(conv1))\n",
    "    \n",
    "    \n",
    "#     q1 = Multiply()([conv1, r1])\n",
    "#     q2 = Multiply()([conv1, r2])\n",
    "#     q3 = Multiply()([conv1, r3])\n",
    "#     q4 = Multiply()([conv1, r4])\n",
    "#     q5 = Multiply()([conv1, r5])\n",
    "#     q6 = Multiply()([conv1, r6])\n",
    "#     q7 = Multiply()([conv1, r7])\n",
    "    \n",
    "    #ut   = Add()([q1, q2, q3, q4, q5, q6, q7])\n",
    "    #ut   = Add()([c1, c2, c3, c4, c5, c6, c7])\n",
    "    out   = Add()([r1, r2, r3, r4, r5, r6, r7])\n",
    "    out   = Multiply()([conv1, out])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    out   = LeakyReLU(0.2)(conv1)\n",
    "    \n",
    "    #conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    model1  = Model(input = [input1, input2, input1_1, input1_2, input1_3, input1_4, input1_5, input1_6, input1_7], output = out)\n",
    "    \n",
    "    model1.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    return model1\n",
    "\n",
    "m = rating_cnn()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to check the files created after the Reconstruction\n",
    "\n",
    "train_list = ['CE18', 'CE28', 'CE14', 'CE25', 'CE24', 'CE11', 'CE05', 'CE20', 'CE12', 'CE22'] # Add this later: 'CE25'\n",
    "test_list  = ['CE03', 'CE07' 'CE18', 'CE27', 'CE17']\n",
    "\n",
    "x_array = []\n",
    "y_array = []\n",
    "z_array = []\n",
    "\n",
    "sample_per_volume = 100\n",
    "valid_vals        = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for name in train_list[:-3]:\n",
    "    p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR-RANDOM/\"+name+\"*.4_\"+str(0.0005)+\"*.raw\")\n",
    "    p.sort()\n",
    "    print(\"*****************************************\")\n",
    "    print(name)\n",
    "    for t in p:\n",
    "        val = float(t.split('-')[-1][:-4])\n",
    "        if val not in valid_vals:\n",
    "            print(t, val)\n",
    "        #print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading the Training Data for Baseline U-Net Model with Multiple Volumes\n",
    "\n",
    "train_list = ['CE18', 'CE28', 'CE14', 'CE25', 'CE24', 'CE11', 'CE05', 'CE20', 'CE12', 'CE22'] # Add this later: 'CE25'\n",
    "test_list  = ['CE03', 'CE07' 'CE18', 'CE27', 'CE17']\n",
    "\n",
    "\n",
    "valid_vals        = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "sample_per_volume = 20\n",
    "\n",
    "\n",
    "\n",
    "for name in train_list:#train_list[-3:]:\n",
    "    p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR-RANDOM/\"+name+\"*.4_\"+str(0.0005)+\"*.raw\")\n",
    "    p.sort()\n",
    "    \n",
    "    x1_array = []\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    z_array = []\n",
    "\n",
    "    y_vol_array = np.zeros([len(p)-1, 48, 1200, 2600], dtype='float16')\n",
    "    \n",
    "    print(\"NAME \", name, len(p))\n",
    "    print(\"*****************************************\")\n",
    "    #print(name)\n",
    "    for t in p:\n",
    "        print(t)\n",
    "    \n",
    "    x = np.fromfile(p[0], dtype='float32')\n",
    "    x = np.reshape(x, [48, 1200, 2600])\n",
    "    x = x.astype('float16')\n",
    "    \n",
    "    print(p[0])\n",
    "    print(p[0].replace(\".4_\", \".0_\"),)\n",
    "    \n",
    "    x1 = np.fromfile(p[0].replace(\".4_\", \".0_\"), dtype='float32')\n",
    "    x1 = np.reshape(x1, [48, 1200, 2600])\n",
    "    x1 = x1.astype('float16')\n",
    "    \n",
    "    val_list    = []\n",
    "    \n",
    "    count = 0\n",
    "    for t in p[1:]:\n",
    "        val = float(t.split('-')[-1][:-4])\n",
    "        if val < 0.5:#val not in valid_vals:\n",
    "            y = np.fromfile(t, dtype='float32')\n",
    "            y = np.reshape(y, [48, 1200, 2600])\n",
    "            y = y.astype('float16')\n",
    "            y_vol_array[count, :, :, :] = y\n",
    "            val_list.append(float(t.split('-')[-1][:-4]))\n",
    "            count = count+1\n",
    "            print(t, float(t.split('-')[-1][:-4]))\n",
    "    \n",
    "    count = 0\n",
    "    while(True):\n",
    "        ix = np.random.randint(128, 1200-128)\n",
    "        iy = np.random.randint(128, 1200-128)\n",
    "        iz = np.random.randint(0, 48)\n",
    "        \n",
    "        tempx = x[iz, ix:ix+128, iy:iy+128]\n",
    "        \n",
    "        if np.count_nonzero(tempx.flatten())*1.0/(128*128) < 0.9:\n",
    "            continue\n",
    "        \n",
    "        #val_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        \n",
    "        for j in range(len(val_list)):\n",
    "            x_array.append(tempx)\n",
    "            tempy = y_vol_array[j, iz, ix:ix+128, iy:iy+128]\n",
    "            y_array.append(tempy)\n",
    "            z_array.append(val_list[j])\n",
    "        \n",
    "        count = count+1\n",
    "        if count == sample_per_volume:\n",
    "            break\n",
    "\n",
    "    x_array = np.expand_dims(x_array, axis=-1)\n",
    "    y_array = np.expand_dims(y_array, axis=-1)\n",
    "    z_array = np.expand_dims(z_array, axis=-1)\n",
    "    \n",
    "    print(x_array.shape, y_array.shape, z_array.shape)\n",
    "    \n",
    "    np.save('x_array_random-'+name+'-2-one-iter.npy', x_array)\n",
    "    np.save('y_array_random-'+name+'-2-one-iter.npy', y_array)\n",
    "    np.save('z_array_random-'+name+'-2-one-iter.npy', z_array)\n",
    "\n",
    "#     np.save('x_array_random-'+name+'-valid.npy', x_array)\n",
    "#     np.save('y_array_random-'+name+'-valid.npy', y_array)\n",
    "#     np.save('z_array_random-'+name+'-valid.npy', z_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading data from numpy array\n",
    "\n",
    "train_list = ['CE18', 'CE28', 'CE14', 'CE25', 'CE24', 'CE11', 'CE05', 'CE20', 'CE12', 'CE22'] # Add this later: 'CE25'\n",
    "test_list  = ['CE03', 'CE07' 'CE18', 'CE27', 'CE17']\n",
    "\n",
    "x_array = np.zeros([14560, 128, 128, 1], dtype='float16')\n",
    "y_array = np.zeros([14560, 128, 128, 1], dtype='float16')\n",
    "z_array = np.zeros([14560, 1], dtype='float16')\n",
    "\n",
    "x_val_array = np.zeros([7000, 128, 128, 1], dtype='float16')\n",
    "y_val_array = np.zeros([7000, 128, 128, 1], dtype='float16')\n",
    "z_val_array = np.zeros([7000, 1], dtype='float16')\n",
    "\n",
    "# x_array = np.zeros([6750, 128, 128, 1], dtype='float16')\n",
    "# y_array = np.zeros([6750, 128, 128, 1], dtype='float16')\n",
    "# z_array = np.zeros([6750, 1], dtype='float16')\n",
    "\n",
    "# x_val_array = np.zeros([3875, 128, 128, 1], dtype='float16')\n",
    "# y_val_array = np.zeros([3875, 128, 128, 1], dtype='float16')\n",
    "# z_val_array = np.zeros([3875, 1], dtype='float16')\n",
    "\n",
    "# x_array = np.zeros([175*7, 128, 128, 1], dtype='float16')\n",
    "# y_array = np.zeros([175*7, 128, 128, 1], dtype='float16')\n",
    "# z_array = np.zeros([175*7, 1], dtype='float16')\n",
    "\n",
    "# x_val_array = np.zeros([175*3, 128, 128, 1], dtype='float16')\n",
    "# y_val_array = np.zeros([175*3, 128, 128, 1], dtype='float16')\n",
    "# z_val_array = np.zeros([175*3, 1], dtype='float16')\n",
    "\n",
    "\n",
    "total_count = 0\n",
    "for name in train_list[:-3]:\n",
    "    a = np.load('x_array_random-'+name+'-2.npy')\n",
    "    x_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('y_array_random-'+name+'-2.npy')\n",
    "    y_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('z_array_random-'+name+'-2.npy')\n",
    "    z_array[total_count:total_count+a.shape[0],  :]     = a\n",
    "    \n",
    "    total_count = total_count + a.shape[0]\n",
    "print(total_count)\n",
    "\n",
    "total_count = 0\n",
    "for name in train_list[-3:]:\n",
    "    a = np.load('x_array_random-'+name+'-2.npy')\n",
    "    x_val_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('y_array_random-'+name+'-2.npy')\n",
    "    y_val_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('z_array_random-'+name+'-2.npy')\n",
    "    z_val_array[total_count:total_count+a.shape[0],  :]     = a\n",
    "    \n",
    "    total_count = total_count + a.shape[0]\n",
    "\n",
    "\n",
    "x_array1 = np.zeros([9720, 128, 128, 1], dtype='float16')\n",
    "y_array1 = np.zeros([9720, 128, 128, 1], dtype='float16')\n",
    "z_array1 = np.zeros([9720, 1], dtype='float16')\n",
    "\n",
    "x_val_array1 = np.zeros([4380, 128, 128, 1], dtype='float16')\n",
    "y_val_array1 = np.zeros([4380, 128, 128, 1], dtype='float16')\n",
    "z_val_array1 = np.zeros([4380, 1], dtype='float16')\n",
    "\n",
    "\n",
    "xi = 0\n",
    "for i in range(len(x_array)):\n",
    "    if z_array[i] <= 0.5:\n",
    "        x_array1[xi, :, :, 0] = x_array[i, :, :, 0]\n",
    "        y_array1[xi, :, :, 0] = y_array[i, :, :, 0]\n",
    "        z_array1[xi,  0]      = z_array[i, 0]\n",
    "        xi = xi+1\n",
    "\n",
    "xi = 0\n",
    "for i in range(len(x_val_array)):\n",
    "    if z_val_array[i] <= 0.5:\n",
    "        x_val_array1[xi, :, :, 0] = x_val_array[i, :, :, 0]\n",
    "        y_val_array1[xi, :, :, 0] = y_val_array[i, :, :, 0]\n",
    "        z_val_array1[xi,  0]      = z_val_array[i,  0]\n",
    "        xi = xi+1\n",
    "\n",
    "x_array = x_array1\n",
    "y_array = y_array1\n",
    "z_array = z_array1\n",
    "\n",
    "x_val_array = x_val_array1\n",
    "y_val_array = y_val_array1\n",
    "z_val_array = z_val_array1\n",
    "\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Astra Projection Code\n",
    "\n",
    "import astra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import time\n",
    "import pydicom\n",
    "import glob\n",
    "from numba import jit\n",
    "from skimage import filters\n",
    "import copy\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "\n",
    "scaling_factor = 1\n",
    "voxel_size = 0.02\n",
    "SOD       = 65/(voxel_size*scaling_factor)\n",
    "ODD       = 4.5/(voxel_size*scaling_factor)\n",
    "detWidth  = 0.0085/(voxel_size/scaling_factor)   # size of each detector pixel\n",
    "detHeight = detWidth                             # size of each detector pixel\n",
    "detRows   = 3000\n",
    "detCols   = 1504\n",
    "num_angles = 25\n",
    "\n",
    "a       = sio.loadmat(\"/media/dril/My Passport/CHO-DATA/NO-LESION-MAT/LE/\"+str(1)+\".mat\")[\"head\"]\n",
    "testvol = np.rollaxis(a, 2, 0)\n",
    "testvol = np.moveaxis(testvol, [0, 1, 2], [0, 2, 1])\n",
    "\n",
    "vol_geom = astra.create_vol_geom(int(testvol.shape[1]), int(testvol.shape[2]), int(testvol.shape[0]))\n",
    "proj_arr = np.zeros((num_angles, detCols, detRows), dtype='float16')\n",
    "testones = np.ones([int(testvol.shape[0]), int(testvol.shape[1]), int(testvol.shape[2])],  dtype='uint8')\n",
    "estimate = np.zeros([int(testvol.shape[0]), int(testvol.shape[1]), int(testvol.shape[2])], dtype='float16')\n",
    "\n",
    "# Get simulation angles\n",
    "start_angle = -21\n",
    "theta       = []\n",
    "for i in range(num_angles):\n",
    "    theta.append(start_angle*np.pi/180.0)\n",
    "    start_angle = start_angle+1.98\n",
    "\n",
    "vectors = np.zeros((len(theta), 12))\n",
    "\n",
    "# For reconstructing real data\n",
    "vectors[:, 0:3]  = np.transpose(np.array([np.sin(theta), np.zeros(len(theta)), np.cos(theta)])) * SOD        # S source to object\n",
    "vectors[:,3:6]   = np.transpose(np.array([np.zeros(len(theta)), np.zeros(len(theta)),  -np.ones(len(theta))*ODD]))             # D object to detector\n",
    "vectors[:,6:9]   = np.transpose(np.array([np.ones(len(theta))*detWidth, np.zeros(len(theta)), np.zeros(len(theta))]))         # U\n",
    "vectors[:,9:12]  = np.transpose(np.array([np.zeros(len(theta)), np.ones(len(theta))*detWidth, np.zeros(len(theta))]))        # V\n",
    "# Creating the projection matrix\n",
    "proj_geom        = astra.create_proj_geom('cone_vec', detCols, detRows, vectors)\n",
    "proj_id          = astra.create_projector('cuda3d',   proj_geom, vol_geom)\n",
    "W                = astra.OpTomo(proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     17,
     50
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert lesion loop\n",
    "\n",
    "#train_lesions = np.load(\"/home/pranjal/VICTRE/victre_breastmass/breastMass/train_lesions.npy\")\n",
    "#train_lesions_array = []\n",
    "\n",
    "# for name in train_lesions:\n",
    "#     temp = np.fromfile(name, dtype='uint8')\n",
    "#     t    = int(name.split(\"_\")[-1].split(\".\")[0])\n",
    "#     temp = np.reshape(temp, [t, t, t])\n",
    "#     train_lesions_array.append(temp)\n",
    "train_lesions_array = []\n",
    "train_lesions_array.append(mask)\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/My Passport/CHO-DATA/NO-LESION-MAT/LE/*.mat\")\n",
    "print(len(allfiles))\n",
    "allfiles.sort()\n",
    "\n",
    "def insert_lesion(image, z_slice, index):\n",
    "    coord = []\n",
    "    count = 0\n",
    "    #index = random.randint(0, len(train_lesions)-1)\n",
    "    \n",
    "    while(count < 4):\n",
    "        k     = count\n",
    "        temp  = train_lesions_array[index]\n",
    "        \n",
    "        tx    = int(temp.shape[0]/2)\n",
    "        temp1 = image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 100-tx:100+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx]\n",
    "        \n",
    "        temp1[temp == 1] = 0.80\n",
    "        image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 100-tx:100+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx] = temp1\n",
    "        \n",
    "        count = count+1\n",
    "    \n",
    "    count = 0\n",
    "    while(count < 4):\n",
    "        k     = count\n",
    "        temp  = train_lesions_array[index]\n",
    "        \n",
    "        tx    = int(temp.shape[0]/2)\n",
    "        temp1 = image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 220-tx:220+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx]\n",
    "        \n",
    "        temp1[temp == 1] = 0.80\n",
    "        image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 220-tx:220+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx] = temp1\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "    return image\n",
    "\n",
    "index = 0\n",
    "for f in allfiles:\n",
    "    data    = sio.loadmat(f)[\"head\"]\n",
    "    print(data.shape, f)\n",
    "    #tx = int(f.split(\"/\")[-1].split(\"_\")[1].split(\"x\")[0])\n",
    "    #ty = int(f.split(\"/\")[-1].split(\"_\")[1].split(\"x\")[1])\n",
    "    #tz = int(f.split(\"/\")[-1].split(\"_\")[1].split(\"x\")[2].split(\".\")[0])\n",
    "    \n",
    "    name = f.split(\"/\")[-1]\n",
    "    \n",
    "    image = data#.reshape([tz, ty, tx])\n",
    "#     index = int(name.split(\"-\")[1].split(\"_\")[0])\n",
    "    #index = index%len(train_lesions)\n",
    "    \n",
    "#     #print(name, index)\n",
    "    \n",
    "#     #if image.shape[0] < 280:\n",
    "#     #    image = insert_lesion(image, 130, index)\n",
    "#     #else:\n",
    "#     image = data\n",
    "    image = insert_lesion(image, 160, index)\n",
    "    #print(image.shape)\n",
    "    #break\n",
    "    \n",
    "    temp = {}\n",
    "    temp[\"head\"] = np.single(image)\n",
    "    sio.savemat(\"/media/dril/My Passport/CHO-DATA/WITH-LESION-MAT/LE/\"+name, temp, do_compression=True)\n",
    "# #     image.tofile(\"/media/pranjal/BackupPlus/CEDBT/CHO-DATA/WITH-LESION-MAT/\"+name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For drawing the Pictures of all samples together\n",
    "\n",
    "index      = 0\n",
    "total_size = 500\n",
    "\n",
    "z_arr  = []\n",
    "drawit = []\n",
    "for i in range(259, 262):#range(index*total_size, total_size*(index+1)):\n",
    "    print(z_val_array[i, 0])\n",
    "    if True:#z_val_array[i, 0] < 0.35 and z_val_array[i, 0] > 0.25:\n",
    "        #print(\"Adding Image\")\n",
    "        drawit.append(np.concatenate([x_val_array[i, :, :, 0], y_val_array[i, :, :, 0]], axis=-1))\n",
    "        z_arr.append(z_val_array[i, 0])\n",
    "\n",
    "drawit = np.array(drawit)\n",
    "drawit = np.reshape(drawit, [-1, 256])\n",
    "print(drawit.shape)\n",
    "\n",
    "plt.figure(figsize=(12800/2000, 256))\n",
    "plt.imshow(drawit.astype('float32'), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128, 1) (1000, 128, 128, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Some garbage code for reading the data\n",
    "\n",
    "x_array = np.load('/media/dril/My Passport/TRAINING-DATA/x_array.npy')\n",
    "y_array = np.load('/media/dril/My Passport/TRAINING-DATA/y_array.npy')\n",
    "z_array = np.load('/media/dril/My Passport/TRAINING-DATA/z_array.npy')\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "z1 = []\n",
    "\n",
    "for i in range(7000):\n",
    "    #if z_array[i, 0] == 0.2 or z_array[i, 0] == 0.4 or z_array[i, 0] == 0.6:#(i+1) % 6 == 0 or i % 6 == 0:\n",
    "    #    continue\n",
    "    if z_array[i, 0] != 0.3:\n",
    "        continue\n",
    "    else:\n",
    "        x1.append(x_array[i, :, :, :])\n",
    "        y1.append(y_array[i, :, :, :])\n",
    "        z1.append(z_array[i, :])\n",
    "\n",
    "x1 = np.array(x1)\n",
    "y1 = np.array(y1)\n",
    "z1 = np.array(z1)\n",
    "\n",
    "print(x1.shape, y1.shape, z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 0.00031360463\n",
      "Test Loss 0.00057295326\n",
      "**********************************\n"
     ]
    }
   ],
   "source": [
    "# Check the loss values\n",
    "\n",
    "check_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "r2 = []\n",
    "y2 = []\n",
    "for i in range(int(len(x1)*0.7)):\n",
    "    r2.append(result_train[i])\n",
    "    y2.append(y1[i])\n",
    "train_loss = np.mean(np.abs(np.array(r2)-np.array(y2)))\n",
    "\n",
    "r2= []\n",
    "y2 = []\n",
    "for i in range(int(len(x1)*0.7), len(x1)):\n",
    "    r2.append(result_train[i])\n",
    "    y2.append(y1[i])\n",
    "test_loss = np.mean(np.abs(np.array(r2)-np.array(y2)))\n",
    "    \n",
    "print(\"Train Loss\", train_loss)\n",
    "print(\"Test Loss\", test_loss)\n",
    "print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the loss values\n",
    "\n",
    "\n",
    "check_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for k in range(7):\n",
    "    check_val = check_values[k]\n",
    "\n",
    "    r1 = []\n",
    "    y1 = []\n",
    "    for i in range(int(len(x_array)*0.7)):\n",
    "        if z_array[i, 0] == check_val:\n",
    "            r1.append(result_train[i])\n",
    "            y1.append(y_array[i])\n",
    "    train_loss = np.mean(np.abs(np.array(r1)-np.array(y1)))\n",
    "\n",
    "    r1 = []\n",
    "    y1 = []\n",
    "    for i in range(int(len(x_array)*0.7), len(x_array)):\n",
    "        if z_array[i, 0] == check_val:\n",
    "            r1.append(result_train[i])\n",
    "            y1.append(y_array[i])\n",
    "    test_loss = np.mean(np.abs(np.array(r1)-np.array(y1)))\n",
    "    \n",
    "    print(\"Check value \", check_values[k])\n",
    "    print(\"Train Loss\", train_loss)\n",
    "    print(\"Test Loss\", test_loss)\n",
    "    print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some signal calculation Code\n",
    "\n",
    ".randint(int(len(x1)*0.1), int(len(x1)*0.4))\n",
    "print(index)\n",
    "print(z_array[index])\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "#print(np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])), np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])))\n",
    "#print(np.mean(np.abs(result_train1[index, :, :, 0]-result_train[index, :, :, 0])), np.mean(np.abs(result_train1[index, :, :, 0]-y1[index, :, :, 0])), np.mean(np.abs(y1[index, :, :, 0]-result_train[index, :, :, 0])))\n",
    "\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()),  ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "y1 = y_val_array\n",
    "x1 = x_val_array\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "index = 261#index = random.randint(int(len(x_array)*0.8), len(x_array)-1)\n",
    "index = random.randint(0, len(x_val_array)-1)\n",
    "#index = random.randint(int(len(x1)*0.1), int(len(x1)*0.4))\n",
    "print(index)\n",
    "print(z_array[index])\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "#print(np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])), np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])))\n",
    "#print(np.mean(np.abs(result_train1[index, :, :, 0]-result_train[index, :, :, 0])), np.mean(np.abs(result_train1[index, :, :, 0]-y1[index, :, :, 0])), np.mean(np.abs(y1[index, :, :, 0]-result_train[index, :, :, 0])))\n",
    "\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()),  ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "y1 = y_val_array\n",
    "x1 = x_val_array\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "#index = 253\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a  = np.asanyarray(a)\n",
    "    m  = np.mean(a)#a.mean(axis)\n",
    "    sd = np.std(a) #a.std(axis=axis, ddof=ddof)\n",
    "    return m/sd#np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "print(ssim(x1[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "print(signaltonoise(result_train[index, :, :, 0]), signaltonoise(x1[index, :, :, 0]), signaltonoise(y1[index, :, :, 0]))\n",
    "print(haar_psi(result_train[index, :, :, 0], y1[index, :, :, 0], preprocess_with_subsampling = True)[0], haar_psi(x1[index, :, :, 0], y1[index, :, :, 0], preprocess_with_subsampling = True)[0])\n",
    "print(np.mean(np.abs(result_train[index, :, :, 0] - y1[index, :, :, 0])), np.mean(np.abs(x1[index, :, :, 0] - y1[index, :, :, 0])))\n",
    "\n",
    "print(np.mean(np.abs(result_train[index, :, :, 0] - y_val_array[index, :, :, 0])), np.mean(np.abs(x_val_array[index, :, :, 0] - y_val_array[index, :, :, 0])))\n",
    "\n",
    "#plt.imshow(np.concatenate([x1[index, :, :, 0], result_train[index, :, :, 0], result_train1[index, :, :, 0], y1[index, :, :, 0]], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([x_array[index, :, :, 0], result_train[index, :, :, 0], y_array[index, :, :, 0]], axis=-1), cmap='gray')\n",
    "plt.imshow(np.concatenate([x_val_array[index, :, :, 0].astype('float32'),  result_train[index, :, :, 0], y_val_array[index, :, :, 0].astype('float32')], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([x_val_array[index, :, :, 0].astype('float32'), result_train[index, :, :, 0].astype('float32'), y_val_array[index, :, :, 0].astype('float32')], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some Garbage Reading Code\n",
    "\n",
    "s = 7800\n",
    "\n",
    "\n",
    "x_array = []\n",
    "y_array = []\n",
    "z_array = []\n",
    "\n",
    "print(\"Reading Done\")\n",
    "\n",
    "while(True):\n",
    "    ix = np.random.randint(128, 1200-128)\n",
    "    iy = np.random.randint(128, 1200-128)\n",
    "    iz = np.random.randint(25, 48)\n",
    "    \n",
    "    tempx = x[iz, ix:ix+128, iy:iy+128]\n",
    "    \n",
    "    if np.count_nonzero(tempx.flatten())*1.0/(128*128) < 0.9:\n",
    "        continue\n",
    "    \n",
    "    for j in range(6):\n",
    "        x_array.append(tempx)\n",
    "    \n",
    "    tempy = y1[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y2[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y3[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y4[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y5[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y6[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    #tempy = y7[iz, ix:ix+128, iy:iy+128]\n",
    "    #y_array.append(tempy)\n",
    "    \n",
    "    z_array.append(0.1)\n",
    "    z_array.append(0.2)\n",
    "    z_array.append(0.3)\n",
    "    z_array.append(0.4)\n",
    "    z_array.append(0.5)\n",
    "    z_array.append(0.7)\n",
    "    \n",
    "    if len(x_array) == s:\n",
    "        break\n",
    "\n",
    "# perm    = np.random.permutation(len(x_array))\n",
    "# x_array = np.array(x_array)[perm]\n",
    "# y_array = np.array(y_array)[perm]\n",
    "# z_array = np.array(z_array)[perm]\n",
    "\n",
    "x_array = np.expand_dims(x_array, axis=-1)\n",
    "y_array = np.expand_dims(y_array, axis=-1)\n",
    "z_array = np.expand_dims(z_array, axis=-1)\n",
    "\n",
    "\n",
    "print(x_array.shape, y_array.shape, z_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For reading the Data\n",
    "\n",
    "input_p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE18*\"+str(0.0005)+\"*_0.raw\")#+str(0.1)+\"'\".raw')\n",
    "for t in input_p:\n",
    "    print(t)\n",
    "print(\"*********************\")\n",
    "output_p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE18*4_\"+str(0.0005)+\"*.raw\")\n",
    "#output_p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE18*4_*.raw\")\n",
    "output_p.sort()\n",
    "output_p_new = []\n",
    "counter      = 0\n",
    "for t in output_p:\n",
    "    if '_0.raw' not in t:\n",
    "        print(counter, t)\n",
    "        output_p_new.append(t)\n",
    "        counter = counter+1\n",
    "\n",
    "output_p = output_p_new\n",
    "print(\"Length of output_p is \", len(output_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For creating signal present and absent training data pairs\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/My Passport/CHO-VOL-LESION/*.raw\")\n",
    "allfiles.sort()\n",
    "\n",
    "print(len(allfiles))\n",
    "\n",
    "todo = [7, 8, 9, 10, 15, 16, 19, 20, 27, 29, 31, 35]\n",
    "\n",
    "def extract_2d_patches(a):\n",
    "    patches = []\n",
    "    sx = 789\n",
    "    sy = 1453\n",
    "    ts = 128\n",
    "    \n",
    "    for i in range(4):\n",
    "        temp = a[28, sx-ts:sx+ts, sy-ts:sy+ts]\n",
    "        sy   = sy-235\n",
    "        #print(temp.shape)\n",
    "        patches.append(temp)\n",
    "    \n",
    "    sx = 503\n",
    "    sy = 1453\n",
    "    for i in range(4):\n",
    "        temp = a[25, sx-ts:sx+ts, sy-ts:sy+ts]\n",
    "        sy   = sy-235\n",
    "        #print(temp.shape)\n",
    "        patches.append(temp)\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "# all_patches = []\n",
    "\n",
    "# for f in allfiles:\n",
    "#     if int(f.split(\"/\")[-1].split(\"_\")[0]) not in todo:\n",
    "#         continue\n",
    "#     print(f.split(\"/\")[-1])\n",
    "    \n",
    "#     a = np.fromfile(f, dtype='float32')\n",
    "#     #a = np.load(f)\n",
    "#     a = np.reshape(a, [48, 1200, 2200])\n",
    "#     #np.save(f, a.astype('float16'))\n",
    "#     patches = extract_2d_patches(a)\n",
    "#     for k in range(8):\n",
    "#         all_patches.append(patches[k])\n",
    "#     #break\n",
    "# all_patches1 = np.array(all_patches)\n",
    "\n",
    "# #np.save('all_patches_lesion.npy', all_patches)\n",
    "# print(all_patches1.shape)\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/My Passport/CHO-VOL/*.raw\")\n",
    "allfiles.sort()\n",
    "\n",
    "all_patches = []\n",
    "for f in allfiles:\n",
    "    if int(f.split(\"/\")[-1].split(\"_\")[0]) not in todo:\n",
    "        continue\n",
    "    \n",
    "    print(f.split(\"/\")[-1])\n",
    "    #a = np.load(f)\n",
    "    a = np.fromfile(f, dtype='float32')\n",
    "    a = np.reshape(a, [48, 1200, 2200])\n",
    "    #np.save(f, a.astype('float16'))\n",
    "    patches = extract_2d_patches(a)\n",
    "    for k in range(8):\n",
    "        all_patches.append(patches[k])\n",
    "    #all_patches.append(patches)\n",
    "all_patches = np.array(all_patches)\n",
    "\n",
    "#np.save('all_patches_without_lesion.npy', all_patches)\n",
    "print(all_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Output image patches\n",
    "\n",
    "y_raw_array = []\n",
    "output_p    = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE27*4_*.raw\")\n",
    "output_p.sort()\n",
    "output_p_new = []\n",
    "counter      = 0\n",
    "for t in output_p:\n",
    "    if '_0.raw' not in t and '.0003' not in t and '.0001' not in t and '.0006' not in t and '0.2' not in t and '0.4' not in t:\n",
    "        print(counter, t)\n",
    "        output_p_new.append(t)\n",
    "        counter = counter+1\n",
    "output_p = output_p_new\n",
    "\n",
    "for p in output_p:\n",
    "    #print(p)\n",
    "    temp_y = np.fromfile(p, dtype='float32')\n",
    "    temp_y = temp_y.astype('float16')\n",
    "    temp_y = np.reshape(temp_y, [48, 1200, 2600])\n",
    "    y_raw_array.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Image patches\n",
    "\n",
    "arr1 = [0.0002, 0.0005, 0.0007, 0.001]\n",
    "arr2 = [0.1,  0.3,  0.5, 0.7]\n",
    "\n",
    "output_p_new1 = []\n",
    "\n",
    "for a1 in arr1:\n",
    "    for a2 in arr2:\n",
    "        y_raw_array = []\n",
    "        output_p    = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE27*\"+str(a1)+\"*\"+str(a2)+\".raw\")\n",
    "        output_p.sort()\n",
    "        counter      = 0\n",
    "        for f in output_p:\n",
    "            #print(f)\n",
    "            output_p_new1.append(f)\n",
    "        print(\"*************************\")\n",
    "\n",
    "output_p_new = []\n",
    "counter      = 0\n",
    "for t in output_p_new1:\n",
    "    if '_0.raw' not in t and '.0003' not in t and '.0001' not in t and '.0006' not in t and '0.2' not in t and '0.4' not in t:\n",
    "        print(counter, t)\n",
    "        output_p_new.append(t)\n",
    "        counter = counter+1\n",
    "output_p = output_p_new\n",
    "\n",
    "for p in output_p_new:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lesion Location Information Array\n",
    "1  1692, 1034, 34\n",
    "3  2043, 280,  18\n",
    "3  2124, 1146, 17\n",
    "3  1272, 236,  32\n",
    "6  1293, 440,  16\n",
    "7  1708, 496,  44\n",
    "7  941, 1100,  13\n",
    "10 874, 1018,  28\n",
    "10 1922, 734,  33 \n",
    "10 1957, 413,  38\n",
    "10 2018, 556,  37\n",
    "10 1961, 470,  7\n",
    "11 1298, 661,  22\n",
    "13 1628, 348,  34\n",
    "13 1797, 854,  34\n",
    "13 1622, 349,  34\n",
    "13 1596, 510,  31\n",
    "13 1550, 669,  37\n",
    "19 686, 1125, 20\n",
    "21 732, 464,  9\n",
    "25 1985, 576,  64\n",
    "25 1440, 256,  57\n",
    "25 1864, 1040, 36\n",
    "27 1429. 925,  64\n",
    "27 1278, 829,  64\n",
    "29 1246, 977,  21\n",
    "29 1380, 905,  19\n",
    "33 1104, 666,  24\n",
    "35 1670, 725,  17\n",
    "37 1128, 877,  56\n",
    "41 1084, 934,  42\n",
    "44 1480, 970,  19\n",
    "45 1638, 610,  47\n",
    "47 1062, 646,  23\n",
    "47 1301, 564,  23\n",
    "47 1870, 625,  23\n",
    "54 706, 1162,  27\n",
    "59 841, 1038,  32\n",
    "60 554, 553,   28\n",
    "60 468, 830,   22\n",
    "64 1948, 854,  22\n",
    "65 1820, 600,  25\n",
    "66 1510, 328,  40\n",
    "66 1328, 1001, 20\n",
    "66 1950, 630,  46\n",
    "66 1544, 529,  37\n",
    "67 1672, 542,  42\n",
    "67 2138, 612,  36\n",
    "67 1797, 694,  35\n",
    "67 1164, 737,  33\n",
    "70 1341, 762, 10\n",
    "71 1433, 769, 14 \n",
    "74 2302, 457, 28 \n",
    "75 2107, 777, 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lesion Location information Array hash Creation\n",
    "\n",
    "h = {}\n",
    "s = open(\"/home/dril/lesion_array\", \"r\").read()\n",
    "s = s.split(\"\\n\")\n",
    "s = s[:-1]\n",
    "count = 0\n",
    "for t in s:\n",
    "    #print(t, \"p\")\n",
    "    a = t.strip().split()\n",
    "    #print(a[0], \" p \", a[1], a[2], a[3])\n",
    "    i = int(a[0])\n",
    "    x = int(a[1].replace(\",\", \"\"))\n",
    "    y = int(a[2].replace(\",\", \"\"))\n",
    "    z = int(a[3].replace(\",\", \"\"))\n",
    "    #print(i, x, y, z)\n",
    "    h[count] = [i, x, y, z]\n",
    "    count = count+1\n",
    "np.save('lesion_array_hash.npy', h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "for k in h:\n",
    "    print(k)\n",
    "    if k < 18:\n",
    "        continue\n",
    "    \n",
    "    if h[k][0] == 27:\n",
    "        continue\n",
    "    \n",
    "    patches = []\n",
    "    values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "    vol  = np.fromfile(path, dtype=\"float32\")\n",
    "    vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    patches.append(vol[h[k][3]-2:h[k][3]+2, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128])\n",
    "    values.append(0)\n",
    "    \n",
    "    allpaths  = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw.npy\")\n",
    "    for t in allpaths:\n",
    "        s = float(t.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        values.append(s)\n",
    "        print(t, s)\n",
    "        \n",
    "        vol  = np.load(t)\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        temp = vol[h[k][3]-2:h[k][3]+2, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "        print(temp.shape, h[k][2])\n",
    "        patches.append(temp)\n",
    "    \n",
    "    #print()\n",
    "    a = np.array(patches)\n",
    "    b = np.array(values)\n",
    "    print(\"Length is \", len(values), a.shape)\n",
    "    np.save(\"dbt_real_patches_\"+str(k)+\".npy\",       a)\n",
    "    np.save(\"dbt_real_patches_values_\"+str(k)+\".npy\", b)\n",
    "    #for \n",
    "    #break\n",
    "    #print(vol.shape)\n",
    "    #print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion for training the calibaration CNN with No lesions\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    #print(f, index)\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "\n",
    "x      = []\n",
    "values = []\n",
    "\n",
    "for k in allindex:\n",
    "    if h[k][0] in test_list:\n",
    "        continue\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     z = []\n",
    "    \n",
    "#     patches = []\n",
    "#     values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "#     vol  = np.fromfile(path, dtype=\"float32\")\n",
    "#     vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    \n",
    "#     dx_array = [-5, 5]#, -10, 10]\n",
    "#     dy_array = [-5, 5]#, -10, 10]\n",
    "    \n",
    "#     temp_count = 0\n",
    "#     while(temp_count < 5):\n",
    "#         ix = np.random.randint(256, 1200-256)\n",
    "#         iy = np.random.randint(256, 3000-256)\n",
    "#         iz = np.random.randint(10, 54)\n",
    "\n",
    "# #         #if locations_flag:\n",
    "# #         ix = locations_array[temp_count][0]\n",
    "# #         iy = locations_array[temp_count][1]\n",
    "# #         iz = locations_array[temp_count][2]\n",
    "\n",
    "#         tempx = vol[iz, ix:ix+256, iy:iy+256]\n",
    "\n",
    "#         if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "#             continue\n",
    "        \n",
    "#         if tempx.shape[0] == 256 and tempx.shape[1] == 256:\n",
    "#             x.append(tempx)\n",
    "#             temp_count = temp_count + 1\n",
    "# #         if locations_flag == 0:\n",
    "# #             locations_array.append([ix, iy, iz])\n",
    "        \n",
    "            \n",
    "#     for tp in range(-2, 2):\n",
    "#         temp = vol[h[k][3]+tp, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "#         if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#             x.append(temp)\n",
    "    \n",
    "#     for dx in dx_array:\n",
    "#         for dy in dy_array:\n",
    "#             for tp in range(-2, 2):\n",
    "#                 temp = vol[h[k][3]+tp, h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy]\n",
    "#                 if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#                     x.append(temp)\n",
    "    \n",
    "#     values_stored  = list(np.load(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/reorder-b-\"+str(k)+\".npy\"))\n",
    "#     ratings_stored = list(np.load(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/values-b-\"+str(k)+\".npy\"))\n",
    "    \n",
    "#     print(values_stored)\n",
    "#     print(ratings_stored)\n",
    "    \n",
    "    locations_array = []\n",
    "    locations_flag  = 0\n",
    "    \n",
    "    allpaths  = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw.npy\")\n",
    "    for t in allpaths:\n",
    "        print(t)\n",
    "        s = float(t.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        values.append(s)\n",
    "        #current_rating = ratings_stored[values_stored.index(s)]\n",
    "        \n",
    "#         if current_rating < 1 or current_rating == 3:\n",
    "#             continue\n",
    "        \n",
    "#         print(\"Some values \", s, values_stored.index(s))\n",
    "        \n",
    "        vol  = np.load(t)\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        \n",
    "#         if current_rating  < 3:\n",
    "#             max_size = 10\n",
    "#         else:\n",
    "#             max_size = 10\n",
    "        \n",
    "        temp_count      = 0\n",
    "        \n",
    "#         for tp in range(-2, 2):\n",
    "#             temp = vol[h[k][3]+tp, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "#             #print(temp.shape)\n",
    "#             if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#                 x.append(temp)\n",
    "        \n",
    "#         for tp in range(-2, 2):\n",
    "#             for dx in dx_array:\n",
    "#                 for dy in dy_array:\n",
    "#                     temp = vol[h[k][3]+tp, h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy]\n",
    "#                     #print(temp.shape)\n",
    "#                     if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#                         x.append(temp)\n",
    "\n",
    "        # Get all Locations\n",
    "        while(temp_count < 20):\n",
    "            ix = np.random.randint(256, 1200-256)\n",
    "            iy = np.random.randint(256, 3000-256)\n",
    "            iz = np.random.randint(10, 54)\n",
    "            \n",
    "#             if locations_flag:\n",
    "#                 ix = locations_array[temp_count][0]\n",
    "#                 iy = locations_array[temp_count][1]\n",
    "#                 iz = locations_array[temp_count][2]\n",
    "            \n",
    "            tempx = vol[iz, ix:ix+256, iy:iy+256]\n",
    "            \n",
    "            if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "                continue\n",
    "            \n",
    "            if tempx.shape[0] == 256 and tempx.shape[1] == 256:\n",
    "                x.append(tempx)\n",
    "                temp_count = temp_count + 1\n",
    "        print(\"Length are \", len(x), len(values))\n",
    "            #if locations_flag == 0:\n",
    "            #    locations_array.append([ix, iy, iz])\n",
    "            \n",
    "#             if current_rating == 5:\n",
    "#                 x.append(tempx)\n",
    "#                 y.append(1)\n",
    "#                 z.append(s)\n",
    "#             #elif current_rating < 3:\n",
    "#             #    y.append(0)\n",
    "#             #    z.append(s)\n",
    "            \n",
    "#             temp_count = temp_count+1\n",
    "#         locations_flag = 1\n",
    "        #x.append(vol[h[k][3], h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128])\n",
    "        #y.append(current_rating)\n",
    "        \n",
    "        #for dx in dx_array:\n",
    "        #     for dy in dy_array:\n",
    "        #         x.append(vol[h[k][3], h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy])\n",
    "        #        y.append(current_rating)\n",
    "        \n",
    "        #print(len(x), len(y), current_rating, h[k][0])\n",
    "        \n",
    "    #x = np.array(x).astype('float16')\n",
    "    #y = np.array(y)\n",
    "    #z = np.array(z)\n",
    "    \n",
    "    #print(x.shape, y.shape, z.shape)\n",
    "    #print(x.shape)\n",
    "    \n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/no_x_\"+str(k)+\".npy\", x)\n",
    "    \n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/x_\"+str(k)+\".npy\", x)\n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/y_\"+str(k)+\".npy\", y)\n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/z_\"+str(k)+\".npy\", z)\n",
    "    \n",
    "        #temp = vol[h[k][3]-2:h[k][3]+2, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "        #print(temp.shape, h[k][2])\n",
    "        #patches.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     24,
     175,
     187
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Getting patches for each lesion for training the calibaration CNN with lesions\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "#print(val_list)\n",
    "\n",
    "\n",
    "for img_counter in range(1, 20):\n",
    "    counter = 0\n",
    "    for k in allindex:\n",
    "        #print(h[k][0], h[k], test_list)\n",
    "\n",
    "        if h[k][0] not in test_list:\n",
    "            continue\n",
    "\n",
    "        counter = counter+1\n",
    "        if counter < img_counter:\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        all_outputs = []\n",
    "        all_ssim = []\n",
    "        all_haar = []\n",
    "\n",
    "        patches = []\n",
    "        values  = []\n",
    "\n",
    "        path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "        vol  = np.fromfile(path, dtype=\"float32\")\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        \n",
    "        px = random.randint(500, 800)\n",
    "        rx = random.randint(1500, 2000)\n",
    "        tx = random.randint(25, 35)\n",
    "        \n",
    "        for tp in range(1, 2):\n",
    "            #tx = 0\n",
    "            #rx = 0\n",
    "            temp = vol[tx, -128+px:128+px, -128+rx:128+rx]\n",
    "            #temp = vol[h[k][3]+tp+tx, h[k][2]-128+rx:h[k][2]+128+rx, h[k][1]-128+rx:h[k][1]+128+rx]\n",
    "            #print(temp.shape)\n",
    "            if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "                x.append(temp)\n",
    "                values.append(0)\n",
    "\n",
    "        locations_array = []\n",
    "        locations_flag  = 0\n",
    "\n",
    "        allpaths  = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw.npy\")\n",
    "        allpaths.sort()\n",
    "\n",
    "        print(allpaths[0])\n",
    "\n",
    "        for t in allpaths:\n",
    "            #print(t)\n",
    "            s = float(t.split(\"/\")[-1].split(\"-\")[-1].split(\"_\")[0])\n",
    "\n",
    "            vol  = np.load(t)\n",
    "            vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "\n",
    "            temp_count      = 0\n",
    "\n",
    "            for tp in range(1, 2):\n",
    "                #for dx in dx_array:\n",
    "                    #for dy in dy_array:\n",
    "                #rx = 0\n",
    "                #tx = 0\n",
    "                temp = vol[tx, -128+px:128+px, -128+rx:128+rx]\n",
    "                #temp = vol[h[k][3]+tp+tx, h[k][2]-128+rx:h[k][2]+128+rx, h[k][1]-128+rx:h[k][1]+128+rx]\n",
    "                #print(temp.shape)\n",
    "                #temp = vol[h[k][3]+tp, h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy]\n",
    "                #print(temp.shape)\n",
    "                if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "                    x.append(temp)\n",
    "                    values.append(s)\n",
    "\n",
    "                    #print(s)\n",
    "                    pp1 = np.expand_dims(x[0], 0)\n",
    "                    pp1 = np.expand_dims(pp1,  0)\n",
    "                    pv1 = np.expand_dims(-1*s, 0)\n",
    "                    #print(pp1.shape, pv1.shape)\n",
    "\n",
    "                    pp1 = torch.tensor(pp1, device=device).float()\n",
    "                    pv1 = torch.tensor(pv1, device=device).float()\n",
    "\n",
    "                    result = unet_model.forward(pp1, pv1).data.cpu().numpy()\n",
    "                    all_outputs.append(result)\n",
    "                    #ssim_temp = measure.compare_ssim(result[0, 0, :, :].astype('float32'), temp.astype('float32'), data_range=temp.max() - temp.min())\n",
    "                    t1 = np.min(result[0, 0, :, :].flatten())\n",
    "                    t2 = np.max(result[0, 0, :, :].flatten())\n",
    "                    distorted_image  = (result[0, 0, :, :]-t1)*255/(t2-t1)\n",
    "\n",
    "                    t1 = np.min(temp.flatten())\n",
    "                    t2 = np.max(temp.flatten())\n",
    "                    reference_image = (temp-t1)*255/(t2-t1)\n",
    "\n",
    "                    ssim_temp = measure.compare_ssim(reference_image.astype('float32'), distorted_image.astype('float32'), 255)\n",
    "                    #print(temp.max(), temp.min(), temp.max() - temp.min())\n",
    "\n",
    "                    ssim_temp1 = haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True)[0]\n",
    "                    all_haar.append(ssim_temp1)\n",
    "                    all_ssim.append(ssim_temp)\n",
    "                    #print(temp.shape, result.shape, ssim_temp, ssim_temp1)\n",
    "\n",
    "        x      = np.array(x)\n",
    "        values = np.array(values)\n",
    "        all_outputs = np.array(all_outputs)\n",
    "        all_outputs = all_outputs[:, 0, 0, :, :]\n",
    "\n",
    "        #print(x.shape, values.shape, all_outputs.shape)\n",
    "        break\n",
    "\n",
    "    #plt.figure(figsize=(40,20))\n",
    "    #plt.axis('off')\n",
    "    tp1 = [x[1], x[3], x[4], x[5], x[6], x[7]]\n",
    "    tv1 = np.array([values[1], values[3], values[4], values[5], values[6], values[7]])\n",
    "    tv1[tv1 > 0.6] = 0.6\n",
    "\n",
    "    ssim_arr = [all_ssim[1-1], all_ssim[3-1], all_ssim[4-1], all_ssim[5-1], all_ssim[6-1], all_ssim[7-1]]\n",
    "    haar_arr = [all_haar[1-1], all_haar[3-1], all_haar[4-1], all_haar[5-1], all_haar[6-1], all_haar[7-1]]\n",
    "\n",
    "    #plt.imshow(np.concatenate(tp1, axis=0).T, cmap='gray')\n",
    "\n",
    "    print(values)\n",
    "    print(tv1)\n",
    "    print(ssim_arr)\n",
    "    print(haar_arr)\n",
    "\n",
    "    tp2 = [all_outputs[1-1], all_outputs[3-1], all_outputs[4-1], all_outputs[5-1], all_outputs[6-1], all_outputs[7-1]]\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "    #gs1 = gridspec.GridSpec(1, 8)\n",
    "    #gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "    top_title = \"\"\n",
    "    for i in range(1, len(tp2)+1):\n",
    "        if i == 1:\n",
    "            top_title = top_title+r'$\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "        else:\n",
    "            top_title = top_title+r'               $\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "\n",
    "\n",
    "    bottom_title = \"\"\n",
    "    for i in range(1, len(tp2)+1):\n",
    "        if i == 1:\n",
    "            bottom_title = bottom_title+\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "        else:\n",
    "            bottom_title = bottom_title+\"   SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        #if i == 1:\n",
    "        axs[0].set_ylabel(\"Ground Truth\")\n",
    "        axs[0].imshow(np.concatenate(tp1).T, cmap='gray')\n",
    "        axs[0].set_title(top_title, y=0.95, fontsize=10)\n",
    "        axs[0].set_xticks([], [])\n",
    "        axs[0].set_yticks([], [])\n",
    "        axs[0].spines['top'].set_visible(False)\n",
    "        axs[0].spines['bottom'].set_visible(False)\n",
    "        axs[0].spines['left'].set_visible(False)\n",
    "        axs[0].spines['right'].set_visible(False)\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        #if i == 1:\n",
    "        axs[1].set_ylabel(\"U-Net Output\")\n",
    "        axs[1].imshow(np.concatenate(tp2).T, cmap='gray')\n",
    "        axs[1].set_title(bottom_title, y=-0.15, fontsize=6)\n",
    "        axs[1].set_xticks([], [])\n",
    "        axs[1].set_yticks([], [])\n",
    "        axs[1].spines['top'].set_visible(False)\n",
    "        axs[1].spines['bottom'].set_visible(False)\n",
    "        axs[1].spines['left'].set_visible(False)\n",
    "        axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelbottom=False)\n",
    "    plt.tick_params(\n",
    "        axis='y',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left=False,\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        right=False,\n",
    "        labelbottom=False)\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    f.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "    plt.savefig('compare_supp_random4_'+str(img_counter)+'.png', dpi=300, bbox_inches = 'tight',\n",
    "        pad_inches = 0.1)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.show(block=True)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40,20))\n",
    "# print(values)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(np.concatenate(x[:-2], axis=0).T, cmap='gray')\n",
    "# print(x.shape, values.shape)\n",
    "#np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/x_\"+str(k)+\".npy\", x)\n",
    "#np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/y_\"+str(k)+\".npy\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# For plotting the images\n",
    "\n",
    "#plt.figure(figsize=(40,20))\n",
    "#plt.axis('off')\n",
    "tp1 = [x[1], x[3], x[4], x[5], x[6], x[7]]\n",
    "tv1 = np.array([values[1], values[3], values[4], values[5], values[6], values[7]])\n",
    "tv1[tv1 > 0.6] = 0.6\n",
    "\n",
    "ssim_arr = [all_ssim[1-1], all_ssim[3-1], all_ssim[4-1], all_ssim[5-1], all_ssim[6-1], all_ssim[7-1]]\n",
    "haar_arr = [all_haar[1-1], all_haar[3-1], all_haar[4-1], all_haar[5-1], all_haar[6-1], all_haar[7-1]]\n",
    "\n",
    "#plt.imshow(np.concatenate(tp1, axis=0).T, cmap='gray')\n",
    "\n",
    "print(values)\n",
    "print(tv1)\n",
    "print(ssim_arr)\n",
    "print(haar_arr)\n",
    "\n",
    "tp2 = [all_outputs[1-1], all_outputs[3-1], all_outputs[4-1], all_outputs[5-1], all_outputs[6-1], all_outputs[7-1]]\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "#gs1 = gridspec.GridSpec(1, 8)\n",
    "#gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "top_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        top_title = top_title+r'$\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "    else:\n",
    "        top_title = top_title+r'               $\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "\n",
    "\n",
    "bottom_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        bottom_title = bottom_title+\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "    else:\n",
    "        bottom_title = bottom_title+\"   SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "\n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[0].set_ylabel(\"Ground Truth\")\n",
    "    axs[0].imshow(np.concatenate(tp1).T, cmap='gray')\n",
    "    axs[0].set_title(top_title, y=0.95, fontsize=10)\n",
    "    axs[0].set_xticks([], [])\n",
    "    axs[0].set_yticks([], [])\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    \n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[1].set_ylabel(\"U-Net Output\")\n",
    "    axs[1].imshow(np.concatenate(tp2).T, cmap='gray')\n",
    "    axs[1].set_title(bottom_title, y=-0.15, fontsize=6)\n",
    "    axs[1].set_xticks([], [])\n",
    "    axs[1].set_yticks([], [])\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.savefig('compare_supp'+str(img_counter)+'.png', dpi=300, bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Old Matplotlib Code\n",
    "# f = plt.figure()\n",
    "# plt.rcParams[\"figure.figsize\"] = [9, 6]\n",
    "\n",
    "# #gs1 = gridspec.GridSpec(1, 8)\n",
    "# #gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# for i in range(1, 7):\n",
    "#     f.add_subplot(2, 7, i)\n",
    "#     plt.imshow(tp1[i-1], cmap='gray')\n",
    "#     plt.title(r'$\\beta$='+str(np.round(tv1[i-1], 3)), y=0.95, fontsize=12)\n",
    "#     plt.axis('off')\n",
    "    \n",
    "# for i in range(1, 7):\n",
    "#     f.add_subplot(1, 7, i)\n",
    "#     plt.imshow(tp2[i-1], cmap='gray')\n",
    "#     plt.title(\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3)), y=-0.15, fontsize=6)\n",
    "#     plt.axis('off')\n",
    "    \n",
    "# f.tight_layout()\n",
    "# plt.subplots_adjust(wspace=0.02, hspace=0.0001, bottom=0.16)\n",
    "# plt.savefig('compare_supp10.png', dpi=300, bbox_inches = 'tight',\n",
    "#     pad_inches = 0)\n",
    "# plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Experimenting Something with individual figures\n",
    "\n",
    "# f = plt.figure()\n",
    "# plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "# #gs1 = gridspec.GridSpec(1, 8)\n",
    "# #gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# fig, axs = plt.subplots(2, 6, constrained_layout=True)\n",
    "# #print(axs)\n",
    "# for i in range(1, 7):\n",
    "#     if i == 1:\n",
    "#         axs[0, i-1].set_ylabel(\"Ground Truth\")\n",
    "#     axs[0, i-1].imshow(tp1[i-1], cmap='gray')\n",
    "#     axs[0, i-1].set_title(r'$\\beta$='+str(np.round(tv1[i-1], 3)), y=0.95, fontsize=10)\n",
    "#     axs[0, i-1].set_xticks([], [])\n",
    "#     axs[0, i-1].set_yticks([], [])\n",
    "#     axs[0, i-1].spines['top'].set_visible(False)\n",
    "#     axs[0, i-1].spines['bottom'].set_visible(False)\n",
    "#     axs[0, i-1].spines['left'].set_visible(False)\n",
    "#     axs[0, i-1].spines['right'].set_visible(False)\n",
    "    \n",
    "# for i in range(1, 7):\n",
    "#     if i == 1:\n",
    "#         axs[1, i-1].set_ylabel(\"U-Net Output\")\n",
    "#     axs[1, i-1].imshow(tp2[i-1], cmap='gray')\n",
    "#     axs[1, i-1].set_title(\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3)), y=-0.15, fontsize=6)\n",
    "#     axs[1, i-1].set_xticks([], [])\n",
    "#     axs[1, i-1].set_yticks([], [])\n",
    "#     axs[1, i-1].spines['top'].set_visible(False)\n",
    "#     axs[1, i-1].spines['bottom'].set_visible(False)\n",
    "#     axs[1, i-1].spines['left'].set_visible(False)\n",
    "#     axs[1, i-1].spines['right'].set_visible(False)\n",
    "\n",
    "# plt.tick_params(\n",
    "#     axis='x',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     bottom=False,      # ticks along the bottom edge are off\n",
    "#     top=False,         # ticks along the top edge are off\n",
    "#     left=False,\n",
    "#     right=False,\n",
    "#     labelbottom=False)\n",
    "# plt.tick_params(\n",
    "#     axis='y',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     left=False,\n",
    "#     bottom=False,      # ticks along the bottom edge are off\n",
    "#     top=False,         # ticks along the top edge are off\n",
    "#     right=False,\n",
    "#     labelbottom=False)\n",
    "# plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "# f.tight_layout()\n",
    "# plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "# plt.savefig('compare_supp1.png', dpi=300, bbox_inches = 'tight',\n",
    "#     pad_inches = 0)\n",
    "# plt.gca().axes.get_yaxis().set_visible(False)\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Experimenting Something 1\n",
    "\n",
    "f = plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "#gs1 = gridspec.GridSpec(1, 8)\n",
    "#gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "top_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        top_title = top_title+r'$\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "    else:\n",
    "        top_title = top_title+r'               $\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "\n",
    "\n",
    "bottom_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        bottom_title = bottom_title+\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "    else:\n",
    "        bottom_title = bottom_title+\"   SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "\n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[0].set_ylabel(\"Ground Truth\")\n",
    "    axs[0].imshow(np.concatenate(tp1).T, cmap='gray')\n",
    "    axs[0].set_title(top_title, y=0.95, fontsize=10)\n",
    "    axs[0].set_xticks([], [])\n",
    "    axs[0].set_yticks([], [])\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    \n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[1].set_ylabel(\"U-Net Output\")\n",
    "    axs[1].imshow(np.concatenate(tp2).T, cmap='gray')\n",
    "    axs[1].set_title(bottom_title, y=-0.15, fontsize=6)\n",
    "    axs[1].set_xticks([], [])\n",
    "    axs[1].set_yticks([], [])\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.savefig('compare_supp5.png', dpi=300, bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     33,
     37
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For optimizing the Tuning parameter using the PyTorch Model in a Loop\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "#unet_model.eval()\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.Adam([input_img.requires_grad_()], lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "opt_counter = 0\n",
    "for img_counter in range(1, 20):\n",
    "    counter = 0\n",
    "    for k in allindex:\n",
    "        #print(h[k][0], h[k], test_list)\n",
    "\n",
    "        if h[k][0] not in test_list:\n",
    "            continue\n",
    "\n",
    "        counter = counter+1\n",
    "        if counter < img_counter:\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        all_outputs = []\n",
    "        all_ssim    = []\n",
    "        all_haar    = []\n",
    "\n",
    "        patches = []\n",
    "        values  = []\n",
    "\n",
    "        path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "        vol  = np.fromfile(path, dtype=\"float32\")\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        print(path)\n",
    "        \n",
    "        px = random.randint(800, 1000)\n",
    "        rx = random.randint(2000, 2500)\n",
    "        tx = random.randint(15, 25)\n",
    "        \n",
    "        for tp in range(1, 2):\n",
    "            tx = 0\n",
    "            rx = 0\n",
    "            #temp = vol[tx, -128+px:128+px, -128+rx:128+rx]\n",
    "            temp = vol[h[k][3]+tp+tx, h[k][2]-128+rx:h[k][2]+128+rx, h[k][1]-128+rx:h[k][1]+128+rx]\n",
    "            #print(temp.shape)\n",
    "            if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "                x.append(temp)\n",
    "                values.append(0)\n",
    "        x = np.array(x)\n",
    "        \n",
    "        device  = torch.device(\"cuda:0\")\n",
    "\n",
    "        targets = torch.tensor(np.ones([1, 1]), device=device).float()\n",
    "\n",
    "        in1 = x[0, :, :]#np.ones([1, 1, 256, 256]) #np.ones([256, 256])\n",
    "        in1 = np.expand_dims(in1, axis=0)\n",
    "        in1 = np.expand_dims(in1, axis=1)\n",
    "        in1 = torch.tensor(in1, device=device).float()\n",
    "\n",
    "        in2 = Variable(torch.tensor(-0.2*np.ones([1, 1], dtype='float32')).cuda(), requires_grad=True)\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        optimizer = get_input_optimizer(in2)\n",
    "\n",
    "        first_image = 0\n",
    "        best_image  = 0\n",
    "        best = 1000\n",
    "        print('Optimizing..')\n",
    "        run = [0]\n",
    "\n",
    "        s1 = time.time()\n",
    "        while run[0] <= 100:\n",
    "            optimizer.zero_grad()\n",
    "            out1 = unet_model(in1, in2)\n",
    "            out2 = rating_cnn(out1)\n",
    "\n",
    "            if run[0] == 0:\n",
    "                first_image = out1.data.cpu().numpy()\n",
    "\n",
    "            loss = criterion(out2, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            #if run[0] % 10 == 0:\n",
    "                #print(np.mean(out1.data.cpu().numpy().flatten()))\n",
    "            if loss.item() < best:\n",
    "                best       = loss.item()\n",
    "                best_image = out1.data.cpu().numpy()\n",
    "                #print(\"Loss is \", loss.item(), \" variable \", in2.item(), \" out2 \", out2.item())#, \"out1 \", out1.item())#np.mean(out1.item().flatten()))\n",
    "            optimizer.step()\n",
    "        s2 = time.time()\n",
    "        #print(s2-s1)\n",
    "        \n",
    "        #\n",
    "        font = {'family': 'times new roman',  'weight': 'normal', 'size': 16}\n",
    "        plt.axis('off')\n",
    "        u1 = r'    $\\beta$='+str(0)\n",
    "        u2 = r'                                    $\\beta_{man}$='+str(0.2)\n",
    "        u3 = r'                                    $\\beta_{opt}$='+str(np.round(-1*in2.data.cpu().numpy()[0][0], 3))\n",
    "        plt.title(u1+u2+u3) #   $\\beta$='+str(np.round(in2.data.cpu().numpy()[0][0], 3)))\n",
    "        #plt.title(r'    $\\beta$='+str(0) +'  $\\beta$=0.2') #   $\\beta$='+str(np.round(in2.data.cpu().numpy()[0][0], 3)))\n",
    "        #plt.title(\"testing \", fontdict=font)\n",
    "        plt.imshow(np.concatenate([x[0, :, :], first_image[0, 0, :, :], best_image[0, 0, :, :]], axis=-1), cmap='gray')\n",
    "        print(opt_counter, in2.data.cpu().numpy())\n",
    "        plt.savefig('optimization_'+str(opt_counter)+'.png', dpi=300, bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        opt_counter = opt_counter+1\n",
    "        break\n",
    "    \n",
    "        #print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [STAR] For optimizing the Tuning parameter using the PyTorch Model\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "rating_cnn = RatingModel()\n",
    "rating_cnn.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "rating_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/rating_pytorch.pt')\n",
    "rating_cnn.load_state_dict(rating_weights)\n",
    "\n",
    "\n",
    "#unet_model.eval()\n",
    "#rating_cnn.eval()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device  = torch.device(\"cuda:0\")\n",
    "\n",
    "targets = torch.tensor(np.ones([1, 1]), device=device).float()\n",
    "\n",
    "in1 = x[0, :, :]#np.ones([1, 1, 256, 256]) #np.ones([256, 256])\n",
    "in1 = np.expand_dims(in1, axis=0)\n",
    "in1 = np.expand_dims(in1, axis=1)\n",
    "in1 = torch.tensor(in1, device=device).float()\n",
    "\n",
    "in2 = Variable(torch.tensor(-0.2*np.ones([1, 1], dtype='float32')).cuda(), requires_grad=True)\n",
    "\n",
    "\n",
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.Adam([input_img.requires_grad_()], lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = get_input_optimizer(in2)\n",
    "\n",
    "first_image = 0\n",
    "best_image  = 0\n",
    "best = 1000\n",
    "print('Optimizing..')\n",
    "run = [0]\n",
    "\n",
    "s1 = time.time()\n",
    "while run[0] <= 100:\n",
    "    optimizer.zero_grad()\n",
    "    out1 = unet_model(in1, in2)\n",
    "    out2 = rating_cnn(out1)\n",
    "    \n",
    "    if run[0] == 0:\n",
    "        first_image = out1.data.cpu().numpy()\n",
    "        \n",
    "    loss = criterion(out2, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    run[0] += 1\n",
    "    #if run[0] % 10 == 0:\n",
    "        #print(np.mean(out1.data.cpu().numpy().flatten()))\n",
    "    if loss.item() < best:\n",
    "        best       = loss.item()\n",
    "        best_image = out1.data.cpu().numpy()\n",
    "        #print(\"Loss is \", loss.item(), \" variable \", in2.item(), \" out2 \", out2.item())#, \"out1 \", out1.item())#np.mean(out1.item().flatten()))\n",
    "    optimizer.step()\n",
    "s2 = time.time()\n",
    "print(s2-s1)\n",
    "\n",
    "# Good counters = 11, 12 (16 is best)\n",
    "plt.axis('off')\n",
    "plt.imshow(np.concatenate([x[0, :, :], first_image[0, 0, :, :], best_image[0, 0, :, :]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For filtering the entire slice using PyTorch Model\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.Adam([input_img.requires_grad_()], lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "opt_counter = 0\n",
    "for img_counter in range(1, 20):\n",
    "    counter = 0\n",
    "    for k in allindex:\n",
    "        #print(h[k][0], h[k], test_list)\n",
    "\n",
    "        if h[k][0] not in test_list:\n",
    "            continue\n",
    "\n",
    "        counter = counter+1\n",
    "        if counter < img_counter:\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        all_outputs = []\n",
    "        all_ssim    = []\n",
    "        all_haar    = []\n",
    "\n",
    "        patches = []\n",
    "        values  = []\n",
    "\n",
    "        path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "        vol  = np.fromfile(path, dtype=\"float32\")\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        print(path)\n",
    "        \n",
    "        for tp in range(1, 2):\n",
    "            temp = vol[h[k][3]+tp, :, :]\n",
    "            #print(temp.shape)\n",
    "        \n",
    "        #1280, 3072\n",
    "        image_slice = np.pad(temp, ((40, 40), (36, 36)), 'constant', constant_values=(0, 0))\n",
    "        #print(image_slice.shape)\n",
    "        \n",
    "        temp_all = []\n",
    "        for tk in range(5):\n",
    "            temp_row = []\n",
    "            for tj in range(12):\n",
    "                img = image_slice[tk*256:(tk+1)*256, tj*256:(tj+1)*256]\n",
    "                \n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                t1  = np.expand_dims(img, axis=1)\n",
    "                \n",
    "                t2 = np.expand_dims(-1*np.ones([1, 1])*0.125, axis=-1)\n",
    "                \n",
    "                x1      = torch.tensor(t1, device=device).float()\n",
    "                values1 = torch.tensor(t2, device=device).float()\n",
    "                \n",
    "                output = unet_model.forward(x1, values1)\n",
    "                output = output.data.cpu().numpy()\n",
    "                output = output[0, 0, :, :]\n",
    "                temp_row.append(output)\n",
    "            temp_row = np.concatenate(temp_row, axis=1)\n",
    "            temp_all.append(temp_row)\n",
    "        temp_all1 = np.concatenate(temp_all, axis=0)\n",
    "        \n",
    "        temp_all = []\n",
    "        for tk in range(5):\n",
    "            temp_row = []\n",
    "            for tj in range(12):\n",
    "                img = image_slice[tk*256:(tk+1)*256, tj*256:(tj+1)*256]\n",
    "                \n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                t1  = np.expand_dims(img, axis=1)\n",
    "                \n",
    "                t2 = np.expand_dims(-1*np.ones([1, 1])*0.2, axis=-1)\n",
    "                \n",
    "                x1      = torch.tensor(t1, device=device).float()\n",
    "                values1 = torch.tensor(t2, device=device).float()\n",
    "                \n",
    "                output = unet_model.forward(x1, values1)\n",
    "                output = output.data.cpu().numpy()\n",
    "                output = output[0, 0, :, :]\n",
    "                temp_row.append(output)\n",
    "            temp_row = np.concatenate(temp_row, axis=1)\n",
    "            temp_all.append(temp_row)\n",
    "        temp_all2 = np.concatenate(temp_all, axis=0)\n",
    "        \n",
    "        temp_all2   = temp_all2[40:-40, 36:-36]\n",
    "        temp_all1   = temp_all1[40:-40, 36:-36]\n",
    "        image_slice = image_slice[40:-40, 36:-36]\n",
    "        \n",
    "        image_slice.astype('float32').tofile('image_slice'+str(img_counter)+'_3000x1200.raw')\n",
    "        temp_all1.astype('float32').tofile('result_slice'+str(img_counter)+'_3000x1200.raw')\n",
    "        temp_all2.astype('float32').tofile('result_2slice'+str(img_counter)+'_3000x1200.raw')\n",
    "        \n",
    "        print(temp_all1.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     23,
     184,
     345,
     508,
     671,
     834,
     997,
     1160,
     1170,
     1178,
     1186,
     1194,
     1202,
     1356,
     1506,
     1656,
     1806
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] PyTorch CNN Model Imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# in1 = np.ones([10, 1, 256, 256])\n",
    "# in2 = np.ones([10, 1])\n",
    "\n",
    "# in1 = torch.tensor(in1, device=device).float()\n",
    "# in2 = torch.tensor(in2, device=device).float()\n",
    "\n",
    "\n",
    "# Define model\n",
    "class MyUnetGN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "        \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU())\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter1//2, filter1))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter2//2, filter2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter3//2, filter3))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter4//2, filter4))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter5//2, filter5))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter4//2, filter4))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter3//2, filter3))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter2//2, filter2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter1//2, filter1))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter4//2, filter4))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter3//2, filter3))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter2//2, filter2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.GroupNorm(filter1//2, filter1))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.d1 = nn.Dropout(0.1)\n",
    "        self.d2 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnetBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "        \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU())\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter1))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter3))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter4))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter5))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter4))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter3))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter1))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter4))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter3))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(filter2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2filter1\n",
    "            nn.BatchNorm2d(filter1))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.d1 = nn.Dropout(0.1)\n",
    "        self.d2 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnetSlice1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block1 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        #self.d1 = nn.Dropout(0.5)\n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y, v):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val1 = self.dense_block(v)\n",
    "        hash_val1 = hash_val1.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val = torch.mul(hash_val, hash_val1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        #p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        #p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnetSlice1_half(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 16\n",
    "        filter2 = 32\n",
    "        filter3 = 64\n",
    "        filter4 = 128\n",
    "        filter5 = 256\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block1 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        #self.d1 = nn.Dropout(0.5)\n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y, v):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val1 = self.dense_block(v)\n",
    "        hash_val1 = hash_val1.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val = torch.mul(hash_val, hash_val1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        #p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        #p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnetSlice2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block1 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        #self.d1 = nn.Dropout(0.5)\n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y, v):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val1 = self.dense_block(v)\n",
    "        hash_val1 = hash_val1.view(-1, 1, 1, 1)\n",
    "        \n",
    "        #hash_val = torch.mul(hash_val, hash_val1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        #p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        #p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val1)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val1)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val1)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class MyUnetSlice2_half(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 16\n",
    "        filter2 = 32\n",
    "        filter3 = 64\n",
    "        filter4 = 128\n",
    "        filter5 = 256\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block1 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        #self.d1 = nn.Dropout(0.5)\n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y, v):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val1 = self.dense_block(v)\n",
    "        hash_val1 = hash_val1.view(-1, 1, 1, 1)\n",
    "        \n",
    "        #hash_val = torch.mul(hash_val, hash_val1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        #p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        #p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val1)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val1)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val1)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnetSlice3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block1 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        #self.d1 = nn.Dropout(0.5)\n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y, v):\n",
    "        hash_val1 = self.dense_block(y)\n",
    "        hash_val1 = hash_val1.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val = self.dense_block(v)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        #hash_val = torch.mul(hash_val, hash_val1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        #p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        #p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val1)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val1)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val1)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnetSlice4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "    \n",
    "        self.dense_block1 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block2 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block3 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block4 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.dense_block5 = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        #self.d1 = nn.Dropout(0.5)\n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y, v):\n",
    "        hash_val1 = self.dense_block1(y)\n",
    "        hash_val1 = hash_val1.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val2 = self.dense_block2(y)\n",
    "        hash_val2 = hash_val2.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val3 = self.dense_block3(y)\n",
    "        hash_val3 = hash_val3.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val4 = self.dense_block4(y)\n",
    "        hash_val4 = hash_val4.view(-1, 1, 1, 1)\n",
    "        \n",
    "        hash_val5 = self.dense_block5(y)\n",
    "        hash_val5 = hash_val5.view(-1, 1, 1, 1)\n",
    "        \n",
    "        #hash_val = torch.mul(hash_val, hash_val1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val1)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val2)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val3)\n",
    "        p3 = self.pool3(x3)\n",
    "        #p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val4)\n",
    "        p4 = self.pool4(x4)\n",
    "        #p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val4)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val3)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val2)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnet_half(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 16\n",
    "        filter2 = 32\n",
    "        filter3 = 64\n",
    "        filter4 = 128\n",
    "        filter5 = 256\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MyUnet_double(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 64\n",
    "        filter2 = 128\n",
    "        filter3 = 256\n",
    "        filter4 = 512\n",
    "        filter5 = 1024\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(0.2),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU(0.2)\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class RatingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            #nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.out = nn.Sequential(nn.Linear(256, 1),\n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        \n",
    "        x = x.view(-1, 256)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "#model = MyUnet()\n",
    "#model.cuda()\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "#model.apply(init_normal)\n",
    "\n",
    "#unet_model = MyUnetGN()\n",
    "#unet_model.cuda()\n",
    "\n",
    "# rating_cnn = RatingModel()\n",
    "# rating_cnn.cuda()\n",
    "\n",
    "#rating_cnn.apply(init_normal)\n",
    "#summary(unet_model, [(1, 256, 256), (1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [STAR] For predicting the result PyTorch Model\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "rating_cnn = RatingModel()\n",
    "rating_cnn.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "rating_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/rating_pytorch.pt')\n",
    "rating_cnn.load_state_dict(rating_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For predicting the result PyTorch Model for Time calculation\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "rating_cnn = RatingModel()\n",
    "rating_cnn.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "rating_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/rating_pytorch.pt')\n",
    "rating_cnn.load_state_dict(rating_weights)\n",
    "\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "#all_outputs.append(x[0, :, :])\n",
    "import time\n",
    "\n",
    "x = np.random.rand(3515, 256, 256)\n",
    "s1 = time.time()\n",
    "for i in range(1, 219):\n",
    "    t1 = np.expand_dims(x[i*16:(i+1)*16, :, :], axis=1)\n",
    "    #1 = [x[i*8:(i+1)*8, :, :]]\n",
    "    t2 = np.expand_dims(-1*np.ones([16, 1])*0.2, axis=-1)\n",
    "    #t2 = np.expand_dims(-1*np.array([values[i]]), axis=-1)\n",
    "    #print(values[i])\n",
    "    \n",
    "    x1      = torch.tensor(t1, device=device).float()\n",
    "    values1 = torch.tensor(t2, device=device).float()\n",
    "    \n",
    "    output = unet_model.forward(x1, values1)\n",
    "    output = output.data.cpu().numpy()\n",
    "    \n",
    "    all_outputs.append(output[0, 0, :, :])\n",
    "all_outputs = np.array(all_outputs)\n",
    "\n",
    "s2 = time.time()\n",
    "\n",
    "print(s2-s1)\n",
    "print(all_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.ConvTranspose2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    \n",
    "net.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2212075710296631 0.013774563985952545\n"
     ]
    }
   ],
   "source": [
    "a = [0.24677252769470215, 0.2077016830444336, 0.2233893871307373, 0.21227669715881348, 0.2158975601196289]\n",
    "print(np.mean(a), np.std(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.523446750640868 0.10497122145263522\n"
     ]
    }
   ],
   "source": [
    "b = [13.407370567321777, 13.721302509307861, 13.491996765136719, 13.50873589515686, 13.487828016281128]\n",
    "print(np.mean(b), np.std(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For plotting the results\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "o1 = np.concatenate(all_outputs[:7, :, :], axis=0).T\n",
    "print(o1.shape)\n",
    "\n",
    "o2 = np.concatenate(x[1:8, :, :]).T\n",
    "print(o2.shape)\n",
    "\n",
    "#print(o1.shape, o2.shape)\n",
    "\n",
    "together = np.concatenate([o1, o2], axis=0)\n",
    "#print(o1.shape, o2.shape, together.shape)\n",
    "print(values[1:])\n",
    "plt.imshow(together, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "code_folding": [
     0,
     17
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [STAR] Comparing the Noise Power Spectrum\n",
    "\n",
    "from scipy import fftpack\n",
    "import pyfits\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import radialProfile\n",
    "\n",
    "index  = 2\n",
    "image1 = o1[:, index*256:(index+1)*256]\n",
    "image2 = o2[:, index*256:(index+1)*256]\n",
    "\n",
    "index  = 5\n",
    "image3 = o1[:, index*256:(index+1)*256]\n",
    "image4 = o2[:, index*256:(index+1)*256]\n",
    "\n",
    "\n",
    "def get_power_spectrum(image):    \n",
    "    # Take the fourier transform of the image.\n",
    "    F1 = fftpack.fft2(image)\n",
    "    F2 = fftpack.fftshift(F1)\n",
    "    \n",
    "    # Calculate a 2D power spectrum\n",
    "    psf2D = np.abs( F2 )**2\n",
    "    \n",
    "    # Calculate the azimuthally averaged 1D power spectrum\n",
    "    psf1D = radialProfile.azimuthalAverage(psf2D)\n",
    "    return psf1D\n",
    "\n",
    "t1 = get_power_spectrum(image1)\n",
    "t2 = get_power_spectrum(image2)\n",
    "\n",
    "t3 = get_power_spectrum(image3)\n",
    "t4 = get_power_spectrum(image4)\n",
    "\n",
    "\n",
    "py.figure(3)\n",
    "py.clf()\n",
    "\n",
    "py.semilogy( t1, 'r--', label=r'U-Net             $\\beta = 0.154$')\n",
    "py.semilogy( t3, 'b--', label=r'U-Net             $\\beta = 0.454$')\n",
    "\n",
    "py.semilogy( t2, label=r'Ground Truth $\\beta = 0.154$')\n",
    "py.semilogy( t4, label=r'Ground Truth $\\beta = 0.454$')\n",
    "\n",
    "\n",
    "py.xlabel(\"Spatial Frequency\", fontsize=24)\n",
    "py.ylabel(\"Power Spectrum\",fontsize=24)\n",
    "py.legend(fontsize=20)\n",
    "py.xticks(fontsize=16)\n",
    "py.yticks(fontsize=16)\n",
    "py.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For getting the SSIM metric\n",
    "\n",
    "#from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "#from skimage import structural_similarity as ssim\n",
    "from skimage import measure\n",
    "import glob\n",
    "\n",
    "import importlib\n",
    "importlib.reload(haarPsi)\n",
    "\n",
    "#import \n",
    "from haarPsi import haar_psi_numpy\n",
    "\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "ssim_array = {}\n",
    "ssim_array[0.1] = []\n",
    "ssim_array[0.2] = []\n",
    "ssim_array[0.3] = []\n",
    "ssim_array[0.4] = []\n",
    "ssim_array[0.5] = []\n",
    "ssim_array[0.6] = []\n",
    "\n",
    "\n",
    "mae_array = {}\n",
    "mae_array[0.1] = []\n",
    "mae_array[0.2] = []\n",
    "mae_array[0.3] = []\n",
    "mae_array[0.4] = []\n",
    "mae_array[0.5] = []\n",
    "mae_array[0.6] = []\n",
    "\n",
    "def my_mae(x, y):\n",
    "    return np.mean(np.abs(x-y))\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "checkit = []\n",
    "\n",
    "flag = False\n",
    "\n",
    "for t in test_list:\n",
    "    a        = np.load(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_0.npy\")\n",
    "    allfiles = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_-*.npy\")\n",
    "    \n",
    "    for f in allfiles:\n",
    "        value = -1*float(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "        b     = np.load(f)\n",
    "        print(f, value)\n",
    "        \n",
    "        for index in range(50):\n",
    "            b1    = b[index, :, :, 0]\n",
    "            \n",
    "            t1    = a[index, :, :, 0]\n",
    "            t1    = np.expand_dims(t1, 0)\n",
    "            t1    = np.expand_dims(t1, 1)\n",
    "            \n",
    "            values  = -1*value*np.ones([1, 1])\n",
    "            \n",
    "            x1      = torch.tensor(t1, device=device).float()\n",
    "            values  = torch.tensor(values, device=device).float()\n",
    "        \n",
    "            output = unet_model.forward(x1, values)\n",
    "            pred   = output.data.cpu().numpy()\n",
    "            \n",
    "            t1 = np.min(b1.flatten())\n",
    "            t2 = np.max(b1.flatten())\n",
    "            reference_image = (b1-t1)*255/(t2-t1)\n",
    "            \n",
    "            t1 = np.min(pred[0, 0, :, :].flatten())\n",
    "            t2 = np.max(pred[0, 0, :, :].flatten())\n",
    "            distorted_image = (pred[0, 0, :, :]-t1)*255/(t2-t1)\n",
    "            #print(np.min(distorted_image), np.max(distorted_image), np.max(reference_image), np.min(reference_image))\n",
    "            \n",
    "            ssim_temp = measure.compare_ssim(distorted_image, reference_image, data_range=255)\n",
    "            #ssim_temp = measure.compare_ssim(pred[0, 0, :, :].astype('float16'), b1.astype('float16'))\n",
    "            #ssim_temp = measure.compare_ssim(pred[0, 0, :, :].astype('float32'), b1.astype('float32'), data_range=b1.max() - b1.min())\n",
    "            #ssim_temp = measure.compare_ssim(pred[0, 0, :, :].astype('float32'), b1.astype('float32'), data_range=pred[0, 0, :, :].max() - pred[0, 0, :, :].min())\n",
    "            \n",
    "            #ssim_temp = haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True)[0]\n",
    "            if ssim_temp < 0.6 and value < 0.6:\n",
    "                import random\n",
    "                lp = random.randint(0, 100)\n",
    "                if lp > 90:\n",
    "                    flag       = True\n",
    "                    ssim_temp1 = haar_psi_numpy(reference_image.astype('float32'), distorted_image.astype('float32'),  preprocess_with_subsampling = True)[0]\n",
    "                    print(ssim_temp, value, ssim_temp1)\n",
    "                    checkit.append([reference_image, distorted_image])\n",
    "                    break\n",
    "            #print(ssim_temp[0], ssim_temp[1].shape)\n",
    "            \n",
    "            mae_temp  = my_mae(pred[0, 0, :, :], b1)\n",
    "                \n",
    "            if value < 0.1:\n",
    "                ssim_array[0.1].append(ssim_temp)\n",
    "                mae_array[0.1].append(mae_temp)\n",
    "            elif value < 0.2:\n",
    "                ssim_array[0.2].append(ssim_temp)\n",
    "                mae_array[0.2].append(mae_temp)    \n",
    "            elif  value < 0.3:\n",
    "                ssim_array[0.3].append(ssim_temp)\n",
    "                mae_array[0.3].append(mae_temp)    \n",
    "            elif  value < 0.4:\n",
    "                ssim_array[0.4].append(ssim_temp)\n",
    "                mae_array[0.4].append(mae_temp)    \n",
    "            elif value < 0.5:\n",
    "                ssim_array[0.5].append(ssim_temp)\n",
    "                mae_array[0.5].append(mae_temp)    \n",
    "            elif value < 0.6:\n",
    "                ssim_array[0.6].append(ssim_temp)\n",
    "                mae_array[0.6].append(mae_temp)\n",
    "        if flag:\n",
    "            break\n",
    "    if flag:\n",
    "        break\n",
    "\n",
    "values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "for t in values:\n",
    "    print(t, np.mean(ssim_array[t]), np.mean(mae_array[t]), np.std(ssim_array[t]), np.std(mae_array[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM results\n",
    "0.1 0.9914873887960779 0.00018285964 0.0061945855375389125 4.591579e-05\n",
    "0.2 0.9469701962447921 0.0002514394 0.02808622002535202 4.0652736e-05\n",
    "0.3 0.8693526790506381 0.00026405914 0.07103994994361851 6.837431e-05\n",
    "0.4 0.7924587842729388 0.00028266825 0.109039188851624 9.9856086e-05\n",
    "0.5 0.7234613368989369 0.0002761438 0.1480347905261776 7.468571e-05\n",
    "0.6 0.6754057684000083 0.00030263996 0.1760634203245287 0.00011321019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625813677591749\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAADbCAYAAAC7tzwgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9yY9k93klemK4ETduxI15HjIjx8qsSUwVKZqUZFGSLTRowA159bTwtOm/4S1r07IkCNKDl168hRbGW3nxYGjhhWVKNkmRKlaxhqycMyMiY57n4cbQi9T5FAk/SW7gFbrcyAsQJKsyI+70+4Zzznd+psVigZvj5rg5bo6b4+Z4lYf5f/UJ3Bw3x81xc9wc//sfN8nm5rg5bo6b4+Z45cdNsrk5bo6b4+a4OV75cZNsbo6b4+a4OW6OV37cJJub4+a4OW6Om+OVHzfJ5ua4OW6Om+PmeOXHK0s2JpPpv5hMpkOTyXRiMpn+z1f1PTfHzXFz3Bw3x+t/mF7FnI3JZLIAOALwxwAuAXwK4DuLxWL///cvuzlujpvj5rg5XvvjVXU2XwJwslgszhaLxQTA/wPgv76i77o5bo6b4+a4OV7zw/qKPjcBILf0/5cA3l7+AZPJ9N8A/DcAUBTlQSAQgMlkwmKxwHw+h9lshmEY8Hg8GI/HMJlMGAwGUFUV8/kcJpMJVqsV0+kU7M7MZjOm0ykURQEATCYTAJDPUxQFi8UCiqLAZDJhNpvBbDZjPp9jPp/L/5tMJthsNkynU5hMpmufOxqN4HK55POn06n8Pc9pPp+j3+9D13XYbDbMZjM5Z36HoiiYTqcAgNFoBLvdjvl8Dl3XYbFY5NwBoNvtQlVVGIYBwzCgqipGoxFsNhsMw5DPBQBd1zEejzGfzwEAhmHIZ/PneI+dTidGoxEURcFkMoHNZoPZbMZ4PIZhGNA0DcPhEPP5HFarFRaLBQ6HA6PRSO4T/20YBgDAYrFgsVjAZrPBYrGg0+nI9ZjNZlgsFlgsFjk/3p/JZAKHwyHnN5vN5Pf4edPpFBaLRb6Lz2QymcBqtcqznc/ncDgcch18xnzui8VC3hlFUdDv92G1WmEymeQ+jcdjAIDdbofNZpP3yzAMzOdzLBYLjMdjKIoi3+H1etFut2EymaAoCgaDAWazGZxOp3wvz2H53HkPea2Kosj5GIYBRVEwHo9htVphNpsxm83k72azmVz7fD6H3W6X95DvJa+T92353vNa+F7yPbJYLPId0+kUdrtd7jnf39lsJs95Op3Ku8/P4jnzd/hdZrNZzpnvJK+Dz99kMsk9m81mcr/4Li5/Ftc37yOvYT6fy/tisViunS/XCK+Z989qtcq952cs//fy9/O+8nd5D5bPg5/F77BarTAMQ859sVhI7OA/PH9eG4Brz5l/zp/l+S2//3wm/G/eB/4/Y5LZbIbNZrt2Psufy/eH5+NwODCZTOQzuPbsdjuy2WxtsViE/l02+PXxqpKN6f/jz67hdYvF4u8A/B0ABIPBxXe+8x0Mh0PYbDZ8+ctfxng8xsnJCarVKrrdLlwuF3w+H27duoV8Po/xeIxAIIBGo4F+v4/Ly0u8++67MAwDT548QTQaxWAwgNvthqqqiMfjCAaDyGazmM/n6PV6WF9fx3g8Rj6fh6IoODw8xJ/+6Z/ik08+ga7rqFQqCAQCiEajKJVKiMViOD09RTAYRKfTwXvvvYenT59iOBxidXVVFlir1UIymcT5+TnW1tYk6A4GAwnyuVwOFosFHo8HXq8XhmFgc3MT9XodiUQC9Xod8/kc3/rWt/CP//iPCIfD+OlPf4pkMinXt76+jpOTE5RKJSwWC8RiMdy7dw8HBwdwuVyoVCq4uLiA3++HYRjodrv4whe+gHw+D7vdjng8jlarhWazCcMw8M1vfhOXl5eS3FKpFJ4+fQqXyyWL02q1IpVKodPpQFEUnJ6ewul0wul0ArhKbru7u+j1euj3+/B6vRgOh7i4uEC1WsX9+/fx+eefIxaLYW1tDfP5HNVqFaFQCPV6HePxGPfu3cOLFy8wn88RCATk/BRFwZMnT/D2229jMBigXC7DYrGg0WggGo3K87VYLHC5XOh0OvD5fNjc3JTvX11dxXg8xj/90z/h61//OrrdLmKxGEajET766CN4vV74fD6cnJxIUPrmN7+JTCYDAAiHw7Bareh0Ori4uEA6nUaxWMSf/MmfoFAoYDweYzab4bPPPoPf70e1WkUgEEA8HsdgMICmaZjP5/I5rVYLg8EAvV4PqqrCbL4CG9xutwRun8+HVqslCXQwGGA4HKLX62GxWMDhcMBqtcLtdsPr9cLr9UpyCQQCsNvt8j0sVlqtlhQNTP4MhpVKBVarFZPJBKFQCIZhwOFwSNDm+xSNRmEYBvr9vgRNt9uNXq8Hh8OBdrst74zNZkOv14Ou6/LzJpMJdrsdd+/exeeff47ZbCbn+OsYgcFggGaziclkgkQiAbvdDofDgVarhfl8jtFohFarBU3TJFl5PB4J6iw42u02PB4PUqkU+v0+LBaLJNDz83MpkliUqKoq/65WqxgMBvD5fJJ419fXUa/XMZlM5HNyuRxarRY2NjbQ7/dhNpsRDAYlOcxmM4zHY1lPw+EQFosFqqqiXq/L/ej1epI8O50O7Ha7JBuLxYLRaCQJxmKxoN/vIxqNStHqcDjQaDTQbDalSPV4PBiNRmi32zCbzdA0DblcDk6nEw6HQ4rc5YKI7wkPt9sNi8WCaDSKXq+HTCYjz2s+n+MnP/lJ5nclhVcFo10CSC39fxJA4bf98HKm3dragqIosNvtMAwDa2trSKVS8vDz+TwikQhUVYXJZMLa2ppUYGdnZ6hUKjCbzcjlcvD5fFKZa5qGTz75BNPpFJqmYXNzE8PhEA6HA+l0Gpqm4fbt22i321hZWUEqlZIHOhgMUK/XYbPZEI1GYTab4Xa78ezZM0ynU8TjcUkcw+EQu7u78Pv9CIVCqFarGI1G6Ha7MJvN+Iu/+Avs7e3JwqnVaiiVSjg5OcF0OoWqquj3+2i326hUKvj7v/97lMtlPHnyBNvb29A0Ddvb23C73Xj8+DFqtRrW1tYQi8WQzWaRy+VQKpUQCoXg8/kwHo9ht9tx//59dDodtNttrK+vY3V1FcPhELlcDg6HQxaWw+GAy+XC6uoqisWivPzr6+sIBoMwDAPPnz9Hu93GYrFAIpFAv9+Xyo73oVwuw+1248WLFzg+PgYAbG9vo1gswufzwev1IhwOIxqNIhqNwu12o1arYTab4cMPP0ShUEAgEEAoFEKpVMLh4SHa7Tb+8A//EIeHhyiXywAAVVXlunq9HqxWK+r1ugTSyWSCzz//XJ5fsVhEt9vFvXv38PTpU6ysrMBqtSIcDiOZTMLv98NisaDdbiMUCiESiaDX62F3dxdvvfUW2u02DMOQ39E0DR6PB5eXl3A4HDg+Pka1WsXXv/51JJNJpNNpeL1eTKdTOJ1ODAYD3Lp1Cz6fDzabDVarFYFAAE6nE263G8PhUJK31+uV6tLpdOLy8hKNRgPD4RDdbheGYcDlcklXGgwGAVxVoC6XCx6PR7oxVrc+nw9OpxOJREKqWkVRYLFYMBwOJbFYrVb4fD70+314PB4oigKn0wm/3w+z2YxwOCwdicViwWAwwHQ6xWAwwF/+5V8inU7D4XDAbrdLJ8BOSlVVeL1ezOdzdLtdnJycSIfHP1cURbpZh8OB1dVV2O12Sca8TpvNBqfTCV3X4fP5YBgGRqORdCHj8RjFYhGapkkRwvvLGBKJRKAoChwOhyRQrn0Ga3aJTBitVgvdbleQleFwCLPZjO3tbQwGA9jtdklewFWgZkCfz+fweDzo9/sAID83HA7RarUkYff7fRiGgU6nI3HSbrdLYWez2VCtViXpWiwW2Gw2NBoNdDodqKqKbrcr18EOBgBMJpOcCxOL3W6H2+2W5zoajeRe81k4nU6cn5+j0+nAZrPB6/XC4XDA4XD83qTwqpLNpwC2TCbTmslksgH4PwD8v7/thwnHbG5uwuFwSNX/4MEDTKdT+Hw+WVy5XE4W02g0gqZpAnUUi0WEw2F5ydrttizGTCYDwzAwGAxQKBRQq9XQ7/fx2WefYX9/XyqOarUqlcrKygp6vR6ePXsGl8uFQqGAarWKer2OYrGIxWKBZDIpLw0feq1Ww2AwkHb07t27SKVSGA6HODs7Qz6fl2SyDHM8evQIz58/x+npKWazGY6Pj+F2u2Gz2RAKheBwODAYDGA2m9Hr9eD3+9FqtZDL5aAoCt577z1omobV1VUUCgWUSiV861vfAgB8/vnnWF1dxWw2Q7fbxXA4hKZpcLlcUBQFu7u7GI1G8Hg8sNlsGI/H0HUdLpcLgUAAxWIR1WoVJpMJnU4H+XwehUIB5+fn8Pv9KJVKOD09RbvdRqlUwtOnT1EoFDCbzQR2LJVKyGQyiEaj0DQN5+fn+Oyzz1AsFgEADx48QCqVgqZp+OM//mOMx2P84he/gM/nQyqVQjqdRr/fh8PhgM1mQ7vdBgCsrq4iGAxiMpngzp072N3dRSKRQK1Wg8ViwZMnT2C1WjEcDiUgWSwW/NVf/RUeP36MyWSCs7MzTKdTHB4eIp/PQ9d1TKdT9Pt9KQpevnyJ0WiEarUqVfxgMIDFYsHp6SmOj48RjUblO9rtNiwWC5xOp8ASHo8H3W5XgpHL5YLVakU8Hkev14Omaej3+3A6nbDb7VBVFYPBAK1WC8PhEJVKRd7p4XAIk8kEv98vgbvb7WI8HqPX60nX0Wq10Gq1sFgs0Ol0YBgGWq0WPB4P5vM5Op0OSqUSBoMBKpWKBMjBYABFUVCpVDAcDgFcwYrNZlOq5tlshlarhWAwKEnlF7/4BSqVCvr9Pnq9HorFolTVlUoFg8FAoJheryew32g0QqVSkcKn2WzKtbbb7Wsw6jKkqOu6QJbs5MrlslT6VqtVKnC73Q6XyyUFLj+T0DfvS7PZxHg8RrVaxWKxgGEYUrja7XbpRv1+v3SY0WgUrVZLYonb7cbZ2RmePXuG8/NzqKqKZDIJl8sFVVXxjW98A4qioNPpSNBnF+T1eqVg4PvDw+v1SoGmaZo8AxaphMZVVcX6+rokncFgAKfTKcnI5/NBURT0ej0AV3B+p9ORezIajeB2uxEMBqXLrFarmEwmMJlMkvSCweC18/utcf5VuT6bTKb3AfxfACwA/u/FYvHff9vPJpPJxV//9V8jHo/LDe50Ouh2u+j1eqjX69A0Da1WC36/H4FAAL1eDx988AH8fr8Es263C03T4PP5cHR0hHfeeUf+7vj4GGtra8jn8wiHw5LUfD4fCoUC3G43YrEYnE4nHj9+DIvFAkVRBKrid7JK/+IXv4idnR1Mp1O02204HA5Mp1MMh0PE43GMx2Ps7+9D13VEo1GpXtgyz2YzpFIp9Ho9jMdj6cp8Pp9U87u7uwCAWCyGZrMJu90uEKLdbsejR48wn88RjUblfKPRKCqVClRVxcrKCjKZDBKJhCRqwgEOhwOdTgeapsnnMdC/ePFCKu/z83M0m03MZjOk02lkMhmsra3h6OgITqcT4XAYxWIRuq5DVVVYrVbhzKxWKwqFAgqFAnZ3dwX2un//Pl68eIFSqQSPx4NQKIQvfelLACDBnPyUoihoNBoAgEKhIPeZVZfJZMLm5iZmsxkURYHZbIbT6YRhGKhUKqhUKkilUpKYNE3DYDBANBpFo9GQyp+wUz6fR71eh2EYSKVSmM/nWF9fx2KxwMnJiXQqAAQejEQiwt+lUimB+Nht1Go1TCYTzOdzxGIx4fLMZjNGo5EE5Wq1CrPZDFVVEQqFMJlMkMvloKqqJA/gKuBPp1NMp1PEYjGpUtmhEGJersYJjZAXrFarUBQF7XYbuq7L+8mgDgAulwvpdBqTyUSe6TLcxi6CcB0Tq6IoKBaLmEwmghD0ej20Wi2Uy2XY7XbhfKxWK3Rdh9/vlwJxPB5LRT4ej9FoNKBpGhaLBXRdF7iM7wK5BFbopVJJnik7bhZQqVQKVqtV4M7FYoHJZILZbIZ8Pg+fzyc8G98Pdoj1el26E7vdjn6/D5fLJR0h3y0mvU6nI880kUggFArJuuB9ZHHAc8/lcrBar9gNFjKGYQjcReTBbrdjPB7LO8JuyuFwYLFYSJfT6/UkkRFyY1z1er0Yj8eYTqdYW1uT4iUcDst3s8ObTCbo9XpSgGiaJuvPZrNhMpngxz/+8aPFYvHmb4vzr4qzwWKx+CmAn/5HfpaLgaT6YDAQTJftpaIoqNVq6Ha7SCQSKJVKSCQS0uYuFgs8ePAAhmGg2WxiY2NDsOPJZCI3i/8+OzuTys/tdgsvlM/nMZlMEI1GcXZ2ho2NDbhcLkynUyE8fT4fBoMBDg4OEAgEEAgE5AEBQK1WQ6fTga7rcLvdqNfr8Hq9MJvN6Ha7AhmOx2OpLpLJJD788EMJOqx0XS6XVCKJREJ+5+TkBOPxGJqmCQ7PxBWNRjGfz6V6PDw8lOrR4/EgGAxKFb25uYmf//znMJvNSKVSGI1GEgTYVpPktNlsEti9Xi96vR7sdrtwTqVSCU6nExaLRRYbv8MwDHi9XoxGI6n8ZrOZVInlchnBYBAvX76Ex+O5lhCm06lAGRaLBQDg8/mg6zra7TZsNhvK5TJSqRSazSZMJpMkQMICTFCj0QhWqxXValX4D7fbLbwX36mLiwvphHRdl8oQABqNBtxutwTqZDKJp0+fwjAM7O/vIxKJSIBkh9tut691L0w+xMQppCBMs0zWsmvxeDySGCaTiXQIuq7DZDJJAmb3Mh6PBYojUc8qn4mJgbbX6yEYDKLb7QqM6HQ6MZlMMBqNsFgs4Ha7JbmwwLLb7UgkEgCAdrstPJTdbsdwOES9XkcgEICmaZhOp2i1WpIAgSvBQTgclmt1Op0SxJer7NlshkgkglarJVU7K3KfzydJkqIWVVUlgbJYY4dCQp7JivyKy+WCpmlyjV6vVzppJtzRaITJZAKn0ynXQ06KEONgMBAkhpxavV7HYDBAJBKRDklVVfnOSqVyTXBCeIpIgsvlEt6HnYXJZJIkzA6HsN4yRMeE0e/3oaqqoCUXFxfC7/HzWAiw855MJqjX69jY2ECr1UKj0ZBk2W63YbfbEQqF8B9pWiwPHz78j+SDV3r8+Mc/frixsSEYKLuNZrMJj8cDVVVxeXkJTdNgs9mkmpvNZqhUKrhz5w729/evYb5cQDabDd1uF4FAAN1uF3fu3JGKq1QqycscjUbRbDahKAq63S4cDgf8fj90XYfdboeu61IpapqGYrEIl8sFv9+Per0OVVWRzWZFYXTnzh3E43Eh6iaTCSqVCu7du4dyuYyXL1+KIo2dT6FQwGg0gtfrRSwWg9vtRqfTkQp4MBgIcZvP5+H3+5FKpeS6SSYSniN3kcvlYLfbsbGxAbfbjZOTE1H3mUwmDIdDpNNpwcBTqRQqlQosFgu63a4s7lAoBLfbjYuLCxiGgVgshlqthng8DpvNJl0SE0ClUsHq6qpwNDabTQJIIBDAxcWFBPtms4larQbDMDCZTNBoNGSRswPK5XLwer3ynlA0Eo1GJdi0Wi2USiWBGIfDIVZWVjAYDGQxp1IpGIYBXdeF52DiY5FQr9extraGra0tWezD4VAgxGAwiKOjI+keNU1DqVRCtVoVHJ3XPpvNUK/XJXgQnqAogO8nkxkDsaZpqFar6Pf7IqDQdV0CIoPzsiKShRs7GACSmBwOB87OzhAMBjEajSQh2mw2uN1uTKdTdLtdUecNh0NRgy2rzxwOB5xOJxaLhay3fr+P2WyGdrsNr9eLer0uCicmNX6GyWSSJM7ihIIFcj/kgXgfqCAk99NsNkVN1W63RVzg8/nQ6XQk+BGqczgc0DQNDocD/X5fEg6LHgpedF0XqJnvC6/B5XKJYpKQXK1WE250OcEZhiHiCp4PO1IqBheLhSQ2CgJsNpsIKGw2m1AE7Fz5HVQuDodD+Yxl6Jdxwul0wmq1SufIjsdqtaLb7YrowDAMWQvs0llAxmIxDIdDEY+Qp1tWGnY6HTx9+rT48OHDv/ttcf61SDbf//73H37729+WboMYJrHnW7duCbYZDAbx5MkTwa+ZqefzOdLpNEajEQqFAi4uLgT/3NjYuCZVJLRGLJTVVDgcvqa2SSaTqFQqSCaTcq5UZKytraHZbKJQKGB9fV2gHqpKisUiptMpPv74Y6ysrAC4IjRPT0/R7/fx9ttvC4SQyWSgqioikYgIB2w2m6jXqLxJJBKi7ikUCvD5fKIyaTabUj2qqgpd19Hr9RAIBJBKpRCPx/Hxxx/jX//1X7G7u4vLy0uppofDoSR3VsTz+Ry5XE4SFQNWo9FAtVoVkQaVNVtbW5hMJkK0ExYgjBGJRPDixQu43W5ks1k8f/5cAsgf/MEfyGcxAFutVni9XqmKmUhbrZaQ9r1eD41GA+fn54KlJ5NJrK6uCvcQjUYlidntdsRiMQkuvV4PT548EWEEg8Kyku7s7AyRSATVahVra2s4Pz/HbDZDsVgUnpD80LNnzwSaCgaD0nWSWGUA6Pf7GAwGUgGzumdXycRGDJ5iGUqiSWYzADBILnMOmqYJfFWr1QBcwTfRaFRUVACk6mXSmkwmAlWTZGfnTDhmWTpvNptRrVYl6TCAsjNmZc3f93g88Hg8ck+YqCg4YcDtdDoCd1HxFQqFrqnbKFJYDsqE4BhAKakHIN0DRReETdnxEBq02WxotVrC7fE82W3wnSeZz/USDocFkp7NZigUChKjKD5Z/m4KO5jcTCYTSqWScDqEwTqdjiR+dmR8nlarVTpQSvSX0aFutysyfa4rFjBUnk2nU6TTaRFjEPIkcsH70+/3Ua1WMZvNhMMjd6aqKh49evT6J5u//du/fZhOp+FyubBYLJDJZKQNZGdycHCA1dVVRKNRXFxcSMLwer1oNBrw+/1ot9tYXV3Fs2fPoOs6dF1HOBxGPB5HtVpFPp+/pnAijulyuRAOh6UiHAwGCIVCoiJzOBy4uLgQ7sHn88FsNkvgo5SS3Vm320UoFEIul4Pb7RYVTa/XQyKRuJYQWb2znebLz+qW0B0XeD6fl8DAl4AvIV/iTqeDWCwmxJ6qqgKpsbPQNE06shcvXki3QtVJsVhELBaThE2OYTabodlsChxmsVjQbDYBXLXp4/EYz549g6qqcDqdKJVKIgWNRqM4OjrCaDTCdDqVIM1qX1EURCIRVCoVdLtd1Go14bdOT08RCoVEiRWPx2EYBqrVKnRdFziIvAZ5i8vLS3g8HhwfHwvu3Wg0BEZi8Gq329cWfyQSAQBks1npbMll5fN53L9/XzrHSCQiCa3T6QiHxufRbDavQaCz2Qy1Wg3BYBCXl5cif2UHzIqRUBsrTQbbUCiEs7Mz4U58Ph8ASNVJeGs2m8m1ejwe6V4onebvUbLPwkJRFEmW7KqGwyGCwaCMFBCyyefzGAwGCAQCcLlccv8JJ5FncTqd8Hg8UkwMh0NMJhO5Zx6PByaTSdYdk9ZoNEIsFhPehcmRAhZ2dyxGeRCqpYyfUPTyrBihad5/nisTHJM4k5DD4UCxWITJZJJnzz8n8mEYBsrlspw/uxjObWmaJuuRXRyhv+FwCK/XK3++zMGxaFmOF+zsKJSaTCaisCPPw2fCcyUtwbXOBEUIjUXqZDKB2+1Gq9USGkJVVSkSlmeWmPR+9atfvf7J5nvf+97DnZ0d4VLS6bS0vtFoVFq+TqeD4+Njqb7tdjtGoxEcDgeCwaBo+2/dugUAEgiKxSL8fj+2t7cFatja2pIKpVAowOv1IpPJSBVArHyxWCAcDqNeryMcDqNSqcButyOTyUBRFAQCAWnNqUw5ODjA1taWJD+2oS6XC7quo9PpwGQyoVwuYz6f48GDBzg7OxOi0+fzIR6Pw2q14itf+Yoo0BKJBKxWK2q1GmKxGAKBgLTUxWJRZnXYSWmaJpVnNpuFqqoIBoNoNpswm804PDzEl770JZTLZcTjcdy9e1faec4ANJtNmQ8pFouIx+NQVRWBQACJRAKdTgf9fh/r6+vCLWiahna7jXQ6LVwc5bPj8RixWEwGL8m7rK6u4qOPPkI4HMZwOJRKdZn8ZjXOe0sl16NHjxAKhdBoNLC3t4cXL15Ico3FYuh2uwiHw4hEIpKgYrGYDGDWajXM53O88cYbAsWwyKFii11Wp9MRyJHPnHMHn3/+uchLd3Z2JIlWq1XhB/i+TSYTUUytra1J8cCg12w2r8FmrK45/ByJRERKHIvF0Ol04HQ6sba2Jl2x1+uFxWKRIUy73S6KQhLDdrsdmqaJqtPr9QpMwu8DcA0KY7FgNpvl+pcJeoppyI/2+30Eg0GR8pIHCQaDonhk90auilAPSexwOIx2uy38CoM2gyWLU4vFIrNdDP4kzR0Ox7XBYsrITSaTKOr4DGazGfx+vxR+7JaW4UUqOVlYECqmDLtarQKA/JzJZBJOkomP7wO7EfJPVHpxPoqcMr+3WCyKwMHv96Pb7YoqrNVqwWKxCMe13DGSL+ZzIozI4dRl/opoEPm3drst32u1WhGLxeSe/Fqt+fonmx/84AcPHzx4IBk/k8kIKcgLYgW7sbEhVXChUJABLurECRNQlbS3tyfKkl6vh8PDQ5EMEn6p1WqSpff39wUCsFqt6Pf7iMfjokgajUYS2PjdoVAIR0dHwruYzWYUi0WYzWZUKhVZEL1eT6qwer0Oq9UqD3U0GkFVVQCQ2ZZsNitVzmg0Qq/XExUSqz4S4G63G41GA4FAQCAAp9OJWCyGfr+Pe/fuCYHMRcvvi0Qi4jLQ6/VEMcUXld2jYRh49uwZgsGgQHwMHjabDaVSCT6fT/gISkiXVThWqxWZTAb5fB4ej0cWdLVahd/vF8hgOByi0WjAYrFItcU5D0JdqqoKXLa5uSmdFgMoFVTE1UkS+/1+4dxIYPN7I5EIdF2Hw+FAt9sVQj6dTuPs7Ew6Tgawer0unWa5XBasPhKJwOPx4OTkROZ9KLKgSIT4OatrChHIGzJAMpAzkblcLpFVEzKjXJ/qpOFwKIQ+AOHo+A7NZjNEo1HpBj0ej3TK/B1CJW63W4IgFU0UvlCyTDeLarUqBMwUOwEAACAASURBVDILIHZb5HHYPXW7XYGIKWJoNpsCBZNT5H/znSfEyMFSxg2KH/izLOqo0qTYhcULCwA+C5Lv5BEpRmD3ywTL66E4g8k0EolI8M1kMtJ9satxOBxyn3u9nvBu7FDIQy+rWzlo2e/3pQjieVitVhn05bMj/aDruhRt/F2+E0R9+FnsrsLhsMC1vMeNRkPgR3KPnIGKx+MSGwaDAQ4PD39nsnllarT/mYPVa6VSgaZp+Pa3v41Hjx4JJlypVKRyplLj5OREKn0GxvX1deTzeQyHQ8xmM6iqina7LTI9KrHOz89hGAaKxSLG4zGCwSDsdjuCwaB0LsTKWR1xkK1SqaDT6WBzcxMA5IVwOByIx+MoFAoCOdVqNWxsbKBWq+Hu3bvw+Xw4Pj4WKxNOgadSKUwmE5nBcDqdMsdTKpVkkpcLz+Vy4fDwEJPJBLFYDMViEaqq4t69eyIV7vf7CAQCOD8/F1VSrVaT1nqxWCCXy+H9998XDoEJioT8eDwWOGq5yiWxzMFJj8cjEs9qtYpKpSJSZxL/7733HgqFgkBZfKE7nQ5WV1cFfgkGg/jggw/knHO5nHQlVqsVwWAQz58/x+XlJdLptJDgwJVUNJvNYm9vD16vV2Ye3nzzTdTrdanWCbsy2ZJs5YwGuSDCXOPxGB9++CGi0ajAoNPpVAQlh4eHkiytViu2trYAXHXWgUAA9XpdKuh2uw1FURAOh2XehiQ2u3lCRh6PR5InAyrnYqbTqQyxUqZKfoLX1e/3BVry+/0SJHgexPvJkXLQkV3PsjUKSWYGORYirVZLRANMXNlsVq4fuFKLkaxeHkDkumI3x3vEcQLgNwT/eDyG0+mEzWaTrttkMgnJzeA5Ho8xGo0EIma84HeRu6B0eNlSZjQaibSZqAPREyq+WMh5vd5/16EwOTP+EFlhR0E1KDsjdrqE4ck9J5NJEUDY7XbpOPnMVVUV7otxgxwQnxljF5WjhMOY1Hn/l5MZi2uPxwOHwyEzNXxmvV4PbrcbJpMJKysr15Sry/Zav+14LTqb733vew8DgQCePn0qsMH6+jqcTqckkPv378tMQq1Ww+rqqlRcgUAA5XJZAhdwVUVfXFxgNpvh5OQE8Xgck8kEL168kEEpv9+Pt99+W2YOHA4Hbt++LS88H0owGITX68WTJ08QDoextbUl2G06ncZsNsPe3p7M8hC6WVtbk+5nPB7j+fPnUmFR/DCfz+H3+/Hy5Uu43W4YhiEt+71795BKpVAul4UUTKfT0lUQZuTiozyc8AkrT0KD1WpVquCdnR3s7u7Ky0x83TAMvPHGG+h0OhIk6WowGo3gdDpFIksugBUmseKtrS1kMhlJFIRVaNVC2Mjn8wlpms1msb6+LoHznXfekcChaRpqtRqGwyHG4zFCoZAEoUqlgkKhcM0TiomTQg0O9F5cXMjgHaEsDsB6vV6EQiF0u11ks1l0Oh0UCgUJDIRtqAjk9RiGgXq9jtXVVZGimkwmgWUDgYA4X3DxsyLd3NxENBqVxOvz+aQypQILwLVASeiWXRsXPIUtFLAwkfj9fim2yB8yUBLHp+LT5XKh1WqJZQ8LrOXpcgYnFogAJMBRPcm/YwBi4mKCYxVPmMzn80kxQLm6y+USmJEwFQMroUHa+5Ab49gAYbfl62WSZBKgVHhZSsz5qsViIX52sVgMjUZDZkm4Dpctf2az2TWZO8+LyT0UCknHQncEdqUslgjpU/pMOLDRaEhiZxHL+8DOhXwbB32pNiwWiyIqYZJlZ14qlaSjYqJnx0nxCWcWiVIQtSDvSIk8u+rnz5+//jDaj370o4ehUEhkvMQ8SWBNp1PBpEmukjAnNOJyuWTOo9frYTgcIhAISBAxmUzXpK6apuHs7AzValVUH/RIOjs7w1e+8hWcn58LeZxIJASuikajGI/H2NnZQbPZRKVSuVb9EH8mlABA2vx8Pi/eZL1eT1QrVH1Qwuv3+0X9xResWq3i8vJSyGQmBGL6d+7cQSKREPiFNj1bW1tSjXMCndXp3bt3RY1XKBREMnxwcIDpdIrt7W3Bg1utFtrtNqLRKEKhEMrl8rVqkd0UuQRN0wTec7vdSCQSKJfLYn1Sq9Vgt9sl4Pt8PoETS6XSNQeIUqmE27dvYzgcIp/P4/bt2+j1eojH41Kd09KF7w4hGVryLBYLHB8fw+VyiRSYcxOrq6t48eIFdF1HNpsVWJXSZ3quUW3GhffJJ5+g3+9jdXUVKysrwgVVq1VxX2DHzKqRdi0MagymrEjJCxAiZdJhR0jehNU+Aw/JYSYEktace2Ii8/v9GI1GCIfD6PV6EuCSyaRwJVxrlLOTV5nP53C73TI4yM6HqkNKb+lGwe6Xs3IM5gy2VAFyxo7QGmdRWDTwuzjXRk6PM3C8pwyy0WhURCMk+VkoLCvezGazFCChUEiUZVSeMUEAkK6QaMayxRM7A3ZcvJ7hcCgDvoxtVAlSrMEhyWazKfwfz5OJnN/J82PnQtiQTgyLxUK6MnbFhGS9Xi8qlYrA2ywOCbEyqVFyDlwJPcrlsjz/5WdB2TnvwX8KNdqPfvSjh2+//TZ8Pp9UE6z6j46OoCgKzs7OJJCvrq7KvAW9kTY3N+VhptNpGVLqdrsoFouoVCoAIEZ0pVJJhACUkN66dQutVgudTkeEB+w8aLNxcnKC09NT3L59G7/85S/h8/nEmJOLjbwHZ1s4+MWksLe3J3zLrVu3UCwWsbOzIxixruvweDw4PT3FaDRCJpORYPnWW2/B7/djOBzizp074uXGqeOzszNJUlSHEYcn38GJ9WW7kclkguPjYywWC5yfn4vwYTwew+FwoFKpiKmpzWaT2QIqnJ4/fy5EIq+NMMrq6qqQsQyQnHamFJxB2WQySeXG2YdgMAhVVVEul3F+fi6ELi1jdnZ20Gg0pOVnMOZQnq7rQpwTStvc3EQ2m8X29rYEbhLy1WoViUQC9+7dQ6VSwcrKith2aJomknKHwwGv14t0Oo1CoYBIJCIdzGQywebmJsrlMvb390XVyAp7GZ4gtMbATsKeliEMWh6PR2Y1CO9S9s5OwGKxiAqSijF2EXyWnU5H4E12Pj6fD41G49rIAe8zC7V6vS6Ef6/XQygUkvOmYoleb6x+WXhxAJaEPXmocrksneh4PIbH40EkEpECaDkxMrk0Gg0JlORECWcSDue9pVqPXUutVpNOiJJpFn2MDctwI9WgVKnyHpIftFqtKJfLCAQCsp4oYGBHz0TLAdllMYOqqlIkUGDD7ovrgPN85HLofm8YhiR+ANL1LU/4Hx4eSsFGFSnVpZxVGwwGIoShs8B8PpchZFVVRb0KQNwS6DZA3vT3zdm8FttCk/zc39+XYMEBR86ffPnLX5aXN5fLCWzW6XRQLpdxenqKaDSK8/NzXFxcwGQy4fLyUioHwgOshOgAa7fbsba2JgHXbrfLjafpHSGLx48fI51OAwA+/fRTsZZ59uyZBF66vPIaDMPAysoK1tbWsLKyAlVVsb+/L/Jakpe0I/H7/TLXEQ6HEQqFEI1G8fLlS6nWVFXFW2+9JS8CBykBSBXH6pZSynfffVeqkUQigfX1ddy9e1c6kE6nI5Lw9fV1qZQpTaVMlsn09PQUkUhEFE0kDN1ut1SgnFQmNKfrOuLxOADg5OREOrBEIoHpdIqXL1+KKwPvPaXOTJocOm00GvjGN76B9fV1qcCJzdPQcDweo9PpIJfL4fz8HJlMBi6XC/F4XIaBGfgpP2U1OBgMkM/nJTk1m01J3vQ+q9fraLVaODs7kwDMYOhwOPDBBx/IO0s7H5KxVOcxYRIeI4zEqpcdLSFOt9sN4AoSY7fidrvlveBzW+ZciO8z+QCQhEDegKqnQqEgcBbhEYfDgUKhIMOYFCo0Go1rnmVOp1PgP1ocLfNPPFjgsIJmAURHByogQ6GQiBI4XEmYnZ8BQMw2OWdHkn+Zy+G9YsFKDov3imgC+VRCUvwMTdNEws17SLVnKBSSgMz/brfbODg4EOjZ6/UilUrJvaOoaVni3O12Jf5Raep2u2WdEYZmEc3EXyqVxOGC3BthwHQ6fU21x44XgEjCOXfGAp3XR9SIbiE8BwAyKpDL5cTx4vcdr0Vn8/3vf/+hYRiIRCKijGJyGA6H2N/fF+z4Zz/7GdbW1tDr9YRUY4Jg5ULVSalUEhsZmg1SGULPLuKpk8kEnU5HyLR6vY779+8jFAohn88jGo2i0+lgZ2fnWjt9fn4Ot9sNp9OJ8XiMi4sL0bInk0nouo5SqQRd15HP52X+pVwuS4AkjGIymWSglF0I5wS8Xi/sdrvMdBQKBalIVFVFPp+XIAVAIJRisShVN7kfQmknJyc4Pz9HPp8XnoHSZiZ6k8mESqUCXdfx7NkzMRalnQh9qPiy1mo1sZKnBU44HMb+/j6azSa63S4+/vhjUb1QRrxYLEQJxql6Bv0HDx6gUChAVVV84QtfkEnwwWAgA4Ek7h0Oh3BCXKiEOUms8rsJz3FehMpDdrOcyCbXwGTFKXuTyYRMJoNer4ft7W1R5dlsNjEh1TRNLD6oPpzNZkgmkyKrpecUIaZcLndNmUbohMOehNscDoe4awNAtVqVdUFTWXYmJMAJefV6PYED+V08R3YNVJKRsyA8yo6BhY7L5RI5Mwdz+T00jeR5ULjD3+fPcH6D0CIVd5QBs4Dj9XEvJpvNdq27Y8AGcK1zZ/fIJEuYimT+MvwFAPF4HIFAQBIXux9yHhQ8sOtzu90oFAqyPUC/35dkxs+2Wq3ScfJaOZfHcQG7/Wr7AsKl5I6XnyEASQCECvnMKBZioUBz0+WimddMxSZ/f9l1gVwZuywWUCy2uC5YoBmGgYODg9/Z2bwyI87/mSOVSi2+853vXMPsV1dXkcvl8OjRI9Gwp1IpgVdom8I22OfzyT4q5Fru3r0Lq9WKy8tLMdI7OTlBLBYTbfuy6/Hx8bHYjAAQXJOzB1SJsNWkESPnWjjlzODAoS5KaPkCBYNB5HI5ZDIZISeJrbMKIQHaaDSwvr6OlZUVTCYTfPrpp2i1WtjZ2QEAIf4BXJtm5vmTOHznnXdknoQ2GqwuWTHu7OxIsOCAIRciAFxcXAg3wu0GSN6vr69LBU5VztnZGd59911ZpN1uF9VqFbdv3xaOi6IGylXX19fh9XplePXy8lIgCrrWAhAZOmGfUCiEX/7yl7BarUgkEnIOo9EIW1tb8Hq9OD8/F9UXYRl20BaLBel0WuA+Cg4CgQAODg4AQLYfYBeTTqdRqVRk2JM2O4Tx9vb2pOKj8onvFqtzbl/BhJFMJmG1WpHL5eDxeJDP5wWCZfdIqSn3dTGZTAgEAuLrx0S07JfF8wcgHBz9rZYrdxZj5DHJdRC6I2dJBwYGQ7pws/In1Ev+hZAQkw2TPQlsWsfQAubRo0f48pe/LHNa5ISofGOBQPgawLUtBniPaV3FbsLv98s7TXJ92W+NFTsFExx25HwS9xXi3NzyvA+5Ec5nUWHJgVOuI6/XK1ZEhOe4LQf/jomB58P1Q7HIst0NcDW+QP6MwhXGRfKF5KsZ1zgMzaTLjocoB42K+/2+zNl4PB6Rq1OZRgn/T37yk99pxPnawGjtdltuuq7r0s6TKOVicDgcIoPNZDICb7hcLtlfhpgpEw9nKAh18eXmni20/FAUBQ8ePJCHAlxtluXz+fDVr34Vs9kM6+vrYlFOOWA2m0UymRQSnufpcrmuCRIsFouYFnKjK8plaafidDpxdnYmFex8PkehUMDPf/5znJ+fyxYC1WpVCMNAICCurfStolcS5aanp6col8syfc5kaxiGzL0Qxjo7O5NKiZCKrusCjXEgllPpTFhms1kUaG63W2YRptMpjo6OJCgVCgXZD6TdbqNer2Nra0sm5InRE2oqFAo4OTlBJpMRO326UTOYG4aBdDqN9K8HSYGr+RoOBHOBWK1WmTl6/vy5qA273S6ePXuGcrks8yfcDGuxWMggKa1BCMHSpYKBr1aryZ4onKVgRbgspmBHw2RJZRgJWyYCvmOtVks2xJvNZrLtBqvrbrcrXT63FKAakVwLhQcUo9DWiMEagOD9hOEoyyVESFKacA/lyISrydf1+33pEihZJ1zIipkuEZTscnAbuNpuAoAkBnY8TD5UCTIpcC6K6ARtcPhuUjnGrQMACJ9EqJ4zOUyAFEmQt6FSkgOWhFgJY7Pr4YwOeRF+N58rOSfCgzR15bNjZ8Q9mvi8g8GgGPcuzwuxu1vmY2m9dHZ2Jt0e3TgIibPw4j1nAUpRALswDtZyQJnc2nQ6FTUlndB/1/FawGg//OEPH7711ltYLBY4OjoSu4hsNovxeCwyPVZgnAAmYWU2m6/BJQwq5+fnMuugaRoODw+lBaeqitAFq2l2V6x08vk8ksmkLExWRKlUCv/yL/+CWCwmFVCz2YSu62g2m0JaDgYDBINBFAoFqSI//vhjIR1VVRUBgKIoYj5qt9tl/5yvf/3rInCw2+0oFotwOp2ylQJJwtXVVcznc1xcXMi2CIvFArdv30Y0GkWxWMTl5SUACLTABMcX1uPxIB6Po9lsirQagJCK/HsuYi664XAoNjecNyIhTqlpqVQSvoIBoN/vY29vD8PhELFYDIZhyAZfHOCjfxjhU3a6nFx//PgxotEoXrx4gWAwKMOtJH25O2en0xFfJ6qhyuWyJEHgyp6GEAN3a2XiazabaLVaAmu2222cnp7C5XJJtZ9MJtFqtfDOO+/g1q1beP78uRDna2trMjfGYEkIrdlsSmGyrFCiU8by7pOEMElQU8FmNpuRzWYlaXFWiZ535HYURRHuhbMj7CrIWwAQKTghQ86LcIiQ4gWqkQhD8Ty5Zqn64/vFzpGGsZ1OB7du3RI4lqQ5OxKao1LkYLfbRZZPro3T8wz+lDkvFotrXn1EGyiM4Nofj8fXrFsI5c5mM9lLilAiYTGq0OhWYbVe7eDKe0xTXHInVNFysJMIBmF3bgJHyJAdFNWZ0+nVFiakFNhRLDuo83xYvHKUAoA8ByIoRDoIjdEXjZ0UO0N+BgUT5M9CoZCs00ql8nthtNci2fzgBz94+P777wOAOMbS04rminwRzs/PUSqVBCbZ2tq6RhwuFlfbI7/xxhuC7yuKgqdPn0rS8Hq9WF9fR7fbRSQSQSgUgtVqxZtvvokPP/wQVqsV9+/fv+ahVa/Xkc1mBWKiVxEdTw8ODmQ6mgmNCrL0r/cEmc1mKJfLuHPnjgzwqaqKvb09mQQHcE3Lr2kastks8vk8zs7OxEG5Wq3KgiB/dHp6Kh0NNzJj10b4ixXi22+/jUgkIpP1nHeZz+d4//33hWRkMqnX6/D7/cJJKYoiu276fL5rWv1EIiHVHA0VLy8vsbu7Ky86vZeoPKS9x+npqeDq5EKoANrf38d7770nZGij0RAHgA8++ECGWkulksCTX/va19BoNMTslNXjdDpFtVpFMplENptFrVbDaDRCMpkUxRihr7t374qdULPZFHKeiajRaOD4+Fj25OGuknb71SZeiURC3gVCFsPhUPzUOK9Egp/Xxg48Ho9fs5jhBD+9Aonll0olSTyc56HMl4FtWTm2srIiIg3gqqAgFDoej2XImkaexPrZtfDzqC7kPR+Px7h7966YazIhcL6IXAgRC3ZxlDsvT+oTXqOCjMrBZT7DbDZLt8D3lXNHwWBQfpbDo5wVIUe1PLzNhMx7xiRLmJQ/5/F45PkxxizzJ9wmg0gK33EqzigMMAxDCs9WqyWeY8v7+XDqn50i4XLCkxRBMDlyWwlu/Ef3ByrjyJkRsWDcIW9GGHB5F1i6jnCQnv/0+300m034fD48efLk9VejkfjjoB0rMk5ap9Np7O7uQtevNiK7c+eO4L7EeBkcIpEISqWS7E9ydHQEACKr5rR0pVKRXTcByIvDDdfo3Etris3NTXzta1+7dvO5ve/JyYm0+Jw4/uyzz6RFJcQSi8WkU5vNZshkMiiVSigUCiiXy5Jc2ZJS/cPJdRKHlUpFhlQ51QtAvNkIp7lcrmtzCCSWK5WKBF+qeFZWVkQgcHh4KKIJkrjb29solUpS1VitV9sin56e4qOPPpLqnsEjGo3KRk0ctqUShv5vuVwOL168kGd4cXGB6fRqt8yXL1+i3W4L8ZtIJJBKpTCdTnFwcCCwKBVznAHw+XyiSopGo8jlcqK64/MhbNbr9aRw0TQN0WgUKysr4qLA94ZDn1THMaERg6cAhF1ZIpHA1tYWLi8vsbW1hVu3bkkFv7wfCBe3pmlYWVmR7oJV6rLyjeIDrhcSxtzSgEGDkB1wfedYHnyf2PGQ/KWqjBAorYRsNpv4mvH9pA0/xTXspJbthLjJX7fbRS6Xk06HvAcn3gldcQCU0BhhRQAyD0Nukwlgmb9YVvHRvV1RfuPwbjKZ5N/c5ZexgKpJKjepziQUyo0cOWxKoQbXHTlJfic5UXb8THCEx/iMyccQaiY0BUDUjiww+LPsds1mswwzM7ESUiMPz9+r1+uiuAPw75SenPsh1MYkwt/j9zG2EVWhlRMLiN93vDadzd27d2GxXBkn/vM//zNmsxmCwaBICff396VNpMkgEwtJR0JEyWRSqgpa51PNxSrgzTffFEI/Go3C6XSiUqkIHABASFBFUXBxcYHnz5/LXjNU8hQKBcTjcfT7fYHUCBGx6uEDyefzMr9AOTZtIXRdx+XlJRaLhcBkiqLg4OAAk8lEPN2ILZN85bDlnTt3hLva3NyU9pqdRalUEvscWrMTjrp79y5UVcXJyYng74RJFOVq/5flAVJWt6PRCPF4HO+8845APZFIRGTD6aVtnNmBcvDW5XJha2sLGxsbGA6HODg4wMrKingxcRCUw5TD4RChUEiUceSruJc7n7fH40EikRBZ82AwwJMnT7BYLK7NBCw7FxPWSiQSCIfDuLi4EONRQm+858TBuW0FEytVZ7Tn58Q74cl2u41AICASbjpAEC6hIzJJcApTgsGgzH/wfM1ms1SrTC6EtKh4osSbPEIkEpEOY9k7brkLIHdKRSjXGxMtB/hUVZUOgCo6FiB0v+D2zgze5AApvKDogEmVAZfFDAtOboewbGRLwQTJf0LbLFT5M8BVwmWCZfdAzoNDpeQ/lv3kqMIiB0teiAUBK/3lPXI4ysAkxvhFZ5BlmydyrlTL8VnQd5B8CQM8oTcqAVmA8TprtZrwpkRkeI8om2dci8fjMhRP2Gz5+bAAodiJ8ZXqSbPZLCKN5Xfok08+ef1htO9+97sP3333XWkVWUUQew+Hw7K/+8rKiuCitPigfJiDnoqiIJPJiJIim83KDowcNqNqgyqxJ0+eSKBlQCVUNBgMRLrMvW3oSRYKhVCtVhGNRlEul/G1r30Ndvtv9jmnYSA3EptOp7Ix2nR6tcEZfcRovUN1UavVEhy30+kgHA7Lvi7LW2XT0YAwGUlPutgyINKEklCax+ORwTZOOnMieTweY21tTVpzWsAfHx8jlUqJB9pgMMDZ2Zn407Xbbdkwji97vV5HKBQSSw5Caey6OMdCI0MuNCqYOJFPvJrwyM9//nNxdXA4HNjZ2ZEBSG4pwY5nZWUFFotF3K/JlfX7fWxubgocQ4duksZ0JGCi4cxGv9+XTdlY5ZXLZbFXunXrlgxonp6eCo7P95b/nk6nMhxJYQSrVwYDADJ/RVKagZZJiFJXJikGZFVVZcCYcxJ0EdB1XYZ/mchI1tOanhUt14zL5RJYm/eRiYudBwM87xkTIRVhvBf0AqOjAK+DYgYGOiar2ezKiZkkODtEbhtByFhVVVk3DLLkzVhAMWgzsQFXkl/uRsnvm8/nMoC7LGQil8QkyVkzzg4R2idczgKN3Sy/m8Uo1wI7O265nsvlhCNiQcfEwBhGuJUuHpSHs3hh90S+KxwOYz6/MiBm0UYxBJM//fgozuCsFvlOFtC0Lmo0Gnjx4sXrn2z+5m/+5uEXv/hFFItFHB0dyY3nPhokXm02G3Z2diQYclKbqqdkMim2D1tbW/LfJpNJxAD0fCIxTAjv9u3bMjeSzWYRDodRKpVElULnYgDY3t6GoijIZrOIx+PC06iqing8Lu62hKEM42pXSz4Ym82GZDKJdruNUqkkUFG/35fdNMfjsSieut2uDH5SokijTFZkXFTNZhN7e3toNptoNBoyjU0pOZMpF/ey3JFKo+n0aifNs7MzeQ602lldXZUuc3nIjQuAAZRBj1sxpNNpccImT0QJOAuKSqUiIgqv14vT01NRUsViMTgcDpn9IIw1Gl25cFPt1O12kclkxMSTFThhiG63C7PZjMePH2Nrawu6rktHahiGuASwq1nemZCVHy09FEXB0dGRVLe8r5xP4g6f2WxWKn9aj9CmhvAu5bMUn/C+snDh9DlFGYR/GDg4MuByuSSxUxxDnzJ2GmazWQo6i8Uie+vQjgaA8EiEyFj9WiwW6V6X9zohXEWugYmg3W4L6U9ojBC4w+EQKx0S5MtbOgBXSbZcLgvMxJksKi75DtNJBLi+BxS5F/JlRCoINVFFxmqdohn+Pdc/1WTkjCgNZzFHCIvnx46Wz47BnGo2i8WCUCgk7iJ0uuDaoTqPXe2yQSsLDPJvwJVUnR0+UQfGRnbO7CopaGKyZOHCz2k0GiKLpviB/+Y9ZjKlmEFRlP8c+9l897vffWiz2ZD+9QZqhFDefPNNgSaoIslms7LxGOcvKIW8uLgQr7Nle36qvDRNg9/vx9OnT9Hr9QR6Ip55fHwsQbTRaIh9TSAQwPPnz0X2yqDHrXw3NjbEEddkMiGRSODo6EigCHZTyWQSp6enaDQa+Id/+AfpIkjUUuZId+ZarQZd1/HRRx+JxDWVSsnvAb+xLee2rxsbG4Ll0tZ9Y2NDFlw8HofH40GlUhHSs1gsCpRHqIHqPqpbAEiFbLFcueKmUilRhVksFqRSKVitV7uIBoNBxGIxTCYTgQbu3r0rWL6ukAAAIABJREFUNi8sIjiMSbNUwk20iCFkwOKCC5gDjDabTWaQnj59ik6ng4uLCwBX/ESxWMTKyopAqxQCaJqGk5MTvPHGG2Lzzw3OODCq6zpSqZTM8VCVNR6P8cYbb8j8VDabla6Ki7lYLOKP/uiPxEGaxc2yCEBRFKysrAjnwO+gAIJBiIGFOD4HBzVNw8uXLyUZTCYTUfJ1u100Gg3pcqLRqMhjvV4vJpOJFEXslpgolh2/l92FzWazDC/TW4/uARzwpLJqMrnaBp1VNvkQ8gNMjssEP+EaQtEWi0W6CJpp0rCTUBbPk4lw+ecpSlgePKbwZHm/G3JvdC2gMovdChVoLE4tFoucL2E1ADIDxITJroXSZvJuHOo0m80y78VN+fj5FNUw2fv9fkFC2AGRk+K5sivk/WCio2KQ4ih23DwfJrFlV2sWRxRS0MF6GXJlMa0oV9tFPH78+PVPNj/60Y8e0qqjVCphZ2cHW1tb8Pv9YgXP9peDZ/F4XLTkuq6LfJgVKKsp4seBQAA7OztCEm9vb6NQKKBer2N9fR1PnjyRwVG+gIFAQHZqDIVC8vLdv39fuovJZCLdCANLp9OR+Yz79+/j3/7t36CqKur1OrrdrlRt5ItyuRzW1takEiXcQLmw1WpFo9HA/fv3Ze6FsBj5BMJr9OAqlUrC/XBPG1aZDKgka1OplEhTmTSXd1nkoqLKzeVyYW1tTe4zd9bkorNarde2Ct7Z2RG13vIiYgdLpQzt2A3DwNnZmXR3/X5ffL/i8bhMrZ+cnIjqJpVKSWejaRo2NjawsrIiwTeTyaDVakHXdfGnunXrliyiZasUdoUUDtCWhLu5UlFGwn53dxfhcBi6frXfUr1eR7vdRiaTEbKZCY6Kq0gkIm7iTMjknHh+hE/YDXDrB5K0JJBZzbJToXyfO1yyUqblDIMZK2bDMKRQIPdBrpRcFafG+f7Qa2s2u9qIkFtrUBTAmRRCuxSpkFOhfQzfIcO42uGSwZdwHEUCVNix6ODEPbs9xgaquZjYOAZBeJVJhomIMOxisZCOadk7jcXfsqsJLZsoTKErMtV70+kUtVpNOB2OYzDxLnNM7H5pGkvVKADhXAHIO8Bij9wvUQcq4djhMEEQdgMgRTXnrbj/ErmiZTcFwqLsEAOBgLwf5Ly4DQI7uY8//vj1Tzbf+973Hn71q18V4z2bzSaQC2EwVrPEEqlyWiwW10g/ci2spvf392V7Y6qVWq0WSqUSotEotra2UCqVYLPZsLGxgdPTU6kqbTYb1tbWZFdBl8sl6iBFUXB+fi7QzNOnT6UaoDR6dXUVZ2dnIoV1OBwyUPnOO++IQGB1dRWffPKJzKmUSiWkf711Ac31+FCtVisqlQparRbOz8+xs7MjL1oikZAKiCQh7fSXX25CfAwWVNcRUjk6OhL1EbHmRqOBcDgMk8mE8/NzUcWxkyA2HI/H8fz5c5meH4/HePr0KZxOJw4ODvDs2TMZBCWBvow5EzfmdD27PFbErDTpB0USttls4uXLlyKcoAPDRx99BLPZjA8//FC4CkIY7777LiqVilgUsUP89NNPsbGxIbCrx+PB3t4eisWiwAk0QxwMBrDb7fjkk08kgLlcLrx8+RLT6RQXFxfyM3w/qFjiZxDWstlsIn+ljJ4zEwxuxMz55wz89N8iFEerHzqfc297dg/0m2NFy6BL/hP4zZbsfL+m06moz5iE2OmQK+EcGBWRiqLIMCwHkNlZWCwWhMNh6YjIXbCAYkJctqViB88KngO4NpsNsVhMlGFc74SHKQJgV8X7RzEPB1VZrFYqFYRCIYGams2mKCC5jxHfjW63Kx3Hsj3Msk/bslKV3RBnwrgeeY+X59bYXVJtSBdq2jFRdMN1Tu5qMBjA5XLJfA9hc8KOy50kDXY3NzcxGo2uOaJTpaiqVxsVLls+UcLNGbbfZ8T5WiSbH/7whw//7M/+TNrFZDIpJBUJWRJxxWLxGom1traGwWCAZDKJ+XwuRpJ8CNwTptfriYUGiW9W1Fy8/IcEHh8oh7I8Hg9KpRIqlYoQvMRtORHP4MHKjvg297ug/JCYt6ZpyOVyUn0xKU2nU6k66eRcLpeh6zo2Nzelwr28vMRsNpMht0wmI+dO2SsragZPyi9p7c5tDEgmZzIZbGxsCFxH80K7/Wo7bAoKaIR4cXEBXdfl/hJv5gxNJpORoLa9vS1usqFQCIVCQUhYko6Hh4fi+lssFrG7uytcQygUwsuXL+Xe7e3todvtSmfmcrngdDqF92LiYeBjFTsajbC5uSmBnOKUarWKeDwunTQ7FhLCmUxGChryCVRXDYdDgRoajYYozyh5Z+FANSKTE1VEVH8RrmJXQ7Kd0AvVahRSUAxC3oQKNVbMFDyw0+Qz5edxuwOqqZgMBoOBCESoUCN3xBkudmO8p1Q3Ldu1EPJioqZvGNc3iXdyB+weycuQB+l0OrKOyH+ya1NVVaxrmGhZLLEL4CAu3QaYYClEIO/C7m+5sGCiYUInDEjIkPAqC1E+Y6oHeV9YdPCd5bvvdrtRq9WEO1lO+DQx5TbmvE+cr2PyYSfIzpexDbjqari1CLvBZb9AduC8z8PhEF6vF7quX+PIyWGxUOJ9G41G/zmSzXe/+92H29vbYlv/5MkTCbycQqbhJedUSECyg+CDZTdA91NOitNokFvVsj0kGclZHUIasVhMSEHCN7VaTXDuer0uWxt/4QtfkBb74uJCOgVKswFINWa1Xnl3cZqew1G1Wk1ECZyDqNfr0olxp09e0/n5uSiBKDogXs5KivY0m5ubmM/nIozg7z9//hzhcBjNZhPr6+syNEaoklP7dFkIBoOwWK48xJrNJhKJhCwydpIul0ukstxzh27CvV4P6+vrODg4ELKXSYyJb9m2hST3YDCAzWYTRSC3pl3el4NwBueU5vOrHS3ZLZB85kQ83xGqjCjbZTdFHzFi01TesWKfzWa4uLjA2toaarWaOPNyiJGJ2GaziXddv9+X+QZCYD6fT/a9YRfBIoZBk79H9wPyhQ6HQ8QUTEyLxUKUewxuVI5x3bDjIefEQkNRFOGHWLyQ/ObWBFRC0i6HA4vsIGazGarVqhRD/H52CAx+hCb5DFg9s0MjQa/ruphosmPnmlzmVHw+n8DtDLTkIskv0dmA3Ci/m0GTpDfXE7tEwm4sEACI0INBnw7MAET6zkQIQIRCTMBMGhTokI+jSpWFL2MgOTsOS9PhfLkrZLdIrojwGWE5vueNRkNQAj4DohCEhxlDAFxzFSe6wk6JHdl4PMazZ89e/2Tz4x//+OGf//mfi00+jfcoVb68vBQbmFwuJ4QwK5tCoYBHjx5hbW0NuVwOb731FsLhsEBYy5Jeell9/vnnsFgsUiWTJOODjUaj0lGlUilRILESJbfUbDavQSEM1ByCJOnHbZMtFotIpgeDAS4vL8WTLZPJIBKJoFgsCmldqVQERuOsw/JeEqyKotEofvWrX2E6nWJ1dVWEASTfJ5OJqH5WVlYE92agogs1oUrCEOw2e72eBIhSqYS33npLYAImKpfLJWamTDSTyZUNud/vx8rKCqbT6bUZC4vFItfEBceN9C5+bbR67949dLtdfPTRR7K193w+x8bGBkKhkAggdnd3JcA8fvxYcPZwOIzpdIpCoSBd2vr6On72s5+JUKHVaiGXy2Fvbw/ZbFaScqPRkJkW8lClUglutxuXl5cyEMiqtl6viyU/7yMTF3fIZFAgocwqmvMZnEVihzyZTGRSm91jKpWS4VLgN0afZvPVnDY9ucbjsYg8longxWIhG8BZLBZJlOwy2PWTc3G73ajX67DZbDIATbcFPr/F4mrbAbovM4gTHqdFDu8ruxYGbSrvWAz2ej0Zup7Pr5y46VDOZMfdLPkMiSSwi+RMFu8hORAWOazwyWGSV+KfsZsjd0exDE03eb8ocaYX4f+g7t1+287vu883JVGijpQoHsQzdZYs2+N47JlJk8lpi7ZPEaBXLQL0YveqN/sH7AP0ZrDANkmbtF30YrvPxWIXKBboosCD3YsiTZN2J51OPAd7PLItWWdKpEiKB1ESJZGmKHEv6NfHP/Uw6fN0LxwBQWY8lkTy9/t9P5/P+/ShAAD/OWFH1HBAxZxlhNFS7JxcCf4fDnlSu0l9KJVKVszgnEZHR7WxsWG85unpqeW6QVHwDLOuhQzB7u5u41R5TmkOeSYODw/tv42MjOjDDz98/RMEGINv376tgYEBvfPOO5aTxaIq1GSNRkOPHz+2jv/Zs2eGr3744YcaGRmxwL+vfOUrSr0MZvR4PIpGo6rValpfXzdn/FtvvaVgMGhdSTKZ1I0bN7S4uGiqnM3NTVOJDA0NaWdnR7lczgoOXTGGLkjC8fFxW04EYU+kzMHBgVKplAYHB82TwesolUp6/PixPvnkEzWbTQuiZKpqtTrLyjC8EVEzPj6upaUlg9/S6bTJZFdXV03VRaJBNBpVJBIxLgqvitvd2bED97S7u2tcE+IMIvQvLy/N/EoRffTokflP1tbWLB6I18K+HrowioAkgyovLi6M4F9fX9fo6Og15VhfX5/efvttTUxMqFgsKp/P6+DgQOFw2NRXkpRIJJTNZnVwcHCtw+MQkzphq/39/bp165YkmW+JWBOmyWazqe3tbY2PjysUCuntt982M7Cka+o+TJovXrzQ559/btJW4n24l5rNpk0+wBQul8s4STgEDmNSHIh6iUajdtDTjTcaDXOGIzShWWJHCU1XV1eXSqWSwSIsoXMmHnd3dxu/58TtmZ7gMYF5Dw8P1d3dbfcF9ywF2ZlqXKvVrJumAMEnceh3d3dfi3DiYKZJwhMDlAfkihGUwg2hDk8IuS51IKp8Pm+QG8pTDv3Ly1ep5YVCwczHkq5JzPv7+y1cF3MpEyoKMK6NJIOfJVkjwL1BYZZkS9+Q+/O5MGlIsqKG3wm4DASHfEOnhJnPDmWgJIPGBgYG7D44Pj6+FhfEhMlkwz38RV+vxWTzgx/84D1CCk9PT5VOp61qQ94eHh4qEolc+/BCoZD5U9544w2THX722WdGvvf0dFJvv/Wtb6lardo2SlRA6NDhSUKhkPEvjOCMi5VKxVJjZ2ZmtLy8bDciHdHh4aHtfoCgZ8Xx8fGxZmdnr5kBuflQo5TLZXk8Hs3OzioYDJo5dW5uTk+ePNHNmze1vr6u2dlZg5+YDoBednd3lUqldHFxoUwmo0wmo6mpKYXDYfMsvPnmmyoWi9rf31er1bIMMn4WuP/NmzfV19dnEeaffvqpRdEkEglb+HV6emprtplCOfiDwaDtzgmFQnYYXV5e2uFHkCVEOYUMqSYTZH9/v0ZGRhQIBLS2tmZwxNTUlM7Pz02MwHSEKozCNjs7q3Q6bWpBl8ult956S/v7+3btaDK4d9rtzqpd5MyS5Pf7dXp6avuT4MhYXwDvgb+FrCn4PT6zZrN5LVWXKBRgTEzHRDExiUIqA59gUgSK5GABiunr6zP4IxQK2f2OSo7GhbR0EhtKpZKJb5jq6aDJXwMGRlpNQgWBnWSJIbOmsSP1nEio4eFhy9u7uLiwRGFngCr+Ir6cpmRCXrkORKiwxBDolkJAV+9yuSwFBNUahlNn/AvKNO5dFr6Fw2GDWIEhUX1dXFyY7BnrgLOIch0ROQFbcq/Db2Fe5ezj55PBhsiDdA4gS9AUVGkUFX5Oo9FZUYC5E+4OZR9TEf40khUQbJG2UK/Xf6Gps+ffUyRcLldaUk3SpaRWu92+53K5fJL+UlJKUlrS77Tb7eoX/Rwmg5/+9KcGDYVCIYtqabVa2tzctK5yampKOzs7Wl9fVyQSUSKR0O7urvb29nTz5k197WtfU29vrzY3N5XL5ZTP55XJZHR2dmbqFcZeyOAHDx5oYKCzaY8uO5PJaHZ2Vqurq/L7/Uomk6pWq5qZmdHx8bGWlpY0NDRksmu/3694PK58Pm/dbU9Pj27cuGGEZHd3t9LptDwej0lRkX4iI3348KEkGcGJ23dhYUHpdNrI2mw2q4mJCQ0NDenx48cmdWZMvnPnjnK5nLxer5lCJRm8JMlgi/39fet0Y7GYHj58aFxFqVTS3bt3zQPBzwS77+rq0q/8yq/o9PRUy8vLmpiYUF9fnx4+fKibN2/awcEBzgE8Ojqqjz76SH19fdrZ2dHl5aVNTXSNXV2dzaJjY2N68OCBwY1wdltbW5qfn9fKyor8fr+lBxOjEggE1NXVZZzKxsaGHbqkev/sZz9Ts9m0osjekL/6q7+yWBp4qePjY5XLZdvtgdeBzaWYeiVZp8tUXigULGpJkj2kdPlMYByyQBZ4KoA0kE1z4PH6gsGgCUokmVqOA6NSqZgKigmSwwVZLMIIFEaIPeAQfD6fotHoNXsBBxqL/1Dc4fa/urqy5X4ULngJ1JM0WRRICj33Dnlr+/v7CoVCxukReOvxeJRIJGwiQsJMejmc08jIiGKxmKmxuKa1Wk0LCwvK5/M2MQUCgWvw8eXlpeLxuHK5nCTZYka8eRQ6IpRoAIDeMpmMrRLnGaDwknhQKBQ0MzNj6jiaLpoDJhkEUcVi0aZXvFDIu50CB86Jrq6uaxl9PJMo+uDunD4virQzbojUBWA/4Nsv+vr/A0b7ZrvdvtN+tTTnP0r6abvdnpX005f//oVfl5eX2tnZsYwyj8ej58+fG84bCAQUDoeN6GYr5Le//W0z4iFljUQiRrDeuXNHwWBQs7OzOjg4sLBH8FdCNHO5nBYXFw1vBQ+G63nzzTfNadvV1aV/+Id/MBknRH29XrcDEn9DoVCQ3++3qaWnp7P2AAMj+yQ2Nzet+9nf39ebb75pEtjbt29fw2Gvrjp7OljoBbQiyRQlXV1d2t7e1vLyssVTpF6uh+3p6eyIr1QqNo6DHTNBIG2dnp62IFNk5DykKHvwOHzyySe2L6NSqSidTltSQC6XM6d8vV7X9PS0qbImJiZsNQLvT+oseGIpnSQ9fPjQuK/e3s5qaEIRi8WiXrx4odXV1WtYN0Tw3bt37foDkYTDYUmdh5zMMtRMLPxiGqHDA8dPpVJmKMQkSKcK/3F4eKhyuWyHB1Mjy7GYAjh83W63wT1HR0fKZrPG1zHNSJ0GhJBaiml3d7disZiJLPgMa7WaTc90sFKnCMK/HBwc2KI8FG7OqBM+m38pS6tarSqbzV4LIh0ZGVGxWLR1G0NDQ0Ysc3Cfn5+bnwvYjnDW0dFRS7DG3wX/B4HP6gm4wUajYeIiEA1EC0wWKL2ckTNHR0c2NQHBSTJUgmuBn4TwVkk2FcNTcS14fUy77LVhsoMf4TXRHBLtxN4knm2+D08R0Ba8CkpETK9I5FmJwDU9OzvT0dGRSqWSKdOQVwOrMbk6eSnMoJwJTIa8HuBRPGdf9PXvmmz+la/fkvSNl//8f0j6fyX9D1/0DRxY3BA3btywbpVO5969e+aHicVi1mHU63XNzc2ZJ2Bqako/+clPjMAiFXl6elp7e3v65je/qeXlZcMZKVySzC3O9sZ2u629vT0dHh7q1q1bOj4+ViaTUTgc1v7+vhUYzF0nJyeampqSJCt6VH6Px2NjZ61W09///d8rEonYQ8a651QqZQ/L6uqqzs/Ptbi4aCGdiCaA6vb393V5eWlJs+fn52bixJlOAfn4448VDAZVKpVsYkJp5MyWWl5els/ns843EAiYP6ZQKCgajdr3p9NpcyzDjwEVII5AbAHXUiqVVKvVrDjX63V99atf1fb2trxer0FiJycnph4cGhrS4uKiKf1QpUkyGIjrB9YO30FnBnyHkmtyctIEG3AToVDIlrJh1iRbjnXcjUbDRBZMN3hGzs/PlUwm9ejRI3ug8ZKgIsPBDe/YaDQsXZmDl2KM2i8QCJhKC1EDEmAgFAoikvPe3l6L24G0Z9Mi0BNhtZj1JNl+G6YpJNb8GcrAg4MDU4BhpsWkW6vVVCgUFI/HNTAwoFqtplgspmKxqNnZWdXrdZt8pE7Rz2Qy5i+Kx+Mm06Zh6+rqslBLnO1E9sBl0ZHzmcI/ocJjUuP9wCfx+ZBSgKGS+5COn5xCYF8nTMghzxR0cXFxLULH7/ebSIPNtij1Li4uFAwGJXXUbHBRTEAej+calAycJ73iOcm+oynGrMwzxucB3HdxcaFIJGJcDAkY8FvI6bGZABVyr/Jsulyua8ni/9rXv7fYtCX92OVytSX9r+12+z9JCrXb7bwktdvtvMvlCv5L3+hyuX5P0u9JsiTlVqtlLm26oLm5Oa2urpr6AmyxUCgoGAwqGAzq6OhIsVhMU1NTymQy9uAxRvb29pqRLhwOG5kF7IQ8tlaraW5uztzyrD6mIKyvr1smWiKR0OTkpCmTeL0vXrywkEycxxQznN10wsTROPX+LP3iBo5Go9bBS69IQAoZMAIP7dTUlJaXl3X79m1Lj52fn7dlcRSGfD6vs7Mz3bx5U6FQSNFoVN3d3SZ6GB0dtYVvQG6pVEq7u7s2MZyfnysUChn8xbQUDAbtIRwaGjL1WLFYVKVSUSQSMSUfHEuj0VkJXS6XdXp6qpmZGX3wwQc2hUpSqVQyox0PDB4qCsv5+bktJANagAOcn5+3CQoIS+rkgMViMUtgcBKzyHfZvoiaDtGK08yH34uIJKnD7Wxvb1v0DooxDH4UM1RAKA0p2og9IHv5/dls1khzfETxeFz7+/smCOAgQOI6Ojqqk5MT81UAJ+IdoUt3uVxGdF9cXNih4vF4JMnEMOD3kq5F38MZOb1eCBcwSELy02iS+Yd8m+6aSQduzgmRIVNutVoWTwMPATQvyQobnyf+EgoR5DtqOFR8+FqYVGKxmE5PT01c5Nx9w/Wk4DWbTfNX4T1jMuBe9fl8pt5D+s3khHcFPxOpD0xmeKeASuGBuG+IfWJScblcButvbW1Zs8H0hJiF13Z1dWVWAbhH3juZiMB2NEW/6OvfC6N9pd1u35X0HyT99y6X62v/1m9st9v/qd1u32u32/dwsaJ8KpfL2t7eNkXR2NiYda3tl4F6kUjERtVkMqnj42Ntbm7q5OREc3Nz6uvrM1ji6upKm5ub1oXxs+i6vV6vlpaWLFWZDzwUCllAJB0i0ldcxnxBrO/s7Gh1dVWXl5cGHSHZJkwQ7fze3p5NQycnJxofH9fy8rKtViZXjRWt5CDhUr+6ulI0GjWPC/BDPB5XKBTS+Pi4MpmMqtWqkaXssJidndXS0pKkDmT16NEjpdNpjY6O2hRCoCNkO5hzJBJRMBi0CQ/fDgvdEA1AOI+OjpprOhKJXJNm8u9Id+myUT8hiwU2kmTFADMkXJfb7daTJ0+0s7NjfAfk/I0bN4zonJiYsCJHEcefUq1WLSgxm83a57q2tqZcLqdMJqPe3l5tb2/be2u1Wjo4ODCYp7u72+BBxBROk5/TSyTJDnauKcQ7xDRKOOT7x8fHxnVwEPX29qparRrp7JTHU1hmZ2dt0qjX66ZWc5LAktRsNvXs2TMTUSDfRYTSbDa1tbVl9/7g4KChCBQzeBmaE5op7n0W7vH9HGYIgJxcB94tr9drfinUebx2Ch3f7/Q8sSfm6upK2WzWoCauB4UHQyOfGbAz6jEOc0JX4aDgK4iawkDLFEPz5WwyyCTjeqIq5fvhSMjTo+mt1+vK5XLXtm9yzYCIW62WpdBzbzu3wF5eXpp3iQYN8zNwKRYH/oymAr4RvxmKPvxCX/T175ps2u127uX/F10u13+W9JakA5fLFX451YQlFb/wh0g20ubzeU1MTKhQKCgSiWh/f1+PHz+Wz+dTJBKxw5uUWqnjXn/69KmN+KQVB4NBI5FZlQs+DhRGp7O+vm4d5osXL7SxsaFms6mvfvWr2tvb0927d62qf/rpp3rzzTdtjF5YWLARcnZ2VsViUV/+8pfNlJrJZLS2tqZkMqkPPvhAb775pt544w19+OGH5m1x4vCQjxwcfX19RgY+ePDAIjIGBgZsWySk8/z8/DWT3cVFZ4cGNysEKXt48vm8vv3tb+vg4EAzMzOqVCrK5XIGJVSrVVu+tLW1pUajoYWFBcuEW11dVblc1v7+vsLhsKVUu91umzCZys7Pz+0wv7i40NTUlC0ay+Vy8ng8ppp79uyZRkdHbUcI6xrK5bKWl5eNb+nr69OTJ0+uZVi9/fbbevjwodLptN588017cD/55BNTP0mvVkQAxQCL+nw+W3rGVtaTkxMFAgGFQiFTVKHwWl1dtWywSqWix48fq1wuW9OTTqfl9/vtgGF6KRQKisViarfb2t3dtQl1ZGREW1tbRooPDAxY0eThd3o2gDPJdAPD5+EniJF9RIQyIscnoLOrq8tgwKOjI929e9fI5X8apyPJuFXWcV9cdBa8IatOJpM6OjrSysqKyZUpIMj7QTGYIgYHBy2m6uTkxHY90XlfXV1ZZhuTt3PPDfwjnAsFEj9QpVKxjag0lC9edBbwoRZF2IAXDH8RrxEyHtMyBy7ZgAgfKGKcQTyD+JtWVlZMyUdxrNc721vxujUanb0yND94iKAQCClGmu+UtROiScp1Nps1aTNNDhtxq9XqNdkzSA1TYrlcViQSMbFKq9UyXw+maCcn+K99/VcXG5fLNSipq91u117+869J+h8l/T+S/ltJ33v5///3L/pZwEYc/tFoVGdnZxbZXygUrDsEGjs5OVEmkzFjGl399PS0dVD4BBhTnRh6pVLR0tKSrTQligKTVCwWM98OsEsmk9E3vvENVSoVC1ecm5uzNFm6cZYkoT6CWE0kEqpWqyqVSlYUnd1LPp/Xm2++KamjXEGVRIdC6uvFxYVmZma0u7trhZh0gs3NTfX39+vq6kpra2t26ODNAKoAQ15eXjZBhDPI8cc//rFGRkZsoVoqlZIki8wfGBhQPB6/xkdASJ+fn1uCc7FY1NDQkEFbhH7SFQYCAX3961/X5WVn/TJbMTExkjMVjUY1PDysDz/80B5ivD08NJFLbMrsAAAgAElEQVRIRJlMxmDYrq4updNpixianZ017xOfT7VaVSQSkcfj0dHRkZ48eSKPx6ONjQ3jdhBJYCKs1+t28J+fn+tv//ZvLWWCaBECK52HPsolZPtwZFwv/D8UJbpqoluYAJm2SYRGDeUMwuzt7bU4HDwlpEu0223zpnE4X15eWjAjvB7kMft2Dg8PbSrjsyB9vFgsGs6PbJ7nGfm187B17loBnkNB6NxYyXMfDAZN3gyqQMSQM26GIuyUBx8dHcnn85k14vDw0EQUZ2dnFj8VjUbtmjonk2g0aoIRJgOeBRqp7u5u+zlkliGRZtEZ3jp4lHa7be+Pn4Hqj2vo8XSWQk5PT9tnXq12xL2YY7l3S6WS+vv7FQqFrMDTgAAPUmSBNfkzrgeTLucNRQfhCepLYnh8Pp9FfP3CmsEo+1/65XK5piT955f/2iPp/2y32/+Ty+Ual/R/SUpI2pP02+12+/CLflYoFGr/9m//tt0At27dsnA8oBUmG6cyZXFxUQ8fPtTg4KAmJyfV09Ojvb099fR0UocnJyfl8Xi0vLys3/qt39KLFy+UzWbl8XhsxCfeBn38yMiI4vG4YfGMqy/fs32oHo9HH374oaLRqMbHx20LJwnHwWDQPEJjY2MqFoumhmq329ZhkTV17949VSoV5fN5xeNxxeNxLS4uqlqt6vnz59cSC1qtlsEeCwsLBkuQACx1un62X/785z+Xy+XS3NycSUelzgF4fHysqakpI9uJJKGDQSQwNTWlxcVF2/kzOTlpi7dIkHWuzSUlGxXY8fGxRQCFw2E77Oh0e3t7NTIyYl1+s9nUwcGBstmsBgcHdePGDXstEKZ7e3sGP7Hdk8MHGGt4eNgWUNExTk1NGckuyfZ3HB0dqVwuW9p3KBSyzp8NnrOzs8Y97O/vKxAI2KTZ399vOXA4tVHJcciwL6e3t9fWabRfJg47TXvcFzdu3NDKyopBhagxEUJMTEyYhBX1XLlcNjUSMBvfB7/TbL5av+70pMCJ0p1zGPX09FjCAVEm8J1AvbwHfmehUDA0gg4fue/o6KiZdoGGUKkBgfE6WFUNx8DX0dGRNV9wJxDu8XjcuAYKPnBQV1eX7X5hYiR1G/WhM0WDBYjwVPAvTBT8dxoFPnfpVdQLPBJFlCkKcUVXV5c9U0weIyMjKpVK17akApel02mFw2GNj4/L5/OZSRo4LBQKmXoSfpfXwMQOLcC5i+kUgZGz2YE79Pv9pj4j1BNP4l/8xV88dKiS/9nXf/Vk0263tyW98S/8eUXSf/Nf8rPotBkBcaoHAgHt7OzYEjR2WVSrVY2MjOjg4MAMcpK0t7enVqul7e1tjY2N6eTkROVy2bBa4lcikYh1jhCDdMNMIfhLIpHItR3sPDiQ1V1dnWVW+Fg4bHw+n1KplLa3t01ufHJyYmont9ttnAZfKHq8Xq9u3rxpnR5Qz1/+5V8qHo9bugIjfz6fV7FYVDgc1ubmphHEzv0kwEcQggR9ZrNZ1Wo1pdNp3bx5U1LHrUy0CJ24JDs8AoGAkbJMaEtLS+ZPYZ0xiQIbGxuKRCJ2Y1erVeOAIPJJtcXgeHBwcC0Dz+v1KpvNGlRCQCYwD1BbT0+PTTIszEOSy39DGg8kwwNF1yfJ3n+j0TBfisvl0u7urqnQEA3QOcI9wglsbm5qcnLSUq7hUTgwMOrBdRErQ0TK4OCg0um0LdcjIw5xAxwD642vrjpbUZkE6I4lXZsU4DaazaYODw/t73CIsu4BSBVhAZDk5eWleakoTj09PZYCwL1N3L1zbw3NAqpSSVb0fT6f0i8TxOfn568lg8PRAVdRYBGHOCNe4EOA6LiPJP2zVGngH+TNUgdeAhJzmlZRD0Luk8pACCiTHeIMLAakYQOZURxfvHihYrGo3t5eWxnhNJAixOC14mVC5YkwivuX8xNuj/dJ2CeePkJAKXacDXiyiMuiYSGD0BnHA5oBPAz3+UVfr02CABAHqcxE0qPAicfjlpGGox+skERnNOWQa7lcTktLS5qamjKuoNFoaH5+3pQhwWBQ3d3d5qQnt6jZbNoBMzExoXw+b6M5qg06H0I3T09PDZLByIdCi3BEbhw4DJ/PZ9JZ9PTSK7MlEm3EBO12W4lEQtFo1OItisWi7XLZ39+3DhHvTjab1YsXLyztltQF1hnjF0FYwM/gUB4YGLC95RjDIDuZCHmgwMB5GGgk6KYuLjr7M9xut9bW1uyBHhsbUzqd1uLiopGWFHVUgSwCww+DVJiizVh/dHSkyclJ9fX1aWJiwhSLtVrNeAK6UArvwcGBjo+PzSyJxJzYGrxOm5ubJhyRXjUIPT09tsqXrhDIFgUaEwyHM7j85WVnDz3XEIwfUx2QsJNLICaE5wEvC5MjBy8dKSQ03ADCGWJRKFx04TRjUieXDO5Dkl0D1GDVatUUUfxOYpsg7gn8RPABFMNkgncGOE7StdgWSXY/AjNJsvtTkplcnQGT+Edcrk7qM5MRIh/UVRR5mj1c9xQynkmXy2VwPCZUPjcSPChQ5K2BGjifF4oNJkkmIKc5kqYGPgyukOkSla3L5TKlK/cZMD4QK4gKkxexPECeNJ+SrJmn4PLeSTDgetE48jytrKy8/kGcf/AHf/Der/3arxkemM1mdXJyYplhT58+Vb1eVz6ft50zwWBQfr9fMzMzxjUgZS2VStdcrfl83vwJBFbig6EYhEIheb1ejY2N6f333zfpK9AbCbMUs56eHos9IVGAnKFoNGpRFWz/9Pv9isVi9n1LS0uanZ3V+fm5BWbiJRgdHTW3NLE9X//615XNZpVKpRSLxYycJ1qmVCopGo2a2YvCcHp6qng8romJCXsg6N7L5bIVlVwuZ5/hw4cPzc8yMjJivprz83MNDg5qb29P3d3d2tvbs5gRcPOVlRX19/drY2PDzIN00KlUyrpUAhRpGHZ2dnT79m2FQiFls1mtr69rfn5esVhM9XrdFprFYjG5XC5Tl0HEP3v2zHivQCCgx48fGxzWbrfl8/k0PT2tjz76SLdu3dL6+rpNvIFAQC6Xy5zxpDuwlI1YndXVVVMqAddVq1UFAgF95Stf0c9//nML9OShJG7G2RkyXRDpgsgD2TwHMtwOKdo0Q841xUxfSNqZetIv08cRDrBymDSGUqlk1+zq6srSpD0ejwkFmKgQTvD76/W6pqamtLm5aV36xcWFTYdMC6FQyPgestyYRGjqaCq8Xq/i8bi9RgJHkW/zd9lmiroM4t3r9Wp8fPxaNhzEOlC5s9svl8v2PPBagQFJ5ibdYWhoyNR0V1dXxvnAXwFPjo2NmXCEooOpk4ZEksGaWAMopmTOgQCA3tRqNWse4cnaL2OygPIQbvT391tEVqlUsmaUooMSDdEF0y9F+OTkxNCEZrNpS+BQD6Ju5blFct3T0/ML42pei2Lzp3/6p+/xAG1vb2tyclLFYtFMjZg9eVM9PZ2gxUQiof39fTOCoSsfHBy0mHe/328HADBaPB63zrCvr0/FYlGNRkNPnjzR+vq6bt26pVQqZWY/YBi6TQ5HblDMk3t7e+aXgA+5d++eyXk5HOl22W7ocrl0eHgov9+vdDott9utaDSqWCymSCSiZDJpXhH2yAwPD9sDXKvVjASlI0Xmvb29bSRsPp/X3NycDg8PFY/HlUgkDHYBFrp586a5/uFYGJGZBqanpxWNRtVut+1QAzLBU3F2dmZqK2BQwhv7+vr06aefWoeHnJuH9/DwUNFo1NIKMOsC3WF8RX7MtAEv0dvbq/n5edtdEw6H9fz5c52dnRm5Pjk5qUQiYds+gcOazaYKhYKtxW6325Zt19/ff223EjtnZmdnlc/n1d/fr62tLeVyOb3xxhs2pdApMu1yPeDYnP4dpky8C3TdqKu8Xq8dDqitMHUyWQA97e3tmfwfgYzTrzY+Pm7GQ2TGTO9ItZlE8cNUq1Vbuc4zNDExYfAW3BVrEYBcxsfHjdvg5/OcItV1pjeQ2OE81FC70YUzMV5eXppvDB+NJFtX4Ha7zWd2dXWlpaUlra2tKRAI2HTHxIHUOxgMXlNxIo6QZIe11PFR4fVhcqBoow6TZAWZ84TEZLxBTK7Ijp3pEkzuQK0UPecuIYRENJPcY0QNeTyd5Wfct0xG/Fzn9QSqdcKIPBu85qOjIxNg8fd/KYrNH/7hH76HmiMSiUjqkPHxeFy7u7u2aRNC1Ov12gVnpwwejlqtpmfPnqlerxtP0NXVZfvQE4mEVldXDeLq6+tTPp/XjRs3rHOQZNAchzpdwYcffiiv16uTkxOFw2ENDw9re3tbR0dHhtHSMRMlA+9Dxtng4KBlIY2Pj8vl6gQBrq2t2cEhdeCKTz75RF/60pd0fHxs2DMOczwjHII///nPrYONx+Py+Xza3t62wEi4qXq9rsXFRRNT4LAnz41IFdQ7SJ3j8bh5SNbX17W7u6vbt2/rxz/+sY33LBQjXXd6etrgLqLfh4aGFA6HVa1WlUqlrsk1u7u7jcuJRqM2fZH7BYQAP3d4eKj9/X1NTk7aPfP06VPbKUIB4O/jfj86OlKxWNTBwcE1w6xzj1IqlTICmHugVqtZWGv6ZfQR8EU+nzf4JZFI2AFSqVRsGmG3DrAfMBOHEBJeJkCUl0zKTAWlUsmCap0LrqRXRDhwJsqkwcFB9fX1XVskSFHBZwLPAdx3dXWlvr7ODhsOc2AqXh9FF5iHe5f7lMOKQsjqASYN4CAUns7vp+j+UxkxardgMKidnR2bGiQZkc/PhANjIoBfYTrEwE12IUZeEgSAvY+Pjw1GRjiBmo9Fb+122wo8Em6uNX+fItZsNk296XZ3FvUBh7HHCJjYaeJkcgPBYBUD8DPqOZSwIBY9PT0aHR217+V+cAoBUOMhkGCyROoO/PbixQvzzvHcfv75569/sfmjP/qj98LhsJLJpKliQqGQSR3L5bICgYBisZjy+by+/OUv27iYTCatUnd1dSmXy+nWrVtyuTrZXvv7+9ZlDQ0NGTQHqQuRxyiMRHB2dlaS7IPHp3Dnzh1tbm5a5AqxJRCMCwsLJiUeGhqy19fd3a21tTWNj48rHA4bJvrixQv7WZCedFinp6cWI3N2dqZbt27ZYrXu7m4lk0n19PSYmorEgFQqpfX1dZNTDg4OKhaL2SIq3mMmk9HpaWd/+urqqil+uMm5cTkQcIcDQbhcnSh81sl6PB5tbm5qcXFRh4eH5l3gv/X2drauAosSsyHJdpJcXFxofn7e9vpIsoBQDiIk1KOjo7Y6AJKcB5Joe3iixcVFSygoFou6f/++lpeXLVqeCS6ZTBpXxs8eHh42grhSqdhDDC+DiRFFGAUxm81qb29Pb7zxhuXgUUSQPMNVOAUnCCW4PxKJhN0vvCcaBKCpoaEhHR8fm9SfHC0iepgcKWRAi0wKmFHhqjjwSNBGxgwHhK/N6aUCYQB+ZeoH48f/cnZ2Zh01nT8QM9J7ijhhmxgHSXng+9hXhLJOkhVERBVwfGdnZ4YukDeH9QGjsdQxDWezWYMNUXii4kM6TGrH0dGRwuGwrb4mTw24DI4N7owzB7WrMzaKvTI8K8B18FLd3d32z5xLFHoKNNJ0ig6TFBMIwhjuYSfHxfdjzkaGj2UCjkiSmWIvLi507949/c3f/M3rX2x+8IMfvMeKXroIJImEPXLwSB0eZW9vTwsLC1pYWNDq6qph1iy1oiNAKjw3N2dLq+ge2b6J2ZFuKJFIXDt0yuWySZhZ2JVKpeT3+20a4WFirBwbG5Pf71ehULA0WPa2XFx0dnocHBxYSi0XdXp6Wj6fz9Jcd3d39c477xjnVCgUtLu7az6AUql0TZvv9XqtOJOeOzAwoP39fU1NTZkaDwycgovIASULeWbcXEB1yHJx1rOcDufx1dWVJicnDQbBQ5VKpQyyk2RrIyBgMR5iOiQmA1VfuVy2nDa6cgQPPETwZpjxgCbz+bxmZ2fNM4QnC8yarnR0dNQgIDiBcrlscS5IfYeHh+0zrNVqBtXCXXk8HptQEZFAaMP58frhzJwdPYfA5eWlfD6fAoGAhXIynUmvpKqSjOzlQCAclg6egiLJCtLExISp7jjAMTdLskOI+HvplSACuT3f29XVZUWeSY+le8T90DXjCeIQZ+srBZtpAvUeHi2n7JiCCvTDfcb3wF9RGFBacfiSwuAk4Sk2Th7q6urKpMwoz3he+Vy5p50KQ6YoSZZzxgTr9LKw2weBEbAvUyb3BIQ8kKczVgYkBAsHPjKaIoQJTPDOgoHYivfv5Oa8Xq+tWaEoOVOwaQJIvPjggw9e/2Lz3e9+9z0eqnq9brtTmGyGhoYUiUTUbHa2QoJ/45VotVqampoyzBLvxcrKisLhsB0WThiFsTydTttN5/F4LM9oa2tLH330kQKBgKLRqEZHR205FiM1DwWHnNfrtffAtMRDRKz4zMyMnj59KrfbrXA4LL/fL4/Ho0AgoO3tbXtw0MdDrpMZhukOaA4TFwcr5G6hUFCz2dmTsbCwYGnLwH08eCTfskCNh7S7u1vf/OY3tbW1ZYnISFM5oI+OjjQ9PW0RG8Blq6urpnKhw2UlAb4e4Bu6zYmJCSOA2ZUBx5LJZCw9eWdnxw7Q1dVVw+EbjYYFPCJcIPaEQ5BJBZm7z+dTOBzW2NiYEetsOb1x44bGx8d1dHRkvhggUTr1ZrOpVCplpDXrAcDAV1dX1dfXp9nZWYOggFrYOcI0AHx1dXUlv99vsBvvgdfI5kz+LlwKRWJwcFCRSETDw8OamJi4BnlIMtUc8GAmk7Eiy6TBNM2BxvSElwOZuiST63Ign56e6tatW7Y3CTUTjdjx8bFNyvAwTD/FYtFgMsh5gi2BsTnIMbRiLiSs0xmYSTfudL6jMB0bG5PUCcwFksSTw1ZLqVMMYrGYeaa4f/L5vAYGBkz+7fQvwUvy+rjO7OFhCic6Cl6GzD2SuFnngVqVhgLBBH/Oe+ZeoGggkKLYMwGRbSbJ9gkBSTqbZsI+Cf9Evk7DjECG+/rhw4ev/6bOgYEBw8H9fr/JcG/fvq3BwUGLDkmlUmZynJycNJLr5OREW1tbNp6DN05OTsrv9yscDtuuGm52MM5oNCpJtgseUu7BgweG0Y+Njdlq40wmo+3tbVWrVcViMZPAVqtVi6fhoMxkMtYd/+hHP9Lu7q5t3wQPxgn+s5/9TFNTUzZ2Dw4OKplM2vTBrhw2PZL/dXFxoWq1qps3b+rWrVva399Xs9nU4uKipI5kEVc9/BaQDnAJN+3GxoZlyJ2dnenBgweW6bS4uKjj42N7OFmh3Gx2dt5QuKROenYgEDAlDonJbndnh83HH3+sUqlk3qBAIKBcLqdgMGjqPfgNzJO9vb3GETnXCtA9vlxLa0nCdNjkcgEx0s3TRaN+HB0dVSwWs/sDSErqdKxTU1PGL4VCIa2trUmScTcjIyNmkKSozszM2EEJjNjb22sSbkJGMcH6fD5NTk7adMVkCdSKFBdoC9hkZmbG8rqcHADhlsPDw8aXAMWdnZ2pUCgYf8AUgzy72WxajFCr1bKmDnl+pVIxFR3YfblctrgnICQnrPn8+XNr/PC04fU6Pj6+xhkNDg6aR+78/NymJ0ys9Xrd1F89PT3a3983KAg/C4GtTFpMhtKr1BIa2lAoZNJzFqcheJBkxR3jLwURyItnBpiSKafRaBjEBdIA9AXHhkR8cHDQGjXyBpG6I/LI5/OWUoJirlAo2D3CVML7hFdDLch0y8pvfFLsy8HYSs4bP2t9fd0a1MPDjkf/6urKIG4EE1/09VpMNt/73vfeQ2IbDAYtsoSgS0ius7MzRSIR3b9/3w4DRutYLGbqj0QioYODA8ViMd24ccNWuaJqcxKm+GmACnp7e1WpVDQ9PW368fn5eY2NjWlvb89i3iXZPojV1VUlEgnDtUkihqTr6urS+Pi4rQGgiKAGqVQqeuONNzQwMKDt7W27YTiwnO8/k8kYOen1erWxsWG7b5jctra2DJIKh8NKp9N2iNFRI21dXFy0WArnf4MkRxJcr9e1srKiWCymzc1NBQIBjYyMGAGK2s3lcqlUKl3jfzKZjGXZ8YAj+aTjhoeKxWIaHR3V48ePJUkrKyt2UHR1demjjz6yroyYjdTL9dqNRkPpdNpMsHgYnj9/bpwH3BZwY6VSsbUQHEqVSkWpVEqbm5u6uuqsF2Dihcymiz87O9Pc3JzxI9wjwGwcJKRUczCjomKCB0vnUAgEAmYE5b2jaHQmPNBpw8URZwKUJL1KhQaSBoJySpUxhTpNkcDOxKLQWAFVErdDgxQOh40L4F7C30LhgbSXOmox+BPeN5ANEx+wGa8DyTA8C+76drttcUE81/i7fD6foQdMsHTrjUbD+CruXd6XM3STKRy4Ez4JUy1Sd94HUBdeKN4XytaJiQlls1mLvqJRpSFGbQdSQvEio40Jg/fAvdnV1WWbbJmyaBiZ3vAKElZL1hxGTpoApst2u23nHn4fniOK68tEldcfRvvBD37w3u/8zu/YDgzUXtlsVm+99ZYk2RpdugF2w5M/tbm5aYvSnj59qoGBAYNs0um0SXXRvjsD6Pr7+/X8+XPt7e0ZbwN0AXlM15jNZlUqlWx/yrNnz2xEvby81Pb2ti2xwrSGPBvislAo2DiMM9sZDU/3RpwOD9Xm5qaZq5CQYgolfoNFTHiPVldX7SZHd59IJJTNZq0T5RA4PT01Q2C9Xtfo6Kj5koC66BZRqQ0MDGhyctIOFCBDFE78nJGREeXzeZXLZS0tLandbiuVSplXiUlhdnbWzK74plqtlm3MdLvdevr0qfx+v00KcDBOnHthYcGyqnp7e3Xr1i0zzfX2dvZxlMtl46lQm52enmp4eFilUkldXV2WbN3f36/p6elrmWTwWPiGisWi7t69q2g0qs3NTePV6HCnpqbU39+vQqFgSQl01sBkFBTuQa4j/g4KATJiDKcej0c+n8++5+rqSuPj4wbF8RrA+J2hkfARkqxb5jp7PB4LmmW1BCQ3r6PdbtvBCn9AEjW/B2IfKJCdTRysdO5wl3TZNHZcZ7gDOBBgRUQ5qKc4nPv6+qy5RL2Fegy1IlMGHBmRWM6mlPeDIhAvDoWXnw23yi4ZZP/n5+em5GIhHNMQBTAQCEiSiUB4n3AzTPq8FnhOPIFMyAg3EBAga3dK2OGIeC9I/2nC4NpQDQLdkSKBepjPsbu7W5988skvR7FZXFw0tQ54ICoT3P0cEiSYcqMdHR1pdHRU+XzeTHSFQkGJRMJ+FvJp/hzOBUMbJC8yzqurKyNCERxkMhnNz8+rXC7r7t27ljYdDodVq9XMT1AulxUMBs2QeXFxoaWlJUWjURWLRetcc7mc7TznRkQqS86a3+9XLpczPH5hYcEgx0QiYV0RB4nTEc7DkkwmVavVjMwEJy8Wi+bfmJubs6RaPk8OBb/fb8u78IrMzc2p3W5rbm7O/DVHR0dmoPV6vbp3754VYnwhKFtSqZQZC9n//u677xpxXiwWLcnA7XYbnEG8hsfjMSgxEolYlp6zS37//fdNgQaJmUqlVKvVbJdRrVYzrJ3PjAKPt4AHsN1ua3l5WeVyWfF43JSH29vbOjs706effmpbEZkWeeg5cPL5vJk24YP4Z/6uy+WyqYYGCfEMhxPcHKkbkM40OECkdOIIUSgIiADgZmji4GsajYZl+/HFtkfiTbin+KyYUmkKKBo44OmwabIwWALzsDeK+8S5PpkDj0zBkZERc7xzz/C+KIJ078BEzugejKAoCJ3RUUxtcBfYFngPzuIF58qE6cxTROxBIQbK55+BpJBtkyJAKjUCFCBRImL4+0xSXLuenh7zonG94AhROCLocLvd9joR9iCMQMjBpDw6OqpyuXwt2YN7lOvZbDa1vLz8+heb7373u++99dZburi40OnpqSYnJ3V5eanT01PbyEjH63K5tL+/r2KxKL/fr9XVVWWzWd2/f1+FQsGIcvTkuVzONuthsMtms5YUvLKyYg/RN77xDQs9DAQCxsPgLWGEZKLC1yNJn332ma6urowXoXBxMECEA/nQYQ4MDGhtbU31el2pVMoUdV1dnc2ShUJB29vbunv3rtxut/EjBF96PB4ziIHpX15eanx83LgSvnCDZzIZG7vp6jHq9fV1NvKNjY3ZA8YNDbxJVAxGUHLHwNHZX5PJZCwMtd1uq1Kp2E3OQrGDgwPt7+9bQgITBYVOknWecE/lclmJRMLy0J4/f654PC6Xy2WmyfPzc7399tumnsEnUK1WLWwzlUoZd4ISife2sbFhhxcHIQnRhMIWi0V5PB7NzMwoFouZL4twUeBM5wSBtJXOnkMRNRxTAwbXZrOzO4ZIfjg2pgb4QWAjglGdbnkgU4yAFF4mIO5rPivUSTQK/Gw+N4olqjK+iIsZGRkxiJh7E/4SuTVcK5/N5uamZXChqoIkh+B3+nrg02ZmZswvhjqPhgohAbEwTl+RJBMWOAsq0S7A7YlEwnxnTAw8nxQymmCaFDhhpgGeabhDpgVirzgLiKrC6Mn9jQ0iEAhYA0wWHwpJ0iQIGeU+AQbEw4VKFFhVkl1f531D4gLFe3R01BoVYEKaALjHTz/99PUvNt///vffm56eNuMe2V7ESjAmN5tN+f1+kwgeHh6q1WrZA0IHCon94sULk0yn02mT+15eXmpyctII7GKxqEQiYaMju0To5OlwCc0juoLDn6RW4k0Yp7nYPT09mpmZkSQjrwuFglwulz30fr/fOhYexEwmo+PjYxupUZjkcjn5/X4rrLj2OUyfP39uh4RTDZPP522HDgcMznKgllwup/HxcW1tbamnp8cK9+7urh0eBGceHByoVCopmUzq5OREp6enevbsmXW2FPFqtWp7NQ4ODsyUiwqLw5I1w8SpoPpzu93a3d21He9ECy0vL1s4Yzab1dzcnCSZOpBAT3xXXKOZmRmTeIOBw29ks1ltbcdueYUAACAASURBVG3ZA1UoFCyN4vT0VHfu3DHYif/RjdKZ4rXo6+vT/Py8urq6tL29bdJoSfb7enp6rgVF0rEju0dl5DzUnWGdHBD4xAha5MB04vbONciojFBf0akjDXaGktIoUbiAGuFUnLwEIgIEKc49MwTIOrmeSqViheLy8lKhUMiIbrx0QIXIqZvNpra3t9VoNKxwk6BAw8rB6zSb0sDxLLEcjteDQALolffLtMk9Tno7vBsRRNgIOJ+Av4F7mShoFuDLeA3EVTlNsiRMNJudYFYUbaAvFDdJVohR+zG9ch+gYqxUKjo6OrJriijDOV3SsMHvcI35LBE5ca0bjYaePn36+qvRJFlwYzwe1wcffGCHALJjeIi9vT1NT09renpaiURCg4ODmpmZUbFY1MbGhiSZ8glSGnKSbmVyclIrKyt6+vSpWq2WUqmUdQlEhySTSc3OzlpUN4Q/cf/NZlNra2vyer22HjqZTJp/4dmzZ+bav3PnjmZmZozAZHKQZLg1i62AVprNpubm5hQKhfSd73xH/f39ymQySqfTikQi17ojiMp8Pq9SqaRQKKSTkxML6Ozv79fs7KwtmQoGg0qlUrq6ujK5NmZElFPBYNCWtg0ODmp6etpIdgImx8fHDeb88MMPdXp6qlgspsHBQe3v71vgpNSRyB4eHtoBgFx9bGxMt2/fViQSMf6IPK9AIKAbN25oYmJC09PTcrlcBk3u7OxIkmVS9fR0krVHR0c1MzOjaDSqu3fv6utf/7o++eQTO5ApyltbW5qbmzOPBZte4ZtILw4Gg5qfn5fX69Xt27ftwcXgSHjk4eGhxsbGVCgULP6kv79f+/v7tqQMeXBPT48tn4KXQhHIITk0NGRwFvcmmVyo8JzJxEAnwLlMgmTegb9zyMMdeL1ey9+iECIegCeC/0EazNTJIQifwuTBNWeSo7E4PT21Qoo/hmcmkUjI5/PZGoNWq2VQHkQ1np9SqWSQI6ILpMVO06kku1aYcxF2IOmmCBP9BEQmyd4LykkEQd3d3UbMA8nRGHHf8DmiQmPqRoXqPNyR+yOSkWTFkHMHiBoLQjKZNAUkhYe0CZ4LPGgIjgijlToFiAYFbxbNGFxdIBAwKI+0Bc4J7jdUfXBrX/T1Wkw2f/Znf/bejRs3jCCLx+N68uSJKYCmp6eNwIQAJMCQBWPZbFZXV1eKxWJ2IRhDk8mkJNmHXSwWNTo6qmw2q3feeceSYsF+m82m+Ti2tra0vr6uYrGo8fFxw/uPj481Oztr34c+nk51ZmZGPp9Pu7u7BnWBIWNy5L2Uy2ULBSWVeGNjwzgrbrqZmRnr0MfGxuTz+fTXf/3XZjykYGFSbTQayufz2t7e1s7OzrVEbMyAGBsxnZJh5ff79fTpU01NTalQKNgOFaawjz/+2KBI4LFKpaKhoSGlX66XRrFydnamO3fu2FS6trZmLnrEA7VaTdVqVUdHR5aSgIgBU+To6Kg2NzdtGgqFQlao79+/b6u1+/r6TKbudrs1NjamR48e6caNG/Z6k8mkyX6lV6uXj4+PzfswODioRCKhcrms3d1dm0TZWkrXy8FGtA48CIpDOBSmCRIHKJz4eILBoAYHB83jgSKM6R05K0osqQP7MEmm02krRHBbQC54TCQZ10lzgsEWyC4YDGpra0vNZtO4O+SuNDeXl5fy+/0aHx+3pAHUfsAqTM5Mss4pm2kAiAlBAjuc+L7z83NTJNIIcs2QYSPYOTg4sGaJjDW8IXAeNCetVutag8OZAmkeCoUMxeBAhy/zeDqbPVFvAbEhXkCajKqOphfVoTNDjaLrnPA2NzctOZwJheedAgZfw8TTbDbNzoHnimJ6cXFhRZz34eTTgO0o6s5zAb5nenpaZ2dnBp0yMTsNn78orua1mGzocNhDIklf/epXLe334uLCZKj37983XB9OB2nqxMSEeWXYi9Nqdfbb1Ot1ffzxxxbdAuxBXAreCMybbrdbm5ubOjw8tCVa5+fnIlbH5XJZt048Rzwet26Yda6/8Ru/obOzzjZAdofjfOchPz8/1+zsrD3Yu7u7mpycVKlUUiqVsjUIcCd+v18PHjxQvV63bZlAXmSzHR8fKxAI6PT0VKOjo9re3tbGxoa5fvEYEYtx584d++zu3r1rCrBCoaDl5WWVSiXt7OzY93d1dSmTyRi+Pjo6qoWFBVUqFYvDALKgkLIBFQEDCi6MYfiDYrGYGo2GxsbG9OUvf/maXPett95Sq9UyWHJ8fNwKvMfjsQV0a2truri40N7enmXuNZtNi+DY2NiwqP1MJmPqJwQT9+7d09jYmD7//PNr3ovj42MtLi7aLhufz2cm44uLC+PWgFQbjYbeffddc84DiyKi4DBot9sqlUo6Pj42uA3sHeWX2+22Dh0YBkh2Z2fHiF3ie5ykPxMYYYxIZ1HTEejq9/t1cHCgSCRiBzxya6JjaJhofBKJhJloKQhAZOfn5waJMtkNDAwol8vZ5831hbNB2k6XHo/HrYlADEPSgJNXvLi4sDQLp5QalRr8R6vVsqaKQgh8KMlQh3q9bkGn3PdIioEPgTGBjIHp4U6xADinfDgt4D6aLu4vJ4coybxYQPe8NqdKrNVqmRINdSm/3+12W2gnnA38HQG28E3OFdRjY2N2bZzwL9MdsCkT6C/6ei0mmx/+8IfvRaNR1Wo1U2JsbW3ZB0eVPjs7s8h6Nm4SZcNhRFfnxH2RFUPq03Wi/KITIpOJhwEFy8jIiE05o6Oj8nq92tzctPgWIvUvLi4UCoUs0oOYGF4bSiR+xtHRkf0MHgw6l66uzra9gYEBPX361MxT5+fnymQy11KRnTDJyMiIjo+P9eLFC5NY4yRmCgSqoZPheyl2OO0J5uzv75fP5zM1C1sDvV6vbRalM5dkWC7ff3Z2pkAgYNlnpO1CAodCIW1sbCgajSoQCNh2T1Yv0IAg2OA6r66uyufzWZ6Wx9PZqZPNZi181ev1KhQKaXp62qKJOACTyaRBPByOeL22t7cNivD7/cpkMsrn8wqFQvL7/WZwRSZK80LQarFYNPgGZRivnUkILJxldHgaIOjhg4BV2XVPYCXpEk7vCfcg6kSeKSYhni+n14aOGygIiAg4GrM0k6ukfwbjAblhMmSLKvAL8BZwIkIMunLQATLF8GI1m03jwuCIyIUD4kGKe3FxYVJcCjrQIb40zIsUnoODA+Nz+H0crHCkxEBRfJzQEQiBUy0GRIeIgwMc2TI7lBqNhindKKxOjw9kPwpHpzqR38m0SPYj3heUpwgVOCtrtZqGh4eNj2aqwbTqdruvZbJxJnE+HB4e2mRLJI/P59Pg4OAvh8/mhz/84Xvvvvuuent7LcqbCBWyv/jq6urS0tKSPUCoIqROl8sF4dDf3d21nJ+bN2/q8vLVet2LiwtT9BC9zyEITg4BTyfEhZ+cnFQoFLLoCw5qSNH79+8rGo0a5koCABLqVqtle0+QMpPU3NPTYyQeKhqv16vHjx/bA8cEFgqFtLi4qMvLS4vyabfb5qgeGBgwGWOr1dLk5KRhxYlEQs+ePbu2RA1xAjj89va26fzZbU6nGI/HjdBkagPuxCxH0rbUEWmghILERKThXHuL4mx7e1uDg4NKpVJ2rXd3d63ADw0NKRQKmdy3Wq2qWCzq3r17arVaNkW9//771r3mcjkTOSDCwNPT19dnn9vs7KyZDul0SduFc0PdJMkOEY+ns66aexLordFoaHx83CY4ij6fERyNJPu5cCTk/pGXhxOcTlWS/W6fz2cqPsh/1HE+n8+KIZ0sPAo8hsvlshikgYEBa3Jo+hAejI2NKRwOW3YY1oRkMqmVlRXjEUql0jXTKDATMC8L/vAT4WuDZyW8E7MmxmkOOzgbuC+pUySYoiC1KTDwknAUV1dXtmKEGCa8KBy+Uge+J64fqTfpFM7QSooI9znS8/7+flUqFfM+MZWenJxYzBRFKZ1OXzuHeK38XAh6IqGI6mG3DAUE8YDL5TJokgaHJoFIHxAKSSYW4rMjFglok8/e+fmMjY3pZz/72S9HsfnWt75leGkikbBROBKJGBmLj2J9fV1+v9+iz5FJQ2yNj4+bWY9dG/39/aaa6u7uxPPv7OxYzhgdJSms8DpIPnEWHx8f2+7vtbU1w5t7e3tNEJB6GauD639/f9/wZCAfHnrkkLFYTH19fXr77betMCCb7OrqMrk2ksWZmRlzz3d3dyuXy2lxcdG69OXlZTNuYbCsVCrq7+/XwcGBdTAul8tgGTxAGGZx+EciEVPicTgxaZK6u7GxYfACDy3QCRMZHSTktPPw4vWEQiHt7e1ZV4jOn0mXA7rVahncCek/MDCgd955R4VCweS+OLCBj4AKORxxx2OkjUQi1vGRTQfxm0wmTQaP+OLw8FDj4+MKBoO2yVGSHj16ZB6lwcFBlUolEx/Q7ZMMTtfMBO9MYcDHQhfpnCq5Z1nnQIFtt9vWHOGhoTABG4G1O932SGKBupCzS7LXQUcP/8SByGfmVOfxXrgX4FOmpqZM7VetVi0BAE4FXxVkOV05rzkUChksSyK3M6aG18/E3tXVZQWTyBWy4Lq7u22CIWiTOCdkvXBmyLIHBzsLBGm0nLyf9GonEHAiBnO3262ZmRmLSOJ7UKsdHh6qWq1anFG73b7WVBBj4wzjRMruvD58L7wd55BTps3P4P+d/h0mKz4vl8ulQCBg15F7AlWi1+vVxMSEfvSjH73+xeZ73/vee1xEiHNJFjAJZIRGP5VKye126/nz5woGg9ZFDQ8PK5PJ2CHe19enjz76SJJsh/3t27cN8pqZmdH6+rrlHAGnzc3NmVIrmUzaayBDqlKpqFaraXJyUtPT05YzBN7tcrlMcptIJPTkyRPV63V9/vnnOj091fT0tPE7TkUMoZikKExMTBgvQOeN9JGNeUdHR7ZwDnkwHIPf77dDuaurswF0bW3NkhNYDndwcHBthSy/L5PJWKG/d++evfeRkRFNT09rcnLSii5JtWdnZ5qenjbOgRSGRCJh3d7u7q5SL5Oce3p6bFpLJpPK5/NaWVnRycmJwUoXFxd69uyZKpWKpSBvb28b3LOwsGAEfj6fV7VatQ4vm80qHo9bYfR4PJbo/fnnn5sxL+1YWofzfGpqSn19febVGhjorMeen5/XycmJpW9z8E1OThqP+M4775g3Ip/P2wRCKgHCBfL3OCzJgYtEIuZcJ2zVWSCcAYlE1WDwxAdGgUeoQeElPJPARjpnpPpwpUB8NHqQ/0iUUVn19PRob2/PPm+2gUqyZwZuDa41/XLpXiwWsy2boARdXZ09P61Wy1IgSPHgc6TB5P05mxAEKPw35+FLoUHBiO+JyBYmTFaaOPnCRqNh23MpyixAxAMIrEaB5zrQyJJdh4ABhOby8tJWfvh8PkuSd9ojCEylEQVORsgBB8U9TXModVAffDJjY2PXZM/OLDX41vn5eRMgMIXV63VFo1G9ePHCGiWax93dXX322Wevf7H57ne/+95v/uZvKhgMampqSplMRtls1iI+WIMcjUZ1dnamfD5v+C7uYPDKUCikL33pS5Y6i9Pe7e6kLEMY7+/vKx6P6+DgwDK9GI/ZT+52u80wtri4qPHxcWWzWfX39ysSiSiRSGh7e1vhcFjFYlFbW1uW0ebz+XR4eKidnR0rHqRKX1xcmFcGb0s8HjdPSiKRUKFQMCITw2Y8HrfIj7W1NSvO09PTtg3S4/Hogw8+UKPR0OHhoTn6CfDzer36yle+omw2q1u3bqlUKml2dtYOn/Pzcx0cHJhDfXh4WENDQ6pUKua3uX37tnWU8EYUymg0aiM75CzkJRzN5eWlnj59qoWFBVMEkb1VrVbNyEvm2NDQkNbX1xWJREyxRWYZByUxMNlsVsFg0AQWPEwUag5SeAugx3g8bk3HwsKCLi87+2yazc76hvv375sBsFwuWwhpq9WJ7mdTJKuSUWtVq1V7YHFxg51DzgNfud1uxWIx+5wkGfHqdncWpgG7on6ia6e7xWj4ySefWEin02zI9IK0+fT01JIJkMDDL/X29trBBK/AtI2KChEBUyz3KgooDMatVkvBYNBsA0B9ksz/FgwGbe0xBmlgUnxGwWDQ0AQk3nyOZPGNjIzYFloKER382dnZNZiMpoZpjImRSQsPCkWSa4E4wJkpx2QDP4NtAEUZ8mTUs/BQmKvhbTB7AzkyeTFJw2ex7qDZbFqRRjzBNSSiBo6MqZmCBF+HVB+DNk0N4ouxsTHzGTHx81pRij548OD1LzZ/8id/8t6v//qvG97d3d2tmzdvSpKKxaKy2awWFxeNoHz69Klp7e/fv2/7PghYxECXy+V09+5d9fX1aXt7W+fn55qZmdHk5KSNpsiGCZRjSmEL5uDgoNbW1rSzs2N4aX9/vxA0kOcGBxIIBPT8+XNTo/T09CgcDkvqdBfj4+Pyer2q1Wp6//33dXh4qFQqZX4XOI+NjQ3VajXLL6PDGh8fNzPr4uKi6vW69vf3DedGythsNhUMBi0+HZ09xQ511eXlpeLxuHEatVpNX/rSl0xpgpyX8ZvATRzhHDxIPD0ej2UmPXnyxDqh09NTCyxFhEDQYz6fN3c8Jj46SWCXXC5nUSEo5Vqtli0/q1QqmpmZsULkhEKGh4dN7JFMJm2a8Pv9NvGtrq7a9NzV1WWqKK/Xayqw5eVlW0KHQ313d1czMzNqNjtbZDGtSq+i3YEyU6mUHXjIs/FlAImQVo1nAv9Hs9k0EyIdL4cUXTAH6sjIiMLhsB2EdLEcTMi2e3t7TQGG8bOnp8d8K6Q95PN5O7CBV1DNUcBogoCwjo6OrHCdnp4av0n6tdfrtX1GFHQOdg5veBKmOJ7RXC5nDQ5fTr6CqQqIlULF7+AAxxCK94QGBMk5MVJut9sO6cHBQdtGy2eGAZLnD+gYeBAoitQDrpVTvINXDmEA0wxCED4nrgkNgDPKCKjQuTOLnwUKQHPRbDYNUuZ3wovC1QArct5wjtDcUbCAmn9pNnXOzc3J5XLp3r172tjY0NXVlW0IxLfQbrdVLBaVTCY1MDCgqakpnZ+f6/PPP78WsUBg5OzsrA4ODqzjRtsO5AYnNDAwoHv37tlWyrGxMUUiEcPq5+bmFIvFNDk5eS1DCLiDLKxcLqfnz5/bwRKNRk05x4OYy+XMsR6PxzU8PGw5Y6hICGIE/gkGg3ZwoZ4iugKCLhAIaG1tzfwukIf8HR66er1u3hu6y2KxaEnVfr9fkUhEf/d3f2evI5fLmVrv2bNnmpubU39/v+bn5/XgwQOFw2Hlcrlr6wx6e3t18+ZNg66Y5Hp6evT8+XNzJBN/39vbq52dHTWbTZ2enurdd9/V/v6+UqmUiRQKhYLtCWq1WtrZ2bFDjAK2ublp/hu4OtRMrVZLH3300TUDL1OfM7qEVO5Wq6VHjx5Zpld/f78R9rVaTel02uJ9EomE9vb2jCvw+/0qFotaXl62YEaaFRRgjUbD4E5EEhhafT6fdaaXl5fa3d1VJBIxPwRFCCUWkJL06tDEz4PUFtm01FE9BYNBaxL8fr+tX6DoACdyoHR3d5vSEQ4KXw9EMpAbzQ+cB/wJKjFQCdRavG7+Hh262+22LDYk5sBsh4eHxpHhmSJbDeEBijugdpIB3G63Bfsy0XOvsnzQ7XZrYmLC+BnEO6xHYGdQrVYz0p4zBm6YAivJYEGez0AgYOIPGiQKiKRrBYUmBMSFAoz3he+9vLy03D++EKVQyAcHBzU1NWXTLlM06l2aGLgleCmfz2cePWA3GhWfz6ePPvro9S823//+99/D4c5hAxdDYCYZXxxM7XZbU1NTWltbM9we8xmSy0QioUwmo0ajoXA4bCnIU1NTGh4e1u7urokFCoWCzs7OtL6+bt0LNxCGNqAQOhY22bndbou1YdeKJMtnazQaJrFEfs2hSNEBm+YBZ4Lo7u7W0dGRQS/Iql2uTnS73+/XwMCAtra27FDt7e211Fkw/6urK/tsBwYGFI/H7f/hmZBtDg0NaWdnx8hQunngGBRCcEMXFxdKp9Pa3d2Vz+cz8UZXV5cikYjS6bRh1hQXoB/e39LSkqRO9wlkQaJ3vV43KIJDDQPj7u6u6vW65ufnjfSFe+jt7VU0GjVo5/z83GBQIAL8MmydhGchRbrZbJqpmC6UPSfOhx3FDoc68lbkyEw7QCR0t3ToTN5Aahwc4XBY5XLZit3Q0JAtYiNrDNKW7+NA4v0cHx9bsUVkIL1KXwBSQoUkvQq3dEqxgVqIbEF8cHZ2ZmZUIDQOc2TCqLDwewCzAs0RIMuUQ6Eiq4wGD/6J0FomHuf0wyFK4ceMTQoyHhw+a4ylTDAULYoioohCoaBaraZQKGSFBNMsAg4mBZpHrgGvh+LM9IECkxRpCjefG9AuSAXP59jYmBUR8gqZyldWVmyaPzs7s6mTZPOVlRV7brnOCE+YgHkvZBqicsS0TOHGP3RxcaFHjx69/sXmhz/84Xu3bt0yoxGdRC6Xs06G5OOxsTGtra1pZmZG7XZnTfD4+LhNGKwRHh4e1t7enhWWYrGo9fV1M9o9f/7cyD2cwNVqVRMTE+aQx68RDAa1s7NjhxmcwNbWliUDwEkQJYP5C3gtFovp8PBQ8Xjc4IGDgwM7MOAoIINbrc4qa7DZk5MTpVIpw1hXV1et60OuDB7s9XpNFs3agFwup2QyeY1HYTxGdomEGMPWzs7ONRjP6/XasjluStRZ5XJZ0WhUw8PDxh+dn3c2htbrnQ2YkUhEP/nJT8xsSsGkuExMTGh9fd0UfQg0Go2GNjc37fc9e/ZMwWBQc3NzCgaDBos0m03Nzs4arFepVNRoNGx6Rd01NDRkRl8iOOACent79ejRI/MUMF1wUMJtvP/++5aETZdbKpXMWEp3iPyVg4EofNRBXE8+U3xImIlPTk4UCoVstYTb7VYymbT1DrwHnPD7+/sGbdHZ/1NTIQoiPCMUNuTPQDHkmvFeWA7H9lp4Ka/Xe807BkTrjL0hu4wmEiiH+1eSFR2EM/v7+7q6utLMzIyp+CqViqUnw3kgZa7X6yYSQJmF2pHfjxSZbC+mRDgRt9utyclJez3Sq0gWhEdAcSjJ8KPwWmiM4X9QW6J4hMfDL4T9gqaA3UxwyEBorKIgnZpGlgibnp4e80Zh3HUWOhSLfHYvXrwwMQkiCgr60NCQ+eS4rt3d3SqXy9bIAeUiwvil4Gz+/M///L3f/d3fNccx8kbGvmazs60R4gqSanNz00ix/f19SdL6+rqpmpgYgGhIBaCDe+edd651++zQgR/I5XJWzE5OThSJRLS9vW2jL+R7Mpk03Boz5sLCgjKZjAkOgELQ1mOs8nq92t3dVW9vr3EnfX19KhaL5uRmyqGrc342kISFQsEOD2S1xEiQ2bW4uKjUy0w0DoBf/dVfta68VCrp1q1b2tjYsAw2Nhjm83ndvHlToVBI5XLZDt9//Md/NMk3v59YGh4QFFCNRuOa98hZAFC9DQ4Oan5+XvF43O6FtbU1XV11Vj1QOOhG/2lx4zCfn59XrVZTMpm0ZHA2wSK8qFarSiaTWlhYULPZNIe9cxqkIQC64DBHzOLxePTZZ58pEAgYZDI8PGxbFlOplNbW1gz2xO2NAq+3t9eUgMB6bKkEg+fzIVOrXC5f64wRyZTLZYM3wNjJw4OAJmn69PTU5McUOLg853+DgAfS5fBErclhjlkZK4LTh0HisdMBz+HFtEuxwPvRbr9aTw1/yNQDROx85py5c3AOKOtisZh9Hkw4kP3sf6IwBINBg7fgN7guTJW9vb124AMdUnj4HmTj3d3dmp2dtemIyCePx6NUKmXiJIoh8LIke5YpvmyhhZcMBoN2vhHCCheHeAIBCxAxJl+n14ciR5QO/ihsEdgmmAYx4fKZSp3C9/jx49e/2PzxH//xe0tLS+ZzyOVyqlQqunnzpmq1mmKxmMVJYG4D81xaWjIn+8LCgkFwPGSDg5210rlczjoiJHuSriX6otJ48eKFraYOhULmj+Am4QZDFQPGXiqVFI/HTQqKvHh0dNSUPixt4+8RbzM/P6/19XVdXV0pk8kokUhck3/SKTJWt1oti7NZWVlROBzW6emp7t+/b/EsuVzOphIgE5fLZTEZk5OTWl5eVjQaNUhgfX3dcpgkmf8GOILpqVqt2ucVDAY1MTFhBX18fFx+v1+hUMhMrs+fP5ckM7B2d3fbqoNaraaZmRmdnJxY1I8kM/aC82NyZYXz3t6e/H6/kb2Qx+RAra+vG8TGwU6nfXBwYKuYG42GPv74Y/NC4IYnbRu5+N27d1UsFu2AowgnEgkzXEajUeNKIpGIXC6Xnj59qomJCfOjeDweg+WA9+BD6Ph7enpMnIAcl/uOtAGKK25+oFY6Wa4VSREoB4FAIIWBf4ErgW14LRxOcKfSq9gSTJCskTg7O7M9OASjonajSACpAmdx2MKnwtMCqdIgwOVQ8JyqOF4PSAX/PjExYXluXHvgOvg2Z1gmRZ1pEPk475lnh3gjlG2SLHWCNIlarWbZc0dHR7YfBzIfBIEDG96JpA6UeU6/ENcBXg0RDEIArgFNDdMwggsEISRUc8/Q1GBiLxaL8vl8NhUCxznVevimKEK/SPrs+kVpnS6X63+T9G1JxXa7ffPln/kk/aWklKS0pN9pt9tVV4et+58l/aakc0n/XbvdfvSLik04HG5/5zvfUTAYVDKZ1Keffmpu142NDU1NTVnIIqodt9ut9fV1hcNh66hisZjOzs4Mrnr27JkCgYBmZ2f14x//WL29vVpYWDCFC9sRd3d3jfAkVQC81+v1WpIviQbAaSQOQIJ6PB699dZbGh8fVz6fN+8HB5PU6eiAM5igUCilUinNz8/r6dOncrvdRjJ/7Wtf06effqpkMmkqGPT8d+7cMZ9Gf3+/Hj9+rEqlojt37phfiYMlEolofX1dx8fHSiQSqtfrroq/qwAAIABJREFUlnxAV0n4ntvt1urqqimKIAhJAyBgFLf8/Py81tbWTJ7MDhIORZaDuVwuxWIxSR0PRqlU0t7enuW/pVIpdXV1XfOCILvc3t62v8cDCB+QyWTsgQ2FQrbldGFhQel02jBuptd2u614PH6NDOahw2g4MDCg3d1dg1J5XbFYTJVKxcQU3GesFbh7965NU/l8XrOzs5Je7UoBm0eEwMFOtz0yMmKwLIevJNsiCd4OOQsej7wdnwicF2nipPyCyXs8HiuKvF+UmXy2FAfnPhYaLaBAYBbuQQypCC8ojpKsObm6ujK/Coct0frIui8vL+11wecioCCWh+KH7wUBBYcxRdBphqTZ6e3tNb6S6S8ajdqzvre3Z4rMnp4eTU5OXlsDgOCDIpFOp+31RiIRM7nyeglGJX2CdA/EMzQxcI68Too0Um6aCFAfYFcUb6Q2oKJERIGQhp/N84JnjJ/JlOiMYcpkMpYu4fP5TLEImhEKhfT7v//7D9vt9r1/7Zz/twRx/u+SfuOf/Nl/lPTTdrs9K+mnL/9dkv6DpNmX//s9Sf/Lv+HnGyFG7hccBGGRZBVls1kdHh6qVCqpXq9rZmbm/6PuzWIbv7N7zy9FkRK1S9xJUaKopUpSLbKr2u4lbsd90530NNJ3XvKQl3szGOC+zLzN0zyNX4J0J+4sQILBvAS49yWDSTpAgmCCIJ30Yrdddi0uy6VSaaMoLhJFkVooiqJKEjkPrM+pvxp97YvMDOAW0Gi7XKWi/svvnPPdjrq7u02ifHJyooODA83MzGh4eFjDw8M6PDzU4uKipqamDG4LhUKKx+OW3IrEkQMxHo8bZ4DcGHI/GAyqo6PDXOfseCGPqlwu6+OPP9b29rbS6fQVRVStVrNdKSsrK9bxAZV5PB6TlPLwMQn19vbqvffe097enmn0h4aG9PjxY5uA1tfXJUmvvfaaEdjFYtFMYoeHh2bso/OiwymVSldCF3G/ExQqSZOTk3YPgAYkmSN8bm7OSPPnz58bh+H1enVwcCC/32+CD2AgIJJAIGDBl6j24DSYNIkbcmY0keK8t7envb09HRwc2F51ZKOVSkWbm5s2hfr9fk1PT1uXioKpp6fHGotr164pEokoHA5bLA8y5e7ubotgB4JaX1+3g2V5eVnNZtNk7pJMCosIgMmDSCEiVcDw3W63qcpcLpddO+AluCae+1KpZJCn1C5sTpc+hYxudmhoSOFwWLFYzNSNkNo4zYEq8YKAz/POQIqzc4rlb6ioEDWwE2lkZMSy8jCZ8hxjRsSUu7e3ZwornhOgKSYx1JTsFaLgwXEQzQ/nxFoHoLNfNHvCxbBg0efz2fQENEWsDt8fiX2lUrHizvfp7++3CC0mKybNvr4+iz7yer3mZ4EjgzshqBPIqlwu6+joyJ5d3jPUjUzHTMM0shhy8R7yTCL8YOICASBOip8XIYMkOytZyHd5eWmiqM/6+txi02q1fiZp/xd++d9L+s8v/vk/S/rvHb/+X1rtr3uShlwuV/Tz/o7z83OL4WZcJGWZrqNWq9kaATKb6L4gDXnYj4+PDYskOJBxFPmnEy4ZGBiwxGimG+nljhFywIaHh7W1taV0Om28QU9PjwKBgEXOVCoV5fN51et1Xbt2zSAbUnnp0oFD/H6/qXuOjo5UKpXU19dnC5uA93K5nLmPMdqdnZ2ZuAD54vT0tD247AE6PT3VysqKstmsJVtXq1V1dnYa8es8/OiYCQKdnp5WIBAwk15fX5+N79euXbNulZBT4EG4qv39fU1OTppT3NlF4qNB5Xd+fq6NjQ2L2Tg4ODAYiyRaihOxGR6PR6lUyhR2z549MzJ6bW3NOtF0Om2wJcoe50FcLBbV29trz1MgELiy8AwIA4kyBxTcSCQSMZ4AfgAYkCLFoby5uWkdZCwW0+joqB0OHKixWMxSnMHzebk5HCTZdOoko/f29lStVm2SQqjglAdz2DFl4f+q1+vGge7v75sfBtksAZwo3CDdgWyBoi8vL82DAlwD5IcCyrkSAa4IcygcAoZdJjOiU4DiJBn/g4iEg53JJxgMmtCjUqkYEgGxztkDt1ev103EEg6HDYIj8FKSTRY0iEw5QIdwOfC+5KcB/aFKZNpCrENDxXZZCgIiFu7jycmJZRVSMAn2lXRF9QiXhxAEhStNBZtmgTKB7IEmu7q6NDY2Zopc4FqmVqanz/rq/Nzf8cu/wq1Wa0eSWq3WjsvlCr349biknOP35V/82s5nfbOOjg5ls1njHYicZ3EWruwvf/nLlriMMQ2IgMM7EolocXHR9ofQuXs8Ho2NjalQKKhQKKhWa6+f9nq9WlxctJFxaGjICHknJFGpVLS0tKSpqSktLi6qUqlc+fzHx8fGT8BpbG1tWd4XHAWREgRiOj03s7Oz2tzc1MTEhDY3N00iDFY7OTl5xUzGYUpGlSRLvCbeIxqNam9vzw5z4jAKhYLm5+ct4aCvr09HR0dWyIAL5ufnrTAdHBxodnZWkmxCSKfTikQiVzZR5nI59fT06NatW7q4uNCtW7e0vr5uHpxGo2H3By4L3wXQHqsHcrmc+YyePXumRqOhL3/5ywarceBsbm5qbGzMFrKNjo7q448/NtkrEuPr169bkjT8EhlsExMTCgQCRmSTatBqtbS+vm4HCsvSFhcX5fV6ja8LBALyeNpbRe/evWvdJWQ/4aSYUpHPAzWy2K7RaKhYLGp3d9f8FT09PUa4A6sAuzhDMknZkF5mdfGOkJXVaDTsmtM0xONxlctl63pbLxKR3W73FR8HO12QJzebzStwIN6fVqtlzRFdvdvtViKRUD6ft+gpp2S6UqlobGzM1JrAfKyCgD8qlUpWzHw+n8mtmTiYHBEL5PN5K84c5HhrELrwPlOISQRH6MDPTHPKmhPgaegIGj3UrUx2tVrNeCeaAozLwOxk6EWjUbs/QPVERXV1dSkWi1mxOD9v76/hnZPaKQsUbgoWkuzOzk5DS0gJocFqNBrmUcPUCb9DhBVZgnxPGg+8RJ/19W8tNv+1r19W3n4pKeRyuf6T2lCbJRg/fvxYw8PDmpiYMB09u+D9fr/i8bjq9boSiYR8Pp8ikYhBcP39/RoYGFAmk1GtVtNXv/pVffTRR1cSTZ8/f27S452dHeXzeb3++usKhULKZrNKJpNaXFzUrVu3jEzf39/X1NSUPv30U9tpwQPCzWAsZlNgo9EwKAHXPF0WvgsKHoeH2+3W1taWOjs79dOf/lSRSMTCPwcGBvT1r3/deIlwOGx/z2uvvWYv1d/93d/ZZsTp6WktLy/bDhUmRhRMRP7z8EEmFgoFe8EQUdDdjoyMaHFx0V5kss8Y87mulUpFr7/+ugYHB41vWFxcVCqVMuiR7grIoaOjQzdu3FCz2Q5BBfLAHPv48WONj49bFh08z4MHD2ybK1l6mUzGwjglWeAqWWc0NMPDw8rn82Yu3NzcNHUXcmLMpASQotyB/K7VahYLRMdLjD5Q08jIiK1qBtN/8Q5c8Q6RTMC1B4/n8Hz+/Lni8bhdn+npaTMMY1KGV6FBYrMi3AMqJZztUnsyxKjndIlTJEhEhr9JJpOS2lwgHTmyXg5Bl8ulYrFoUnyeKVSVkuxdAloilRrlF40euXRut1tPnjwxHouCw3QANByNRu2aQJZzLeGBUJvyXjKBwyHR0A4NDdm0CIe4u7urs7Mzy3uTZFMGzwkcE9FU8CfshgE+xjPY0dFh/CFwGYc/akXMyASDAr3STCFwoSjjBWI9wdDQkIrFoinRuDYUSAQTkmzqQdaMQi0Wi5nJlwaHwNfPLQ6fJxB48VIkJf2DQyCwIunXX0w1UUk/abVa11wu1//x4p//6hd/32d9/2g02vr2t79tXZokM7SBMZ+dnWl0dFQbGxsWdXFwcKDp6Wmtra2ZNHN0dFSffvqpFazd3V0jndl+5/f7ValUVCwWravBncyE8/z5czvIUfEgImBiQmv/N3/zN/rmN79pBxM3iMMHox+ubl5w4IGBgQFtbm7K7XYbAU9cBkGhIyMjlvR8dnampaUlTUxM2IRzeHioUqmkYrGojo4OW9nMITo/P28KLH5dkn1GRBMcwjxwbrdbfr9fm5ub6uzsVCaT0d27d61I4VehE2SLZTweVywW03vvvWdRQxMTE6bhRwWEiosV4GD2eJt4QVhDjXQaknxzc9MWe5GfVyqVlEqlVCgUNDg4qI2NDTWbTd25c8fCRdnZc3h4qDt37qhQKGh8fFw//elPbcqs1WrK5XLm6/F4PFpcXJTf79fAwIB5vyKRiKamptRstvO8Wq2WstmsBgYGbP0Ee5h6enosxBI4mD1HFAD8Mcjy6d4h2SFv6YjxgBDmiu+os7NTu7u7JovlcGFSAtrDIQ4swmHGtOVyubS+vm4KKemq2MEpcQZiRcWEMAM1KTwAZlB+HmChSCRiPink+5FIxAo3jRPQLQQ/z+3e3p5tD8VcjF0ACOvw8NDgIq4pcnxJlqrQbDYtYJZ4fTIHkaHzLH3pS18ygQiiFQoA8DPXiMIryXg6STYpsibE4/GY1B7jJoowJ5TGPYO/vri4sGICdIt3h+mUgg4kxrnipBbgheCVSDUBJXC52luGEQ38/u///v9rgcAv+/p7Sf/xxT//R0l/5/j1/+Bqf31Z0tHnFRrpZUIqeCD7Pbq6urS+vm4H6CeffKKJiQnjDSC9nbDH1taWIpGI3aTh4WGFQiFVq1Uz4K2trenRo0dKJpM2XZCWy+jO1ktJpmLa2dlRsVjU1taWlpaW5HK5lE6n9cYbb5jnhbRU/AzAC+Pj4/J6vVpeXtbR0ZEajYaWlpYsapxu6OnTp9aVwzHNzc2po6O9DOzy8tLk4LFYTFJb4dbX12ecQ09Pj8Ei9+/fV2dnO02YSSkWi6mzs9NSZCmyGMIODg705MkTffjhh0Yqdna205olqVAo6ODgwDxNzWbTIC8K68TEhK0nYI/H2Vl7lTcbUAk+TKVSNq4D23B4kFLQ19dnh8vJyYnu379vhlJ8RhxmQFeSlM1mdX5+rlQqpbW1NYMgzs/PNTk5aUQty8FYpre+vq7T01ONjY1pfn5e169fN16ONAiCOuEXmFZDoZDm5+eNj2PLbDQatV0xcAoEewJnARmhOAK6Oz09NZ8MPi0OGBo0PFpOcQQqLacCDUgJVz+YPAcwcBE8QLVateioRqNhXTubaiWZ0ILmFSkuHObZ2ZlJ0tPp9JXvxVRHMaBrhzfj0EY1iWACuTKxSnwW524k1G3Od5JJnPUfmBuZBojGoiBS+Ni+C6c2OTlpoZ+IYViWV6vVTI3HRMRhzq9x/VAKon6F+9rf3zfEBsEUn4W0D9SuCJkwhTotD5hZuTfcB/hVJ9UgtTl04Dv8NvDNiEVYi+FytRe08b591tfnwmgul+uvJP26pIDL5cpL+t8kfU/S/+Vyuf5HSVlJv/Pit//fasue19WWPv8Pn/sJXjyYdIjHx8e6e/eujo+PNTs7qx/96EemXorFYtrc3LT4GUjeVCp1pfODbCwWi5qfn1fmxdIuUlX5O+iAGVvxcGxtbRmOzUFKpwK8QJR8NBo1pQoxKoz5jPiQ+CcnJ+ZngOwlGobYFgL5pJex4MBNkgyvR7AgtWXIpClwrSAtE4mEPVzwKYQ8kqNGGi8Q4+LioqlRnKkHpCGgksvn8+arKJVKpngBXpRk3SLKnampKVOPMd4zaT1+/FhTU1N6+vSp3G63Rc0cHBxYsgHqqUajobW1NdsSmM/nde3aNRM7sAMGuAXodXh4WLlcztLFeWmRojabTRWLRYvHWVlZMUwccx1QG2GxtVrNOKuhoSH7/j6fT8lkUsvLyyaaQEyCjJ+DSJLBHtwXGipy0/isxCA5AxeB7SQZSc4BOzIyong8bs81xYbQWYoKfzfGRcyfiA8g651LBiH7gWh5n+EfiIPZ3t62dAWaDqcBkbQC7h1CIHxlJE3AHThNoKATRCBdXl5emVJenGOW+IzaChiIKR/RAcXOyYVJsuKFwtLn89l0IcmgKK4h1wiYrNlsWiIEMVd8Pq/Xa9we0TAIFiKRiE02Ho/HOGLEAnw2p5AArxRNG6o6oEeKH8+IUybOLiQSPqQ20kSEE00dZxL36fO+PrfYtFqt3/2v/Kd/90t+b0vS//S5f+svfDH+8fJD/Pr9fs3NzSmXy+n4+NikdvPz8/L5fIbFk8M0OztrAoG5uTkjgMm+2tra0vj4uF5//XXlcjkLM0QBdnh4qFQqZXEa3HiCH91ut0Fp7I+IxWI2iVxeXpqOnZyyhw8fqru7W48ePbKDEny6v7/f8Giw/Ww2q4ODA5NUn5yc6PT01K5PvV7X+Pi4TTJHR0cm4T44ONBrr71m0AEv7PLysnEiKN7wkiSTSVMLhUIhLS4uamBgQK+99prJaY+OjizGh1ynUqmk3/zN31SlUjEPwcTEhNLptCRZBwnR6ff7NT8/r3q9bgSvJNvD4/f7lUqltLm5KUk2rWLMzWQyljt3cHCgVCplsCXrASh677//vrq7u3Xjxg2lUimVy2VT4dBBE1XU1dWlSCRikt2JiQmDEIA0yAMLhUJ68uSJcUQsibu8vLSJARHF+vq6RX5QIOhg6/W6UqmUDg8PTV4NjEkBotE5Pj42x/rQ0JBarZappLg+OOtZ+ZBKpWyqoKvH2Mh71Wq1tLe3p1QqpaGhIT179szURzQ+pEVAcHMAAtsSebO3t3clYof17RymHR0dSiaT1uAwNXV0dGh5edliksgu4/1wKjdBMKrVqiUC8LmIqYHsBzbinuMLIRMOZOHk5MRWICMHR53F+0gDkkwmLW2bTEW4FNALzguut8vlsuw3JhKSR6AHmFyJChobGzPeikVqFEBChslo4zPiv+rv77eV6kB/cF/wYc5gUAoKSdd8lctlk6kjPefvp5GVZBFZQHCf9/WFSBD4oz/6o7fHx8eNgPV6vdZZMJGgaspmsxatD6ZI6ByriYeHh1Uul9Xf328ciDPsDriA6t/R0WFYJB6Her2umZkZI8LD4bByuZzGx8evpOM6N3V2dnba6P/pp58aHDI8PKx4PG65XXRfdMCQbSjKSG29fv26+QlIEujv7zdF1crKik1aS0tLJntOp9P2MySTSWUyGQ0ODlpH54zHYP0BqqBKpWLTHJHmjPyoT7LZrCl5arWarl27ZjwBGC/wGoo+Jr2TkxOtrKyoUqlYx+b1evXw4UN7Sdxut/mW4CAgX+lqvV6vwVYjIyN2+DIlQtxi6GS/x87OjjY2NuT3+y2Gv1araWlpSUNDQ+rv7zfYFpEA8TLFYlE9PT0mjOBAY4Ph1taWqRF7e3u1s7OjcrlscBZSdg4hCF44K0QsQLqo1FD+IHfH2AyczPsCjEZsDUWIzLVwOGwdP5NPNBq1zxCJRFSr1UwliDqRQsNziGKzVqvZ/ZPaHS7GSX7v2dmZFQU6YeAyRBYYHeFU4XVQbbFlFZ/b3t6e8ajAOpi+6dJ5HphkvF6vRdUg/EEgQ9YXUB1iCIo9Jm6eCXZW8T6gsITcB7Z2KvEoCJwJpC84CXribprNpqkCkZYz9QKjI/oAKcHfhtiIgkCDKL1MkQbCBTojRgkkgwYB4ZFzVYSTA+LdYBnj8vLyFz+u5p133nn7xo0bcrvb+xHu3bsnr9drIyQqpvX1dfl8Pj169Ehut9siS9DrB4NBczo3Gg3zfjx+/NgiWTKZjE5OTszseHZ2Zk5miEsuIkGARLEw8aAiCofD+uSTT2z8jcfjtm+GXTJIZ1lnjdx1a2tLPT09yufzmp6etiictbU17e/vKxqNqrOz05RyQGEDAwMmKrh165ZBOh6Pxzb9lUolfeUrX9Hg4KA+/PBD3bp1S6VSSS6XS61WS/fu3ZMk2zqJK3x8fNy6zIuLC2UyGUtx5nAlrLKzs9MgmLfeestyy4gioQvGaY+HCVkw3g664ImJCets6WTBint6erS3t2dFOZvNanJy0viKarWqcrms9fV1RaNRBYNBSW0Se3R01OCEqakp6/BoUoD8WIPAdWE1tdRWs6G6gxRG7MDCN5ohSdbMADssLCxYagH+inw+fyVll+ePe0H3z1qGcrlszzbXA1c5fiF4F64VvMTx8bH9+8DAgHZ3dw1KIb3ACe+6XC6DbpEhQyhHo1Ejspk2KOY0gIhgSDI/Pz/XxMSEFT+2pg4PD1voJxFMfNbd3V0lEgnz9cBTnZ6eXlk7wn/DpwcfQ4Gi4YLDIN8MTouJcnBwUCMjI8YPEuxKQnU4HFYmk7kSr0MB4isajers7My4FqT8wI/8fuTiPCckfNCYnZ+fW4qzkwMi9BMojGkViIzm15kYgFyZnxc5drPZvJJjh7qWyZrwVyJraDIQGXAO0vxNTk7q5z//+a9GsZmfn1culzMlTCQSsYceNy0qLyo5FXdzc9N223g8HlN/9Pb26sGDB4b7YvaDBA4EAopGo6a+2Nzc1OrqquGwOKmnp6dtV8nR0ZFlte3s7Gh5edmgMWS6pAp3dXVpY2NDCwsLljlWq9W0urpqsMH09LRBLJC1Xq/XiFGUSEhrMcU5VV2FQkGZTEYTExMaGxvTm2++qXQ6bTJdqS1fhrxHZklyARLOjY0NDQ0N6d1337WASPT5JM52dXVpZWXFPkM0GlU6ndbW1pYp3zo6OmyCnJiY0P7+vt544w3bVvruu+/q9u3byuVyWllZkSQzkRaLRU1OTppZEkm4z+fT9PS0nj59qlAoZBtbyYDr7OzU+Pi4wuGwNjY2zK8SCAS0trZmUf3OHe+s+MV9Tef37NkzMxq73W7dvHnTCgq7kiSZ2TYej5siCOgQOJCpNpfLWcihJIuYkWTdLZMK+DnmRGfsEDwXExLwEZ0/UnzEBh7Py6VtiEGQBXNwMr1igsYNjlQbyIv0ajgFTLuHh4cmMyaTDHUdhyxcI0rOrq6Xm1NbrZY1AU61JvEuTFvI77FKUExdLpf57vjcksx/x4RIwb24uNDu7q4VL7fbbVM50xC8kRNCwiDpTGNoNps2FUjtSQKpOJAaRRkjOOkPTjSEIk+8DEkLCBWq1eqVgsI9BKJDLIDsGV6THD48O/x3+BqnWAQ4DIUj5y8/n5PfZGsoisgXie6fWWz+rWq0/0+/6A6olnQ3ZKJBBMIHJJNJI0QbjYa+853vqFqtam9vzw5IYCCp7eP56KOPdHJyYuqkfD6v9fV1PX369IoSJZFIaHBwUIFAwJKH7927p7GxMeukS6WSzs/Plc1m9frrrxvMsbq6apEpxWLRukM2/CGXnpqaMlLN4/Hor//6r7W4uGgmT3w0HCqZTMYc+XAnkUjEPA7kPsFhIJduNl8mwyaTSYPvvF6vIpGIPbQcBECG3d3dWlpaUiqVkt/vV6FQMBI0nU4rHA5bhEihUJDX61U0GtX777+v09NTBQIBLSws6NatW9re3tbo6KhyuZzW19fN1Q7MgHLr7t272tnZsUMM1RXdtSS7XrlcTpubmzo8PFQmkzEZb7lc1urqqqQ2bJrP580UWqvVTEVGkwF0EY/HTf1Eqi4H0fHxsR48eKBEIqFUKmUrEPA0gFmjXFxZWVEmk5Ek45uy2az5QGiW+H8OTEkGQVEkUBPRXNXrdVvaxs4cSebXQIHJdA7WT4FheqYwAaPs7u7atdjf3zeeAiiWYFaW9+Guh0u6uLgw/xCSXQovzePm5qby+bwdek4BgyQrWPyswF5SG/4hPYBrj/yYYkFmGLwK8CEcF4IIeBOi+bu7uy3Ljzw+JmgO/oODA+Nki8WibeYdHh5WNBpVT0+PRecgzEFNxtTgbNawGzAhUYA49I+Ojkx8Q6FneiROh69Wq2XXAGESRYoVBpxt8I8gQUxTZP6haEOpyjtRqVQMycC0y3vCv/+3fP03+Wz+//4aHh5u/dqv/Zr8fr86OjrMT8JFu3Xrlu7fv29dNsZIXsilpSV961vfsi7mhz/8oa5fv65KpXJlU6dzlw2ROE+fPtV3v/tdU0X19fUZ5o0DulqtqlQqGTxDp4HZNJ1Omyv/S1/6kkV/AIek02kL5wQ6YOsk3TcHb0dHhzn6gRgkWefE4TU8PGyTHXERxKNgsARqYIsmvg1MrmNjY7p//77q9bqJFyiCpVJJT58+1Y0bN4wEPTo6Mu+C1O7sYrGYdW9S29C4s7Nj5sxYLGbyWwyncAGoy4Atj46OTFBQr9dNZTQ/P2+8A4m0kqwYYeYNBoMmTDg5OdHNmzfNrMpEy+eQ2nBZuVzW5uamhUgODw+bJ0lqk6WpVMoi53kx6R4pZqOjoxaCWKvVbJpiAkHS29fXZwpFJLB4ODiEWy8SdWkMcOiTBbe/v6/d3V1TQwFNDQ0NmdCFAkOXH4lE7ADikG40GpqZmTEekRyx7e1tWx/w/Hl7fTCyYoQYNDgkpksy7gmYBoius7PTYCriXYjNoYGj0ANVUqw4HDmQySmjCDJpkLQATMiB7pzmMIF7vV6bxOnWmSIpWlI7+BTxEX83nxsBkcvlsjQB4PuDgwOD/UKh0JXVEggGmPwQ8/D+AS9vbW1ZbAyinP39fQUCAW1sbJi6kVQRpn2aUO4vohnnCm3uoVM6jzgFKI2GCI7o8rK9Pp4GiQl6aGjI8u3+9E//9DN9Nl8IGO373//+27dv3zYMEc/JK6+8cqW7QDHFoQjpizlre3tb+XzeOlk6IwxVEJq8gByeyEG7u7tNknt52V6vOjo6agqVlZUV9fT0GOZPcCBBhozddBjo11EtQaru7u5e6XAh23j4Q6GQ7bX3eDyKx+MWh4InZm1tzdRO4Psc/LxQKGIODg60u7trKbcTExM2QSB5PTk50bVr11SpVFSr1SwRmwd9eHjYumVMiYeHh4aHs4YWwhqPU7Va1c2bN1WpVIw3IvCS8Rzi3umBQCbMYce1wi8iyUjiWq1mplLutcvlUiwWM7NmtVo1aS27ZXK5nEXhw6VNZ6sRAAAgAElEQVTwPxIM4M5Q+RBOyb1utVpKp9NWwBA5VKtVmxy5D4hKgEt4Tujyuf8Q1hxSvAMQ6wggOGQh7Hle+B/udHLX8JChKnI69VG10UQ5py2gIqTWdMTwSD6fz2T9wDuo6OjKgeN4X0OhkMFrQGY8q6i5uNddXV32jBM8yioApnt4JYopTnsn1EWzRwZdb2+vEe9MQUBoTsNqKBS6At9TQBEosPH1/PzcImiYZJmwgO+cJnXn9IANQnoZeYNalecDNSHfE5MtiIXUnnKdqyJoAHp6euz5oumRZEIIYDIaFybd8/OXK64RNzgz6ZwJ0Z988skXH0ZjhCTOul6va39/X/fu3dPS0pIWFxftQXCSgbw4sVjMRjnwV4hFn89noy7jLEUAzPzs7Eybm5tG+jEtJJNJg6C6urrMlOfxeKzb6+/vVyaTsUVpKOgymYxtugQC4+GjE/T5fPL7/dre3rbQ0ZmZGcOnI5GI5ubmbM/L8fGxqUz6+voUj8ctFZkpDoJwY2ND9Xrd1GWkCgwNDRkJSlYTBxbeB5Q2r776qpGShFhKMhfz/Py8QQi1Ws28IxTY7e1t9fb2WmEhCdnlakeVo8RLp9NXjKXEspyenmp/f19HR0caGRmx/064ZW9vr/x+/5UDkPwn8sV4MXp6ejQxMWHELLwYC/YIGvz6179u0CccyMrKikl+mTSBYp375DEvdnR0aHx83EzHTOIcDkAijUZDuVzOJjmKDzg+hxdmQrpeDmLeF4QjcA5050xGlUrFlHGYjyH2UQwC0TSbTcViMfNM8XeRCiDJIC7eFczCvDfAPKjTgsGgwdr8nv39fVOoYRDk3+FWmKBJAGcKAbJiIqRJRb6LZJlmha6dYFySzTs7Oy3h3Sn7lmT/HbUZawcwHsOTocTCnMnUS4OCKCLzYv0A3JEzJge4lF/je9I00UBSBAcGBhSPx01BhzmWosazhkqPgoh0GhUcz5dz0iIGiwBV4GE4LKZ7trMC31G8PuvrCzHZvPPOO29/9atfVTwe19LSkhWG4+NjLSwsGAHMAQN8QDRKvV63ePvr169ra2tLhUJBh4eHWlhYMIxxdHRU6+vrZuRCgUXHAFleLpctQZoXEzyZzhX1UKlU0u/8zu+o2Wxqa2tLsVhMc3NzV7LPSCJmc+Tk5KRBADMzMyY6QO0yODiolZUVjYyMaGNjwzwem5ub1tWwII5cNhztbrdbmUxGbrdbk5OTCofDarVappTp7e214kY0CEoizIbJZNKkzuFw2DB0EgLY68GqAyexubu7q4WFBVOV0cFhamX9AOu9uY6oxVA54StBugoEkslkjOCfmpqS1+vV6Oio/uEf/kHj4+P2vb/97W9rdXXVnPkUaTo9FH9sSYVshSCnez09PVUqldLp6amy2azi8biKxaJNveDcmUzGDoVIJGKL11jCB5wrSR988IF6e3stDp4uHTMlBwuZUxwecEBwiYhYMPf29PTYtWRNBTJmpKxcb77A8pkmmACBFGnKEBmMjIxY9pokUzHBN/JuBAIBDQwMGJJAo9JsNk0ocnR0pFAoZEUdiBD5LlDl+fm55exxYCMrPj8/t8nfqQykQ6cgOaHl4eFhI8rJtuvt7bVlZUz2THm/OO0AzR4fH5uZFPEQDSGLxXDvc8AnEgmDslGnMUkiRCgUCnZdQUyY+nhW+vr6LA8P/5+kK7Ai0DAwJDAdClkKhNOUyRRzdnZmSRso6JjsmDaZxvk5fiXWQv/gBz94m3RhnPskq+IGxp1NxAcLiDBBEet/cXGhra0tVSoVxWIxzczMGKHn1MVjJOUghEzN5XK2VVGS6fH39va0ubmpgYEB65Dr9bomJye1vb1t0JjU9sngFHbKSQOBgBWT8/NzRSIRG0fj8bhxEHRZPGhAWoy5dLKRSMTc6XRAQDiRSESSlMvlrENDDHF8fGwQY09Pj8bHxxWPxw1ugggeGBjQ4OCgyZqfPXtmhW17e1vRaFThcFhPnjzRzMyMyXifPn2qzs5Ow/5JJ65Wq6pWqyoUCkaOktWFzBVOBeUR3AUwFxljw8PDVlyr1arm5+cNauBQ2tnZMb8G0vharabbt2+bigl5+dDQ0BXF2tnZmcbHx01KzPeF4J6YmNDy8rJlcHFf6WhTqZReeeUVS6sGynAe5MBP3FeXy6VgMGhTAhMQpDVp3hxyPFtMBkipgVGR+iIkcB7QiDrI4MNdj9cFxSVTMYfu8fGxqbswNUq6ItMm0RlHO1CxJIvhQe0EUQ8HRFeP34prBlleq9UMeuR5q9frRpQzhTAZUXhIGHF6zBALUAiA2yjwkgytQAjT1dVl5D9TMwgLXjKv12sNS6PRkN/vlySD7eA4geCRaMPXIfgYGhqyLbV4nYCoEctw/RCXMJ0B4QK3ka/I2gpMofC+TDaSDFLkmuBF5DngPUBcgZjnV2It9J/92Z+9DYkcjUZtSZYzzI8Y+FKpZHJVr9erVCplkBKHytnZmZIvHMsPHz7UyMjIlcVhsVjMui5CEEnJpbPyer2WUMthAowwMjJiDxYqGQj4cDhshQGYga4vFAppYmLCZMe1Ws1WCRSLRYO86CaQFKIkIrQP8xn7y/Hx0IlA3MKRkJZAGsDR0ZEWFhbsACAmB2Pf8vKy4bVSe50AB9j169cNEkSOSZru9va2Tk9PTd3EREFHD+ErvYz+4P8jkYhBKLOzs+Z/oHBPTU2pWCyayg6TJc5rYCiXy6XJyUldXLSXyeHFmJiYUCwW08rKisEOHFj1el0ffvihhoeHtb29bQcSS7zi8bjC4bCkdvGmo2TnCM3DwMCADg8PNTk5qY6ODj19+tT4Pkx4XV1d9j+eHa4tzxWKNLpdimcwGLTDA2iQaQRjKVtseQ6AOJkU4J0g4jmo8UUxgfDMoS6j00Z66/V6TbSA74J7TRAmMB9NEP4c8t+AfsgE42dDwQWsR0fP+8SUAmwEyY6fC9tDR0eHPW/IrkOhkEFbJClcXFwYlNzX13fF0EqXz8/M4jqg4vPzdugm7xISadR8fFbMrZLs/vE+A/Xx85JK7owpwnPG+YSNgqns5OTE9t1wr5BU83ehBK1UKrYFlM/HdWAi5DoywYTDYQ0ODlpBA2ZFjl2pVPT06dMvfrH5/ve//3Y4HFZ/f78RheCGoVDIlFgYptjTws5vYC9UFUhA8c+0Wi09efJEN2/etG2G29vbhi07k56j0ah12rxoqDG4idVqVcVi0UykqF2AMy4uLpTNZo0/SiaTJjcFQ81ms5LaL/Xe3p5u3LhhD20sFtPBwYF5DygS4Ph4kDAOAqlEIhHt7u5aojKHKQUNMtDpz6jVagoEAubUZ7ri8KLbRaABzovahiyyxcVFBYNBjY6Omjdqd3fX8sOApAqFgm7dumWxJpFIRF1dXVakiRXh/kP6csgfHh5qfHzciigBnwMDA2bCpfsPhULmFUF9uLu7ay9yqVSyAyMajaqjo0M7Ozt2iAcCAZ2ft7P3KpWKHbZ00c6DF2UV8AjTXCQSUSaTse4UnwmYOtMY8m0OHSaWUql0BRJhSmWTJBAzXBGdOnwRzwnFmCmDAwXil6mS0Fnc7BzWTvGG8xogKyZKh4ahs7PT/l7nGg62i3Kf+Jkg9vn58AXt7+/bKgc2TjJx8TxTgODBKKI86+TecZgj1kHIwHUBIqNYYAdgWuGzME0zieFRofEjEsiZuABXDIzMO0KxoWFCgctZA/RN4gBnIwc9fBsTGcgPIhtgWQQH+KUkXYlaajabBltz/eHx8AfhOyS/kQkUJOZXYrJ555133n7rrbcUDodVq7WXDD179ky9vb1XwhKPjo6USCRMTlsqlSyRlnGP8ZhOrre3V729vUqlUqbS2dnZsUwkp+EtHo9rc3PTRsuOjg4LECT/iReM5WdTU1NWXEZGRhQMBk318sugEkkWXYIiiJcGou309NRw76WlJZN1gh3zkFSrVfME8YCCp1J8ERCQ+QbBFwwGtba2JrfbrUqlYkYyOitUKHBbYOtIT5vNpqm/gF447DgcyGZD4l2r1UwmykOMeobDZmxsTE+ePLGpja6WVQLANJh3ub+ffvqpHWxTU1NG8Pf29mp9fd0c5VxnZ4c8NjZmGDz71glYjcfjBrtBRIdCITMgEqCI7yCdTptYgsOio6PD8vf4mTkEnZth+b2sywA2pDkA/mE6cZLoOL6ZeMi1Q5EkvRTPlMtlM/2hRPT5fHZQcviNjo4asUwUPQWy0WiYqAep+eXlpXXL2Aa470QBUeQoWBR2SeYD4jlGdUfjAXzH+gQn1Mz9dB6KJEQwQTuVnyjZ+HvgIjjMPR6PwVAULZ/PdyXCCciP5xKoDwSE6wt8BlzmnDY5rHnvuK8c4Kjp+vr6rqRsM3kwzRJDxDu4s7Njn5NrQFAvEUE0NvjKoCEwgzrTDUATXC6XTUiSDJrc2dnRs2fPvvjF5o//+I/fnp6eNikumvObN2/aBWJTIlMJE0s2mzUJMAqwUChkrm23261nz54pm83q9PRUMzMzVrkxdXIT19fX9c1vflPZbNZuOGMzUBfkNDd7fX3dEgS6utpbHLe3tzU/P6/+/n5tb2+r0WhYXEk0GjVOBdMXMSok4hJ7/sEHH9gheHp6qunpaSWTSRWLRQUCAX3yySeKRqPa3t42shgV2+7urgqFgiqViqanpyW1ISBksCcnJ3bwANX09PRoa2tLc3Nz5klyu9vpy2DCFCt8IvAZEJNdXV1aW1vTp59+qsvLS928eVNer1erq6vWbeGbQR6KioiYGnB3MPL9/X3dvHlT+/v78ng8ikaj1i0/fvxYx8fH2tra0ltvvaVYLKZSqWRGPWC0pMMIPD4+rt3dXV1cXCgWi2l5edmEFLu7u/J42unfXV1ddu05FPCjDA0NmcM9HA5rbGzMctq8Xq8tzOvp6dGTJ08kvYQRBwcH1dfXZz8n/gZUTDQfHNbAJnhaUKJx4Pl8Pu3s7Fz5c5LMHHh4eKijoyMdHh7q+PjYChyHLlwa/hawe2f3TqdL1H2tVjNbAN8Dorm7u9tEHkzKJA83Gg3bu4QR9+LiwkJnURgiAqI5cEYYcWAjJqHwOSNmMDNCupNR5hRicO2xWgCXU3w4Y5wQEzC2U8kJZwrsRKxTX1+fTewQ9Vx7ChQFCA8NYoPe3l5Tk5VKJYNVx8fHTamGnNrJz3V2dppBtrOzU8fHxyahBj7lmjFVOnkdJm4aGRASJyfEe87Ud37eXpqYTqe/+NLni4sLpdNpi5BBqfXw4UMVCgVNTk7aRk18MYuLi/J4PLp9+7YpeyKRiGZmZqxjQW1x584dvfXWW0omk/roo48sHHNnZ0eRSMRe/MnJST18+NBkux6Px8i94eFhJV/sv7lx44aRyBDcSHBRoL377rtaWVlROp2Wy+XSW2+9pa9+9auKxWLWOQGhFAoFi7Phvw0NDWlmZsa4p1arpeXlZd27d8+WjP3Gb/yGms2mgsGgOcFZEsVUhSQUshWnNPJaSXb4QUr39fWZ8gzcmunEqa/3eNqrtq9du2YHIn/++vXrhlE/efJEyWRSs7OzdtBXKhV961vfsjSEjY0NbWxsKJfLaXBw0HxGTDG5XE7lctncz5VKRR9//LGktsjht3/7t41XQQwgteGfRCIhqZ3VRUjp6OioGQkXFhYs8JHE4YuLC4OCEomEFhcXzR9x8+ZNM96RGHFycmJm03fffVfPnj2zbDj8RMAzkO7wNpKubJ11ykiRqpONR5fNFA9nRKEClnEeGk7BCSY850oFulTIb6ZuqR1kisQXHhLzI3JeZ9QKBx6kudfbjuLHi8SUxffp6enRyMiIPVOQzz6fz7gc4HHiloBvkGMz+fBzHB4eWiwQSAQwEgIK/ClOlR7XCzkv0xDXBnEO7wW+Pw5gYFXeNY/Ho2AwaNMUk5lTOEEidX9/v8mnnTJz0JDe3l6Dz50GWBAfbAfVatWWzlGUUNry34rFoql7aV74s8+fP7cJHp8W55pTes4kC2KDoOqzvr4QCQLBYLD1e7/3e1cI+Fwup+HhYYNE0KHHYjFdXFzo4cOHisVi2tvbUz6fNwILqK1cLmt2dlaffvqpdbnb29uKxWK6f/++UqmUotGo3TRuysTEhEljA4GAFhcXJbX3ekciEaXTaVUqFX3jG99QvV5XOp3W5uamkdIeT3ub3fHxsdLptK5fvy6fz6etrS0j8efm5rS6uqpSqaRms6nZ2VnDQYFgzs/PTTCQSCT09OlTJRIJ3bhxw+C99fV1LSwsGBRITEq1WtXi4qKplJzKFEm6efOmdbHlclnJZNJI4EKhoEQioYODA5VKJU1OThpRyQtIGnUul9PJyYlNLazjvXbtmimoDg8PTel0dnZmRDA5ZENDQ6ZiIhxwbW3NHPXEC4VCIQWDQXP9BwIBgzibzabtbPn5z38uqQ1hXL9+XbVaTdvb26rVasZj8FnZUAgUWq/XVS6XNT09bU3DxcWFnjx5ovHxcduBMzQ0ZKGj+HpyuZxtfB0cHNTMzIzu3btnByHxLm53O9EaiIM1A5hXDw8PTZq8v79vYgKKC/E4QIL8GQySdPlE8wDFEKgKL4FkFsk8hxhQSTab1czMjHmHgsGgdfeYqFET9vf3q9lsGqxbq7U3qXKPpXZDg3Sbwwv1aSAQUDAYtADIkZER8+8w9XZ1dVlALAWaxAOv12sNE7LhoaGhK5wL4otyuSy3220rHpg6mBzgObh2pH0AFfP9gJbgFYEvSZ3nXjebTU1OTppxmed8c3PTRCUUASf0T9HHQO7kr7lfzqb15OTEEvOBwkKhkPl6WNqHLJpmh4KESIDvy1TI9cFQvru7a8ZnxB5wU3/xF3/xxU8Q+N73vvf21NSUyYyj0aiRWdLLNbjsO4HUIgOMl2Rvb0+RSMTwxSdPntg+CBaJ4RtBc043QkI0o/no6KjW1tZs5EUmevfuXZ2fn1te2Pl5O7AxEAgYXgyEgGcDEhl8OJPJ6PT0VMFg0AoT8ksISHDy2dlZU4NQXJGAA4UhoSTmnE6DvTudne2QSv6b3+83iTOcDL4HJolgMKhwOGxcRzQatSLABFYsFk2eDuQYDodVKBQsYdZpbgO3ZqsmZPTo6Khhyeyc5+UlfmRhYcE4n+7ubtvHw8HicrVDA+l6d3baC2IbjYYGBwf105/+1GTFFCiIUxKdt7e3lUgk9PHHH5sRcWpqSpIsQYEk3/7+fkltmTuHv9Q+FFETBQIBhUIhK8ZwERQJDi0nrEIxoRlAIYbo4fz8XIlEwqYY5LuIaJwHFoozYF+eMYyLTpUZIgEIbYoFPB0dNnwdUycCDCZgRBJ7e3sGG0svd9rz8znlzShJgXEQ7Ei6YspEjcaWUg5gSVfUZ3CVTIJOuTBTH7YDj8djKRoEnbJ2gSQJJ4mPkq7VahlfQ5NJEWSKwrIAXCnJRD6ovlCf0khwnSXZteeadXR0GK/DBESTwTPIvQZu5BlhGiFh24l+AC8zQfJeMcEiROA6A7U6RRQvGtwvPozG2EmHkkgkDEpi/Ozq6tLq6qpyuZx1UNPT09bx0mWSRkxnIMkeXIoMa5HBQ5GgQsYmEglVKhX19PQomUwqEomoVCqpu7vbTKHOsZLujc+QTCbNI0ISNbxOKBRSMpk0X8rOzo6R+p2dnZagMDIyYg/j6Oioram+vLzU0tKScrmcQV9wNolEwlYu4/wlFDQWi9nhzWH/6NEjSe30YpJpW62Wrdfu7Oy0oiO1E23BiSnqPp9PsVhMkUjEmgIKpSRLf0YqCoTp8XjsM/7kJz8xMh2Z9cDAgG0jXVhY0MOHD1WpVDQ1NWX3EFwdCTmFva+vz9KZ8V1R0OhWJVm0PwWQPT14mEgsYFsh8GOtVjN5OIcHjnj4D7fbrfX1dW1vbxv0yIZLSVeKDztw4GiYcpDdk95NEgOyVSAeIJtAIGCiE0yqTvIbMp/pi0McfgCcHhgaLxL+E2TVAwMD9mwjy6UocogS3omMv1ar6fnz51YwLy8vLTaI1AM27zabTUuOAJYiWYJnh7BaeDDy5jiUgamcU9jh4aFBdxDtXV1dFp3DFlAgRvw8zjgqeEzM5PBnnZ2dBjNeXl6a6pFCs7OzY/AeEwRpJF1dXTYN0Sgi2PnFQFISEGgu8Oxw1lEUA4GAuru7LU9PkiWbcL+BOlE/svqB+8i9ZF1CsVhUJpMx3gsxE1Dx557zX4TJ5gc/+MHb3/zmN+Xz+WzUXl9f1/HxsarVqlZXV3Xz5k15PB6L16CjldrE97Vr16yD4aBkl8fg4KDu3LljggJcr8A6vb29mpiY0MnJiebn5w1yGR8fty6RKWF2dlZdXV0aHR21GBPC6kZHR60j54HGbRyLxfSNb3xD77//viX00vngfGZUPTs7M5gnn89Lkqanp41f6u3tVTQa1cDAgN59911T8Zyfn2t6elqvvfaayVEPDw81NjamRCJhDwqdXLPZNHMXUBCS7sPDQ/v58M4AHYyMjOjx48dGDuOTYeEZHaHP51M4HLaXk1w1CGKpvQNkcnLSZL74gJBTQ6Jev35d/f39SqfTWllZsZebaQkTHC9/vV7X9va2xsbGLFaoq6sdaz8+Pm6T7cjIiPmDpqenLS/v6dOndhi4XO09SECr1WpVfX19xpkUCgUdHx8b5Oj1tncx+f1+E36wIoHvh6AC6LBYLCoUCpn3A7gJKI+wQ5RgmFvxYQwMDCgQCJg0mEMYYpepiUWAEP74Sig6zp05rVbLbAQQ9jRskkxtCCkP0d5oNHR0dGQTFLJnuCPuXU9Pj8WzUAg53JkU+Awou1CQ0nHz3AM9SzKDNp8TeTNTJ1xSvV5XJpOxn61YLFpBARYEQqYJCQaDNi3jNaFB48/iLcKDhsAI5AMPFypTGlGuP7mOhULBzkigfkzbNE0UdnxVNA00MIhwgFfdbrcJXmj+mPbgbDAB01zSKJ6dnRmfSdH0+XwmmX7w4MEXX432zjvvvP2Vr3zFHiYqeiAQ0O7urkFYaNArlYpFvMAFFAoF84JAwLJKGhKORFRe3KOjI1UqFYXDYQuMTKfTBuc8f/7cIlQgJoHESNZ99OiRBgcHLXeKNdR0cxzodPJ0CP39/Xr06JHBMdPT01pcXDRYcG1tzWTad+/eNdmm87DJ5/O2/6VUKulrX/ua7STZ2NjQwcGBXn31VdXrdS0tLcntdmtiYkKSTP6IlJZDye/3a2xsTIVCwaYpcGX22J+enpoSCcURJCmqmFarpWQyqWw2q1AoZNJdDpvR0VGNjY2ZVJ3wxIODA21ubpqU89mzZ4rH49YB4qgmgiSfzxv0hjQ9n8/r4uLCXnpkt0jGnS5tp6kN7w184a1bt3R4eKj9/X07aLlWUltuzOoKPCSbm5uWXs5CM+AQSQbdSrrieaB5As6AD3MaLY+Pj62Yc91psJgGkQrj02GHCT87MC0HFxmC3Euk6whAnCvPeb/w1LRaLZXLZZMdHx0d2TQITLq9vW1J4VwLCgdeJOBPrqMTIiSg1emD6+josFRj1JBI8YmnoVATDUMYqjPNgJy+VqtlSjIKDUICJi24HJ4VUhjcbrdKpZKp2LhXpIsAgSJp7u3tVbVatecYCA0Yk3/nQKdgA9khuEBt5/V6Df2hmDFtO6OMmGT5bDRFPT096uzsNO4JDpLrQrOHAIJlhCMjI1ao4KZ+JYrND37wg7cxBHZ1dWlra8tMhWRrXV5eKhwOWwYQOGmj0dDu7q78fr+RVix14iGPx+Py+Xwql8uqVqvKZDKW3RWNRu1lOjw8tJe8UqlodnbWDm9C/TY2NqzTPD4+ViwWs8KUyWTk9XoVCoW0sbFhcSq9vb1XjJCZTEbhcFhzc3OKRCI2aSCPfP78uRKJhBWiSqWi7e1tBYNBM1J+8sknNqJzIN29e9c61qOjI5VKJY2Njamjo0PpdNrkuXhy6MLA28FpIYkx7g0ODtpBDiwCR8YLCD9wcnJiYgzgDwjLSqWi8fFxnZycGDwEhAgsQOI1voKjoyPdvn3buI2zszPl83klX6RNQ9bzQmSzWQuTXF5eNkwZOBOIhp1EKOzC4bBCoZDm5ubswCOeHh/C5eWlJiYmTHRRKpUUCATMl9Pb22sNEMbf8fFxK6JIdp2hisBQPLvPnz+3fDKaASJRIKBZZ/H8eTuwVGoXPr4HPxfdO54XZw4a3SxQmiQ7vGgKTk5OjLMggobOGHIYaMf5vsJ/ALnRpNEsoLYLh8N28AHbMO243W59+umn5mFCnYa0vL+/36ZgxAtMSLxDCAMQxwCt8++8B7zP8BLsh3n+/LndM6A4ipzH47G/h3XcwIrYCOAx4Xl4xhHGECgLRAmPivcMBMblaieG9/f3m7mVzw9nhPiFCCMMrPCMcGvcC34mzhd8YTwHNO3cZ1JLnEIIJkUChn8lis2f/MmfvD03N2edfzQa1YMHDwyfJOQO38Te3p5OT081PDxs7mwyq87OzjQ5Oanz83M7JDk4iMPhoYlEInbYDA8PK5/PX4my5wFYXV3V/fv37c88ffpUm5ubun79uvkWgsGgxsfHzU/gdrstWh+yjjWrY2Nj2t3d1fDwsA4ODhQOh5XNZq0j4+Xv6OjQ7du3Va1WValUzJS3uLio8fFxLS0t2bSBp4LuY3Nz04I1u7u7zRn/3nvvaWhoyGAH9vRAcPP3hsNh+7kyL0Imi8WiddaNRkOHh4e6e/euwZrEZ7z55ptKJBJ2GNAdbWxsqLu7W9PT09re3pbP59OHH36ooaEh3bhxw+A8Di5MgBSKzs5Oe2GZTpiSPvroI/ORTExMKJPJ6Nq1a9YQgEUjm3a+nD6fTxsbGyYhlV5i3/ALJD6cnp7aWgK6aKaos7MzJRIJBYNBlctlxePxKwZkcHUgWaBJp8CAz1kqlSyChMmBn7tarVpiM2IFChIcDRAzhafZbJo/iemZzw1/ub6+bn8XHBRcAs8F0ByFg04bCAuIGUgsHntqXmMAACAASURBVI/bz0H0DxOZx+Mx+I1Jlp8xm82acVmSheLyWZCVIwBAVEGoLM0nzRfXAR7pF3lIpNPAkvhUgIqATOFTnc0uRQwinwmMxAEUfNFo1IomEBiTDlAozz+GTT4H/kKQHEQLEPz8O/+Pqowmg/eIdAMaYXgXoDZgXYRIFHruT3d3t3G0PEsskfunf/qnL36x+d73vvc265T7+vqUz+fNOIRyqFKpaHh42DpnVF0Q8vv7+7p+/bparZaRsriXEQRAgvv9fvNuuFwu+f1+U89MTU0pkUjI7XYrl8tZJ0M3RAd2dnZmnTlrBFCgsOCL0bqjo8PW2A4MDCibzSoQCJivI5/PG8TACD8xMaFSqaSlpSUzKvJwdHZ26oc//KGi0ailS4+Pj9v3pyMBJ3a73drY2LBulmKBkAJJpTNxgEmMrlWSYf8Qt3ROmPjAjcHunZ0gBzy/hpegv79f09PTpiJqtdrriR8/fqyRkRFtbW1JkmXRUTRZ05BKpVQul/XJJ59ocnJSfr/f9txQOHi2nEIOuC/8EuDOkPter9cSwPH2IJWGXIUwZyUD0lnELPAUfX19tqwL6SzXhUPamedFNA4QBQ50YC8wdzpmSaYcghRncmU1siTjFChKkow3IHFBeulOZypkxxGGRafAgs/Fc4IiEk4KCBFzNAILpphqtXolcYPD3eVqLyUjmwwxxNnZmRH3TLr8O3AYEwqwFgXCSbYDEZGS4Xwu4fPi8fgVoYEz0wy4kfOp2WxeKb58HpRbwM5AVkyFkiw5mntJUgP3mz8DWc9EQpFjGmWq4tlhYqagEcuDOIV1JBD+TLw0vHxP51oQIDtnNBCf58c//vEXv9j8wR/8wdsLCwtGCj548EDRaNS6ouPjY83PzyubzVoYI6P0nTt39OTJE7toGKj6+/s1OTlp0fp4ShAePHnyxAoE8R6SDOeE72F89fl8Wltbk8/nUyQSMeVMoVAwp3g2m9X29rbu3r1ruDxufySLxI8/ePDACOTx8XGFQiF9+OGH2tvb0/T0tB1C3GSnbJaRlhdako3rz58/17Nnz0ye/PHHH5tXAmVVo9Ew6efMzIx2dnbU0dFxJV0BGfnBwYGSyaS5kV0ulxXoWCwml8ul+fl5PXnyxCKA6IbgezCI4RnK5/PWqQL7FAoFdXW1N19CPHMIosxrNNr7X/BccZCgUrt3755BfHfu3DGj289+9jMjOMfGxgxaKpfLGh8ft62IqVTKcsOAJm7fvm1QBt1fMBhUoVBQZ2en8vm87t69a50gRKvH49Err7xi4opCoWC+h/Pzc9sBw33k4AGa4efDB+HM4CJaBnEJuWwEn0IwE9KIP8QJ13IYYWpEFYZJE8iEQsuzenBwYAWMrh0YF74J7gSvD4neJG5Q0Dk8+/r6rnwmYKxms2l7nEZGRiyG5vT01Eh/Dj2aJDxHSHQh0jlAMZCCXgwODhq8zbPD6gG/328FfHBw0PIOkYzTdPp8PoOlSJZAfQYXSsw/ikvMrOVy2Yo2SjimV7hJzLZ+v18HBwf2HiJgAcLnZ6VYw8vSKPP5MA5zTTC7AreRegD/A8xG2gififeot7e9s+r+/ftf/GLzh3/4h29/5zvfuTLan5+f24UdGhqyKYYHbmxsTB988IF1w5FIxNQVYMKog/b39y0Ez+fzKZfLWbIru2LW19eNJ8B573K1E4QfPXpkMeeM0BCieEXQpk9OTlrHJMlemmq1ajAPcTQ4qnngk8mkwuGwYaEon4ib8Hq9ymazhgc7oZiBgQGxpoGcsXQ6rUQiYZ08kw54L1E4+DYuLtphoaurqwqHw7q4uNCNGzess6ZLZR/9wcGBHcJ0Ti6XS/F4XKFQSMViUcvLy5Yr19PTY1NgX1+fTZyoho6OjqyAQC6jzsJsyQtVKBQshsfj8VgsCx2kJOswCWUsFotKJBL2TBADT+5bpVKxwywSiVhoosfjsd1JOP3pqKvVqknl2anS29urDz/80KYfPFl056zl5t8h8J1dN4QxogCaDUQ0FGngIPB7nODg+pKMTEaJxWHvjOBh5/3l5aUlLvAZmGAxxCIyoMuHjyDehzQGfg7UezQYwEqINtxut61nIFYFQp1rw3tA88JB70xAYAsnBYyunOQBlHLAoyxA9Pv9CoVCdu2Izkegw9TKZMbCQDIU9/b2TEHZbDaN3CcSR5KSyaTxRSjjEFJwrSnWKDcvLy8txbm/v9+WAeLhk176dniegGThe1HYMa0CedOsMHkdHx9rb2/P+Fq+J3QE74HzPv/rv/6rbt68qVarpUAgoB/96EdffJ8NGVtsiqzValpfX7ckAXZnRCIRm1L29vbU29trFX1wcFBf+9rXrPqenJyoXC5bDA57wSE0weqDwaByuZz5MSA1icPgBqPumZmZ0fz8vCKRiHXr4XBYlUpFuVxOjx8/1j//8z9btlc8HjeI6fDw0LpPkp95AYAGd3Z2DEZByoynBwgH38/y8rJtekTbDwyAAmZsbExzc3M6PDw0HJwuicKNeg5hBF2t1+vV5OSkIpGIUqmU+vv7FYvFDHoaHBzUz372M/3kJz8x2TOE5OLiou0dohA1Gg09fvzYUgNqtZodZnSG5XJZx8fHWlpaMl0/waKQkfV6XdevX1ez2dT09LR9pl//9V+3e7W/v28bXlOplFKplG7dumWdKOGW+DmIbF9dXdXp6akdyI8fP9b7779vO9w5dPHizM7O2iqD0dFRSVI6ndbs7KyRzOx7xyCLIrJer5sUHXVcX1+fQqGQRkZGzJALf9hsNs3jApwFZMT+IqJKOEyAy5gcJRk3gGeHYsYURHFCKcbhjk/p/PzcZLIjIyPy+/0mbKAhoXA4VXXARG53O42cpAA4H2TB8Jv8MzJq1FuYj+nww+GwIpGITVTAXOywAW6iMKKmw+wNvEXqOo1guVw2bgilJhAx0DEIBvePqQsuiqaOyZWm9dGjR1fOO34/2XLBYNCk+hRYPHdInKEJOGuYkjm/iKnhz5IUgJKWxqVcLpsggYkaKwHWEERHTJ5HR0d65ZVXjOfByvBZX1+IyebP//zP337jjTfMkMnqX6Jn6FAJOgTrvXHjhunzh4aGlM1m7cXu7u7W2NiY3XzWEbCUiwyk/v5+pVIp1Wo1JRIJLS0tqVKpmAQX4yAk4eDgoCnSrl+/rqWlJeN6enp6NDo6asmozWbTgjrZnshh5fP5TCYdi8XMeIh82u/3a2BgQJkX+VPItAOBgD30o6OjZp4jEmV+fl6FQkHJZFKpVErn5+2QvJGREX3lK19RLBazggr/g5mLCY3Ccn5+rsXFRV1cXOjevXvWOUUiEevm8ELV63Xr2EOhkDKZjAKBgIrFom7cuGHcDova6I6CwaA1EHxWj8ejeDxuUB1QA1DJ0dGRqaRIekZV6ORU+vr6tLKyYqkQW1tbunv3rvl02GlEFh5BnGdnZ7pz545JVZl0KYzg5MSpMBmhBCIUE0n99PS0nj17Zjt76OTByCF9kbQ61WBAvajLkOI6pat06ixUgzjGR4NUGhk4kmNS1YmJQbqOso+YIe47pmAKFYINfFRAj4ODg1YY6KKBDgmCJfeMoFUW+gEtUhRwtQNx0eS0Wu2Nk/w+CHbyFRFUUOCckx5TDU0uzcXGxobxVtLLJWJ8L8JfgbwoQjQBSMcvLi40PT1tXAu7ruBhpJfeI4/HY1MnvAnTDUUbji0cDtt9dirSWOyG4bSnp8cKLEkQZEWenZ1pe3vb0CF4VN4Hp+QbEQfXlmLIhHR5eWnKtN7eXr333ntf/MmGTml3d1eNRkO3bt1S8kVel8/n0/LyshKJhNLptJm1+vv7tbS0pPX1dUkyjBUoA2UUnAjmK+AxLiAPy+joqKampvTGG2/YeuFUKmXmT2TTkK8EX15etpeGAWsgBkC5wmdl/XQkEjGhAxsiNzY2DDO9c+eO6vW6stmsKpWKqtWqxsbG1N/fr5mZGd26dcsUQgcHBxodHdXs7Ky9uCsrK7aRMhaLaXNz04hLuBC6PWSjmBw7Otrx9tPT0xoYGFClUlEoFNKzZ8/k8bT3xufzeUscqNfrWlhY0Je//GX5/X4NDw+b2ghpKmtwg8GgisWiCoWCdnd3zSj39OlT46AQYpDfxEFJwm9HR4cZW2OxmG7cuKHp6Wl1dHSYITUSiSgej9sOkZmZGZ2dtXfTsNIZboBDqa+vT1/60pfswHe73dra2tLy8rK2t7clye7FtWvXTOWEim9xcdEI8v39fVMlNhoNpVIpm5IkmUuftAwc7G632xoMhCWSLPMKOMlJ8DonEGBaCjIpD8AzPPfRaNRiSpgs4Xsk2aFE5AmROf39/UYUO6Wz+GwQRsDNoILEX8P0hIhkfHzcDMEUVN4rphr+br/fb/YCoC44BZ7Lk5MTdXV1mccJ3oamDq8dsTXATMCPpVLpSpI52X7OIsszKMnWjHNfpJdTLw0RBfLk5MSMtpJs4oA/4x5SIHgG+czNZlO7u7vK5XLa3d01OBUokQQD/DGdnZ2WJtHV1WXrJ7gfGEfPztop8dxzChwTMEID4ESaCoJn4a1Q/n3e1+cWG5fL9Zcul6vkcrmeOH7tbZfLVXC5XI9f/O+/c/y3/9Xlcq27XK4Vl8v1m5/7Cdp/xsYxIhXYJnlxcaG5uTm53W69+eabpk9vtVr2YGWzWcNvMfh1dXXp9u3bqtfrZvhsNpu6ceOGgsGgki/SlAl+hPjs7OzU1772Nf3Wb/2WYrGYTUv1el3T09O2vbFcLptc+Stf+Yo9lHNzc5qbm7OgSIIn6fro1tlGifEM4+XS0pJGRkbMyAkeSr7ZwcGBVldXrfDCVaFyCgaDWl1dVbPZVDqd1sjIiFKplOHIxPOk02mD4oAmPB6P9vb29PDhQ7sfRKh0dXWpUCiYyo/uFPiBA//evXvKZDIql8sGcXq9XuNqKPB9fX1WJJvNpra2tnR+fq4bN26YyIDpB8xZkk0NfX19un//vp4+fWrrbkliIPuN4MZSqWQTEx4uHNxMKLVaTclkUoFAQFNTU6rVaopGo5qfn1dfX5/Gx8eNeMdNPjExoWQyqWg0asKK4eFhra+vG6m/tbVlQhMmB6eCbHh42CTBcEtut1uRSMRWGNCI7O/vW9NAjhexNqxEcE4Azn1JwLIU8bGxMYswAnbi/7k2zogXBDaYOfF+AMW5XC5TdZGZhioNEpu/Hx8RvCCS6s7O9qZYuBAk7zjanepHrh0TCvEs/B4aS4o1hzBiE/iS09NTUy8yFYKiECLL9MP7C9TLZOrz+SzoEy+QU53KpMYhDZfFwQ8PwvVANXl2dqZ0Oq1MJmNTTG9vr11rihcTFerKarVq7yr8J1M81xOBDI0En1GSLZVk6namP9C07O7uWsOBmOFzz/nP+00ul+vrkmqS/kur1bpBsZFUa7Va7/zC752T9FeSXpMUk/QjSTOtVuvys/6OaDTa+t3f/V3buX3r1i1VKhV1d3fbgi+w6bW1Nd25c8c8G+wnKZVKSiQSWl1d1auvvqqLiwuLo0DfDlmGpNHj8ViGGYGP+E8Yp0k/ZuVqOp02mAEvCatw19bWLPmAGBPIvGvXrpkwAEUKUSGPHz82vJ+OpNls2gE5PT2tra0ttVotU8ft7u7a902n0xocHNTi4qIikYh6enrswGCyIBS0u7tbU1NTOjo6svGbCSeVStmf5edm1AcmYspYW1uz3UNIxZlEPvroI11cXFiYZXd3t65fv27TELLvSCSiYrFoy9kWFxdNBbewsGAigGKxqJ2dHZVKJY2Pj1sqwcOHDxWNRjU0NKTFxUWdnZ3p1VdfNXw6k8kYzAqejtkTmG51ddU8KmS15fN5TUxMKBQKWTccj8fN67Szs2OQzc7Ojq5du6Z8Pm8mWZernZqMcABOCt8CsAsmyXQ6bbAS/AZbSYnx4eWHm5Fk3CTud6fvg2w3CjV8ED+rUwZdq9WuLLDjQCSIs9FoKJlM2uHL84JfjEMHuAvjMAQzSQ0opJg8IKMxJvPzYCgEZiUckoPU7/cbhwd6AayK/wgFJByFJJOzj4yMaHd315ovJhagRnxR5KdRzIPBoMmngVA5vHnesSjAF3EPpJeBwlJ7Un7zzTe1tramkZERs1Hs7e1Zrh2fGyUeNgcmVlRlNK3AhEwZtVrN+GTEFpyBwLz8fBivMWgTd0XhBY2hwNIEOdOh33nnnc9Mfe78rCIgSa1W62culyv5eb/vxde/l/R/tlqtM0mbLpdrXe3C88Hn/UHCJP1+v5aXl+Xz+bS7u6vJyUnT6UttzwQvU6PRUDweN5XQ8PCwRkdHLQxxfHzcigojJQuNcrmcGaIk2YuAsY9ICTDUg4MDM00SzEeceSQSsb8LQ5zUjsP45JNPNDU1pZ2dHdXrde3t7enXfu3X9OMf/9i8PyQRHxwcmFFRksEsOzs7V1zB+/v7Bo198MEHRiq/+eabWlpaMv4Egn1sbMzUfPBBrVZ7VXZvb6+CwaBJoXESDw8Pq6urS+vr66a8euONN1QsFpVOpyW1PS7ZbFZjY2MqFotGmE5MTGhvb88KIa7/er2uSCRinZ2TmwPOAtJBHkqCMqY4FpeVy2VNTExYPDtLsorFonWXTIRk0THJ0Gnjvl9aWjJIpl6vK5FI2MGMKIFDbn193dSFFJKPP/7YXPDAJ0wM8HavvPKKEc88b5JMjUSjhQlPkiUAjI6OGuwBnk8MPPAOhQPhBwc/EyFNJTlnTsc/8A2Fxu12G5SD9cAZnU9HXSgU5PP5LO3bmYWGyozvR1d8cnJipDdwH6pIPjfkO6o//CHVatUCOE9PT02wQIyO1DbFjoyMmLoNtSYpGUw33AtIfPxGrGDHH4WjnwJQLpclyeBOlLNnZ2fa3Nw07oMJiXQAriH/PDg4qHw+bw0z8B7fl3eOZ5Kfj6IAkgFPw3I56WXyNxA00zAqOJABuE1SASgyqAcp/E4uj4kzkUhYI0Liwed9fW6x+Yyv/9nlcv0HSQ8k/S+tVutAUlzSPcfvyb/4tc/8ajQaunv37pUk1lwup2QyaUuoIOfX1tZ0fHysBw8e6Lvf/a6CwaCWl5ftQeeFvHv3rvL5vDye9pbAnp72+lkcxN/+9rf14x//WOVy2eTPfNENS7KXrFaraWxsTJubm+rr67NY+9XVVRWLRZtGiMDhsFpYWDBCmwTWs7Mzc7W3Wi2NjY1Z9tjQ0JA5xOFn/v7v/169vb32GXkpWYR08+ZNnZ6eKplMqlKp6Pz83GTPvKi8LB6PR8vLy+rp6dE3vvENHR0daX193ZR+rFCmK4zH46a3f/jwoU1q7G8HZuvs7DRn8dnZmcFCgUBAx8fHZpBl7XJXV5dJu6X2Ycgeos7OTltPQKGBtETMAUFLoWYvDZ0/PhZeBDgBIKpGo6F//Md/tOwo7kupVNLc3JxBeGtra1pYWLBpjxW8Pp9PY2NjJiqg0NEYxWIxSW3Jq1OmTBYasFWz2bTDFbMfsOjZWXudNz8Hvpjnz5+rv7/fFFlsyZyenrYdODRY4OyXl5e2uZYcLDwxyHUhsJ2KPQ5LFHMQ23hb4K5YtkdApdPbwiEHP+RcB+AM3uX+YGr++OOPLS6KTaoUGooRhyYG25WVFZt8yatD6o7E2RnM2d/fb9eIa+7z+ezaDQ0NaWlpyVaIBAIBixVqtVo2FfDz1+t1g7uYhGkg8I4BsfHrNKlMvKQLgCAwkdXrdcsZREjBVk7eG+ekMTAwoJWVFZtKIP/hoPh7XS6X7UViEoVndRqxQXsuLi5UKBTMx9NqvVwl8Vlf/1aBwP8uaVLSgqQdST948euuX/J7fylO53K5/pPL5XrgcrkeXFxcaG1tzXY0hMNhXbt2zZYhNZtN64hTqZQkaWFhQaenp1pfX7cImlwup62tLZ2cnNjhAJxEHhH//V/+5V/Mz9JoNMwwykFNB4fsMxaLWdYVRGCj0dAbb7xhSdBAfR0dHXr48KHcbreCwaD8fr8SiYRBfRCmdJ2EeDojXTwej2HqN27ckM/n0+zsrGKxmPx+vyKRiPr7+xWJRJTNZg1mAveHDN/f39ff/u3f6unTp8aNceA9efLEYizu37+vcrlssmgKkyQlEgmDKyG9Z2dn1d3dbXwVEwDwCdwSnTv4OhwKBfP8/NyMdvl8Xl6v19IWtre3VSqVrBMfHBxUOp1WoVBQPB63DLXLy0u9+uqrphIqFotyuVwGv927d8+k62SZkb/FfYOjQHlULpflcrksXQHnNodoOp3Wzs6OcrmcXZObN29qZGREwWDQPFvlctn8HwR6YhxESYW8GEIY+GJwcFDHx8fKZDLG3+3t7dmB4EwRGBgYMCiGJXAonOBr4G66u7tVqVSsk63VajZFgO/DS/G9mRAvLy9N0VYsFu0wDYVCGhsbM8Uefw+8Dgf6ycmJSeyZKhDoIFdmKgkGgwapVSoVswRwEJP/t7q6qr/8y7/U8vKy+YAQAeHGZ4LAtAoMhOiBd80J76EypIGq1WqWrye9jA5iPw/wHfeA3wd3giiAQsDaAopvV9f/Q92bxDaeZ3eeX4qidoqSuJMSRVFrSMoIRSozKjOy3GWXC6iyLz0DA2MYPkyfeg6ewwBz6L5NGnC7VrTRvgzgQR+6gVlswANMY2AUyjbs2jIrMzIiFFIoFNooUpRIipKojdooUpwD8/Pyr3I7s9A9h7SAQlZGKiTyz///9977bq/dOFGmneHhYfn9foMuq9WqKTfh8Jii4KB4DmgaS6WS9vf3bc03xmNUaOQ8wp95PB7jvrFU8HORVyPAIQrsV/n6Lyo2jUZjr9Fo1BuNxq2k/01NqExqTjJDjm8dlJT/R37GnzUajbcajcZbLpdL2WxWx8fHFizHAdje3m43GXH7sVhMMzMzlny8sLBgozpYJiQhWvJKpWKTDu5vJIQcdmQ69ff3m0eDGyqdTqunp8cO5EqlYlH5T548UTqdto5rYWFBR0dHlqcF1lyvN8NEEQkQlElRoiMDB15bW9OHH36oi4sLDQ8P62c/+5k++ugjrays2N4aHvRarbmT5eTkRJeXl9re3r6TrwVvMjg4aJDdwMCA1tfXTUKOoonJBCcxh5Eke8/t7e1KJpP2YE1OTtoBHovFbLJ59eqV3G635Tqxo6a/v18ffvihqXWIE8lkMlpaWjLYp1KpWNc4MjJikuGWlhYVi0VNT09btxiJRO7kSwGNjY2NGdxZLBatOYG0vbm50djYmBKJhEKhkD30vK5f/OIXltsG5k6CBN08irBYLCav12tcEtsT2WkCXEQECwcYMBZeJRQ+wBSYehFPSJ9Nby6Xy9ZZAHVgtOSZ4ODr6ekxjmRjY8OKHLAc4gIahq6uLpu2MbmytCsajcrv95t6iUMSuBqOR5L5mfDMIKioVqsqlUoGJ5dKJeXzeUu9oPECYuVeZAstaql79+7p6urKJtVfDonkGXCuGHAmJiDg4b0DU3GQQuDTePT09FgRODs7sww2JwQJH4pvhnu60WjYosirqysTK6BeRQXGZwY3AsfMlCjJCifcnTPHjKLkVPDS1CLHhgfGlIpZFWk7iRnO2DBsEZJMOPCrfP0XwWgulyvaaDQKn/7rfysJpdp/kvR/uFyuf6umQGBc0sdf9POQOPOw3N7eam1tzbB/SSbNZPo4Pz83zf7Y2Jj+/u//XoVCwcZmstTC4bAWFxe1u7srn89nhzn+CBaFDQ0N6erqyqTDkHuHh4caHBy0A29ubk7Ly8s2opN+KjUfZKJSOCQI9ZOkRCKhv/iLv1C9Xtd7772n3/iN39D+/r62trasG6TbW1xcVDgcVmtrqxYXF80IeXXVXPdaKpVUqVQ0PT1tCrlCoaB4PK6dnR1TfAFZ3d7e6sMPPzTFHIfbzMyMdVBXV1cqlUqanJw0NRaTAlp/5K7lctnIWGd8+e7urnXVUnOz3/r6uiQZHAkROTs7q9bWVs3NzWlhYcGgrK6uLnsP/f39tufn/PzcYkOAjtra2vTee+9peXnZiMypqSm1tzc3kO7v71sXiypMagpNIpGIdnZ2LDZEksGsyKUl6fHjx9b1Pn36VPV6XV/96lfV1tam1dXVO25u8HCk3dPT09YASDI/RHd3t5l78fEAV0my4M5kMmnTAjJjIFpCFCHLNzc3dXNzo+HhYXPo0+RgdkWl6PP5TKZOjFGlUrF7FYUVXS98DdcP0x+yXoJJXS6X2RGmpqYsimdtbc0aAIrA3t6ehoaGTOkmyTIJnUZFprZ6vW4dPjAcSr16vW7WBLw5kixVRGryYuzGAfYJhUJGnPPMwDXhnmeFB8WdQkkKulP2C0/IQjGieEjeRn2IJwxJNEpS8hoPDw9tF9P4+Li8Xq+y2awpxHi+gLHg61DFMoki6CAFgOJCJBMJ3njy4CPJk+PMhdeDa8X4jSqY++Lzvr6w2Lhcrv9T0q9LCrhcrh1J/4ukX3e5XHNqQmQZSf+DJDUajWWXy/UXkl5Jqkn6gy9SoknN6jw/P28rhk9PTzU2NqbOzk5tbGxY8B94/PHxsaLRqElqq9Xmrnu6ja6uLu3u7pp35+joyEyfqKl4CKnyGxsbmpiYsAcVOAnZIyPq4uKibdvE0MT4vLq6aqanVCql3t5eHRwc6ODgQL29vVZAAoGAGo2GstmsPVSvXr3SN77xDaXTaY2Pj8vn82lgYEClUsl4n/X1dVuU1N/fr8PDQz1//tzklZDTjx8/1gcffKB8Pq+JiQlTn/BQM14fHh7q3XffVTabtc2WTD0ozNjtThgjXgS67snJSXV2dpp02efzmSelpaXF+AK6bVY9JBIJOxicYzpd+urqqiYnJ63ZIPm7Vqtpfn5eR0dHFutBt81BD0cC3+P3++09c9ilUilTBPJPyFhUjB6PR6lUSoeHh4rFYiqXywaRFYtFw9JJSJZ0p7sm6ZgAT9Y0kNaA4otoFyYpyGK2UpKPhpqQ7plrixQaIyhFDMUVKl+RsAAAIABJREFUpkoKHWRzuVy2rpfGiMMKJzsL6SguyIThKuiU8WtA1ns8HjOZIuI4Pj5WKBQyDoqsL9R0yJC5juSllUoli+JhkmOC5swAVgTqw0t2enqqSCRiXT/GSCTLJB/wnt1ut3Gp3C+ICiDKJRmJT7GFn6Ip4zUBHXOtkEzTjDD1AkdWq1UNDg4aR0WjQaHAkoDnCkN2e3u7+dUuLi6Ma6EZ5r5D9t/T02MKPu5ToDM8WpyNLpfLVt0DI5L6wH2L0Orzvn4VNdrv/Wf++N9/zvf/G0n/5gt/8y99PXv2zJQgPT09tg8+m82qpaVFyWTSDF6pVEovXrywuGu8AMlPd5x4PB5NTU0pn89bfDfuWTBc1iOjYqMASbKNkhDCfr/fuklG34WFBXPhS7rjZcGol81mNTo6ag8QMk78ERsbG5qamrKlZ9ls1vT9b775pnZ3d1UqlUySyU0SiUSUz+c1OjpqsB1mudnZWW1vb8vv92t4eFh7e3sqlUpKp9O6f/+++vr6tLS0pJubG0UiEb18+VLvvfee0um0bm9vrfPq6OjQD3/4Q3tQnRzO/Py8IpGIFhcXDRJJJpPWGQFFAj22tDRXFrBagBUI5+fnmp+fV39/v8W+cO2RKgPHud3uOxlkpC4cHBzYavDz83Otr6+bGg0uhIgR9oxcXFxoZWXFFHeY4DAztrS0aHBw0FRzkrS0tGS8E0WO9QnEpYRCIa2urpoYIfPpfqN4PG4xStxfGEMphJIMh0d9htPfSfwidQX/r1Q+W1bGgYnyCJ6E1d6Li4sKBAK2toCiR5EGcuIaoiSjCSCxwKlsgmOCg4tEIioUCgqFQpZDyJ8z+fB+icYHqiaBQpIdlsDj2WzWChTTEpA215tNr36/X7lczp6Js7MzxeNxS/EgPBS0hEIMGiI1G1sOegqL3+83vpPJEw8QMBSFGV4KzoVCxiRzdXVl/Ca7kghKxWPGa0eVSVEmKBcVImiI2+020QxcdSgUsiLPZMIEBDyGB45mhgn78vLSUIrh4WFrJtkXxpoOis4XfX0p4mq+973vvT8/P28HCyGJQAGoN/x+v8WGoMLxer3a2tpSKBSyygsWzDRAcCNcA3sdOPyR+MbjcRvtkTVXKhUL3OQi12o13bt3786WOzgESabukJomRLLPUG+h4vB4mrvUt7a2dHBwYOSzU7pbr9cNPkGejNy1s7NTOzs7FigYj8fl9Xq1v79vW057e3vvZCahuAFP9vl81p1zkEK6czAzFTn3qyAN7+/vt0VibEKFPOcajIyMaHl52SKC6HhRiUGmOpdQnZ2dmceGqSKTyailpUX5fF4nJyeKRqPm4t/e3jaOKRwOm5mWiQOi2ul94PAhHXlra0vValXPnz/XyMiIubjxmcBrFItFM+ONj4+b5PX169dKJBImiR4ZGVGtVrNlZ0i/cWEzgSF3x8BLrh3yaEkGL1IwIYW5dkwmq6urSiQSRkQDT0OQM8F2d3cbdMV0CJTrzAwjpglEoFarmQeO/C3eA7E519fXpvLikEbNxs+neAEz4diHj4M/8vl8lnTAewZJIK6I98hUQ6Hk73Z1dSkWi92ZtOE5ie5HRQbHRafONSQhAVEGqQ68BlAWDOfcK5xhBPYCacMjS5/5f2gunMIkpgbSzYEioQuur6/tmgN18e/OZG/WGKA25DUC6aJa5Z5iJcT1dTMpnSBa55oDoLbLy0ulUin96Ec/+vKnPv/gBz94f3Z21mJQbm6ai7ogo3hYv/Wtb+nw8NDUSORf0fXB4WA4xKBEZAWmQzgASTYxfP3rX7dRcnl5WRMTE1a4JJkLmagL8r/IWcMEtbq6ag7fYrGoyclJk7lyQ0my0VqSNjY2zJcQCoVMqAD5mc/nDT+VZAvlgAs7Ozvv5KClUinrXNvb220bKLBVZ2enMpmMksmkHjx4oNbWVhUKBTO07e7umnF0amrKuj2nukaSGfmkZifKThR8DblcTl6vV69fvzY4C68FERrAnTwobW1thp+n02mThK+srFhk/fT0tH2OjUZDAwMDev36tUWh47ZH5dfR0WFwKJtJiSO6uWkukGOJHVAIB6DUlC9PTU3J7XZbKgIxJbu7uybnvby8tKVwQ0NDdng1Gg1tbW3ZgcoBwX3Adby9bW4Y5XtQYOJ+Z0KHqOXPkEr39fVZJhdTGX4WijcdMeZZGiCENG53c5snTRi/gykOBODm5sa8X0w4QMpE5CAeqdWawbk8S7VaTfF43AqKE/JEpQc8COlO8bu+vrYQVZoieBTy4zwez521HhMTE6baQs3l/GxY+wFsBAcCTMUX14KJC3KczDSKcyAQMEMuED8TCdwZxeDm5uZOKCzngt/vt+auWq2agpAUfMQlR0dHdq8CzdKMYjCnMMDjMK07U1gkWaAqgbHAkXC2rG0AWqSZJGrphz/84T+NYpNIJHR0dGQKs+npaV1fX5tkz+/368mTJ8bp+Hw+C2BklN7a2lI0GrWYdwh9JKszMzOGgU9OTqqtrc0kvNvb29ZpoNSgKFEAWVaGhJQpglReNlnSQeJjQP6MQoeVyMRZxONxVSoVjY6OamRkRJ2dnVpYWFAkEjEZ571790z+CyzBWgKI8YWFBcViMX3wwQcGvfX09BjZLknRaFR7e3uWStzV1aW9vT2TWgPjsWP8k08+scOBTgnCFmUQ+DcJBufn53rjjTdM4UaAKERzNBrVyMiIisWiHj58qIuLC+NQcE47VWHAhzMzM3r48KFBrPV6XZubm9rY2NDk5KRJaMPhsHZ2diwyhQ5+cHDQHuRkMqlcLmcTMbtqkHVXq1UTSqyurioUCunw8NAMpbVaTWtra1pbW1NLSzPgdWZmxnK6qtWqFhYW7DMbHx/X6empbYJlQgX3lz6LmYd8BbcH0guFQjbN4yIHoqSYkwdGo4HnhUOCg5TwWiAkDj6gIDKyEGkw6V9fNzdWolJjjw1wM1BrX1+ffZ/P57M4pKmpKc3MzBjsJEkTExMqlUq25RY4Db8HEBPeJzgXScZJ0PAhtAABAe04OzszmIoigjCDxox0A3a+MB1KTdM53hl8LrxeoDWgP4oDAgyM5vBseFacgbEQ9kiiCWFloRuGd/hDCi+iKPjaSCRiPxMPE4WaSZNsPGdjwD3Dv0ciEV1cXKhUKunw8NC4J/xHWAMymYxNwj/5yU++/MXmO9/5zvvo3CGjCYdsbW01Fdnx8bHi8bjp+dlh0tHRobm5OdvhMjo6qouLC42MjKivr8+C9WKxmMEJxMQgd2TRliSLOJ+fn7duA0Ma2U6EEdJV02EcHBwomUzeUejgq6ADBIoaHR3VwMCAXrx4YTlYp6en2t/fl9/vN+WMJMs0I4uIyYwpoqurS3/3d3+n/v5+88nQ0QEHIXmNx+NaW1szZ//w8LB8Pp8GBwdtaR27aPr7+63gVSoVFQoFu9nr9boCgYCePn2qSCSidDqtRCJhcTxScyJkZTcQUzqdNpwdYpmgUm585JcsS/v1X/911et1PX36VAMDA5ZxhbLJ7XYrlUppa2tLOzs7Ojg4UCQSsWVdHAIjIyMWcsoyvM7OTg0PDysSiVjQ4enpqa2cwHSJUqlarWplZcXMslNTUwZ5uVwu7e7uihRzEg8++OADi45hSr69vbX7j6ni+rq5Wjoej5uCbn9/36ZqoBVEH6TyMs1wsEoy6AmfDZAPB5fTb8IhhGAC/wj4PbJsfDHcexyYmFGR/TKZe71ekxtTnJiSuru7zRTLxEBDQ3w+fCEcBokAGE4DgYBBXnAwqAiZrohdcr5m1H24+UlbQNVJwec9XF5eKhwOa39/Xx6PxyBEOKVyuWzx/MCSTPkQ/+QAAktKupOS0Nvba88MyQXSZwgCsG+lUjEUCJ6bz+Xy8lLRaNTuhf39fZv2eN3ApYgO8CEB6wKxI97o6uqy5Abg+/Pzc2tWrq+vuce//MXmu9/97vtTU1NKp9PWYbFrBi/Hq1evlEgk7hzkq6urlidF1SWniJvhyZMnVni4efASQLIi57u8vFQmk7HuaGdnx7Zh4ngvl8v2YG9vb9sHJ8lC8gjGw82PhNHtdmt7e9sIeOAJsN++vj69fv3a3MJTU1MGA8JvIFKA80Gff3l5qdHRUSUSCZVKJUWjUbvB6Hr39vbsBuYGfPTokR2KjUbD9ulsbGwYpIiJlZ0h9Xr9zqpgCMmTkxOLLnn9+rWq1aolYyPG4ICLx+MGDZbLZUvWBkZDOsp7Gx8fN1jM6R2QZAozDMHZbNaMiRTo7u5uI0adfgi8BM+ePTO40Ql3wQ+8evXKFIfAYEwekKbwXXSuFEznIjiuH00AIhMc3sjdUfuwuZSsNEm2ZIsiwD3tXPWAwgo4jUOQw4YYJrp0/CBAWKiSKDZElwDR8BqJeYJnciYHMDEQvw80BVTEROKE1zC0OsU2BMFyIKO8Q6bOMwd3w99nMoZXoDniOYIDWVtbs4LlfNZ4riXZs0a+H8gKvqi2tjatr6+rr6/PchT5fJGzt7S0WPIBpnDe3+1tcy8WXDSvnfsAZSFQozOjDK6FSZGCRmMCmpPP5zU3N2cmVOC7RqOhYrGoYrFoBYnnlAacz4dmgEgtScbfffLJJ1/+YvPtb3/7/XfffdcgkzfeeMM6ai4msI7X6zXfBrEOQFPlclnLy8vWDa+vr+u9996z7glnLDJZfASbm5s2Wl5cXCgcDpvAgE6GVNlyuawHDx7o4ODAcHke/OnpaYNQJicnbQ3w8vKyRkZGlMlkFIlENDIyovPzc21sbOjg4EBut9sCNh8/fqxKpWLmy0wmo/7+fgtWZGkceU0UCbKfSqWSNjc3bY9FNBq19c6jo6Pq7e01hzQ3TLFYNK8CAYJMHsB/0Wj0jit7d3dXOzs7mpub0+bmprq7uw0ugADmc0Nx4/P57IBG9n16eqpUKqVsNqtoNKpAIGDepPv372t0dFSjo6PmDeAwpFOsVqva3t6Wy+UyhRwCBGDK4+NjI6OB6uj6p6enVSgUdHBwoHw+r9nZWV1eXgoOMRgM6sWLF+Z3ICg1EAiYSosDGO9ROBzWwcGB1tbWDHrb39+3LpYpAp6go6PDQhHhTwgFpRhCkhMCy7SDARhOjoMHfoKiCeHLhA3xT/PCQUUBGB4eNlKcRW7cN3TCg4ODBtNivOR3wn0x1WBmRTjAvYXSiusIh4bJk6aoo6PDYCTk1RRR/G7VatW4QN4LCjAgRK45KjtJlmNHc9DT02N8yOnpqaLRqAl4ODOOj49NXs0kFwqFbFrlPdPosKpkaGjIoMZYLGZTOsW0ra3tjkSe68N9gocH7obCgUgBMQFTL+gLBX55edmg+Hg8bg0Iz+Mv81YkBUj6B5CjJMtH+9SD9uUvNt///vffr9Waqamjo6Pq6uoy7wEfGv6Hy8vLO2udXS6X4bjlclmdnZ3mzieokfRhbiJuuM3NzTsVHMisq6vLokOWlpaUTCbV0tKivb09K4AciNFo1HbY7+7u2trhkZER5fN5hcNhO2AwP52dneno6EixWEwul0szMzMm08RTwEMEoSnJoChkm7x/4u/xQFxdXcnv9+vRo0eWZ/TixQulUqk7GXC3t7fa2dmR3++Xz+dTJpPR5uampqenbbEb6xmy2azxW6VSyeLjKa6pVMomAnxShC4iZqAjc7lcBqUcHx/r8PBQc3NzRpyy54e8MEQf6XTa1jrwgBKn7vV6tbGxYco4HqZ6vW7wFykURNejrikUCiYVhydgVXa9Xlc2m7XEX6ZWYCg66Pb25hKwvr4+7ezsGK+SSqWMkEdRBvTp9FHQjZ+cnJghGH8EUSR0skwRHo/HIBN4H6ZrvB5AUshWETagcoIXQFXJlE0GWzQaNdLYeR8D1+zv7xtBzZSFTQDzNM0Yr7mjo8Ou5cnJifFXTpIcVzyHP3wV79MZbcNn2dHRYX/mdNET5U+hxTPC1FcqleyZYlJ3fjb4/NhRxBRKU8b1pkAQoomvhuuKx+f29lahUMiaJwo4a+OZuikuXAcmCOf04XK5jJsql8t2rSUZQgNXKMkSOGg4UOvxvhEzweEgyHAqALkfSTVAOv/xxx9/+YvNd7/73ffn5+fl9/uVz+fNMDgwMKDu7m6Db4BlMBAyZheLReMT3G63mZv6+/ttPIQABkIB50ZmDTx2eXlp3TC687feesumqlwuZ8oactLwHni9Xq2urpoSxuPxaHh42IyJvIfW1lZtb28bDgt3QhotDzQPIJs9Ly8vFQqFLCxzfHzc1EpMMU68f2NjQ/v7+4pGo7bVE3Pj2NiYEXwej0fHx8caGxtTtVq13CwmxsHBQSNtSXPGZ4BAY2NjQ+l0WhcXF5qdnZUki7phLQC+E5RQT548sS6ZP89kMnr9+rVNCSsrK/J4PNrZ2bGQ087OTrW3t2tlZcUSFTY2NjQyMmIPGEUezwIwEdAfm0YJzWShGxPhhx9+eGf1MqbEcrmsra0tg1ULhYKR8Mlk0l6HU2IuSXt7e2ptbe6vByZBIs2EBE4OSXt+fm5FgIPh4uLijlQVGToHHBE8TKHn5+d2SDPJUMTq9bp2d3flcrmMM+zp6bGf29bWZinBwEUul8tgbBAC4CsOJ2dOGFlfxOQApzFl8V6IDWKBF9MIKRY8C3AGHPxE/jPFtLW1GX+GYgyTLAo0qZl95/P5LD0BRdvg4KBxFoSOggYg/ujoaG4DJbAT9RZTpCSbpgnjREINPMlnRYoyYgRUjV1dXSZPp0GBS6aB4lojBMLiwD3u5N+A6kBBkPADbTLdAr81Gg1LiOD3oeaVmkkboARMiV8Eo/3XpD7///bV+DRgEPx7cHDQTHvBYFB9fX0Gd21tbWlkZERdXV1KJpPa3t42rwfrg7lx1tfXDRJ49eqVksmkxXUjd+WiA1XFYjHl83krFp2dnXr16pV1x6Qh0/HxgaLQisfjWlhY0D/7Z//MdkcEAgGLxEc2yUOH78Lr9apQKJgHwnlDrqysyOv1KhaLaXFx0bwlmUxG3/rWt7S3t6dyuaxoNKpcLqd8Pm9ENOM7BfHmppmczPcRFU78z+HhoT755BNbx4yjGa5jd3fXGgKiRoAZpWbnxAHU1tZmh+f19bVmZ2e1srJi4g5ubLLhSqWSent7NTo6qsHBQXV2dloqMdBQOBzW6OiopW8Tj4NzmsMBop/iTbf27rvvamlpSffu3dPq6qpdfwIZ2fTKgU1AK25+glHJSxseHtbu7q69f+KQKC5bW1smf8fTgEkTE7LL5boTf+LsnLkGXFv8Tkj+W1pazKjMcjM6c0h9uIZkMnlHSMDUwUFWq9XMRMgU4JS7UzhPTk50fd3ch4IxFDEDXffAwIAKhWailROiw6DrTAiQdGcHDp4ZAiPJJORgJL+P18VEI8m8cRRp5OsIQXp7e03Mw/OBuZZm1BmiSUGgUPGcS7JUAb/fL6/Xa1OzJAsDRunI/cskA4RNhI4zrsrJS7rd7jtBqUw9wH4kViCv7urqsn8HDqNRJQ6Kz6ul5bO1AXC7TsEKqku4TUkmWKJxQazyq5g6vxRrobnJzs7OTBGyu7t7B7pYWFhQOBzW2NiYAoGAPWSPHj2yYMC5uTmNjY0ZEVur1fTOO++YMxhTWjab1eLiok5OTky6Nzg4aJE0dCPARZeXl9ra2lI6ndZ7772nR48eWdfJlkefz2cR+ffv39fAwIDJEHO5nGHa3MTJZFLFYlFbW1uq1WoaHR01XL/RaGhmZkaNRkNLS0saGxszU2YwGLSOr16v6yc/+YlOTk7s4UYBh2sayW42m9XFxYUSiYQkmZmOYtzb26vl5WU1Gg39zu/8ju2h4RClsHzta19TMBjU3Nyc5ubm5PV6jQsC7uB9Dg0N6fHjx6aQ6+/vVywW0+7urgqFgr72ta/p0aNHunfvnn70ox+ZZ+PZs2fa2dmxIkuIIjzL8vKyFhcXDW6EOJdkqsWrqyvlcjnDyScnJw0ChBtob2+/kydF0gB+AxblRaNRCzy9vr5WJpPR2NiYrQMnwocOEgKbKSGTydh0QFMF/NDa2mqwFTwAkw6KK7xDKLb6+vrU+DQkloaJ34cIwxn0WK1WTZZLE+DkCfldwD0c3Ofn58rn89rb2zOBBfJmJxnPhNTT02NKReehxOGPGotnx+12m6BiYGDgju8D9Rldd7VaNQiLAkfIKQotPDcej0eDg4N3XPMc4Nls1mArpj6eJfZHEdESCoVMwco6BEQjqNzo6jmUmdSAOr1erxUBJiCEH8j8OeMoRAgvWExHw0hDAX9KigUrreFTsYIw7VKYmGBpnCmgLAMEVnW7P1u9DXWB6IDGj7MU3mtvb+8Lz/kvBYz2h3/4h+8HAgGbAHjh5H/99Kc/VX9/vxFTdErhcFgul0tTU1Pa2dmxLntnZ8fiMtLptOr1utbW1lQqleT1erW5uSlJptKYmZmxA3pvb09ut1uzs7O2LOvhw4d644035Pf7tbS0ZB1SOp02biMcDqtSqZiC5Pr62mA4piGUOMgG0d0TrSM1N/jhEK9Umhs219bWFIvFVK/XtbOzo42NDVs1wLZQqblVlOgYXO+YGf/8z//cJNgLCwuWd8RDeHBwoLGxMfX19en58+caHR1VPp+3pOju7m49ePBApVJJMzMzltDLwQxGDzkJxEIxjUaj9u9sPRwaGrIIfWAOJ8eGsQ34Auns0dGR4vG4QZ1OPwUdP10gah8gkXw+r/Hxcct/IuqeiW9gYECvXr0yMQiQBPcaUuanT59ayOa9e/ds2oNTAIpkAeDW1pZ1862trdrZ2bmjRDw+Pra8LDpoEsKJOuFAYrOjU1YPJMzkQPQS7x2vBZCTU6WGCgxTa6FQsGeJyJOrqysj4pHJQrqT/YdwIxgMWjHnvfG7uTdQvKGspMCgOIQrAVoiEuf2trn6HQ9Rf3+/KQgzmYwdqjs7O3c8S0waeJay2azJpok76unpsaR04Krb21sTDsDN4HEBmuR1Mak1Gg3j9oAheT4x4IJsOLkXPjeEFVw7JP7hcNg+k46Ojjt7eeD0sChQ6EqlkqU3OCfhlpYW4xGZxkgyJ84HiJGpB58TzQnqNUQQS0tLnwujfSkmG8Y5JMtS01eSy+UkNXXzAwMDFhiJCiwUCpluPhqNmkdkenpa+/v76u3t1YMHD4ywJqKCNdCVSsX4h0ajYeGZONNvbpoJujy4kGZwDS0tLSazXVlZkc/n0+TkpBKJhO0Az+fzWl1d1fHxsTY2NqzobW5uGneyvLxskA5qGrrdtrY2SwTY3t62ThiTWi6XU61Wu0MAVioVzc/Pq6WlRR9//LGur69tyrm5uVEoFLJiIDWzzt566y3T6ff09OjZs2fWnRH+yU6O3d1dO8QrlYpxKHilotGoTk9PVSgU7GAAJhofHzf/Bhp+XPNtbW2WWED3yrI1umcUfhx24+PjBlXQdWc+3f/CvUNYY1dXl0KhkPl8EGlg0JM+I54PDw9NWi19hv9LzZw00pHx43BAeDzNFRYsvmPa5f5G7AK5yoQRDoetk4cPYCOr83BCMdTR0WGfD0WarpkDhJ+Pj4QAWeLpWfjGlAEEhxy6q6vLFGCkAHCPAZdi7ru+vrYYF2L39/f3VS6XLSYFYYRzxTKRNE5JNaouiH1Jd7ZQ0rh5PB4zpNJcMEGHw2GbtvHKJBIJM3Iy0dGp08UDYwE/wSfRFCBMYYUBAg6fz2f3F3AV38PkgwwcTgxFYWtrqzXZ/CwSRWje+BkUJ6KomMg5N3H+Oz8bJlleL58d9yPXkSzBg4MD43AwlUqyIsVExUI5ZyLG5319KSab733ve++3tLTI5/OpXC4rFAqZSe/29tZkvWNjY7p//76tVkVBhlqjvb1dW1tb5totlUoqFAoGaXk8zb0hsVhMPT09tj72zTfftIfknXfekSTjdYj5wAMSCoXk9/tVKBQ0MjJiC9HowHZ3d+0DxMG7t7envb09nZ6eKhQKaWho6B/sBmHXfCQSUblc1v37902N1dfXZ8XJ5XLp3XffVWtrqz766CPNz8+bWzubzWp9fd1WBVQqFVv61t3dbeqslpZmaCmQ3PHxsQ4ODnR8fGybUEOhkG2sPDw81MLCgt588029evXKYLBEIqGXL1/aQwIMwCIm+BaEDYVCweS0HG7lclk+n0/Hx8f6+OOPFQwGtba2prGxMQWDQX3wwQfy+XxaXV217hFlTiwWs7DI8fFxI/qBN0k98Hq9Ojw81JMnT8x06DRLkgpOuKkkKyBAPfF43CTSZEN5PB4NDQ3diStZWlrS6OioXr58aZl6jx49skVySFOBbLq6ukyFRWoFZCzKLed0giS/vb3dun0mDJSGTArcx4ODg3ZoI6AgJRlhC5Mb/hkSKiRZI8B96hQc+Hw+dXZ26vDwUOVy2aYSl8tlHTOTpjO+Br6LqY0ol+7ubuMAWTZHgwWBfXx8bKpRoMXb21ubYuBxIPCZIMh1K5VKxukgX2bSoiGjWNO8cRgjPiBLjeuM740pB1MzgZ5wWWQQoj4FIajX6yaSQGHGmQIFgJn96urKuCvgcAQGqP7IXru8vLTXApcD/8izUi6XNTw8bPcwzycTMNtJndMuZynXIxqN6qOPPvryq9H+6I/+6H0eLhyt+CLwLOzu7ppiCWcuGxATiYRJHylWGAfBSSlY4XDYME6gDj5cVD9HR0cmQyask2JDBP/FxYVt/aS7IcLG6/Ua/8GhMjIyou7ubnO+g6n+Mn4sydzVNzc3SiaTSqfTkmRrBIAy6OafPn1qBXZtbU2pVEo7OzsGSwaDQUsZuLy8VCAQsGsyOTlpEBTxF1NTU5ahxbZTsF+EBqw45oaHUwFC8Pl8ikQiZmBtNBoWuwF/FAgEtL29rVevXhkfUCqV9O6776qnp0eFQsGuN3lmuKW9Xq/Oz88Vj8ft97LOgetDZ48AAB4ApRRqpMnJSTPz4msC2uPzZ2ICWu3u7lYul9PW1pbxYCz543PZ2NicEL8/AAAgAElEQVTQzMyMzs/PDdbhdeG8B2blcyVEEjUWBw0KL+e2SeT3TnMfk9nV1ZUdznjEKC50wyT+AvegYJNkjRCGZw58mhXgL9YiAJUSwcP3Oyc1OnTCMHntwEXA5Ezd3GvE5SB2gKeimPNswEWgnurq6lKxWFQ8HrcCJMkSxfv6+uysAarCd8JnfnJyosPDQ4PCmdCZVHiN8BgkNOAp4kyjyPIZTExM3MkowxuE0dMpIkBFSeMB/EqBA3anWHCOSLJ7gXsHQQ4QmyRrOnm/mKGdQhOmPKeHB1k2ier/JKTP3//+998fHBy00M1YLGYHCLwGB9vJyYlGRkYsxr9arerg4EADAwNKp9PW9ZIFtb+/bzlOmJ/Y28CDdn5+boQmnTYKDSLBOzqamwkxNQ0NDdka45OTExWLRQsTJHlgaGjIumFSAYAUnPExV1dXGh8fVyQSsQeBUT2fzysSiZgbWZKF6gERsQfESYJ7PB5NT0+blJcOmm64WCwakc9iJohpqXnYxONxm2xaWlq0ublpHouuri7l83nV63UtLS0ZRMF+HXwZFDkUQChhmDY5FDAxulwuPXr0SNVq1XwrqMP4vc6mgoVxXH+KIg8AmVSXl80V4hRWrqXUhGxfvnypwcHBO1lUzk4QrJrJiC4/GAyamxzoFLycCZiDGwiDwEY6Qw47OC8+k1qtpnA4bDJoj6e5I6Zer9tKYaT8QGOdnZ3a29u7cw/z+8D2mbwbjYbJmFGaAUv5/X7j8kAdOByZpniumGSlz8Q+TK6BQMASDvidfC/kOqpOpglnqCWHOtcFUyUyasJ3mXACgYBBRK9fv1YwGLTJxwkxISVHKUYRdMq0Kd7cD0wezhw2phMmeoo+fBVQLM1Wd3e3RT7RYNCscn7wRQO5u7trxlPuF5oJj8dj3iT4MF4fPBDP9PLysh48eGAFB16N6RHuiELn8/ksZYXGDcUvTQnowae7vr78xeY73/nO+1/5ylfuQFE3Nzfa2NhQoVCwmxc5aiwW083NjT7++GMVi0VLP+ZDSKVSamlp0bNnzzQ5OWkPBF221IQTIITZXOk8rF6+fKloNGoj/+HhoT7++GPzdZC2fHp6qomJCWUyGQ0ODhqpDdGK5BK8W2oq0YifIO/N7XYbrCPJolyOjo60tram169fG4QxOztreUxALCMjI6bY4WbHbU3o5fHxsXVv19fXJukm/h6lD2GoTo09D/7FxYXm5uYsVHN7e1tzc3M6PDzU5uamwZ1MF5lMRn19fdZJtra2mu+Jgw8xAzJYoEgEEOSbITN2eiLq9bpJYYvFoq1WIGhxZGREL168UKPRUDQaNeiVSQiT39DQkPb29hQIBJRKpZTP59XX16eRkRELeG1razO4MhAIKJfLaWJiQh999JHtceG9QrYnEglls1lJMi6QPSAUGaAPYEgI6fb2diuyGHgxDtLRn52daWBgwKAsCgJKIVRUHR0d1pVKsvgSnoXr62ubGnkOUdDR9MFt8j5o1Dik8HsgPHBOY0DKwN9+v99SCeCzJJl5Gx8Hogs6+YGBAXk8zQh+BB7AisiYkQnTbDA1MHEQTVWvNzd/8ufwpEyMzjUBkOOIYeA96vW6rbfA1EqKBgWQ54eJrrW11YQCPT09CgaD2t3dvePzYhKikeBzkXQnvQC+G85WkjUloDZwYgR8Xl9fKxgM6uLiwjaw8rqYcmgueI4JFOa+rdVq9pzj23r58uWXv9h897vfff/BgwdGmPt8PvX19dmmRq/Xq66uLqVSKcOPifS4d++eYb3AHJjcYrGYFalwOKyBgQE7NKSmxn1sbMxCMVldQIdxfX2tdDptqhgmA7K8JiYmzH1LYmxHR4c2Nzd1eXlparBEIqGJiQn5fL47Ud90uh6PR/fv3zeJKWnPJF7H43FbXgTWSsIrB3d3d7fS6bSFDvL6UZPU63VLVmAsTyQSSiQSFuNTLBblcrk0NDRkgahAcNyk29vbtna5paXFDn8wbW5klH34FJDZ7u3t6eXLl7q+vrYYFCA8cGK2i/LQgN/zALPzhfQGoDGnpJbpgGgRrj2J0mS4HRwc2EGBcZD/3t3dfaebB85B9XN0dGQHW6PRUDKZNIiuXq8bXMpyM0yTQ0NDpsjC7+Fc7iZ9FirJZ0eqAPAfHANFh0QA+BKgmd7eXg0NDVleGV0vRayjo8PuB2AvstIoVqibKAgIPjBPcxizEhm4lnubLpupRJLtHkKUQBFxJg4wJUBcu91ui1ZCMcX9Ay9EmgCQD0UN+wMTGUWOzxj+BbEBSQw0I0DeSMSZCEhQ4LOhEOFfgcvkegKlsaUUbovFdaAal5eXd6gB7gVgR2eBbzSau2lYJ4DYob+/35IqSAzgrMBUy+TjvN+A2yjwFHkKDfeX2+021OTq6uoLi82XQo3mcrnMwX96eqpcLqdMJqPFxUVT46BI4oMGBpKa3d3BwYFSqZS5/F0ulymheLDhIRg/8/m8dfMYq8B+nbHedH0o2NgzwRgKpk2eUr1et5XSLEGDXHO73XbzAiNdXFzo6dOnBtFhBJ2YmFAymTT4pqenxzwrkpROp+V2u01j39/fb90P+DXYcywWM1z96OhIgUDAumSgxuHhYcViMTND0nnBL3R1dSkSiWhzc1O7u7tyu90aGRnR+Pi4PB6P7Z5fXFy0UNOZmRnr+jlsnV0hGDyHCbLira0tLS4uant7W5ubm6pUKravhky1Z8+eWeoC75/PgEVwW1tbkj4LJyR1AQ4oHo9rcHBQDx480MzMjHEGQK0ILcjaYxVEW1ubcUtMMtwPiURCZ2dnisVidsgRGUI8DwckZk+KJYGZzriQarVqXAiY/enpqRqNhhkrOZjoUIlPwYjLRMV/Q76LhJdnCwL49vbWCgMkOa+Xw40O3amScppo+YxRcGEAJCQVLsnr9dr7oWCi2pJkYgZQCQ5tCHEmLyYVpqlgMGjTvrNo4zXi72NeZXJEcATs19fXZ7Ev5XLZzJwICeB5QSUODg5MSejxeKxR472Q6M46j3K5rM3NTYMMq9WqBgYGLG0cDyJenqurKx0eHhq1gJ+K7aD9/f1mV+D9opajyBJtw7lE8eA1o4ajEUENyATJ9cPXxrnzeV9fisnmBz/4wfu///u/b0ThwMCALRlKJpMWXUKWEiQwq2HByDElkSeWTCaNyGRrpyTrfojI3tzcNAgC097bb79tJCfTTK1WUyqVUldXl87OzpTP53V0dKRaraahoSHFYjGFQiEjUXkfdIuQjIgGbm5u9OLFC52fn+vm5sYOBW7OtbU1hcNhk6JeXV0pn8/bDUWyAhsCeagQB3D4wX/QpaLdp1uLRqN6/fq1vcaVlRUzJEKCHx0dmc+CfUHZbFb1el35fF67u7tmKIxGo3rx4oVGR0e1trZmQaQ7OzuqVCoKBAI2sWSzWQ0MDNghQz4VkA5c1dnZme7fv2/+CnisQqFgCioeJqTtcGwcrGdnZ5qenjbPCIkE5EpJsvUDwBt4d+r1ut566y0z+Z2enmppackgrGg0Kkl2H83NzZnghFXbzsn49vbWfDzwdzzEGBYRw9Bhdnd3G5eHmZHVAYhH+Dt0vSQyF4tFK3ikRcdiMZMck3l1cnKi/v5+y94jJigcDpvBt1arGQQJaU/QKv4Sdr+0trYqnU5brA6HuCSbKPb29uw1cw+wOoSYHHw3OPwxOYIUSM00bKKASLzARwas3NbWZikAKAqJwYLvIDwWJSneOHg7TMB7e3vG9V5dXVmyB00ekxtmdSA7XiPTL/L3er1uSyG5lvBqTliSSbFer9/h9GgA4Pvgx1BxAt3z86rVqkGPfX19JhrCjE6TTrMbjUat2e7o6LB8N7IRf/azn/3TmGxQjXV1dSmXy1miMw7wgYEBzczM2KZFxuzt7W3t7u5qc3PTMtJGRkZMSlwsFo38oxvZ3d3Vy5cvTUkCbs5N2traqtXVVcsbQkaZzWYtggYYLBqNWqwEoydcDnr9dDptRYsHOpfLWZQ+3hG8FUAdvM/d3V2bhq6urjQ2NmYCCQoP3pTx8XHNzs6qUChYYjWvBbUQD1IkElF7e7tyuZy2t7ftwB4fH1c8HlcwGLSRf2BgQC9fvrSH4/j4WDs7O6ZootgBCQ0NDZm7uFarKZFIKB6Pm38JcQNrpA8ODmxtNw1ENBq1hyAUCqlYLGp8fNyCI+l2ScZlhTNcH2sP4Ova29vts2BilmQTW6lUstDQ7u5uBYNBmwaQwl9cXCiXy5nhtru7WxMTE/Z+x8bG7GGlcK6urtqkwZZSuAU69L6+PoM/mbxQovG5s6cGWb0kU1Gdnp7a4QdkV61Wlc/nDc/Hi8H0DOfH50TTA2+BuICpk4mH4sY04OQOgGHI+3KuUgdi5DCF98GADfzNZNPS0mJcJBwfHhQ8c5IM2unt7b3ji0N1B6KAz0WSyX/hdZzFYX9/36ZnICgmwnq9btMnzzQFUJKZzsljo1iySps0B4prJBKxIoXoA+sHogq4F8Jv4ZGA9ID4WT8N1cBrxADa19dnQguUdVxvPFrE1MATcn9gHEbRy+I40IpMJvOF5/yXYrL59re//f7Dhw9N6ourm4dscnJSS0tLOj4+1vPnz617QC4NRu4kG0ulkrnz+/r69OzZM11eXqpYLOrHP/6xjd1/8zd/Yxj/xsaG+vv79cYbb9jDGo/Hlc1mTUUkyeSA2WxW1WpV+/v7CgQCthuDwjY4OKjj42NNTExYNAVQxMuXLyVJU1NTtnmULYD9/f0aGBjQ3t6eKbAGBga0urpqmVXhcFiFQsHIWGThV1dXisVihk3T8ZZKJeuQOzs77/Ay/f39Ojk50czMjEFIxN4cHBwol8spnU5ra2tLGxsbFhd0cXFhQaZ0s7zWtbU1gwESiYSWl5fldjdj54ElKpWK8vm8WltbTVVEd5VKpQwS+/nPf65vfOMb6u/v19bWlimtgKxyuZypAp2ObDaY8tAdHh5qdnbWihMCBeBUMvZIFWdyPT4+tuy9qakpHR4e2mf5wQcfaG5uzmL2Z2dnlc/nVS6X73TPe3t7tsrY7XabIoxmB5MwLnImCwhmumUOAF53Mpm0GJiLiwtbP8AeH2TKbrdbOzs7RlonEgmDxCC2mdKY1mksnCpAj8dzJwSXOH2eC+TcCGKcMTBwaEzppEnf3t6aiRBZM1FCSKLxhmEiJuwUSbfX67XwTNRpQIc45/HtIAf3+/26vb1VsVjUxcWF9vf3bcJh+kFUw4QMVEjgJUpH1Fx8NkwPnZ2d2tzc1MXFhYaGhsxoynTDNUJdBn9DI0KqN88LEwrvDRiRDa2oVCH5mYCur6/vFFX4XH6/syhRLFFQcp9xnwJBc49gU/knIX3+9re//f7v/u7van19XRsbG3eiuHGpLi8v21hJx/jkyRNzrjOdcPCgWILkzOVyGhgY0AcffKDr62sNDg7q6dOn8ng8ikQi5q5GUjk6OqqnT59aJ8TILjV176urq4pGo1pfX9f9+/eN48jlchaDwQ6Rn//853K73VpZWdHQ0JDdnLFYTJeXl3r9+rUODg7U39+vsbExU305U2RXV1c1PT1tic5sNwyFQhodHVU8Htfh4aHBIkhPLy4ulM/nNT09bXAQnR9cFftfmCZ9Pp8mJiZUrVaVyWQsZyyRSFj3BTkaDAbV29tryiYSuYHAKG5sQiWOBBPp7e2tSqWSBgcHFQgEbDcON3sul7MFeXRnmUzGxAFPnjwxSHR0dNRI3XK5bNe6t7dXLpfL/BZ8ngMDAyqXy7Z0jgmQgihJqVTK8vo6Ozv105/+VB6Px+4Vr9dr2XJ4UiDTPR6PCoWC8TLAR3BAHOTcowRxchCjBgImZLJxiguAGKXP4vThLVC9AbexuqG3t9f8GUyiCAUozIg2EEggRcabBC+DH+jq6sqMoEBLNA5AajQDqNng6mq1mkG9Q0ND9szX63Xja4Cnef6Aspg6KWLOOH7ucWTJXDOmB5qbTCZjMmX+Lh4ZjNHOvDCmG8QMiF14LdxzLABk/wyNWKlUMhgXlRsLIJmIJNm6ZyBIDKJMXCSMcFYyLdGcXF5emt0ASTXnGbJo4njIQCPDjbXdoCAICXi2aeouLy9VKBTU3t6uhYWFfxrFhkMrFovp4uJCkUhEr1690vDwsOLxuKLRqP23e/fu2bgIlJRKpSTJXMVHR0d6/PixcTwYH8FswU4Z5xmN5+fnTYEBKUp0SiwW0+npqdbX1xWPx41j6u3tVSqVUjgcNuEA8AUpAOVyWVNTU9rb21NHR4cePnxonT7xH8BWPGBwEMFgUFLzIRsZGdHV1ZWmp6dNRcYU193drdnZWXV0dGhvb8+i/dnxDoF/enpqyqFyuWwPdyQSMfyW/DVSmsPhsCYmJkx9xs0aj8ftoMzlcnd0/XT2BJGiouFAAKbyer1aWFjQ5eWlxsbGLJGb2BWmXiAiSFcKGng3m1tdLpcdDHhECFgkNJNkaEm2pwgZuFONk8lkLBqEA5UC4HK5LAH57OxMlUrFpN4clqyahj9wqr+YyiHQiUoi+ZsJgCYLrwy4O7JYDtFMJmOeCQ55pjxJdrCzKFDSne2nwNjcIxw0/Hw2iiKHZlJA3XR0dKRIJGLfMzo6egei6erqMpMsjQbKM8Q+oBUEguJb4nknzgU4mM4ewQvFDukuz/Ivq+KYEOAhKP5AUAgcJN257sisIdgpiKAx/D3gSIo2SkyaCK4RUCBIDvE68IxORRtrVHD5EyNErFC9XrfUZyTop6enpkREQUpjzOd7dXVlrw2FI40Lak6Ue7zuzs5OFYtFm0IvLy/16tWrL/+KAcLqstmsbe97+fKlYd/IezF94fLu7+839/bp6anhiMRB/OVf/qUFVQ4PD5sJ7v79+3bR6Vr39vYsB4plaIODg4ZJkwrt9/st0r6rq0vxeFxLS0u6vLxUPB63mHvIxUgkYi7yQCCgpaUl5fN5lUolzc7O2sNzcnJigYDpdNrWSDtTEk5OTrSxsWFSYiYSYDtG276+PiWTSb148cKKH7JgUo3RzYfDYYN4VlZW5Pf79fLlS7uZyRvb3t6WJI2MjJhqhYOWKYRDjM8TqejExIROT08NDmGnO1tK8VZIsiLAZMZ9cXx8bNAFfgEKtdRU5qVSKYuFIZEAqIKiSAgr0Eh/f7/a29u1u7urWq2mo6Mjc7C3tjZXQADF4N/p6elRIpEwSKpWq9kOo2QyqZWVFft+1G1OGIyiy0HqNDbS7btcLttq6oylQc3EOoh8Pm9cH1wLhQOPF4cw6qPb21srtHTtCBQajYap3YgG4rpTAOioWXkMUYzPDQ5obW1N0WjUcsyWl5f127/92zbl+Xw+W89Qq9Vs0yvCBqAdZ44Zsm8OQ8QE+M3g8DhMfT6fKSnxhNTrdb18+VKNRkP5fN6m3dvbWwuWJWEZE6XTOc9qZ+5b1qLc3NzciQW6vLw0cQBNKZMz3qPt7W1dX1+bmIVDHYQFLkySTclO5z6fjySzd/D5YRegSQL9QQ0JAnRzc6NYLGbTz+npqWKxmE2/SJslGZQIvInwCP7z876+FJPNn/zJn7xPReYAoyPiIeLG8Xg8dlMGAgHD2wlzDAQC6u3tNXKcPRk8RCTpsvGxvb3dTKDDw8NGAiPrA5fe3t5WuVy2ao86CGPayMiIua7D4bDhmBjPXC6XxdmzEKqjo0P5fF5ut1vz8/PK5/M6OzvT2dmZRkZG5HK5FAgEtLu7aw8eRCkEORj92dmZbSj0+/12k7F8bW1tzTBjDr2+vj4z/BExA6RAmKYzKQCY5fr6Wru7uyYBBcLgxuWAxYiYSCRMHUOkC3JduvhwOKz79+9bx073y3I2r9ereDxuij2nXJbFcRy00mf70qvVqiKRiJHWTF4c3tls1iDJYrGosbExg1J4HXSShFHCryA2YSsrjYYk47EQa9BQ8HPAzZ2cDQogpk6IeAhhXg/SXYx/Nzc3xm8RiYS4BO8QyQfAH8jsgYWA6ZBBc3+xrpptriwwgy9h1xETK528M7dMkjU2GB7ptCkiKJwQj/BaKdrcD5hmEe2Qt1epVFQqlWyqhFRnKRyNDruUiI0B4oRsd7vdOjw8tGeMwoiBFY8VawiQqDsd/uQ1AlPhD0Now3sj9gp1LM2TU+TB+4brZZpFps7kSWGqVquG2nAd2ODLveLku3nvTD1cI5a4UTS5P/i5zvsPKHBtbe3LD6P98R//8fuQtR0dHTauS01zWzQa1crKinK5nMmU0eHHYjFNTU0pHo9rfHxcbrdba2trCgQCOj8/N8Oly9VcRTA+Pm4pBH19feb58Hq9FgOPbySRSMjn8ymfz1vuFnlnZJdxQG1sbBg0sLa2pgcPHujp06caHh62jmp7e1vj4+Pa39/X1NSUxebv7e3p9evX1sX19PTo5cuXcrlcSqfTdpCurq4qnU7r5uZG7733nhH4ONC58ZiKUDYh5UQNJ322d/3evXtyuVx2jVBqwWU9e/ZMg4ODeuONN7S8vGzGPA4mYC1gAw7Oer2u2dlZhcNhO5iOjo7MD4DZDuPh+fm5nj9/rtvbW9sQWKvVlE6ntbCwYD4SUqc5nFpaWhSLxVQoFFSpVDQxMSHps82YfLZ4bog8YhcJDYvf79fo6KhaW1s1MjKizKc7aEgW5/ePj49buOfy8rJ14FdXVya62N/fv7P+m+RnZzYZEAwqQvgOUgM4VCTd2elDc3BwcGBFCL8WhwjTHp8pEwAH0tXVlR3CJGZfXV2ZNwR1mDPuhEBHrh9rNSgEFA2W+CGFR6bN5ApsWqvVTGFJfAw/AzFNKpXS6emppV7AKZJGAd/E88XaDTgq1FckqVNQjo+P7XpgqkWijiKShgSpOJwXMBmmVre7GQKLkfL4+Ng4WRrEm5sbO6yz2axBZZIMsoX7olDzWuF5aBwxEAORORWKbW1tNrH+MlyNRJy19QgqSJjwer1W3JlUgNP43TybTN6suUCs8/r16y+/9JlYj2QyqZGRkTvVt1araXFxUblcTicnJ/J6vQoEArZjY2NjQycnJ9Y5gkFTlfmA3njjDb3xxhuqVqsaGxszTwmS44uLC/3Wb/2WHWhg50dHR1YAEomEBgcHNTExcUeBAtaJ+iQSiehv//Zv9fDhQ4MnkPT+1V/9lRlP0eYTS+7xeJTNZg1iOz09VTqdNqHDzMyMHjx4YHt1lpeXlcvlLCV4bGxMo6Ojd6TQ5G0B8TUaDYsDwkMyPz+vX/u1X9PV1ZWGh4fV39+vZ8+eWdTH2tqatra2jNjt6+vTwMCAksmkPB6P4vG4RdHMzc1Zh9vf36/h4WF1d3cbPOXz+XTv3j1TCpKsfXt7q+HhYRWLRT179kyZTMbSmB8/fqyBgQFlMhn19PRocnLSOJp4PC5Jevfdd/X48WO9fv3alFJDQ0M2+RaLRZVKJTswOAj5jJnExsfHtb29rWq1qqGhIe3v76ulpUXb29tW/FBN+f1+WxbHoUdH+vz5c4NLUJ3hk5BkkAnFn1Xj/Ay4O0yXxK9cXV3Z7iZSApAUh8NhBYNB88UAz+XzeZMqo24CYkPBJskkxSRPU6zPzs7MRxOJROy9nJycKJFI2JSCWjOfz5t6Ct4BCIqJjsYGiJck6nA4rI6ODvX39yuXy5lZEgk8HNze3p5Jg/EnQWBTDJggCNAlezCRSKijo+POlE3ixfDwsMFUHNYUACZlZOc0xkCgcD283tvbW2u2+Lw8Ho8hEawu6Ozs1ODgoPm6kDOTeQiki1DCmWuHv6tSqZhvy3lvQEUACVerVUWjUSvQoBO83/Pzc+PguPdYnMf7BZJEeAA8/4Xn/Jdhsvn+97///sjIiJnZWNh0eXmp7e1ttbW16Z133lEoFNLIyIhqtZolCJC5JMmi8omsn5yclMfjUTgc1vr6+p3qPj09rQ8++ECSDK46Pj5WJpOxbnFzc1OlUskksNVqVd3d3SqXy1pbW5Pf71cwGDQNPV1pT0+PvvrVr1qXxofIQiwO0ouLC52dnekrX/mKkXAQ0NzcwHn1el1DQ0Pq7u62zYTr6+u236ejo0OLi4tG/BaLRVNaka3k9/vV2dmpgYEBg8HOzs5ULBa1tram2dlZtbY2E6dRhZVKJY2Pjxv8ls/nTYlTrzeDD7e2tiz+ggIHLLC7u2vmT65hKBRSW1ubNjY2TN7N+yYXiyYBsQhbFzE2BoNBm9hQiuEbSSQSd2TepNhWq1XNzMxIkqX7FgoFvfnmmwZnAPXt7Oxof3/frh/83ubmpnFTrKVgtTTcBNNXtVrV/fv3TQnFe8ITxIGNcg2TbkdHh60GhwdArg08KskecmT/fAYkGV9cXNxJFpBkkK6TqAZCgUeq1+vGb/p8PitaqO2YXJ2J2LxHIE6mFooL0nb8SU4IB3jQ2VljXi2XywZjIsvm78OJILCgoKL6QzSDd457AMUd15cUEQ5MvFmxWMwKIsWLYFGnOZUJiNw0pjS4SbwtkuzZRRxE8jJQJ9MdBQxjptOThfeHoFZEEK2trTYxsWGY6w/6AIoAr0cwLoUSjpxkE9R2RC45hSo0UoFAQF1dXfrkk0/+6wQCLpdrSNJ/lBSRdCvpzxqNxr9zuVwDkv5cUlJSRtJ/12g0jlxN6cu/k/Tbki4k/YtGo/Hs834HAXAul0vZbNZIbZKMg8GgWltbtb6+bkR/NBq1g5UsIq/Xq3Q6baZCViqvrKwomUwal5LL5XRwcKCvf/3rhkOur68rlUrZSPz8+XM9fPhQPT09WlhY0OzsrGWPpVIpffOb37QcsnQ6rcvLS9v4ybpgqbn9DgMn3dWbb75p3c319bUWFhYkNUfqzc1NJRIJvXr1yiTUe3t7crlcGh4etqK0s7OjSCRiEBt4/ebmpgWIkonV2tqqsbEx26x3fX2t3t5evXjxQvfv3ze10srKim3SZMHVxcWFpUin02mNjo6aF4AHBR4B7JwYnJ/85Cf2ID148EC1Ws3WBvB9qauNOCYAACAASURBVFTKjKW8drYpSs3QUql5SBKbIskW1DFZAtM8evRI5XJZb7/9tj7++GMLoEQwsLW1ZZDTkydPbJIeGhqyDKijoyPdu3dPt7e3SiaTev78uSmM6Pg6OjpULBbl9XpN5Yd4ZGhoSPfu3bMdL0iM6UqBZPA4VSoVg35QfXEN6SLJjmO1ApNBPp+3gFYmBxoVt9utZDKpg4MDy5kj2QIRBxPD1dXVHe6CiQ2yHSh5eHjY5Lj7+/vWyJBZRhdNI3Nzc2MGQ6lJwpOxhQCBQ9BJ+geDQUv95lDnXuZzd7vd5jWRmhAdZmHSyQuFgvr7+/X8+XO53W47P5yrKlDDAYFS3OH9nJ4jkq45oA8ODoxjCQaDBkOTFIHS1OVyWfoH3AwFFx6NaQZJNcGmFFk4GgQarEsJBAL2LAJzkc7gLHQo78iaZAmi3+9XNpu1XU34wCieNzc39sw6o6zwKf2qk82vokarSfqfG43GM5fL5ZX01OVy/bWkfyHpbxuNxndcLte/lvSvJf0rSb8lafzT/31F0v/66T//8V9QqxnEgkSV7k9qjuWQxCgsSqWSGUApRoFAQLFYTNvb20aCso0RSAJJKOQeODoPYyQS0dbWltra2rS8vKyxsTFTxz148MA+CIjo1dVVI9VQthBqiTmMbhJ3M0q3fD6vYrFoiqfl5WWDpubn57W+vm5qkNvbW+3v7+vw8FBDQ0PyeDxKpVLWVaJsqdebq6PhhrgZMGISmDk+Pm4qrGQyqVgsprW1Nd3eNvcA1Wo1ra6uGl6MwOLHP/6xhYqyI4jumdgKJkSWckFAAxceHR0pm81qYmLCxArFYtGkzKi+pGYCNIIP/j5F3gkp0FlfXl5qeHhYv/jFL2z7Jv8kW66trU3Pnj2zeHSmktHRUXk8HkWjURWLRROs4JDu6upSW1ubiUhQ9vX29hqP1N7ersXFRc3OzhpfxPRLWi9JC0wiNzc3tmmztbXVIlI4PPB88PD39vbe2bBJEC3+DxItKBJ08XhO6GKlzw5wOIVEImGyf6Zc/GKSjDxnd9LJyYlBLG1tberr6zPxjsfjMaOl1+vVxcWFHVwURdRriFuYMujGnf4vSG4OZFZCSDKzIhMlsBqGWoj5/f19S2hwqvSI+eFzQaXoXCZGkriT2zw7O1NbW5stGJNkkm3ELiABTG6cPzQHQPdAVhcXF/b6K5WKNVgkexMnxJRMs05RxCNHWv3t7a3ZA7q7u+/AfdVqVYeHh4YSoEh0ZvWhYoT3glMbGBiwiYf74/O+vpCzaTQaBSaTRqNxJmlFUlzSP5f0Hz79tv8g6b/59P//c0n/sdH8+oWkPpfLFf2838GNR4dBVhbwEPgz2nZwSXaf12o1xWIx+/Bvbm4UjUbvyIOZXriRCBGUdCfUkzSASCSisbExnZycqFAo3HFvE83S399vsk3wXdRmhIAyqhOvQ8giktFQKKSlpSVLKYDok2RdORMKgZ9AhXg7eEgQM2QyGVPMUAgPDw+1v7+vYrGofD5vODSQBA8hmycPDg60s7NjBzvXbWRkxJafQfizb+b4+NiMYPV6XY8ePVKxWJQkE19ITak7pjYgiGAwqLffftv21wMxxGIxtbe3W+o1ozyHNlMtMUX7+/taW1uzgwl4k+RdPovr62s9evTIojckmaN9ZWXFotbJExsfHzeIT2p20UNDQ7Y+guQBCgzqSQqSk6hHqYgaCgEF14MCWKvVbCsm0Sr4PbhGcGUcsEQAMa1IMlUTsC/TFp8dUCTGVCArumPy2q6urowTxVgNxETUDB0xDRY5erjq6eKB1GiAmFCB8TAVopCiMQTWcbr6Pz2bLD2EpgOOkknm7OzMlF2kJCA9RrI8MDBgZlhk8xQdl8ul1dVVO6Q9Ho/8fr+JT0htxziNSMnr9ZrZE3sGYgKEI6QnM906IT5+F4GvcHRut1vBYNBk31JTKHB0dGS+GWBKijbQPuZz+ETpMyiP6+hMJEAyznVE1OByuUzQ8EVfLuCKX+XL5XIlJf1E0qyk7Uaj0ef4b0eNRqPf5XL9v5K+02g0fvbpn/+tpH/VaDQ++aWf9S8l/UtJamtrm/+DP/gDdXR0WHbV8fGxAoGAJTpPT0/b5j02JY6NjRl+CtaLsz2VSlnWFZs+ERZUKhV7cIvFokKhkM7OzpRMJnVycnLnhsYQWalUNDk5aWnHkL+EE8JJAH1woC4sLNiiJBRWTp4Jko2uAmIWQ6kkvfnmm/roo4/U29tr8uNoNGqpAyimfvjDH0qSqYlyuZzGxsasSN27d0+S7HC7urrSJ598YrARHRPSaWCN4+Njg7+AOCEIJdl7YQ0E2vuLiwstLi4qGAxadI3b7bYxnPdXqVS0tbVlU+fJyYlF2KTTaQUCAV1cXGhpaUnf+ta3zAd0//59raysGEGN14qA1Xq9GRL6zW9+U62tzTXa8XhcZ2dnOjw81PDwsKmKKEgrKyuKRCJKpVLGCVQqFZMAZzIZBYNBjY+Pq1Kp6ODgQPv7+7bgam9vT7OzszbBJZNJbWxs2GR2cnKi7e1tDQ8Pm/GT68J675ubGwuNBMbie+nEUQjB2dRqNZs6kLIDAyFcQcLLfyPfz7kcLhKJWBfOgdZoNExmTsdL3BMxQBw8wGPcz0yeyM4xWpL6wMQzOTlpqwzI6Eun0+atwcuEsAaCnPcGeT82NmZiCmfTgrBAkr0+1ks4TdjxeNyk0pJsKyZhntgPaAqASPGu4KcD1iTYlPX05MHxzEciEUtUpnFE2elUhpGnxudLAYMHJaHDyb3x5fP5bH0IjRD3gtSE79nwybWkkQGevr6+tuaSZ5eJj2bhT//0T582Go23/rH68SubOl0uV4+kv5T0PzUajdPPqWT/uf/wDypao9H4M0l/Jknt7e2N169fW5EJBoNmcMtkMtZ1gHPHYjHrUnAxf/3rX1cul9OzZ8/U3t5u8fxEUIRCIeNc3G63+WY6OjoM92xpabGV0oQBUvza29u1sbFh0w4dFWqWw8NDzc/Pq1wua2dnR8FgUAcHBxocHNTV1ZV5BDD1nZ+fK5VKWReGVwE+xufzaWxszHbjEK8xNjamra0t7e7uKhaLKZVKaX9/XycnJ4rFYvJ6vTo7O9PW1pbtyCDZmJsQyXUymdTg4KDFYGxubioUCtniOKeK5vb2VrlczviAjY0NTU9P6/z8XJ988olGR0cNAvF6vRahTmDo2tqa3Zx0VchKPR6PhoaGTAwClNjR0WETai6X08zMjMmRPR6Ptra21N7ebp1Xe3u7eXHwyQwNDVkYJBPp6empHj58qJcvX9rKYg6yeDyuZDJpKdTb29va2dkxqO+dd95RV1eXFhYWrOvv6+u7040ypfLAp1IpbW5uWvry0dGRotGovUaUjRz88Bz8fTpsiipTA0IFYoBweHN4kFLAASTJjKJwNzs7OyoWixYoSUcPV8QCM7D/np4eK+ZAKngyiDpi+nc2gDxPvFemN6JzmKLgaBCaoNQio4yGzKk6I2wWsy8JHE4vHAIQoExUhgcHBwZVYxyXZFwNohegvZubzxarMeFwFvL/T09PrYB4vV7j9iQZJEYoLYpWzhGKJNeXz4kpmJ8Dwe+0dtA8gLRMTk5qZ2fH/q4ki6Thd1IA2T3F2QBKg00BDx1CKhp8mmXe1+d9/UrFxuVyedQsNP97o9H4vz/94z2XyxVtNBqFT2Gy0qd/viNpyPHXByXlP+/nt7W1qVAoSJLp2CGJv/rVr+r8/Nw22TGeQp4BKWxtbeni4kKpVMp2kfT09Gh0dNQwZ7oN9O7z8/OmAGIL3Ve+8hWtrq4qHA5rZWXFVD4rKytKJBJ2OJbLZUUiEav4TFBPnz5VPB43LP7y8tLSCZhuqtWq7t27p5ubGy0sLCgYDCqRSGhzc1P5fN7yuCqVinXQxWJR3d3dWllZMa8LwoNQKCRJevz4sRYXF410xnRIRhiZW6iVWKnMw72wsKDT01P5/X7du3dP6+vr6u3ttQPh4cOHKhQKOjk50dtvv62hoSE9ffpUv/d7v6eFhQW1tLRoa2tLjx8/Nny50WjYigEmGKk5Xb1+/dpUSuvr65qenla5XDbV1qtXr5RKpXR7e2uL34A82RGDUmp1ddUKDkUFnJlpYnZ21nipdDqt3t5eZTKZOzBJqVQyEtftdlthe/DggX784x+rVCppbm5Obrdbu7u7d4y+Nzc3mpyctKJC4T49PZXX67X8uGg0qkKhYNFDo6OjthOEDLFYLGYwGJ2u1ORMurq6zHCMUg4sHl6E52l4eFiS7FkBsmRiQ3VE4Xe73QYVSjI+jLgXXgMqNRYNEh6LsxzFFWIH4G0gKklWWHgGneQ4pPP19bXtsmpra9PExIT29vYsPJPXRaeP8ARj4vb2tkFXHJgoQ1knzk4kpltJlnDAtNrT06NisWjydwo9ECKTSEfHZ8vOEF2ghEPmjtpPkvHFwGSYePGgATPD39TrdVt4yPp5SZbzR0HEFhIOhw3ipzhyZtJABgIBUzQSaEsGG/ekc88QuYEUOrxWX/T1q6jRXJL+vaSVRqPxbx3/6T9J+u8lfefTf/4/jj//H10u1/+lpjDgpNFoFL7o9wSDQRUKBeuI4Ano9OkoMHqx1AxOolarGURGofnN3/xNW+n705/+1HaouFwuOzgJJiwWi+bVIYmYIjM9Pa1YLKZwOKze3l75fD7NzMzoRz/6kbmdcUVzyL948cIOBiJzPB6PTSiZTEaBQEBjY2NKp9PGuUAeQ7pyc9Ih1mo18xuxdZLUXDqqkZER6/54bdls1grx/v6+JWBLTSjvzTfftEic2dlZS1bI5/OWfp3L5ayDRCEzOTlpN3c8HlehUNBf//VfW84b1ycUCun09FRjY2N6/vy5vF6v/H6/otGorZRA1owp9cGDBxbfzoZR1oTPzc1JkgYHBy0ckgRtrofL5dL+/r75otbW1hQMBu2QxVyJFB2jKDycM3Xg6dOnFqW0s7NjBw7NEVBPS0tz2yUNQDweV39/v1ZXV60rRb4Lf0C3SXoEHTaTPtJgSHhgMKb2X87K4jkgnDEajVpGn/SZevP/a+/NYxvN0zu/70vdt0RSIiWSuo9SXV19VF8zO3D3ZIzxwHD+2QFsBNkFsogDJEHWQYBgvQsYnTE8PYYx3nWAJPAuHGwCONkgcIIYHl9z2B5P9/RRd5VKt0RSIilSokTdpETqzR/U5+lX7ZnqMTw9XTPNH9DoOlQS+fJ9f7/n+V4P/BcS4dbWVlMr8kxy+HOwsCEhzwUuZSIpZmsOBzoeMrzokICGSNVA2kunx0ZGcYFfhw2QzwlvDSQ2mzoCg6amJtsMvUIKSHWv0o8QUzhVKnepesDSuZRKJYvI8RYCkiwDD7XWhxVc+F6A0TB/4ovxSvC5FzgMJZnKjlgjfEggJMCOkozrxkQryZKjuaaYP3ntdMyo2yTZgcvex328vb1tnSoDHZ+0fhRT52ck/aeSXncc5975f19S9ZD5guM4i5K+cP57SfpTSSuSliT9O0n/5Uf9AKSRTGG8cuWKdnZ2TKr7+uuvKxaLWSvY1tamsbExTU9Pm2N4Y2NDDx8+1Pr6uj3o3//+95XJZPTOO++oqalJn//859XS0mJDo2gbGaEKoQ6+3d3drf7+fjU0NGhsbMwMWoeHh1paWrIsLZQlBEmi+unv77dDkQ/c602gkurq6jKZM5p1FEpUnMPng+CAp1DegdtHo1Ftb2/rpZdeUqVSMckwsSkIHPb39xUKhdTS0qLp6WmrdNngdnZ2tLCwoIWFBduECd0jZZvRAJubm1pbW9PS0pIp2q5fvy7pg+QHSeZ2Bs4pl8vmqZmdnbUqcXZ21h70VCqldDptJOv6+rpSqZSGhob0mc98xnLjpCo0cO3aNZXLZYtVGRsbMz8CYgk+1+eff96gqbOzMw0ODlqFjjoKHwxwFEGXkORAugQoEltfKlWH70WjUfMJIZel8h0cHFQoFLogfSVIkY0dfiASiVhulddtDoaPGZSD8urVq2bWpWDzTsGka6CLgXeRpPHxcUvIJk6FxAGgXHwWHKhsrD6fz8QKjMnAiIjggCoeQp4xCsSsYIRkc4YnIQ0DgpvljaaBi+D3XV1dBjEikGhra7PEDfhEoELXdc0AS7FTqVRM9t/S0qLu7m7rAhAiIJzgMEAByjXd3t62qZpYG1KplEnFOTgJxOQQ5pqgimOjR1rOwYWKjNfBc+7leOCzIP6BJNmzgD/pknO5nMGNkgzupTva2toyPhye13vg/rD19xIIfFwrEAi4DB3CSQzsAlyCdj2bzermzZvWlpP+uri4aC57HtpMJmPt9dDQkI1pLhQKJjSg0qfyuHnzpvL5vJkpqQ5Rn4Ezh0Ihvfvuu4Z5An9MT0/bIdbT06P33ntPN27csOq9WCxqdHTURhTQQc3Pz9sNEgqFND09ratXr2pmZkZbW1u6fv26Hjx4YA/s9PS0MpnMhWwkos6ZuhkMBhU/TwImZ66zs1MjIyPa3d1VLBZTIpFQOBy2uTX4QwqFgqkBi8WiKpXqqOvbt28bl+D3+xWNRm1+CpUeSieGndG+E/rI3KC1tTVLVggGg0aq08V1dnZqcHBQuVzOpo8yrAxzKVyE10dCcnFDQ4Pm5+eNw6irq7NJiA8fPrSAVsI9EVzs7+9bnpokTU5OanNzU/fu3TPIa2lpSZ2dnZYSzqFEGCVEvhfmw+PAM0eHIskKErqA3t5e62jpfjY3Ny0dnNh3zJZs6JIMg8egFw6Htba2ZhwGnRu8CLAWxLz0gXcqHo8bbEsVi6Qdi4BXzEM3EAwGzfPmjdEHKuro6FB/f79xW3BqBFsCe0HAE9OCWpFDH0kvisRsNmsJCHReoA4c1hjGgajGxsas2y0UCjo9PbVhjogcMJyzYePVIqqFUEr+HM4I+fHp6al5lOhQfT6fmaXpcuBFbt68qe985zsW6ksBgHjGPc97xGgNv8NBxPc8Pj628FRvugCp4ru7u5Jk9wVTU7lmjuPYIcefcTBxj9OF/f7v//4TBQJPRYLAm2+++QYeh5OTEw0NDZm6KJVKWRvc2dmpBw8eWHYW7SOjiskhg5jE6UqUC23p9PS0TZckgiOTyViU//37961KBmJgmBcVAfg+ZCqHld/vV1tbmzY3Ny9knZF6gBCBA4yK9vLly1pdXdXVq1dN8UMcB/ASfgge/oaGBoPuBgYGzNwJ8evz+XT9+nX19fUZb4VyBRgpmUwqGAzq1q1blkmHYbG+vhpVTw4WA7EQbwAZbGxsqFgsmviCGH/eN5UkN2axWLTEYkZek7BL0CIwDE5/Mrkcx7EBW1TrXV1dWlpasvcHwb68vGzwYiwWM+lxe3u71tfXNTY2plQqpe7ubhsWx0GJ3JoqF4luR0eHCTi84a3ElSBJl6SpqSkzVyK7pwtBlSXJZLiOU03J5rNnU2OThENA7cghw6HGKAI+Nw5sKmY2X3B5eC1gx56engvRLHTWFBsQ8hg54T+oxLm+hMLynjhIqNKRF7e2thq3AoRGFwo8hnKKQgqJeGdnp6ke2WT57L2pBF7oi8MSmTabNl8LykEnw3XxSq29Yge6Ogh51GRwUPBAHLiSTAThpQlaWlqMT+W+WF5eNsUgRQeBsV6pOHAoaRnwsfB3dMR8Po2NjdaxHBwcmBgAxEbShbBfkBevaZgOqqWlxYzfzc3Neuutt57+IM4333zzjebmZo2NjSkWiykejysUCplDmoeJaAq8OCgwmIuSTqcVjUYNonIcR/F4XC0tLZqamrLJlu+++66i0aief/55JRIJ9ff3m/ggGo0afDY+Pm4hjwgSwPa7urq0vLys4eFhk0Py4bW0tGhra8sUPowBDofDmpyctJuDGzASiWh9fd0k0RDSyWRSCwsLBh/i10BrH4vFzN1+//59DQ8P65133tGNGzcMD08kEkqn07p//75isZipgIDjcBWD3+NJ6O/vtxwsNj/EFpubm+a89/l8Bh2g/lpdXbXKCTUL1SL5TTdv3tTx8bH8fr9lol26dMkOHwhPx3G0vr6uy5cvW64TplDUSQgQVlZWNDIyYp8/D8f4+Lh2dnbU2dmpZDJpMesYTanmh4eHbeNJp9P2ENJFEXdUX18N68RId3JSnVcEDDkyMmKjKgYHB5XNZi0ensowHo+rrq5Op6enptojIYEHuqOjQ52dnaa4oyMgARixCxsiZkk2fJ4VjIeoEf1+v21y3jRpvofP57P3SpcHL8Ohh5LL2zlgGuT1ASFTnNEBQmrHYjGDAoFY6WohxOl8MWgjFeeA4hAhxoeN8PDw0DZnr58pk8lYGgDKO4o/rkmlUrFQUooqNm84SGKF4NVQZOEBo4PioC8Wi2a+9gZgSrIMOoJBMShj7iUyq6mpycQNXl8V8CGBoRSA+LNQn2GroMjBi4OgiGeGQwl+hvdbKlXHW3N9ed0UHN/73vee/sPmK1/5yhuf+cxntLW1ZcO8INSZUEfWD5Xx2NiYxX6k02kbqAb5zUbb0tJiM2DwTrz++uuW6YPBkfReIAUOsXg8bhtMIpGQJCP6m5ubtbS0ZBsAzvdoNKrm5mbdunVLbW1tGhkZUVtbmxYXF5VIJMwpTNUxMjKihw8f6saNG1pdXVU4HDZBBFgx8sm9vT3dvXvXyDkqQP4Njv1AIKDNzU0tLy/b4clGB+ZKxD3V5NHRkVKplEEIQGYvvfSSjSjG4ErGFBsYCdocLMBD3Mizs7OGf1+/fl1zc3PWfr/zzjsGCyLHzGQyCgaD6u/vN+/J6empCoWCFRF0Yn19fXr8+LGZFpeXl+3+SaVSOjo6kuM4ymQyluRNAOjw8LDC4bBBqU1NTdrc3DTIEZlzKpVSW1ubVldX7X545plnlM1mtbS0pH/0j/6R7t69axDt66+/bp/Dt771LRMRgK3j5yAXDT7k7OzMDlxvNMnx8bEmJyftMIHUlqq8AGnD5M7BXXE/s0mxQaCgY1PH9yLJOB7c8qin6GD4DPb39y0bDlhnc3PTKnykzsCCR0dH5gkjssV7/0GUt7a2XuDDsCLw51TaFGGErVKNI9HmAAKuZO8gqkaSdcfk2uG7wvjJAdjQ0GDcGXApr4sukkOHg4jOQ/pAFILfhe6BopjPBfMnBx7mYJ4j4Hw2f5Rl8MTwaV1dXdre3jaVIpApP4Oihqw1uh/4H4zHSPpRN7LnkJINr1epVH46xkL/xm/8xhuf+9znlMvlVKlU7E3AXzQ2Nl4YC0tL7430QNqJr2R+fl7JZNIqR3B5LmIoFNLjx49tNsTs7Kzh/kA4p6enljgdPx/YhokJMs3n89lm1dnZaSOeUYPFYjGD3jo7O7W3t6dsNqtQKGSHSX9/v0EcYKRLS0s2+jYWi1mKM1XJSy+9ZAoedPCLi4tWGfEQMVMdySkho1tbW5qamlKhUDBfCYqxK1eu6Nvf/rb6+vo0MDCgQqFwwRRZqVQsiufx48fa3t7WtWvXlE6nzXyXSqUUCARsBDUybm7MQCCgw8NDpdNpw8zxPICn7+/va3t7Wz09PZYzxeHO+yUEc3p62jYNr7IM7qqurs4+WyBMNjdMtHQkGBq5ZlSo2WxW4+PjBrvCE4ZCIb399tsGb7a1temdd95RW1ubcWZAb8A3+CngBoEduYfJ7GKDlGRkN3AHBmb4CjgmxC/AX2zCxWLRCji6KsygQJUYEYFZSQ+gqIHY595H9MBmjlGa+9hLchOFhIpua2tLe3t7tjn29vaa+hERBBaCvr4++9yAkDkYCoWCZYchjECcQQIJZDmvyTugjIMdRIKwTGwOpDGcnJyYtNurVAOlwLANzMfBATy8tbVlhwLdHcUGhWRdXZ1dX/hS4D4+E0yyFASYvOlk8CDB4ZFKwDMB/wVaA1WA+pUOxzskDi+V1wi8vb1tB+7e3p4ePXr09B82X//619+g2mKDZEqkz1cd15pIJOym5cak+onFYjajAkIvn8+ru7vb1CXMweGBJJdsb29P+Xxen/vc57S3t6eJiQkbiHVwcKBIJKK9vT07EJBWS7LgSR5K9PJnZ2cWgd7c3KzZ2VnLSvP7/RoZGTGoBIMUlRbXoL+/3/iD3d1dE07k83kdHBzo7t27FjeTyWRMQFGpVMw7wAZBXhhd3OLiosVcjI+PK5PJaGJiQo8ePTJCkjBEeCz4BEha+I2zszPzPSWTSWvfOzo6rGBIp9P2c0guxthIpP3a2pr6+vqUyWQMQurq6rL3hPkS6XJzc7PFwbe3t9vwsvv3718QFoAtS7JrmMvlrBsdGBhQOp02HoMcvbq6Oq2srKilpcXmzECiQsCSfIuJcGtryzZd7gUMhaQuoKKjA8LAzH1Dfh+RS2zqZNRRbOD4ZrOlY6Igg+PKZrP2ayJ/8IfwntjUKATYQIBUUK5RDKEWYwP0wkAcaASb8n3w6mSzWesKKJLOzj6YYYQKC54KawMCFL4eZz9iBzZnum7CR3t6esyyEIvFjMRHfdbW1mZdFVAy1T4dEs8nsOPGxoYp+8rlskXPBAIB8/8Aq4+Pj9t1pGOkUOY/BEVtbW3q7OyU67rGeTH/R5IVzblcTl1dXQabogRD2u413JKL19LSYgP2CGKlq5U+GHkBj10ul+0+5J4GzTg7O7Nni33v5OREMzMzPx2HzQsvvGAGuqWlJesEuru7DQen7ff7/Xr06JE6OjrU2NioW7duGQZK5Ud7KclwT2IYjo6OtLq6avNvICdbWlpUKBTsBpVk0sSmpib19PQomUzKcRxFo1E9++yz5s8ZGBiwKpl4D0nG3WQyGRsdS+VFtQc2vrGxYQoVKrP9/X1LYZaqEMfs7KxF7ku6ACEmk0kNDg5ad0NnAPRDQgOp06enp4pEIoaBl8tlc+AHAgFznFcqFUWjUWUyGZuKir8Dktnn812QkCPnBKsmFwxpLO8PQp5DjhufgXZesQX3AF2tz+czcQWfL5lkXtycjpkHaXBw6PalxgAAIABJREFUUC0tLcaJID8FlwaaQSBQX1+voaEhZTIZ22RRviFgYeMC3quvrw73g5col8v2OS4tLcnn85k/gUoVMhlyvb293VJ9IaMJpAWGOzo6sk2UjRJZPp+LtwspFosKBoOmMqLbQ4wCmczhyGaD1BiJOOIc5P9scpDOfF6o7NjQvXFPdDnAgvA9kmwjK5VKF9AE4CdUaRwadIw8U7xOOuGzszPjYbwbMjmGkqwzoMOm8GDj9oZSSjLFGflmfO7cW9zP3N/wbhwMiJBALSgmPhzHg0ihXC4bcc9BgoiiqanJ0g0oDLimiBiALvk9/56OiWgo7iEKCWA2kgOAQikyWltbdfv27ad/eBo3JCd4Q0OD5ZGtra3ZB4HKg8h9qaprh29A7w0eKclc+/39/ers7NTdu3f19ttva2VlRQsLC0omk0ZQlkol9fb2amxsTJLsYGDIEm1sOp02JzrdCTcmlR0VeTweV3Nzs02QZCMhvwwDZXNzs3VutNPFYtFmgc/OzlpVEwgEtLKyogcPHhiXwTCkk5MTPXz4UPv7+5qfn7eDCu6irq46WZD34vf75ff77WbCbe2V0e7u7mpzc9OCBgOBgMEtiAJ2d3e1uLio5eVlUwIC/zHWgYcQ/4LP57OR0UTsYCYNh8MmDonFYtrf37+QaNDU1GSmtffff98gOFRP3A88yJKM+AbaLBQKSqVSF9RGTU1Nxs/AnwwMDFglSUgsfAlKQFRkKIiYiprL5ZRIJOx7nZycaGdnx+DURCJhEBt8F0Qz99bc3Jzh/67rGlwJWY/iCZUacCGFVzabvXAAYfpjo2cD9Pv9ikQipo4C7iSE8fT01EQXXvktlTphmxQLSG9LpZIGBgYsjdpxHPPPcJDA7bBpUwim02kzm/JMbmxsaHNzU8Vi0XLaBgYGTKjT2tpq3rHGxkbb2OkeSUJAQk4AKwUiRQEHV1dXl0ZHR817dHZWHfTX2tqqUChknjaKAzoCOnwSpnkPpVLJFKHIqYHa6TRQgQElQvRzaMEjlctli/OiwIa3QbJN4UIRy3XkvaJeg+PzKg3Jx6PjAp4FJgR6Q0L9pPVUdDa/+7u/+8Zzzz1nktFkMmnBkE1NTTZal4rR56uOAmZoFrlc6XRag4ODKharEzBXV1c1MDBgnQQ+h0wmY7JWOphIJKJkMmkkZCgU0sLCgvx+vxnd2JgTiYQcx9HCwoLa2toM7sHnQYWCM5+ugw0Hp3JjY6OlIxB7g4pnZWVF4XBYh4eHevz4seLxuGKxmH7hF35BgUBAc3NzKpVKGh0dtQy55eVlm4SJSc6r4mttbdXa2prxDCcnJ1pYWFA0GtXS0pI5zaXqIT4xMWEEK7DIzs6OFhcX7eHp6uqy64E0+d69e6Y0A9eem5vTnTt3THFHJA1y9sHBQcPQe3p6TKjAiIZXXnnFlEkYU3F1h8NhjY2N6eHDhxoZGVGpVFIsFrMxC3ymq6uryuVyOj09NaiDJAT4AKDWaDSqoaEhm0jKEK5SqaS3337b0rHJraJTZSgesfZwf5iWqaapIgcGBmxD5tBAzs6GwuZB58khC5/i8/kuiGp8Pp914HTKVL0clGz6CAeIx+EAQo3G5hwKhS50147jWAWMoRMxAx0UnBMHQ7lcVjabNbGJF15LJBLmsSKkNJPJmEJUkhU9hE6SZEEKcUtLi9ra2qxApWAAxsxms7Z50rnRMfn9fvX09Jjy0ptigGcMnxAWAwQveHNAEyjiKARJqueQpYvwyrGB/HgukDgjoGhubjaRBQcHHQWkPjAZykPUa3StFAUcal7TJn4nYHv+HZ0h6dQUoyALFDEHBwdaWFh4+mG03/7t335jfHxcfr9fy8vLeuaZZ8z5iuQQbT9ad1RoxOaXy2WNjY2ZJ6Kzs1OLi4uWC3T9+nWl02lTZHFTobZgKt/JyYmWl5etKtvZ2dG1a9e0u7trHprh4WEbWgY8k06ntb6+btENc3Nz9jNyuZwR2Mywp8oIhUJmoNzf3zdhAa7mfD6vXC6nw8NDhcNhfec739HxcXVcLAdrX1+fMMV+uCLmgItGo7YBYQgECqALe++994wTo7VGu4+5LhqN2kZ0fHystbU1tbS0WLLszs6OxsfHFQqF9M4775hSbWdnR5OTkwZXHB4emokOkx3pDY8ePVJ9fb0uXbqkoaEh5fN5TUxMaG9vT+l0WrFYTOVy2TKzlpaW1N3dbanRQCuDg4O6deuWqXm2trZ07do1O0BzuZxtNLjTz87ONDU1pVu3bimfz2tnZ0eRSESnp6daW1tTZ2enkbkkcJP4AKcQDofV3t6uXC6n4+NjG66G/wuiFv8RCQrAEmwIPMiHh4dGpGNSppg5OTmx0eYonOCLMJDiIKdaLxaLFhFD1wKHB0fq81VDaZmlg0qPDDfvZsn355kg9RiezytTBqLiPdAJbW5u2iZPIrMku0c5JNhMy+WyVldX7TnhkNvb2zMZL5siUmc+d/xObKTYBBACAEXxNfBmFJQINYAFgTYxjcMxHh0d2bXhwOAac+Cyp9TV1dkwMrpNUhOAmvEL0cGAkMBD0zmTWIHajM8YOgCOBak4/5ZEA0QM3uQBukMk1rwXuOaTkxMtLi4+/YfN17/+9TcIzWtqatI3v/lNtbS0mMy2UqloYmJCu7u7JrXD80K7DEnNRsxUwVgsZq7xtrY2q5KGzxOhuYj19dUJgHQWYPiXLl3S7OysBgYGND8/r/v371uuEVAFA4yGz0cUlEolXblyRc8995xtEkzSxEldqVQ0OztreVhAFouLi8rlcrp+/brm5+e1u7urSCSiQCBg83MgufE6LC4uWggl2nngDirWXC5nNyZ4LioSDnPSCFC19Pb2KplMmkCCg5ONitTswcFBbW9vK5fLGY+FFwBjIwT6zs6OLl++rKGhIeNHkHc6zgfTSLu6uvT+++9rdHRUXV1dWl1dVXNzs4aHh9Xb22tx/RhYh4aGzHPDLHeUeqjp0um05ubmzCB7dnamRCKhiYkJm9MC39fc3KyJiQmNjo7adebw4fUVCgUbZ83GDwbPXCSfz6erV68qkUhc8CRxPxwdHV2IPwGe5Pfc7z09PRcMpxgsEXS0t7drb2/PPFhtbW3q7+83bgnYA66He5yBdEDQx8fH1v2dnZ1diC1hpAZFFkkaEPWQ3AguUAPu7OxIkqVro4ijcCQZgYMNocbJyYlNTo3H48Zp8cyyqXo/T/LP2Ezp4EhogKNqamqyAwaZMl0cBxZhpV63PhAiHBOQFocEPIe3QOO9YzhHzdne3q7FxUVLJkFqzYHPHkfwryQrwLkGjO/g/XMwYvoEnkQSf3Jyos3NTXt9sVg1MxmoGfUcohiKhLa2NkvX4CBHOMJIi/v37z/9h82bb775Rn9/v1UKmMC4Gdj4qB6JnkAVwjQ6TFeofXDpAnURl1IsFs3xzdcEg0Ftb29renrajI4oQcgG46FhkiUk/jPPPCOfz6doNGoVBA8UVanXgU1LPTQ0ZA8DGwVJzEg/wUcbGhoUjUbV29trsCKzQ2hzeVhSqZR1O6hyUKfhSGdTJX1hd3fXcqok2UNI9Acud6pejKCbm5vKZDLGs1E1wdtIsqFlYL/9/f3KZrNGZFLFnZycWDhiNpu1TLpEImGyUzBi4J98Pm9ZeBCoQF4oloBRIJD5ufirmEfCYVMul5VIJNTZ2amJiQnt7OyYYZcIFeBQZhUVCgXreqgEMbLCB9G1eElnko9JiUAejYqLKpY4HG+cDNCUl/RHtcbPoEpFQSfJ4DDUV3wt8fqQ1HSbXimv13fC96ciB3ohP48kCTY+Nns2LA4AL8zD4EH4UknGk1AcQo7TeQPVEukDzERR6K3MOUQPDg4sLYCUBToRvEzIrunAvHJh7i0UZhwkcMnsZXRhXAM+16OjI5XLZYXDYVMHknjCc0x3xZ5C54qoQZKp3ri3EEDB09BBUkhIss+Ag9SrSOzs7FShULC0FQpq9gRvoQqUTpjp/Pz803/YfO1rX3uDXCY8B5yYyJzZKIDFIMYw7oFxc9FTqZRVDHV1dVaZw794lSLMswECo2JnVg5x/ySoIjgolUom/ZyZmVEsFlNnZ6dBAEAEXqNVPp/X2tqaVd2IHtD3kzWFuofNCNhgd3dXqVRKoVDIZvoQicMAKNd1FQ6HDfrIZDJ67rnnLGofXwmcTmNjo8m9GSSGuosIIIIx2fSBUDY2NhQIBIysBkZhABkEPEqW7u5uDQwM6N69e4ZpSzJcn+qOBHAOSJR0kizEk42KTRRRCKpANsRMJmPTTeHzvLEb3d3damxstPBN/CI47RGnsBHwOnFXM46bn1tfXx3Y5eXgwNTZACCAyT4jUogukIIFyS2bpyQj0iGvt7e3jXugQ+BwYWPByAgMx2bKYYJ8ulKpmB2AjoGkcn4+/BEpBsBVGJGRgpdKJXu/wDEcAMBCKBrpDPFX0T2ymfPZYjJF4szr9r4WSZbEwSRf7iHEAfAv+LBIgWhvb9fm5qZyuZzxbUB3vGa4NVSrdM6np6dWOHmTG+jgfD6f8YOSDNaiYMDrhJADXxAbPPyd67qW6s174vrB/3GgkdpAcUPaANwe6keKF/xXFMB8RnRjXpsHkCKw4k/FYfM7v/M7b7Cp7ezs2Bvu7u7W+vq6lpaWLlTGCwsLyufzmpqaUmNjoy5dunRBxuc41ZjsmZkZ83FcvnxZp6enCgQCunHjhsXRh8Nhq2pv3rypmZkZ4w54YPr7+y3ZIJvNWmglxsb29nbbeP7qr/7Kqpzl5WXzFtDeY3bjJqa6wzOCogqFzdHRkSm8mIfCtEzHcbSysnLBS0KUDMGgW1tbNqirVCqZgx7V0tjYmHZ2doxIRz8/OTlpElvI7HA4rDt37lzYXA4ODnRyUg2avHnzpkZGRqy9LpfLhhe7rqurV6/K5/PZ9E4mZi4vL5t3B6ybTmRxcdEe4s7OTjP8ovXnwcWct7GxoZGRETU2NioejxuUKMmKheXlZdv4wesDgYB2dnYsi48Ydrwb6XRa8/Pz9rnj3Tg6OrJBWDyQxLEfH1cnP0YiES0vL5uTu6Ojw4oJKl1+Ju5tqVrRX7161Q5BrnVdXZ2CwaBxC4ODgwoEApqamrJOHvIcZRUxLZ2dnWbaZMPi4KHzBk2AJIe/g4NZW1szwQMJwnwOON+LxeKFEQ1Ik+GtvF0+Hjm6IFROGA53dnbMIMz4cmAdeBZk2cVi0TxxUtU/Eo1Gtbe3Zxwam+jY2JiZM+EoyuWyHULIpNnEz87OTGzBPsN7oyuAEwGKZT/jdXNYwa2SsAw85015ODo6sm6Rgx6VJUXi3t6eHdjeqBwKFWTS8GTwVxRoFCbA8MTzIP5A0NPe3m5dD51TLBZTsVjNdxwcHPzpiKv56le/+sb09LQKhcKFcMRKpaKZmRmL+a9UKlah9ff36+zszKZUwmOEw2GDnIaGhnTlyhXDLVFQjI2NaWFhweARspWWl5c1Pj6uVCplbnQ+FPDXVCplhwPhdKVSSdlsVqlUyshUWm54oo6ODquAW1tbrXtyXdcqaG5EICk2YAjq4fPJmih/2tralEqltL+/r5GREc3MzCgcDuvk5MQ2KUYIlEolra+vW5UViUQ0OTlpnZfX5Oa6rlZXV41g7u/vt2qfajqRSGhra8vw+xdffFFLS0umluFwmp+ft3wt1IRHR0eamJiwpOu+vj6DoKSqNDQcDmtkZERHR0eanJw0hdfp6alee+01nZycWKdF4vDu7q6Wl5e1urqqfD5vggTmH9XV1Wl9fV1+v1/x8/HOkM4PHjwwkyWiFLLaHjx4oEuXLpnXanh42N7L1taWdZA9PT3mTyqVSrapb29vK5PJWKo5wa0dHR0GiwBNok5jvgxVPx0Q1TVueaTDVKdAXl1dXdZ5chgUi0VTYNJVwhtB3kNGk8tGp9HS0mJKPSAwOixmrnhhSBznwLx0O8hxj4+PlclkjDtAEk+XzEZJACXfC0Mvwhw2V64hWXFIwQkVpbg4Ozuz8E4MlfCFdE10lXyv5uYPhpmx6PpIjfC68Plc+vr6tL6+bgIBigj4Ha/lAI4TEQNmUtRsfr/fig0OSFAXpOOSTF15fHxsQgkKdZSQFASIWdh/KAq9pluQA8RUXu+O1291eHioe/fuPfGweSpGDLS1tbkM0jo6OtJrr71maicqeu/AK3BtIKShoSGbqpnNZnXt2jXLUGIo2fj4uDlvgZju3bun1tZWxeNxq8w46ILBoFUjtMW0vENDQ9aiptNpXbp0yRIJjo6OFA6HJUmXL182tRLGvLt371pi7crKimKxmF566SVNTk7qrbfeUjgcNoFA/HyeTCQSUSKRsGqLGBxJRjQvLi5qaGjoQsWdTqe1v79vJk6UblNTU2poaNDVq1d19+5di/pnhDJDrqTqg8HBwIgH4Dewbao/ugr+PZvvycmJ5ubmdOnSJUnVDmN3d1fBYNA6l5OTE2UyGZtZs7i4qFdffVU+n0+f/exn9Y1vfMOy0oAxwcrB8XFsb25uGq8FZ0G1hgkS4vbFF1/Ue++9Z5sQ9yAjdTmgYrGYWltbjbcjo6qpqcliPUgOZ1AdfFlHR4f+9E//VH19ferq6rpgkGSDpVChUgRj5zPjkGdD4oClCJNk85b4mRy0a2trtsED/SIiyOfzVpnzeXvHEKPQAz5miml9fb15cugIOIA3NjaMs6JrmpiYUEdHhxYXF+1gaG1tNe5PkokDQDVIDafj2d3dNX7Om2rMYXB2dqZMJmPJ6HBKpVLJOE04PyBEvD+SbA4M0UheHqtQKNhgPuJv2JThmYnE4hoy5mFra0ulUslUs/v7+4pGo9rf31dPT4/Ozs7sYMRTRPwV3R3XkfcAFEr3TfIKcDX8K740RCdAnRQE8HleQzr3iRc6hQJAAg0fhQClXC7rD//wD5/+EQO/+Zu/+UZfX5/Gx8fNK8BBs7GxoZaWFoszYZwyuG2lUrGNtKmpSS+++KJWV1fV3t6u27dvG3bpuq4WFhZ0cHCgQCCg5eVl9ff3K51OW4wLN1GpVNLS0pL6+voMXqH1BxqhOqYiKhQKFlbHg0bVxo0AlAGOTjREW1ubCoWCksmkPbg3btywB4PUV8xuU1NT9gBh6KpUKjYCeGNjQ65bnWnS09OjkZERg5i4OScnJy07jo4FlRR8VyAQ0OPHj01tx0ZAmjDhqAQT9vX1KRKJ2OGayWQs8gXlFJg9ijFu1NXVVSMd0+m0BgYGDILY3t7W1atXjZidmpoybioYDNrDUSqVDOOXZJ0s1S0CEg6PSCRiHSZcXU9Pj+H8QCXj4+Pq7u5Wb2+vDXgLBoNW3XqDDnd2dtTT06Pd3V319PQY2f3o0SODFVF34bZnEyNzig2LKhI1VHd3t05Pq3NR1tfXzb8lyYozOhi8Mtvb25aEcHJyYp9rJpMxot4rJKDL536gwicyBoiGA4LPAXUeajcqaDZyfDl00sT2cD04gAqFgoU88m9QScJfNTc3W7EApNTd3W0dXH19vQ3ug9djNhX3Gz+X90vngyyd14xIAEENAb1cB/arfD6vhoYGOwT5DFDGceghHOCzZRIq4hhvQY2oAFEG1xVOF0ECRlDudQ7BWCxmBwYCC4oN/j1cFZxfS0uLHUx0WBxS0geqNaBE0I/6+vqP7GyeisPmt37rt95wHEf5fF6XL1/W3t6ehoaGzLWMooRoDyrjy5cv24dDdS3JnNgzMzPq7OzU5uamwuGwzYJPpVJaWFhQfX291tbWrHuIRqNaX183YpmUaH4+1SCdSywWMykoSqLl5WWD8oDJenp6DGZrbW21GBCqNwQC4MV0WVtbWwYTIfskwI9YEcYtBAIBm/9CAgEwDZtfJBKRJLuRJBlZ29/fr6WlJTNjIkOH4ORnx+Nxg/x4EKjifL7qRM5gMGgD0WZnZ02xtL+/r4mJCYM0l5aWzDvy6NEjFYtFdXV1KRaLGV+EegyIhweTzRz4D9c/mWOOUx3FkEwmtbKyYp0WSd4YIjHwnp6emjiCbpZ7DTPvwsKCkckzMzPa39+3jorrjew7mUya96mjo0P37t2zwwKFEuGSmAIlGZnLtT87O7PqF87AW7Bsbm6qra3NNkPgFTZ+PCu8/87OTuO8kACTc0b2Fbl0QCkNDQ1WbHD/NjU1WRVdV1envb29C054OBlgNK6pN0YHbgIe4ejoyCBirhvQIJFLQOI7OzsKh8N20NMlAf2wyXtFEPwsolaAMJEOc6/hN6Fz5vrw+fBv6Dby+fwFxR/8qfSBQhK4FtIfqM4rkuH10XHQufK9+az47CQZNIZEnem1dFte7vTo6MisGEQNFYtFM7RS1PC6mInFvcHhj4BD+qBDrFQqPx3S569+9atvTExMWBXk/XUoFDLTExcPhdri4qK56Dc2NgxPJqZ+dnbWZIIzMzMql8umcimVSpqbm7NJdmRlhUIhq3JXVla0ublpypz9/X2DxpLJpOrq6pTNZrW2tqauri5LIGDstHfeCtJh74wP4Am/32+E+ejoqPb29pRMJpVKpQwX9eYQwWkgj6aTymQy6u/vV7lcjXQnqoQDE59ER0eHRfyDxfr9fjMHcnO6rqtIJGKwHDDJ5OSkdnd3jXBFUccmlc1mNTY2ZmRmLpezKjsSiSiTyZhHpbGxUYlEQsVide7P+Pi4hWTCM2F848FiWBkDvyDMCUTkgaeT6ujoMBEABOfJyYmuXLmiUCikxcVFg5PGx8e1tbWl3t5e6w7q6up0//59ua6rtbU1ua5r8T9sxnV11RkfhUJBhUJBkUjEVJWzs7OmbGxpadHR0ZFCoZCJAUinQMpMsgIke6VSMUMhieLAXl5uCHc7IxIY2cDXEc/CGHLpg4iTbDarrq4u82IA13BvpVIp+zXcoqQLMlhIdGA2Ujvq6uoMHvL5fOrt7VWhULAMOpIH+vr67NmFAEd1SEKFN9KqpaVF29vbKpfL1rl1dXUZ17S7u2uQFvJoRCFHRx9MBA0EAvYcAcdx4HjJcjo9YPDu7m7rpil0OIi8sKQ3B5DuhYICOAyhCocgewcHIzFY+/v7f0fhR7cI1Ok4jo0LxxND4YpnCzSCQxojeKFQ0NbWlvmMkNFLsvflVQpLMkHVrVu3nv5sNG6keDxupCZ5RZubmzaXBZVIc3OzHj16ZFwM1SVzT4gqn5qasngaNpnbt2/rz//8zy3c8fLlyyoUCnYDciGDwaDlpMGP8KE0NDQoHA5rYGBAoVBIvb29mp+fN6yZh3dvb88+OKCBfD5v8JnXxYtqrlAoXBh09f7775vBlY0VpUp3d7dCoZCGhoZULBat/WfDBw6KRCLWPm9tbWlubs4qI0nK5/N65513rOql8sFkhzrO7/drYmJCh4eHNoyMNhw1DdDJ/Py8kedDQ0MaHBw0xR3RH+FwWMFgULFYzKSX3jkmhHf6/X7dvn1biUTChp3h/4nH45qbmzPuCjgIOTeCBw6HZDKpkZER6yrIhOrs7NTY2JgVC2wWPp9PGxsbymaz2tnZseoyFoupt7dXCwsLpnIEPiFChPgQlHUoyhzHMcUWKddbW1tWddMZHBwcGGzBJoOElkq3u7v7QiR+qVSyGfd8L0nm3EcuTB4fVgCgILB8Ogy+nq4FObNXcMPGz73Ha8XYSaGDsi+Xy9lz7/P5FD8fcCjJnh+uP50eXSJqNa8CjGuOe55KHxM4XAnKrb29PfNX0T1KMkgRGwawGwcIEnjeG3whqkC6fxLET0+ryd1e8yjOf+BAMtIaGxut40O2DYTK55fL5S4UAHSPROAAf8GrUIBwvdhjiAVDCQi0R4flNeESx+P1jtHxkQkp6cJ+8sPWU9HZfOUrX3njypUrOjo6MvhFklZWViTJHlhgA288O5s1RCI3zNramgUicgLj0E4kEubml6TR0VGtrq7ahUMBRPhcKpXSCy+8oEgkong8rq6uLm1ubqqvr0+JRELJZNISBoBl8DiQNMzNh1LI5/NZqGZbW5seP35sHMjZ2ZlWV1cN6oKsrFQqWl9f18DAgHp6euT3+/Xtb3/bIAeUQWC8vN+trS2bYok5FUc2QZcolV577TVTqiBu4LDc2dnRpUuXdPv2bfO9NDc3K5fLme8nn8/r5ZdfVltbm1XhjA7gxh0YGDAfCvN0Hj16pBs3bhgkNzY2ZoIONhoOdb/fbzDa3t6ebTBE7p+dnZn/JxgMKplM2jwgHuidnR0Tevj9ftuQjo+PtbCwcKHDSKVSGh8fVywWMzl8Q0OD0um0KXmGhob03nvvGTcFlIriKx6PX8hX875mPF1UqvAKQCZAId6Jqh0dHcrn88YxALvQYaAuYwPx+/222SJ7Bt6BA6HjZ2Olk6Qyxl3PYUVlTBdPF04cDoc/yAQ8GDwCqjteA34NoDl4DcyH+DvgmKiy+dxQeHkPXshsSXYf0YXSNVKxo7DzStCB7TAdIwgB4pNkieR0cWdnZwa3UhwCB0qygxUVKFAtBQRxUPxc3g8KNbotOD9v+gkjMTgA6TTxDHHPISzh9RGthU+JjpXECq4LYh6KUd5LuVz+6YDRfud3fucN5pEwURICneRkyEEqdsj/SqVinhKc0RDSyWRSS0tLFhOfyWR0dnamz33ucxZKSbAj3oHh89HAkGLpdFp9fX0qFAoG9ywuLurg4EBdXV3KZDKmwiqXy3rttdc0NDSkYDCo1dVVbW9vG6cEYdjV1WWvf3t7Wy+++KJ6enr0jW98w1RnHHQ8jKilGIGNSZDNyXVdRaNRi+ZYWFgwmfjJyYl+8Rd/Uaurqxo+z3XzShYJthwZGbE4lampKfl8Pq2vrwul4PLyspkdd3d3bUT04OCgdnd3tbKyolKppOXlZfMakaAgyfgE6QO/AFAKEx6Pj481PT2t5uZmO3xI8W5sbLTxCd5NiODJ7u5uhcNhS/vF9wCUCBeG258UbcjbV1991SAMDttQKKSWlhZ961vfsgeMyt5GzrRYAAAgAElEQVTv91uln8lk9Oqrr6q5udky6E5OqiGh8XhcGxsbSiaTVkWS48WGAmRGwXR0dKT333//gieDw6+urs54Hg4Xrgf3bjgcNuEKGyf3DF0W4g4KHKAhzMjAaQxyQwlIygYqKBAHZLZU0Nvb2/aMkpyQz+etOES8w6GGAIFDhfcNZwF/SefBxsehwvhqgi9R8XkrdiTcFKJ0DkigqeDhBum4eU1s3nRNwLb7+/tWRJLQgS8IEzSCHOZNMQoD8zmHHSGevA9UnYzHJmmAA4SOD3778PDQDp/GxkYbcQ1/y54ATAmcnclkDL5GHIOBngKCVAgoA0lmlP2pOGy+8pWvvEHVQ8YVA9RwNWPM4iYFkuEmpSuCAENOmM1mFYvFrJIGXySkkjZckp5//nl1d3ebUW12dlbpdNqqH0gyJk7SGRA/HovFbOQymV2YM6k6ma8C6bu/v2830cDAgK5du2YQB/Ll3t5eq+Rpme/evauxsTHzIyF5ZSwyOLAke0/E9ezv71+QlHZ1dZl8nAQD4jiIk0EGzsZzfHysgYEBk0Lncjnt7u7a0Dk2azq5S5cuWQhhsVi02HtgloGBAet4IKEJsOT9Y6AErsxmsyb8gByGbCalGEKdoWuJROJCaCf8jc/n0+3bt21qZTQaNU9IPp+3boSR0xhkgTqQK/PwT0xMWJHBXB42XPwhbNRwBJhPIac/7Dmh4qXy9hYM+FtQtnl5BzosVHRsiHQsQDKlUsnyBpubmy3+BGgHXwd/xmfJe8GAGAgEDAKl6wD2QiCBCo8igsBXuviuri7Nzs4aj4ThGc6T/DmIcNRmcJpU/TxHmFJR/LGPYLDmmnBwciBS4HI47+zsqLW1VZubm6pUKua9QcAATAYkDfzNoYlUmGvH/lYsFu2z49CjuyNBhC4DaJHXCiflTYsgEYOiCwUo9/vx8bEVTqjivGkNPOtwiXRfHMQcWIODg3aorqysPP2HzZtvvvlGJBKxCp5Z8hwumLn8fr9VQ0ACRLUAA/T29iqTySgWi5laDHIvEAhofHzc2lBvHAw38p07d0zN1t5eHR/NDYLaY29vT11dXdra2tLy8rJxPgsLC3YgPXr0SMFgUJOTk5qbmzMCnOqDQ7JYLGpiYkKZTMYOT+AjuIyjoyOTGlKJNzU1aWFhwdRipVJJkUhEd+/e1eDgoGWzPfvss+ZEDgQCtuF2dHSoUqkonU7r9PTUUhQ4RGdmZmxjwnHNZgSnxI3c09NjIxEgRJn7093dreHhYa2vr9vfPX78WFevXrUDljad0EXMm5OTkzZ3qLu723wh0WhUg4OD8vv9ZjjkUPHORUqn0zZBka7MG+WOHDQSiWhgYMC6SBIV6Gwcx9G1a9cMskOW2tzcrAcPHtihgYiCahsZcDqdtomSQBlwI6idEAxIsk5A+iAZAa6Hyhu4GIc38nVgKySsTU1N1mkAs/Lv4RmCwaCCwaA6Ozs1fD4iHAiGZ5JDHL6FjZ3Eb7g+vB0Ujxx2wEjAePCj5KpxT7e2tmpvb0+ZTEYdHR32XPM1kixtAK4mGAxe8OtQTJFIzSHnFQs0Njaa9+b09NRgQohy+B9Cac/OzkyWzddywPL68FChli2VSsbNcgC1tbVpd3fXDnM4QQKEKSIGBwctNQNRBvJnSSYuAJkA1qbDgTtC+s219aY+c404dOkk4QQJ7EQKT8HFoXl6emqv+ZwPffoFAtz8oVDI3hzEdHt7u21Yo6OjFipJ5cn0PtKTV1ZWTJePsY8NIhqNGmnGDTs1NaVr165pZGTEKq3Hjx8rn88rHA4bLktFI8kcwl5VCe57Av46OjpsqBiY+uLioggcpRrDj3J6eqq9vT2LsEEMUCgUNDk5aYSiJMPHo9GoYep4RLzej3A4bJAcc28kWVdFJDw39NDQkP0d7y2XyymfzyubzapcLlvoJ54EbmI2UTZrQjmpgiORiHkfwM451NkM4OCCwaA96JJMIbezs6NoNCqfz6e1tTXt7e1ZSrEk66SAKvAUUR02NjZaFY0BEznvysqKGYHZ8NjI6QA5kEKhkG2WdFa7u7u24dHhcGDAyfl8Ppt8ipqO6hWcnwy0uro6UwJCGNPBQqzTuTG+OxKJWFUMZIQ8nuKA5wRBAgcZhQ88BuoxcuPwsfEM8vmgppJkkJTrupZxR+VPUcD9W6lU7DlFpdna2mrdFDAjSABZXZKMBKcAoeInIgjvGXwfcmAMvUjPEWEgHkIABKwJAe+67gXYDqm5Nxma+BzuEdz5JCJ/mOyHFuA+QknLe0cFWywWLcaLLpLrxkGBZ62pqcmiZThs4HopLuEBQXNIYsGf1N3dbWiG19Mj6cKhxf3IPgCF8aT1VBw2kswoyByQ1dVVuxEIyGxtbTXMEdjg/v37kqSbN29euKm4WYhLj8Vi+uxnP2vtLxXZysqK/H6/8vm8ZmZmjHDzGscYY9DX12cSYQIL8ZQA3bzwwgtqaGjQyMiIKpWKHjx4oI6ODk1OTprCDV6AjQ6sns1pYmJCCwsLisfjlvPFocZ1Iq2AbocRv1NTU5KqSQjIj0OhkO7evXtBmQR8SKdRKpW0srJivAIblNfdzYKg5UFbW1uz6abcuOl0WrlcTmdnZ5bltr+/r4GBAU1PT5s7n4oTA6kkE2rcuXNHTU1NikajxiHU1dUZfDUwMGAObTYPqSr4uH79uh3gGAO9ybxwAFeuXLmAmadSKbW3t+vGjRva2trSwsKC1tbWbLxAXV2dFSLe4Vt9fX0aHR01zwV+J2+xgbS1p6dH29vbtrkhzqAyRfpLccAhHwgEzB9BojgVLoccnSKwG58ThQeVMQIAug8OZpACOBivLwMOABgQYp3KGrELMnX8Ps3NzQZretVkFFDI9JHsB4NBO+S4F/DvwPHQbbS3t9vGR6eCbJjAVjZWFGHAcMToYJ5k8izeHcQXFJBMzUX5xvA+rhfPbyQSufD8EH5Kp8YhgxkTuMrn8ykcDpvdA9jPm1kHF0SRwcGO4hE/FXYE+Cb4NLLh6urqDBGi4Gg7n8ILdBmNRg3y9Pl8VvygPINbpDH4qPVUwGhf+9rX3iBrjAcABRdYeLlcVjqd1t7enilmrl27psbGRo2MjGhlZUXRaFR9fX3Wwk9MTFyQMUYiEd27d89umunpae3t7Wl7e9tiMH7u537OZsccHh4qFotZ5AcVBy76S5cumZGroaFBCwsLCofD6urq0sLCgqQqD/SXf/mXcl1Xw8PDdlDOz8/bQ85NMDQ0pMPDQw0ODqq/v99afUYnQyYfHh6aWotcq+PjYy0uLhr8SPeFhJxDan19XX19fQqHwzZZE6Mlihj8MlJVEdjR0aF0Om1VOcRwW1ubcrmcxsfH1dTUpJGREQUCAR0fHysQCOjll19WMpk03svLMywvL2tra0uBQMDUgCMjIzo8PNSNGzesEt/e3tbU1JR5LNhU33//fevgQqGQstmsent71d3draWlJVUqFSUSCS0sLOjq1avq6urS1NSUUqmUiUmmpqY0Ozurvb09Xb58WYODg1pYWNBnP/tZgyhxUXuFCuVyWf39/apUKopEItrZ2bG5LtlsVoVCwTD47e1t22A2NjZsaBZkP1zfh133KH4uXbpkCd2EIdbX19tGg1eE+xwIp6GhweARSWYuhiQG1qPDRZBzcnJi3RObJFUuyiU8OBD6yJ05kHiP2Wz2ArQHL8Xzy8HDXCIk7zzv8Dv8TOBwCjZ8LkTFcA97/TB4nXj9fA9UdGzgvHc8RPAqQE3Mo+GAYrwEzwRGS0QvdHx0kKFQyEy0bW1tNqzx9LSaW0aHgQ9IknFx8MVwJyRHcODlcjlLTYBjoVOh0CuXyzaiPZfLmZqOLpgDikMdOT9wM3Ao3rNMJmOHMP6ueDz+9HM2X/va195gnC9wBNi8JHOgY5BDNorzH6iNDxuTGC3e6uqqfL5q2vCNGzdMJz4xMSHXrU7xdBxHzz//vGZmZrS8vGwcC2qivr4+9fX1KRQKGREbjUZ1584d9fT0WBcFKcwDm8vl5DiOrl+/rr29PX33u9/V4uKiTbbMZrN6/vnnLfb+ypUrKhaLpsBDiUIXAvG6uLhocKI3nRiPA5X2W2+9pUAgoIWFBcsIGx0dtVb/hRdeUDweVyaTsY0GiavruiZ7bmho0Pz8vCVGo0bDKwKsw9dBqkrS+vq6hoeHrR0PBAKanp6275fP523GTSgUMi8Nqqp4PK7W1lbzD0xMTBjs+fjxY/ucMceenZ3p/v37am5u1pUrV7S5uanR0VGDS4aGhixxAqgSeMIbq48EPplMand3V4lEQs8884yZCIeHh1UsFrWwsGBScziERCIhv99vo8oRTXBdkRf39fUZ/+NNwwBKBSYlhsRr3kQxdXBwYEq0jY0Nu/ck2WeCt6ulpeVCSCNeGjoCYMS6ujr7b2VlxX4uEB/PJV2BN2UZ7wqx9yRWQMbzf8aF0LV7Z6g0NzfbfQVMzc8FZkehiXeNzLuGhgZDQiRZ1+vtziQZz+GNM+LZ4d4GaoTfw2ZAVhrvjwBUrgNdF9AfQ9CAwOB4ODyB2LhuRPqcnFSHndE1UQiD3nC9mTh7dnameDxusmTkzCguKRSYKHp0dGQFDNwLY16AHIFfoQe8dgEk1uFwWLOzs/+wIE7HcWKS/ndJYUlnkv6t67q/5zjOG5L+c0mb51/6L13X/dPzf/Prkv6ZpIqk/8Z13b940s9ob293wYQnJycvmOfK5bLGx8d1dHSkVCqlwcFBJZNJq8JPT081MDCgF154weS3SPZaW1uVSCRUqVR048YN6wCYzzI2NmYYP3MskDYeHx8rmUxqaGhIjY2NmpycvBBm2dRUnVqJgIEoh0AgoGQyKUmKRqNaW1vT0dGRhoeHdXp6euEA+P73v6/u7m4NDg6qVCoZfNLT02OcQ09Pj41eJpW6UCjY1xITQ+W0urqqoaEhXb16VW1tbXr33XetWunp6TH3eUdHh8mxMaYuLS2ZLDsajWphYUE3b960SvDBgwcql8t65ZVXLARxcXFRra2tun37tiYmJlQsFnXz5k1L1UZ1ND4+bl3I7du3rdNC/eVV5JGg8Oqrr17wRHR1ddkhDSQGUTw6OqpSqaSrV68qn88rHo9bmw88heFTkoaGhrSxsWHS1rOzM127dk1vv/22iSSIOkJ+nM/nNT09bbE3x8fHmp+f1/b2to6OjjQ+Pq5gMKgHDx7IdV3z1nBPUK2jLsIkyGZNxwjkAY8JMTswMGASZRReqIgCgYB1OFS9kNfwb3QAqO92dnbskItGo7apUvGTUwfRDQzFZ0rM0cbGxoXsMjxXpGLzfTGR4n1BTUUALJwICjLUeMBgRDVxCNLVbW1taXt72zZt5OEcBBzKdN34Surr65XJZNTX1yfXrWbPEUpbLldHM5TLZa2vr9vrhXPFXoEIhtgXuqnNzU2DnoESUcVxD9D19fb2WpeDkZfkd8QBwWDQYnXgNumc6urqLMGAYpEIn/r6euXzeYPD6Ujhuihm6GRR68H7cK9RHHR3dysQCFjMF+hIV1eX/viP//iJQZw/CmdTlvTfua47LellSf+V4ziXz//uX7uue+P8Pw6ay5J+WdIVSV+U9D87jlP3pB9A2CFwEQdPLpfTCy+8cAGTx7cC7jk9PW1VQUdHh3p7e22E8OLiouHaGxsbWlhYUENDgy5dumQ3BpP9kG3irWloaLBxx5gAj46OLF2ahwcJNkRyMpk0RRSqjqmpKeVyOW1tbSmbzWpqasqC+8C2idgnyYBKzufzaXh42KAzIEa8JFRvkLtSNbhze3tbs7OzxjXB5SCiyGQyWltbM/5iY2PDwj3b2qoz4zG9gvuHQiH5/X4TNPh8PnPiA6UxE2N0dFSSrBKOx+NaWFjQ8fGxEbRwcAcHBwZPNjY2anV11QhSNsdyuax8Pq9UKmWy1JWVFVPNnZ1Vx00sLS3ZAwsfRiWMA7q+vt5GF1Mt7+7umioI3o6JocALcC44qqVqQTE8PKxr167ZZxcIBDQyMqLh4WFLGAcG9RZCzCvq6uoy/o0UbYISNzY2bKOh2iXFF3n62dmZstmsIQOoy0KhkIrFonZ3dy+YE1tbq7NNRkdHrWBjcurJyYnW19clXYzR5x6HG6HipVsAFkM1R84aAgik5gS4dnZ2WmcA7u+NtWHOCs8B8Th89sjzkW4TxcPwQu9z7fU1cQ9wMFHMUMkDR8LDOI5j6eGtra22QSPSoejgdUu6YDytVCqmaOXvW1tbtbGxYeMHkJ3jEYIHIx4K7sfr3Gc+D50gIglgSAp17B4o7VpbW60Logsj5RohBtdZqoosUAwGAgFTBnM9eJ8/yvrIr3JdN+O67p3zX+9LmpUUecI/+Y8l/QfXdUuu665KWpL04pN+Bic6ybFSNaaCmBhmtpCVRf4X4YP19fVaWVmxTbu5uTq4DM3+2tqastms4vG4keCBQMASCshqggiVpEwmY7gnGOj+/r4GBweVy+Xshuju7jZ3NviwJAvoI4xTkvk0gsGgHKc6FpqbhUMBGAhiG5KbDRVpMAY5Nm9gl4mJCQ0NDRlxjxmLqsprRGPENFUleVaDg4NWTR0dHVlGHPHreElIPuZ98+CVy2WbCAqxjnR2fX3dfElo9ZGpx2Ixg7See+45w+Mx7pLqgGeku7vbomeALeLxuOLxuJaWlpTNZs0Ul8vlTEjBg93Y2Kh0Oq2dnR21t7dbB4SqkKq+UCiYg5yOIpVKWWgilWWpVLKkhEwmYzJTNk3iVbwkM/+Oew/RAPJj7r9UKnWh85Z0YR7T7u6uDg8PlU6ntbu7a90aBwswE58DbnC6Aw5CqVr8wY/6fD4z58K5IRVm80Q0gxl0fX3dqmV4JpSFHG5sjNzfcEzeyH1Jxh9AptO18L0oZo6Pj1UoFGziKykjIBbwFrxGuBM6O2/GmLcwQHVHYcfn0dfXZ+8fGwNZhEz8JIcMGJBofzxj3MuIGHiWINu5F1FuSrKCkKGGeKqA0Ck4kVRLMjjTmyqA0RSVG+pBopLOzs6MkmhtbTXeiO8FHItClq7zSav+I7/CsxzHGZb0rKR3JX1G0n/tOM4/kXRL1e5nR9WD6B3PP1vXDzicHMf5VUm/KsluMohQzFijo6NaXFw0vHhqakr7+/vK5XLGX/zZn/2Z6urq9Morr2hra0vPPPOMVldX5bquJUfjAqdqmJ+fV0NDdWbE0NCQpU3fvn1bUlXaDFlcKBTU09OjQqGgYDBoSg4OgEQioZOTE+N19vb2tL6+rlAoZPDYrVu3ND4+bgkF6XTaft/Q0KC5uTmdnp7aMDHw+KWlJWUyGX35y1/W6uqqmU3X1tb0uc99TpVKRalUyjodDoyHDx9aqz41NaWNjQ0999xz+r3f+z3zRPzt3/6tbt68qbm5OX3+85+3WP+GhgYlk0mTXLP5NzU1aXFxUVK1g0RpxhTF2dlZbWxsKBqNmhl1b29Ply5dMsc+E0+pmo6Pj/X2228rFouZ2x3OZmlpSTdu3NC9e/ds1k5fX59SqZQCgYAdWihqjo6qw9W8M0/oxB49emTTGzELcwjAQZVKJc3OzioUChmEAazQ0NCgl19+Waenp0okEsZ3bG5uamBgwD4Tkibi8biJLsLhsO7evWuxNFSPSIHZsFBf8SCD25Ovh8kPVRRdDQdPT0+PcTEIFNhA4QOJR/G64TmAUIHyd7jTURdy6EqyogQIk/Rruja4p/Pn3P59d3e3dY90Q3g7kMEzRmNzc9Niq5DkAo1xOKXTaVPp8T7/5m/+xuKR6GYaGhosPgYpMsULXQop42zwvC9J1hEARVGkUICQecZnQaIB6EM8Hldzc7PBsX6/32JvJBlU6zVRcsj29vZeQF7g1rzdEyhOe3u7Qa0UuIgvdnd3La0bwh+BEgcvhytwL8UO0CkczfHxsXWOUhXWTCQSH3l+/MjSZ8dx2iX9kaRfc113T9L/ImlM0g1JGUlf50t/wD//O8SQ67r/1nXdF1zXfYENkJb1+PhYS0tLampq0ttvv6329naNj49rcXHRKmtJZt586aWX9PDhQ21vb+vBgwcaHR01B+3y8rIluZJ2vLa2pu9///t2oQ8ODnTnzh319/ebIVKScTqoyDCVkqPGyf748WM74UmhRbkxPz9vGxhO9t7eXm1tbRkG67qu1tfXTe0EHIcj/t69e/L7/ZKkYDCoSCSiO3fu6ODgQDdv3tTY2JhtND09Pbp27Zp6e3vV0dGh7u5uvfTSS6qrq9PNmzcViURULBY1Pj6uhoYGI7nhJPL5vPr6+vTzP//zRl6j8/cqgWZnZ/Xo0SNzyE9PT2tyclLpdFrvv/++wS137tyxzvPu3bsql8t6/Pixurq6DPJCPi7JhAcUB1evXtXNmzcttZZk293dXZt5Q/cEgbu2tqZgMGjemVQqpcePH1v3ePPmTU1MTJjsm1HYQ0NDJgFvaqrOmX/55Ze1tbWlfD6v733vezo9Pb0wQG12dtbkwhsbGzZ4D78QUtRQKGQbBXyDJEtn8DrL2eTc8xw21Fx0D6urqzY2gMgVNjo2TSCxcDisSqVinU9nZ6e59ZEvYzmQZMIFDkPk6SSfQ0ojQ/b5fCan5ut5H7wHwmXxReF1kmTdRj6fNwUiSky6Mp5JhBuRSMRSDoDYhoaGDBpEIISkV5JB09ls9gLhjowaDhBuq7W1VQ8fPrSDkcIgGAyaPwd4Fd6WboUUA8JNOYQRINAduK5r6ADSZ6D07u5ug/Vw81NgeA9CYEIUtwcHB4pEIuZl48D1yrC9SsBKpWL+t9bWVgvXRDlXKBTMpgBPjJAGYQJGz49aP1Jn4zhOg6oHzR+6rvv/nN9EWc/f/ztJf3L+23VJMc8/j0pKP+n7cwEdx9Hs7KzpxROJhG7cuKHNzU1dvXrV5rKggT84qM6CpzoGvmFo0OLior74xS+qvb1d7777rqW9SrIgTCJAXnnlFYM0ent7NTk5qeXlZX35y1/WH/3RH6murk5zc3Pa3t5WOBy2+A5JNrRse3tbX/rSlyRJ7733nqQP/AwNDQ32MwmaJApjfHzc4jXW19fV1NSkZ555xqC9YrGo7373u7px44a++93vmsH0xo0bWlxc1MTEhNbX1w02xCnc09OjRCKhhoYGjY6Omls6EAgon89LkiXUlstlc5u3tLTo7t27unz5skZHR5VIJDQ9Pa1kMqm//uu/1sjIiJ5//nlzagNnLC0taXR01PDriYkJxWIxXbt2TTMzM4rH49ra2jJn/8svv6ympibjgFAIUnwkEgn19vba90de3tvbqxdffFHJZNIeXFK+UaUhoujs7NQv/dIvqVQqGfnb3t5u3oQvfOELRqDiWUIFhrKJ+JxoNGrVOIPpwLThEjs7OxWLxYxM3dnZMagK6TapAizSuPn+mC452OkgvMPB2EwLhYIVTYyxgPMoFAoXzJRwRKiLUKr5/X7duXPHFJ3cG0iU4baAwkAVsCpAiqO+8g7cCofDKhQKZjKUPtj4UWPRzXFAYjIdGBgwOfTJyYlt3qFQyNKKuaZ08hSKdIdAdsB1kUjEDhoED3QYjKSYm5tTOBy2bjqRSJjSjA0bBSqih4GBAc3Ozl7gdDKZjM2uQeTCc07uIV0yUDr3IR0sijigfLgyvjYWi5lHxnVdS02giEC4QafEgcsET3LVeLb6+/vtewGFApMSZdXQ0GByeWKsBgcH9dZbbz35HPkR1GiOpP9N0rbrur/m+fN+13Uz57/+byW95LruLzuOc0XS/6EqTzMg6duSJlzX/aEZ1N3d3S4eCao5ojiAYIhd6Ozs1L179xSNRo3II0Opvr7efDTDw8Pa3NxUNBq9MJWyoaGaghyLxbSysqK9vT0jF5H/TU9Py+fzmVMeDBiZ5cDAgFZXVzU2NmZYOK5iuKXu7m7zyBwcHBgEND09bbzQ6uqq1tbW9Nprr9lcD4JHQ6GQ9vb29PnPf94i419//XUbH5xMJtXW1qaJiQlLFWZja2ho0NramnK5nJ599lm5rqvV1VUzacE98ACSjF0sFnX16lXNzMwoHA5rY2PDvCFU4uFw2AyIxWJRw8PD5jgmC2p6elr7+/s2AhgfCWQyD9Pg4KDdA0ANVGzHx8dmRGRFIhFtbm7aJrm6umpy84GBAcXjcT377LOmvjo5OdGDBw8uEK34Yrq6uizepre3Vw8fPlQ0GtXS0pJBFPX19RoeHrawVbxa3qmtHN6BQMD8WHzuRHmMjY1pZmZGGxsbph4bHh62SBTUj1S1UrVwoZvl90ScsDg4T09PLVYnl8uppaXFTIZwQ6SEk3wBLMcmiCpQkm14W1tbNn6b7wcEKMmSFMjgosthUB5cUKlUnZQJIV0qlS7EAWFQ3N3dVTQatQMH7gSI7uDgwKApn89n81cCgYBxCggtMNxubW1ZZ9jU1GRjv6nMK5Vqknpzc7PBxY7jGN/BoQ7nCbwI/wLvxMHBpg5fheCJ0FgO3u3tbUkymAx/1YdFLfCeGGZnZ2c1NTVlApaBgQHr+EFGJFlhQB4fKQ+IbeicsCyUy2U7OHp6ekz4g5gFSfjq6qp53vDTra2tqbW1VX/wB3/wRDXaj3LYfFbS30p6qKr0WZL+paRfURVCcyXFJf0XnsPnX0n6z1RVsv2a67p/9hE/Y1PSoaStJ76YT/cKqnZ9nrRq1+fJq3Z9nrxq1+ej10ddoyHXdXt/2F9+5GHzk1qO49x60qn4aV+16/PkVbs+T1616/PkVbs+H73+odfoqclGq63aqq3aqq2f3VU7bGqrtmqrtmrrY19P02HzQzN1aktS7fp81Kpdnyev2vV58qpdn49e/6Br9NRwNrVVW7VVW7X1s7ueps6mtmqrtmqrtn5GV+2wqa3aqq3aqq2PfX3ih43jOF90HGfecZwlx3H+xSf9ej6J5TjO/+o4Ts5xnEeeP/M7jvNNx3EWz//fc/7njuM4/+P59XrgOM5zn9wr/1x7CQcAAAQFSURBVMksx3FijuP8leM4s47jzDiO88/P/7x2jc6X4zjNjuO85zjO/fNr9D+c//mI4zjvnl+j/8txnMbzP286//3S+d8Pf5Kv/yexHMepcxznruM4f3L++9q18SzHceKO4zx0HOee4zi3zv/sx/aMfaKHjVMdPfA/SfoFSZcl/YrzwfiCT9P696qOY/CufyHp267rTqiawsBB/AuSJs7/+1VVM+p+1tcPG3NRu0YfrJKk113XfUZVs/UXHcd5WdJvqzoKZELSjqpzpnT+/x3Xdccl/evzr/tZX/9c1dR6Vu3a/N312vnIGPw0P75njKj3T+I/Sa9I+gvP739d0q9/kq/pE7wWw5IeeX4/L6n//Nf9kubPf/37kn7lB33dp+U/Sf+fpC/UrtEPvT6tku5IeklVx3f9+Z/b8ybpLyS9cv7r+vOvcz7p1/4xXpPo+Wb5uqo5jk7t2vydaxSXFPzQn/3YnrFPGkaLSFrz/P4HjiP4lK6Qex7/c/7/vvM//1RfM+fimIvaNfKsc5jonqScpG9KWpZUcF2XQDXvdbBrdP73u5ICP9lX/BNd/0bSf68PIrcCql2bDy9X0l86jnPbqY6AkX6Mz9jfa57Nx7B+pHEEtXVhfWqvmfOhMRfOD481/1ReI7cadnvDcZxuSf+vpOkf9GXn///UXCPHcX5RUs513duO4/wcf/wDvvRTd20+tD7jum7acZw+Sd90HGfuCV/7975Gn3Rn8/ceR/ApWlnHcfqlasK2qtWq9Cm9Zs4PGHOh2jX6gct13YKkv1aV3+p2HIei0nsd7Bqd/32XpO2f7Cv9ia3PSPolx3Hikv6DqlDav1Ht2lxYruumz/+fU7VYeVE/xmfskz5s3pc0ca4KaZT0y5L++BN+TU/L+mNJ//T81/9UVZ6CP/8n52qQlyXt0ub+rC6n2sL8gaRZ13V/1/NXtWt0vhzH6T3vaOQ4Touk/0hVMvyvJP3j8y/78DXi2v1jSd9xz8H3n7Xluu6vu64bdV13WNU95juu6/4nql0bW47jtDmO08GvJf28pEf6cT5jTwEp9SVJC6riy//qk349n9A1+D9VnXZ6qmrF8M9UxYi/LWnx/P/+8691VFXwLas69uGFT/r1/wSuz2dVbdEfSLp3/t+XatfowjW6Lunu+TV6JOk3zv98VNJ7kpYk/d+Sms7/vPn890vnfz/6Sb+Hn9B1+jlJf1K7Nn/nuoxKun/+3wx78Y/zGavF1dRWbdVWbdXWx74+aRittmqrtmqrtj4Fq3bY1FZt1VZt1dbHvmqHTW3VVm3VVm197Kt22NRWbdVWbdXWx75qh01t1VZt1VZtfeyrdtjUVm3VVm3V1se+aodNbdVWbdVWbX3s6/8HV46uINjwX6cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 691.2x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.concatenate([reference_image, distorted_image]).T, cmap='gray')\n",
    "ssim_temp = haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True)[0]\n",
    "print(ssim_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HaarPSI metric Results\n",
    "\n",
    "C = 200\n",
    "0.1 0.9858204980953706 0.00018285964 0.011030629237313055 4.591579e-05\n",
    "0.2 0.9441371588055242 0.0002514394 0.029445817913910526 4.0652736e-05\n",
    "0.3 0.8953782020430879 0.00026405914 0.0610303481328526 6.837431e-05\n",
    "0.4 0.8582752275967497 0.00028266825 0.08258155017354446 9.9856086e-05\n",
    "0.5 0.8333061976821139 0.0002761438 0.10266725558456456 7.468571e-05\n",
    "0.6 0.8278191186427702 0.00030263996 0.10160239220458343 0.00011321019\n",
    "\n",
    "C = 100\n",
    "0.1 0.9781404488519797 0.00018285964 0.01689025516708194 4.591579e-05\n",
    "0.2 0.9161082165669477 0.0002514394 0.04262870928171611 4.0652736e-05\n",
    "0.3 0.8528422052051116 0.00026405914 0.08093317170347102 6.837431e-05\n",
    "0.4 0.8089372698393853 0.00028266825 0.10316644268939193 9.9856086e-05\n",
    "0.5 0.7805865981601848 0.0002761438 0.12404749575544136 7.468571e-05\n",
    "0.6 0.772734007012864 0.00030263996 0.1221296098897257 0.00011321019\n",
    "\n",
    "C = 30\n",
    "0.1 0.9578447597119935 0.00018285964 0.03167215278443286 4.591579e-05\n",
    "0.2 0.8526258075981621 0.0002514394 0.06833211279899469 4.0652736e-05\n",
    "0.3 0.7715300871905484 0.00026405914 0.11194060661440992 6.837431e-05\n",
    "0.4 0.7223023686087682 0.00028266825 0.12983286520123713 9.9856086e-05\n",
    "0.5 0.69266904946197 0.0002761438 0.14962337437161627 7.468571e-05\n",
    "0.6 0.6805525969198479 0.00030263996 0.14551783795880077 0.00011321019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion for training the calibaration CNN with lesions only Noisy patches\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "for k in allindex:\n",
    "    #if h[k][0] not in allindex:\n",
    "    #    continue\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    patches = []\n",
    "    values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "    vol  = np.fromfile(path, dtype=\"float32\")\n",
    "    vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    \n",
    "    temp_count = 0\n",
    "    \n",
    "    for tp in range(-2, 2):\n",
    "        temp = vol[h[k][3]+tp, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "        if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "            x.append(temp)\n",
    "    \n",
    "    x      = np.array(x)\n",
    "    \n",
    "    print(path, x.shape, k)\n",
    "    \n",
    "    np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_x_\"+str(k)+\".npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion for training the calibaration CNN with No lesions only Noisy patches\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    #print(f, index)\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "\n",
    "\n",
    "for k in allindex:\n",
    "    #if h[k][0] not in allindex:\n",
    "    #    continue\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    patches = []\n",
    "    values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "    vol  = np.fromfile(path, dtype=\"float32\")\n",
    "    vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    \n",
    "    dx_array = [-5, 5]#, -10, 10]\n",
    "    dy_array = [-5, 5]#, -10, 10]\n",
    "    \n",
    "    temp_count = 0\n",
    "    while(temp_count < 50):\n",
    "        ix = np.random.randint(256, 1200-256)\n",
    "        iy = np.random.randint(256, 3000-256)\n",
    "        iz = np.random.randint(10, 54)\n",
    "\n",
    "        tempx = vol[iz, ix:ix+256, iy:iy+256]\n",
    "\n",
    "        if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "            continue\n",
    "        \n",
    "        if tempx.shape[0] == 256 and tempx.shape[1] == 256:\n",
    "            x.append(tempx)\n",
    "            temp_count = temp_count + 1\n",
    "#         \n",
    "        \n",
    "    x = np.array(x).astype('float16')\n",
    "    #y = np.array(y)\n",
    "    #z = np.array(z)\n",
    "    \n",
    "    #print(x.shape, y.shape, z.shape)\n",
    "    print(x.shape, k)\n",
    "    \n",
    "    np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_no_x_\"+str(k)+\".npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For plotting Power Spectrum\n",
    "\n",
    "from scipy import fftpack\n",
    "import pyfits\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import radialProfile\n",
    "\n",
    "image = #pyfits.getdata(‘myimage.fits’)\n",
    "\n",
    "# Take the fourier transform of the image.\n",
    "F1 = fftpack.fft2(image)\n",
    "F2 = fftpack.fftshift( F1 )from scipy import fftpack\n",
    "import pyfits\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import radialProfile\n",
    "\n",
    "image = #pyfits.getdata(‘myimage.fits’)\n",
    "\n",
    "# Take the fourier transform of the image.\n",
    "F1 = fftpack.fft2(image)\n",
    "F2 = fftpack.fftshift( F1 )\n",
    "\n",
    "# Calculate a 2D power spectrum\n",
    "psd2D = np.abs( F2 )**2\n",
    "\n",
    "# Calculate the azimuthally averaged 1D power spectrum\n",
    "psd1D = radialProfile.azimuthalAverage(psd2D)\n",
    "\n",
    "# Now plot up both\n",
    "py.figure(1)\n",
    "py.clf()\n",
    "py.imshow( np.log10( image ), cmap=py.cm.Greys)\n",
    "\n",
    "py.figure(2)\n",
    "py.clf()\n",
    "py.imshow( np.log10( psf2D ))\n",
    "\n",
    "py.figure(3)\n",
    "py.clf()\n",
    "py.semilogy( psf1D )\n",
    "py.xlabel(‘Spatial Frequency’)\n",
    "py.ylabel(‘Power Spectrum’)\n",
    "\n",
    "py.show()\n",
    "\n",
    "# Calculate a 2D power spectrum\n",
    "psd2D = np.abs( F2 )**2\n",
    "\n",
    "# Calculate the azimuthally averaged 1D power spectrum\n",
    "psd1D = radialProfile.azimuthalAverage(psd2D)\n",
    "\n",
    "# Now plot up both\n",
    "py.figure(1)\n",
    "py.clf()\n",
    "py.imshow( np.log10( image ), cmap=py.cm.Greys)\n",
    "\n",
    "py.figure(2)\n",
    "py.clf()\n",
    "py.imshow( np.log10( psf2D ))\n",
    "\n",
    "py.figure(3)\n",
    "py.clf()\n",
    "py.semilogy( psf1D )\n",
    "py.xlabel(‘Spatial Frequency’)\n",
    "py.ylabel(‘Power Spectrum’)\n",
    "\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     26
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN using Real DBT slices Data\n",
    "\n",
    "#10336 4148\n",
    "#6920 2770\n",
    "\n",
    "#2160 864\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "#trainx = np.zeros([153, 1, 256, 256])\n",
    "#trainy = np.zeros([153, 1])\n",
    "#trainv = np.zeros([153, 1])\n",
    "\n",
    "valx   = np.zeros([63, 1, 256, 256])\n",
    "valy   = np.zeros([63, 1])\n",
    "valv   = np.zeros([63, 1])\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "traincount = 0\n",
    "valcount   = 0\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_x_*.npy\")\n",
    "for f in allfiles:\n",
    "    print(f)\n",
    "    x1 = np.load(f)\n",
    "    y1 = -1*np.load(f.replace(\"noisy_x_\", \"y_\"))\n",
    "    #print(y1)\n",
    "    \n",
    "    #print(f.split(\"/\")[-1].split(\"_\"))\n",
    "    k = int(f.split(\"/\")[-1].split(\"_\")[2][:-4])\n",
    "    #print(k, h[k])\n",
    "    \n",
    "    x1 = np.expand_dims(x1, axis=-1)\n",
    "    #y1 = np.expand_dims(y1, axis=-1)\n",
    "    \n",
    "    #print(x1.shape, y1.shape)\n",
    "    \n",
    "    if h[k][0] in train_list:\n",
    "        #print(x1.shape, y1.shape, \"Train\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        #trainx[traincount:traincount+x1.shape[0], 0, :, :] = x1[:, :, :, 0]\n",
    "        #trainy[traincount:traincount+x1.shape[0], 0] = 1\n",
    "        #trainv[traincount:traincount+x1.shape[0], 0] = y1\n",
    "        \n",
    "        #trainx.append(x1)\n",
    "        #trainy.append(y1)\n",
    "        traincount = traincount+x1.shape[0]\n",
    "    elif h[k][0] in val_list:\n",
    "        #print(x1.shape, y1.shape, \"Val\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        valx[valcount:valcount+x1.shape[0], 0, :, :] = x1[:, :, :, 0]\n",
    "        valy[valcount:valcount+x1.shape[0], 0] = 1\n",
    "        #valv[valcount:valcount+x1.shape[0], 0] = y1\n",
    "        \n",
    "        #valx.append(x1)\n",
    "        #valy.append(y1)\n",
    "        valcount = valcount+x1.shape[0]\n",
    "\n",
    "print(traincount, valcount)\n",
    "\n",
    "# # trainx_lesion = copy.deepcopy(trainx)\n",
    "# # trainy_lesion = copy.deepcopy(trainy)\n",
    "\n",
    "# share = 10\n",
    "# allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_no_x_*.npy\")\n",
    "# for f in allfiles:\n",
    "#     #print(f)\n",
    "#     x1 = np.load(f)\n",
    "#     #y1 = -1*np.load(f.replace(\"x_\", \"v_\"))\n",
    "    \n",
    "#     #print(f.split(\"/\")[-1].split(\"_\"))\n",
    "#     k = int(f.split(\"/\")[-1].split(\"_\")[3][:-4])\n",
    "#     #print(k, h[k])\n",
    "    \n",
    "#     x1 = np.expand_dims(x1, axis=-1)\n",
    "#     #y1 = np.expand_dims(y1, axis=-1)\n",
    "    \n",
    "#     #print(x1.shape, y1.shape, k)\n",
    "    \n",
    "    \n",
    "#     if h[k][0] in train_list:\n",
    "#         #print(x1.shape, y1.shape, \"Train\")\n",
    "#         if x1.shape[0] == 0:\n",
    "#             continue\n",
    "        \n",
    "#         #trainx[traincount:traincount+int(x1.shape[0]/share), 0, :, :] = x1[:int(x1.shape[0]/share), :, :, 0]\n",
    "#         #trainy[traincount:traincount+int(x1.shape[0]/share), 0] = 0\n",
    "#         #trainv[traincount:traincount+x1.shape[0], 0] = y1\n",
    "        \n",
    "#         #trainx.append(x1)\n",
    "#         #trainy.append(y1)\n",
    "#         traincount = traincount+int(x1.shape[0]/share)\n",
    "#         #print(traincount, \" traincount\")\n",
    "#     elif h[k][0] in val_list:\n",
    "#         #print(x1.shape, y1.shape, \"Val\")\n",
    "#         if x1.shape[0] == 0:\n",
    "#             continue\n",
    "        \n",
    "#         valx[valcount:valcount+int(x1.shape[0]/share), 0, :, :] = x1[:int(x1.shape[0]/share), :, :, 0]\n",
    "#         valy[valcount:valcount+int(x1.shape[0]/share), 0] = 0\n",
    "#         #valv[valcount:valcount+x1.shape[0], 0] = y1\n",
    "#         #valx.append(x1)\n",
    "#         #valy.append(y1)\n",
    "#         valcount = valcount+int(x1.shape[0]/share)\n",
    "# #     elif h[k][0] in test_list:\n",
    "# #         print(\"Found in test \", k)\n",
    "# #     else:\n",
    "# #         print(\"Not found \")\n",
    "\n",
    "\n",
    "\n",
    "print(traincount, valcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN in Keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "aug_train = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "tempx = []\n",
    "tempy = []\n",
    "#\n",
    "#whileaug_train.flow(trainx, trainy, batch_size=32)\n",
    "\n",
    "for i, (x, y) in enumerate(aug_train.flow(trainx, trainy, batch_size=32)):\n",
    "    for k in range(len(x)):\n",
    "        tempx.append(x[k])\n",
    "    for k in range(len(y)):\n",
    "        tempy.append(y[k])\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    if len(tempx) >= 30000:\n",
    "        break\n",
    "\n",
    "tempx = np.array(tempx)\n",
    "tempy = np.array(tempy)\n",
    "\n",
    "print(tempx.shape, tempy.shape)\n",
    "\n",
    "#tempx = np.reshape(tempx, [len(tempx)*32, 1, 256, 256])\n",
    "#tempy = np.reshape(tempy, [len(tempy)*32, 1])\n",
    "\n",
    "print(tempx.shape, tempy.shape)\n",
    "\n",
    "np.save(\"trainx_rating.npy\", tempx)\n",
    "np.save(\"trainy_rating.npy\", tempy)\n",
    "#print(i, x.shape, y.shape)\n",
    "#print(aug_train.flow(trainx, trainy, batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     29
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN in Pytorch\n",
    "\n",
    "trainx = np.zeros([160, 256, 256, 1])\n",
    "trainy = np.zeros([160, 1])\n",
    "valx   = np.zeros([230, 256, 256, 1])\n",
    "valy   = np.zeros([230, 1])\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "traincount = 0\n",
    "valcount   = 0\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/x_*.npy\")\n",
    "for f in allfiles:\n",
    "    #print(f)\n",
    "    \n",
    "    x1 = np.load(f)\n",
    "    y1 = -1*np.load(f.replace(\"x_\", \"z_\"))\n",
    "    \n",
    "    k = int(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "    #print(k, h[k])\n",
    "    \n",
    "    x1 = np.expand_dims(x1, axis=-1)\n",
    "    y1 = np.expand_dims(y1, axis=-1)\n",
    "    \n",
    "    #print(x1.shape, y1.shape)\n",
    "    \n",
    "    if h[k][0] in train_list:\n",
    "        #print(x1.shape, y1.shape, \"Train\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        trainx[traincount:traincount+x1.shape[0], :, :, :] = x1\n",
    "        trainy[traincount:traincount+x1.shape[0], :] = y1\n",
    "        #trainx.append(x1)\n",
    "        #trainy.append(y1)\n",
    "        traincount = traincount+x1.shape[0]\n",
    "    elif h[k][0] in test_list:\n",
    "        print(f)\n",
    "        #print(x1.shape, y1.shape, \"Val\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        #valx[valcount:valcount+x1.shape[0], :, :, :] = x1\n",
    "        #valy[valcount:valcount+x1.shape[0], :] = y1\n",
    "        #valx.append(x1)\n",
    "        #valy.append(y1)\n",
    "        valcount = valcount+x1.shape[0]\n",
    "\n",
    "print(traincount, valcount)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bad index -> 2, 6, 23, 18, 20, 36, 54\n",
    "# For paper -> 10, 16, 33 (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lesion Location information\n",
    "\n",
    "1  1692, 1034, 34\n",
    "3  2043, 280,  18\n",
    "3  2124, 1146, 17\n",
    "3  1272, 236,  32\n",
    "6  1293, 440,  16\n",
    "7  1708, 496,  44\n",
    "7  941, 1100,  13\n",
    "10 874, 1018,  28\n",
    "10 1922, 734,  33 \n",
    "10 1957, 413,  38\n",
    "10 2018, 556,  37\n",
    "10 1961, 470,  7\n",
    "11 1298, 661,  22\n",
    "12 \n",
    "13 1628, 348,  34\n",
    "13 1797, 854,  34\n",
    "13 1622, 349,  34\n",
    "13 1596, 510,  31\n",
    "13 1550, 669,  37\n",
    "16 \n",
    "17  \n",
    "19 686, 1125, 20\n",
    "21 732, 464,  9\n",
    "23 \n",
    "25 1985, 576,  64\n",
    "25 1440, 256,  57\n",
    "25 1864, 1040, 36\n",
    "27 1429. 925,  64\n",
    "27 1278, 829,  64\n",
    "29 1246, 977,  21\n",
    "29 1380, 905,  19\n",
    "31\n",
    "33 1104, 666,  24\n",
    "35 1670, 725,  17\n",
    "37 1128, 877,  56\n",
    "39 \n",
    "41 1084, 934,  42\n",
    "43 \n",
    "44 1480, 970,  19\n",
    "45 1638, 610,  47\n",
    "47 1062, 646,  23\n",
    "47 1301, 564,  23\n",
    "47 1870, 625,  23\n",
    "50 \n",
    "52 \n",
    "54 706, 1162,  27\n",
    "55 \n",
    "56 (bad)\n",
    "57 (bad)\n",
    "58 \n",
    "59 841, 1038,  32\n",
    "60 554, 553,   28\n",
    "60 468, 830,   22\n",
    "61 \n",
    "62 \n",
    "64 1948, 854,  22\n",
    "65 1820, 600,  25\n",
    "66 1510, 328,  40\n",
    "66 1328, 1001, 20\n",
    "66 1950, 630,  46 (test)\n",
    "66 1544, 529,  37\n",
    "67 1672, 542,  42\n",
    "67 2138, 612,  36\n",
    "67 1797, 694,  35\n",
    "67 1164, 737,  33 (test)\n",
    "68                (train) \n",
    "69                (train)\n",
    "70 1341, 762, 10\n",
    "71 1433, 769, 14  (train)\n",
    "72                (train)\n",
    "73                (train)\n",
    "74 2302, 457, 28  (test)\n",
    "75 2107, 777, 40  (test)\n",
    "76                (train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -0.171 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.171_1.raw\n",
      "1 -0.167 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.167_1.raw\n",
      "1 -0.137 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.137_1.raw\n",
      "1 -0.113 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.113_1.raw\n",
      "1 -0.091 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.091_1.raw\n",
      "1 -0.063 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.063_1.raw\n",
      "1 -0.033 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.033_1.raw\n",
      "1 -0.011 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.011_1.raw\n",
      "1 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.0_1.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-40-LE-R-CC_3000x1200x40.4_0.0005_-0.171_1.raw\n",
      "3 -0.164 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.164_3.raw\n",
      "3 -0.159 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.159_3.raw\n",
      "3 -0.096 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.096_3.raw\n",
      "3 -0.086 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.086_3.raw\n",
      "3 -0.08 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.08_3.raw\n",
      "3 -0.065 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.065_3.raw\n",
      "3 -0.056 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.056_3.raw\n",
      "3 -0.052 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.052_3.raw\n",
      "3 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.0_3.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-33-LE-R-CC_3000x1200x40.4_0.0005_-0.164_3.raw\n",
      "6 -0.172 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.172_6.raw\n",
      "6 -0.163 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.163_6.raw\n",
      "6 -0.113 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.113_6.raw\n",
      "6 -0.083 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.083_6.raw\n",
      "6 -0.05 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.05_6.raw\n",
      "6 -0.033 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.033_6.raw\n",
      "6 -0.02 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.02_6.raw\n",
      "6 -0.016 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.016_6.raw\n",
      "6 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.0_6.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-20-LE-R-CC_3000x1200x40.4_0.0005_-0.172_6.raw\n",
      "7 -0.174 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.174_7.raw\n",
      "7 -0.151 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.151_7.raw\n",
      "7 -0.089 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.089_7.raw\n",
      "7 -0.088 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.088_7.raw\n",
      "7 -0.076 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.076_7.raw\n",
      "7 -0.067 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.067_7.raw\n",
      "7 -0.04 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.04_7.raw\n",
      "7 -0.023 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.023_7.raw\n",
      "7 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.0_7.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-19-LE-L-CC_3000x1200x40.4_0.0005_-0.174_7.raw\n",
      "10 -0.191 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.191_10.raw\n",
      "10 -0.176 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.176_10.raw\n",
      "10 -0.134 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.134_10.raw\n",
      "10 -0.102 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.102_10.raw\n",
      "10 -0.085 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.085_10.raw\n",
      "10 -0.05 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.05_10.raw\n",
      "10 -0.032 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.032_10.raw\n",
      "10 -0.018 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.018_10.raw\n",
      "10 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.0_10.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-16-LE-L-CC_3000x1200x40.4_0.0005_-0.191_10.raw\n",
      "11 -0.165 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.165_11.raw\n",
      "11 -0.145 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.145_11.raw\n",
      "11 -0.103 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.103_11.raw\n",
      "11 -0.08 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.08_11.raw\n",
      "11 -0.072 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.072_11.raw\n",
      "11 -0.066 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.066_11.raw\n",
      "11 -0.043 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.043_11.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 -0.038 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.038_11.raw\n",
      "11 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.0_11.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.165_11.raw\n",
      "12 -0.193 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.193_12.raw\n",
      "12 -0.173 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.173_12.raw\n",
      "12 -0.138 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.138_12.raw\n",
      "12 -0.117 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.117_12.raw\n",
      "12 -0.077 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.077_12.raw\n",
      "12 -0.06 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.06_12.raw\n",
      "12 -0.038 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.038_12.raw\n",
      "12 -0.025 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.025_12.raw\n",
      "12 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.0_12.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-11-LE-L-CC_3000x1200x40.4_0.0005_-0.193_12.raw\n",
      "13 -0.171 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.171_13.raw\n",
      "13 -0.128 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.128_13.raw\n",
      "13 -0.108 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.108_13.raw\n",
      "13 -0.107 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.107_13.raw\n",
      "13 -0.101 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.101_13.raw\n",
      "13 -0.071 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.071_13.raw\n",
      "13 -0.067 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.067_13.raw\n",
      "13 -0.044 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.044_13.raw\n",
      "13 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.0_13.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-08-LE-L-CC_3000x1200x40.4_0.0005_-0.171_13.raw\n",
      "16 -0.195 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.195_16.raw\n",
      "16 -0.137 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.137_16.raw\n",
      "16 -0.131 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.131_16.raw\n",
      "16 -0.1 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.1_16.raw\n",
      "16 -0.083 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.083_16.raw\n",
      "16 -0.08 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.08_16.raw\n",
      "16 -0.073 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.073_16.raw\n",
      "16 -0.038 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.038_16.raw\n",
      "16 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.0_16.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/MC-02-LE-L-CC_3000x1200x40.4_0.0005_-0.195_16.raw\n",
      "17 -0.172 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.172_17.raw\n",
      "17 -0.159 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.159_17.raw\n",
      "17 -0.131 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.131_17.raw\n",
      "17 -0.124 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.124_17.raw\n",
      "17 -0.09 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.09_17.raw\n",
      "17 -0.084 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.084_17.raw\n",
      "17 -0.018 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.018_17.raw\n",
      "17 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.0_17.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-L-CC_3000x1200x40.4_0.0005_-0.172_17.raw\n",
      "19 -0.169 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.169_19.raw\n",
      "19 -0.146 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.146_19.raw\n",
      "19 -0.082 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.082_19.raw\n",
      "19 -0.073 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.073_19.raw\n",
      "19 -0.072 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.072_19.raw\n",
      "19 -0.057 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.057_19.raw\n",
      "19 -0.021 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.021_19.raw\n",
      "19 -0.014 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.014_19.raw\n",
      "19 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.0_19.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-20-LE-R-CC_3000x1200x40.4_0.0005_-0.169_19.raw\n",
      "21 -0.193 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.193_21.raw\n",
      "21 -0.171 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.171_21.raw\n",
      "21 -0.103 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.103_21.raw\n",
      "21 -0.074 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.074_21.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 -0.067 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.067_21.raw\n",
      "21 -0.053 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.053_21.raw\n",
      "21 -0.026 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.026_21.raw\n",
      "21 -0.014 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.014_21.raw\n",
      "21 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.0_21.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-L-CC_3000x1200x40.4_0.0005_-0.193_21.raw\n",
      "23 -0.19 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.19_23.raw\n",
      "23 -0.149 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.149_23.raw\n",
      "23 -0.137 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.137_23.raw\n",
      "23 -0.129 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.129_23.raw\n",
      "23 -0.12 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.12_23.raw\n",
      "23 -0.103 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.103_23.raw\n",
      "23 -0.024 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.024_23.raw\n",
      "23 -0.016 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.016_23.raw\n",
      "23 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.0_23.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-19-LE-R-CC_3000x1200x40.4_0.0005_-0.19_23.raw\n",
      "25 -0.13 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.13_25.raw\n",
      "25 -0.105 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.105_25.raw\n",
      "25 -0.079 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.079_25.raw\n",
      "25 -0.078 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.078_25.raw\n",
      "25 -0.075 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.075_25.raw\n",
      "25 -0.064 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.064_25.raw\n",
      "25 -0.046 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.046_25.raw\n",
      "25 -0.024 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.024_25.raw\n",
      "25 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.0_25.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-L-CC_3000x1200x40.4_0.0005_-0.13_25.raw\n",
      "27 -0.192 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.192_27.raw\n",
      "27 -0.171 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.171_27.raw\n",
      "27 -0.145 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.145_27.raw\n",
      "27 -0.099 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.099_27.raw\n",
      "27 -0.085 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.085_27.raw\n",
      "27 -0.071 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.071_27.raw\n",
      "27 -0.059 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.059_27.raw\n",
      "27 -0.049 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.049_27.raw\n",
      "27 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.0_27.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-18-LE-R-CC_3000x1200x40.4_0.0005_-0.192_27.raw\n",
      "29 -0.184 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.184_29.raw\n",
      "29 -0.171 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.171_29.raw\n",
      "29 -0.104 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.104_29.raw\n",
      "29 -0.1 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.1_29.raw\n",
      "29 -0.097 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.097_29.raw\n",
      "29 -0.08 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.08_29.raw\n",
      "29 -0.042 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.042_29.raw\n",
      "29 -0.028 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.028_29.raw\n",
      "29 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.0_29.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-L-CC_3000x1200x40.4_0.0005_-0.184_29.raw\n",
      "31 -0.191 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.191_31.raw\n",
      "31 -0.182 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.182_31.raw\n",
      "31 -0.162 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.162_31.raw\n",
      "31 -0.141 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.141_31.raw\n",
      "31 -0.137 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.137_31.raw\n",
      "31 -0.029 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.029_31.raw\n",
      "31 -0.022 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.022_31.raw\n",
      "31 -0.012 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.012_31.raw\n",
      "31 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.0_31.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-17-LE-R-CC_3000x1200x40.4_0.0005_-0.191_31.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 -0.177 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.177_33.raw\n",
      "33 -0.167 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.167_33.raw\n",
      "33 -0.156 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.156_33.raw\n",
      "33 -0.133 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.133_33.raw\n",
      "33 -0.102 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.102_33.raw\n",
      "33 -0.047 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.047_33.raw\n",
      "33 -0.03 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.03_33.raw\n",
      "33 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.0_33.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-L-CC_3000x1200x40.4_0.0005_-0.177_33.raw\n",
      "35 -0.129 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.129_35.raw\n",
      "35 -0.126 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.126_35.raw\n",
      "35 -0.121 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.121_35.raw\n",
      "35 -0.098 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.098_35.raw\n",
      "35 -0.085 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.085_35.raw\n",
      "35 -0.052 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.052_35.raw\n",
      "35 -0.042 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.042_35.raw\n",
      "35 -0.041 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.041_35.raw\n",
      "35 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.0_35.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-16-LE-R-CC_3000x1200x40.4_0.0005_-0.129_35.raw\n",
      "37 -0.172 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.172_37.raw\n",
      "37 -0.115 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.115_37.raw\n",
      "37 -0.089 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.089_37.raw\n",
      "37 -0.082 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.082_37.raw\n",
      "37 -0.081 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.081_37.raw\n",
      "37 -0.078 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.078_37.raw\n",
      "37 -0.077 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.077_37.raw\n",
      "37 -0.062 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.062_37.raw\n",
      "37 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.0_37.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-L-CC_3000x1200x40.4_0.0005_-0.172_37.raw\n",
      "39 -0.168 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.168_39.raw\n",
      "39 -0.146 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.146_39.raw\n",
      "39 -0.121 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.121_39.raw\n",
      "39 -0.111 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.111_39.raw\n",
      "39 -0.06 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.06_39.raw\n",
      "39 -0.057 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.057_39.raw\n",
      "39 -0.051 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.051_39.raw\n",
      "39 -0.043 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.043_39.raw\n",
      "39 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.0_39.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-15-LE-R-CC_3000x1200x40.4_0.0005_-0.168_39.raw\n",
      "41 -0.2 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.2_41.raw\n",
      "41 -0.169 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.169_41.raw\n",
      "41 -0.157 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.157_41.raw\n",
      "41 -0.141 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.141_41.raw\n",
      "41 -0.13 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.13_41.raw\n",
      "41 -0.116 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.116_41.raw\n",
      "41 -0.104 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.104_41.raw\n",
      "41 -0.07 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.07_41.raw\n",
      "41 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.0_41.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-14-LE-R-CC_3000x1200x40.4_0.0005_-0.2_41.raw\n",
      "43 -0.179 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.179_43.raw\n",
      "43 -0.165 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.165_43.raw\n",
      "43 -0.116 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.116_43.raw\n",
      "43 -0.075 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.075_43.raw\n",
      "43 -0.072 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.072_43.raw\n",
      "43 -0.062 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.062_43.raw\n",
      "43 -0.03 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.03_43.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.0_43.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-11-LE-L-CC_3000x1200x40.4_0.0005_-0.179_43.raw\n",
      "44 -0.188 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.188_44.raw\n",
      "44 -0.184 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.184_44.raw\n",
      "44 -0.171 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.171_44.raw\n",
      "44 -0.102 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.102_44.raw\n",
      "44 -0.084 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.084_44.raw\n",
      "44 -0.075 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.075_44.raw\n",
      "44 -0.041 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.041_44.raw\n",
      "44 -0.032 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.032_44.raw\n",
      "44 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.0_44.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-10-LE-R-CC_3000x1200x40.4_0.0005_-0.188_44.raw\n",
      "45 -0.198 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.198_45.raw\n",
      "45 -0.186 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.186_45.raw\n",
      "45 -0.123 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.123_45.raw\n",
      "45 -0.118 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.118_45.raw\n",
      "45 -0.113 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.113_45.raw\n",
      "45 -0.101 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.101_45.raw\n",
      "45 -0.016 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.016_45.raw\n",
      "45 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.0_45.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-08-LE-R-CC_3000x1200x40.4_0.0005_-0.198_45.raw\n",
      "47 -0.195 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.195_47.raw\n",
      "47 -0.188 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.188_47.raw\n",
      "47 -0.135 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.135_47.raw\n",
      "47 -0.131 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.131_47.raw\n",
      "47 -0.074 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.074_47.raw\n",
      "47 -0.071 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.071_47.raw\n",
      "47 -0.029 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.029_47.raw\n",
      "47 -0.025 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.025_47.raw\n",
      "47 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.0_47.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-05-LE-R-CC_3000x1200x40.4_0.0005_-0.195_47.raw\n",
      "50 -0.196 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.196_50.raw\n",
      "50 -0.165 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.165_50.raw\n",
      "50 -0.148 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.148_50.raw\n",
      "50 -0.125 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.125_50.raw\n",
      "50 -0.079 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.079_50.raw\n",
      "50 -0.054 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.054_50.raw\n",
      "50 -0.031 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.031_50.raw\n",
      "50 -0.022 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.022_50.raw\n",
      "50 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.0_50.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-03-LE-L-CC_3000x1200x40.4_0.0005_-0.196_50.raw\n",
      "52 -0.18 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.18_52.raw\n",
      "52 -0.178 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.178_52.raw\n",
      "52 -0.167 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.167_52.raw\n",
      "52 -0.163 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.163_52.raw\n",
      "52 -0.156 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.156_52.raw\n",
      "52 -0.097 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.097_52.raw\n",
      "52 -0.068 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.068_52.raw\n",
      "52 -0.058 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.058_52.raw\n",
      "52 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.0_52.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-02-LE-L-CC_3000x1200x40.4_0.0005_-0.18_52.raw\n",
      "54 -0.183 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.183_54.raw\n",
      "54 -0.18 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.18_54.raw\n",
      "54 -0.166 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.166_54.raw\n",
      "54 -0.153 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.153_54.raw\n",
      "54 -0.1 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.1_54.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 -0.097 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.097_54.raw\n",
      "54 -0.077 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.077_54.raw\n",
      "54 -0.054 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.054_54.raw\n",
      "54 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.0_54.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/CE-01-LE-L-CC_3000x1200x40.4_0.0005_-0.183_54.raw\n",
      "55 -0.196 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.196_55.raw\n",
      "55 -0.195 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.195_55.raw\n",
      "55 -0.162 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.162_55.raw\n",
      "55 -0.157 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.157_55.raw\n",
      "55 -0.156 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.156_55.raw\n",
      "55 -0.12 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.12_55.raw\n",
      "55 -0.117 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.117_55.raw\n",
      "55 -0.05 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.05_55.raw\n",
      "55 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.0_55.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-36-LE-R-CC_3000x1200x40.4_0.0005_-0.196_55.raw\n",
      "58 -0.182 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.182_58.raw\n",
      "58 -0.135 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.135_58.raw\n",
      "58 -0.132 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.132_58.raw\n",
      "58 -0.096 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.096_58.raw\n",
      "58 -0.089 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.089_58.raw\n",
      "58 -0.074 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.074_58.raw\n",
      "58 -0.063 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.063_58.raw\n",
      "58 -0.028 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.028_58.raw\n",
      "58 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.0_58.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-31-LE-R-CC_3000x1200x40.4_0.0005_-0.182_58.raw\n",
      "59 -0.194 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.194_59.raw\n",
      "59 -0.17 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.17_59.raw\n",
      "59 -0.169 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.169_59.raw\n",
      "59 -0.126 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.126_59.raw\n",
      "59 -0.109 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.109_59.raw\n",
      "59 -0.077 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.077_59.raw\n",
      "59 -0.033 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.033_59.raw\n",
      "59 -0.029 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.029_59.raw\n",
      "59 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.0_59.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-CC_3000x1200x40.4_0.0005_-0.194_59.raw\n",
      "60 -0.155 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.155_60.raw\n",
      "60 -0.147 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.147_60.raw\n",
      "60 -0.113 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.113_60.raw\n",
      "60 -0.088 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.088_60.raw\n",
      "60 -0.073 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.073_60.raw\n",
      "60 -0.06 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.06_60.raw\n",
      "60 -0.049 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.049_60.raw\n",
      "60 -0.032 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.032_60.raw\n",
      "60 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.0_60.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-29-LE-L-MLO_3000x1200x40.4_0.0005_-0.155_60.raw\n",
      "61 -0.198 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.198_61.raw\n",
      "61 -0.175 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.175_61.raw\n",
      "61 -0.157 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.157_61.raw\n",
      "61 -0.131 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.131_61.raw\n",
      "61 -0.108 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.108_61.raw\n",
      "61 -0.038 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.038_61.raw\n",
      "61 -0.013 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.013_61.raw\n",
      "61 -0.012 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.012_61.raw\n",
      "61 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.0_61.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-MLO_3000x1200x40.4_0.0005_-0.198_61.raw\n",
      "62 -0.194 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.194_62.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 -0.188 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.188_62.raw\n",
      "62 -0.179 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.179_62.raw\n",
      "62 -0.169 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.169_62.raw\n",
      "62 -0.166 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.166_62.raw\n",
      "62 -0.112 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.112_62.raw\n",
      "62 -0.068 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.068_62.raw\n",
      "62 -0.015 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.015_62.raw\n",
      "62 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.0_62.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-24-LE-R-CC_3000x1200x40.4_0.0005_-0.194_62.raw\n",
      "64 -0.182 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.182_64.raw\n",
      "64 -0.16 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.16_64.raw\n",
      "64 -0.146 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.146_64.raw\n",
      "64 -0.098 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.098_64.raw\n",
      "64 -0.061 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.061_64.raw\n",
      "64 -0.038 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.038_64.raw\n",
      "64 -0.026 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.026_64.raw\n",
      "64 -0.011 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.011_64.raw\n",
      "64 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.0_64.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-CC_3000x1200x40.4_0.0005_-0.182_64.raw\n",
      "65 -0.156 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.156_65.raw\n",
      "65 -0.143 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.143_65.raw\n",
      "65 -0.103 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.103_65.raw\n",
      "65 -0.098 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.098_65.raw\n",
      "65 -0.092 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.092_65.raw\n",
      "65 -0.042 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.042_65.raw\n",
      "65 -0.039 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.039_65.raw\n",
      "65 -0.038 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.038_65.raw\n",
      "65 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.0_65.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-23-LE-R-MLO_3000x1200x40.4_0.0005_-0.156_65.raw\n",
      "66 -0.198 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.198_66.raw\n",
      "66 -0.183 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.183_66.raw\n",
      "66 -0.157 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.157_66.raw\n",
      "66 -0.115 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.115_66.raw\n",
      "66 -0.087 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.087_66.raw\n",
      "66 -0.048 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.048_66.raw\n",
      "66 -0.039 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.039_66.raw\n",
      "66 -0.021 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.021_66.raw\n",
      "66 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.0_66.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-MLO_3000x1200x40.4_0.0005_-0.198_66.raw\n",
      "67 -0.199 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.199_67.raw\n",
      "67 -0.181 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.181_67.raw\n",
      "67 -0.155 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.155_67.raw\n",
      "67 -0.143 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.143_67.raw\n",
      "67 -0.133 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.133_67.raw\n",
      "67 -0.107 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.107_67.raw\n",
      "67 -0.088 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.088_67.raw\n",
      "67 -0.065 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.065_67.raw\n",
      "67 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.0_67.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-22-LE-L-CC_3000x1200x40.4_0.0005_-0.199_67.raw\n",
      "68 -0.151 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.151_68.raw\n",
      "68 -0.115 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.115_68.raw\n",
      "68 -0.11 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.11_68.raw\n",
      "68 -0.087 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.087_68.raw\n",
      "68 -0.068 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.068_68.raw\n",
      "68 -0.02 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.02_68.raw\n",
      "68 -0.013 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.013_68.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 -0.012 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.012_68.raw\n",
      "68 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.0_68.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-CC_3000x1200x40.4_0.0005_-0.151_68.raw\n",
      "69 -0.164 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.164_69.raw\n",
      "69 -0.152 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.152_69.raw\n",
      "69 -0.124 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.124_69.raw\n",
      "69 -0.118 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.118_69.raw\n",
      "69 -0.095 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.095_69.raw\n",
      "69 -0.082 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.082_69.raw\n",
      "69 -0.023 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.023_69.raw\n",
      "69 -0.014 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.014_69.raw\n",
      "69 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.0_69.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-19-LE-R-MLO_3000x1200x40.4_0.0005_-0.164_69.raw\n",
      "70 -0.2 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.2_70.raw\n",
      "70 -0.185 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.185_70.raw\n",
      "70 -0.179 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.179_70.raw\n",
      "70 -0.15 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.15_70.raw\n",
      "70 -0.138 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.138_70.raw\n",
      "70 -0.056 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.056_70.raw\n",
      "70 -0.023 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.023_70.raw\n",
      "70 -0.02 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.02_70.raw\n",
      "70 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.0_70.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-MLO_3000x1200x40.4_0.0005_-0.2_70.raw\n",
      "71 -0.199 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.199_71.raw\n",
      "71 -0.189 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.189_71.raw\n",
      "71 -0.149 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.149_71.raw\n",
      "71 -0.049 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.049_71.raw\n",
      "71 -0.021 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.021_71.raw\n",
      "71 -0.018 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.018_71.raw\n",
      "71 -0.017 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.017_71.raw\n",
      "71 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.0_71.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-16-LE-L-CC_3000x1200x40.4_0.0005_-0.199_71.raw\n",
      "72 -0.195 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.195_72.raw\n",
      "72 -0.169 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.169_72.raw\n",
      "72 -0.161 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.161_72.raw\n",
      "72 -0.117 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.117_72.raw\n",
      "72 -0.116 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.116_72.raw\n",
      "72 -0.075 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.075_72.raw\n",
      "72 -0.029 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.029_72.raw\n",
      "72 -0.014 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.014_72.raw\n",
      "72 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.0_72.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-CC_3000x1200x40.4_0.0005_-0.195_72.raw\n",
      "73 -0.183 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.183_73.raw\n",
      "73 -0.161 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.161_73.raw\n",
      "73 -0.148 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.148_73.raw\n",
      "73 -0.137 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.137_73.raw\n",
      "73 -0.056 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.056_73.raw\n",
      "73 -0.026 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.026_73.raw\n",
      "73 -0.013 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.013_73.raw\n",
      "73 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.0_73.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-13-LE-R-MLO_3000x1200x40.4_0.0005_-0.183_73.raw\n",
      "74 -0.197 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.197_74.raw\n",
      "74 -0.165 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.165_74.raw\n",
      "74 -0.154 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.154_74.raw\n",
      "74 -0.111 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.111_74.raw\n",
      "74 -0.106 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.106_74.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 -0.102 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.102_74.raw\n",
      "74 -0.084 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.084_74.raw\n",
      "74 -0.046 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.046_74.raw\n",
      "74 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.0_74.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-MLO_3000x1200x40.4_0.0005_-0.197_74.raw\n",
      "75 -0.191 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.191_75.raw\n",
      "75 -0.19 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.19_75.raw\n",
      "75 -0.084 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.084_75.raw\n",
      "75 -0.065 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.065_75.raw\n",
      "75 -0.054 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.054_75.raw\n",
      "75 -0.029 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.029_75.raw\n",
      "75 -0.016 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.016_75.raw\n",
      "75 -0.014 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.014_75.raw\n",
      "75 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.0_75.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-09-LE-R-CC_3000x1200x40.4_0.0005_-0.191_75.raw\n",
      "76 -0.159 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.159_76.raw\n",
      "76 -0.149 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.149_76.raw\n",
      "76 -0.147 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.147_76.raw\n",
      "76 -0.116 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.116_76.raw\n",
      "76 -0.114 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.114_76.raw\n",
      "76 -0.067 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.067_76.raw\n",
      "76 -0.011 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.011_76.raw\n",
      "76 -0.0 (40, 1200, 3000) /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.0_76.raw\n",
      "Main file:  /media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/AR-06-LE-L-CC_3000x1200x40.4_0.0005_-0.159_76.raw\n"
     ]
    }
   ],
   "source": [
    "# [STAR] Code to get the patches\n",
    "import numpy as np\n",
    "\n",
    "#todo = [15, 16, 19, 20, 27, 29, 31, 35]\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "all_list = np.concatenate([train_list, val_list, test_list])\n",
    "\n",
    "for i in range(1, 77):\n",
    "    if i not in all_list:\n",
    "        continue\n",
    "    \n",
    "    #todo = [15, 16, 19, 20, 27, 29, 31, 35]\n",
    "    #allfiles = glob.glob(\"/media/drilnvm/ubuntudata2/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(i)+\".raw\")\n",
    "    allfiles = glob.glob(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/RECONS-NORMAL-QUADRATIC/*_\"+str(i)+\".raw\")\n",
    "    allfiles.sort(key=lambda x: float(x.split('/')[-1].split('_')[-2]), reverse=False)\n",
    "    \n",
    "    mainfile = allfiles[0]#glob.glob(\"/media/drilnvm/ubuntudata2/REAL-DBT-PROJECTIONS/RECONS-LINEAR/*_\"+str(i)+\".raw\")[0]\n",
    "    \n",
    "    all_vols   = np.zeros([len(allfiles), 40, 1200, 3000], dtype='float16')\n",
    "    all_index  = []\n",
    "    all_values = []\n",
    "    all_values_z = []\n",
    "    \n",
    "    #temp = np.fromfile(mainfile, dtype='float32')\n",
    "    #temp = np.reshape(temp, [40, 1200, 3000])\n",
    "    #all_vols[0, :, :, :] = temp\n",
    "    #all_index.append(i)\n",
    "    #all_values.append(-0)\n",
    "    \n",
    "    counter = 0\n",
    "    for f in allfiles:\n",
    "        a = np.fromfile(f, dtype='float32')\n",
    "        a = np.reshape(a, [40, 1200, 3000]).astype('float16')\n",
    "        #a     = np.load(f)\n",
    "        #a     = np.reshape(a, [40, 1200, 3000])\n",
    "        all_vols[counter, :, :, :] = a\n",
    "        \n",
    "        index = int(f.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "        value = float(f.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        \n",
    "        all_index.append(index)\n",
    "        all_values.append(value)\n",
    "        #all_values_z.append()\n",
    "        \n",
    "        print(index, value, a.shape, f)\n",
    "        counter = counter+1\n",
    "    \n",
    "    total_count   = 50\n",
    "    all_locations = []\n",
    "    \n",
    "    print('Main file: ', mainfile)\n",
    "    \n",
    "    # Get all Locations\n",
    "    while(True):\n",
    "        ix = np.random.randint(256, 1200-256)\n",
    "        iy = np.random.randint(256, 3000-256)\n",
    "        iz = np.random.randint(5, 35)\n",
    "        \n",
    "        tempx = all_vols[0][iz, ix:ix+256, iy:iy+256]\n",
    "        \n",
    "        if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "            continue\n",
    "        \n",
    "        all_locations.append([ix, iy, iz])\n",
    "        if len(all_locations) == total_count:\n",
    "            break\n",
    "    \n",
    "    # Get patches\n",
    "    for k in range(len(all_vols)):\n",
    "        y_array = np.zeros([total_count, 256, 256, 1], dtype='float16')\n",
    "        counter = 0\n",
    "        \n",
    "        all_values_z = []\n",
    "        for p in all_locations:\n",
    "            iz = p[2]\n",
    "            ix = p[0]\n",
    "            iy = p[1]\n",
    "            \n",
    "            all_values_z.append(iz)\n",
    "            tempy   = all_vols[k][iz, ix:ix+256, iy:iy+256]\n",
    "            y_array[counter, :, :, 0] = tempy\n",
    "            counter = counter+1\n",
    "        np.save(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-\"+str(all_index[k])+'_'+str(all_values[k])+'.npy', y_array)\n",
    "        np.save(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/zvalue-\"+str(all_index[k])+'_'+str(all_values[k])+'.npy',   all_values_z)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.171.npy (50, 256, 256, 1) -0.171\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.137.npy (50, 256, 256, 1) -0.137\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.063.npy (50, 256, 256, 1) -0.063\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.167.npy (50, 256, 256, 1) -0.167\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.113.npy (50, 256, 256, 1) -0.113\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.011.npy (50, 256, 256, 1) -0.011\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.091.npy (50, 256, 256, 1) -0.091\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-1_-0.033.npy (50, 256, 256, 1) -0.033\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.052.npy (50, 256, 256, 1) -0.052\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.159.npy (50, 256, 256, 1) -0.159\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.056.npy (50, 256, 256, 1) -0.056\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.065.npy (50, 256, 256, 1) -0.065\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.164.npy (50, 256, 256, 1) -0.164\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.08.npy (50, 256, 256, 1) -0.08\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.096.npy (50, 256, 256, 1) -0.096\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-3_-0.086.npy (50, 256, 256, 1) -0.086\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.163.npy (50, 256, 256, 1) -0.163\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.113.npy (50, 256, 256, 1) -0.113\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.083.npy (50, 256, 256, 1) -0.083\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.033.npy (50, 256, 256, 1) -0.033\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.02.npy (50, 256, 256, 1) -0.02\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.016.npy (50, 256, 256, 1) -0.016\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.05.npy (50, 256, 256, 1) -0.05\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-6_-0.172.npy (50, 256, 256, 1) -0.172\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.088.npy (50, 256, 256, 1) -0.088\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.04.npy (50, 256, 256, 1) -0.04\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.089.npy (50, 256, 256, 1) -0.089\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.067.npy (50, 256, 256, 1) -0.067\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.076.npy (50, 256, 256, 1) -0.076\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.174.npy (50, 256, 256, 1) -0.174\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.023.npy (50, 256, 256, 1) -0.023\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-7_-0.151.npy (50, 256, 256, 1) -0.151\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.043.npy (50, 256, 256, 1) -0.043\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.08.npy (50, 256, 256, 1) -0.08\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.145.npy (50, 256, 256, 1) -0.145\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.103.npy (50, 256, 256, 1) -0.103\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.165.npy (50, 256, 256, 1) -0.165\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.066.npy (50, 256, 256, 1) -0.066\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.038.npy (50, 256, 256, 1) -0.038\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-11_-0.072.npy (50, 256, 256, 1) -0.072\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.193.npy (50, 256, 256, 1) -0.193\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.038.npy (50, 256, 256, 1) -0.038\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.025.npy (50, 256, 256, 1) -0.025\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.138.npy (50, 256, 256, 1) -0.138\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.077.npy (50, 256, 256, 1) -0.077\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.117.npy (50, 256, 256, 1) -0.117\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.06.npy (50, 256, 256, 1) -0.06\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-12_-0.173.npy (50, 256, 256, 1) -0.173\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.044.npy (50, 256, 256, 1) -0.044\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.101.npy (50, 256, 256, 1) -0.101\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.071.npy (50, 256, 256, 1) -0.071\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.107.npy (50, 256, 256, 1) -0.107\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.108.npy (50, 256, 256, 1) -0.108\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.128.npy (50, 256, 256, 1) -0.128\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.067.npy (50, 256, 256, 1) -0.067\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-13_-0.171.npy (50, 256, 256, 1) -0.171\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.038.npy (50, 256, 256, 1) -0.038\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.131.npy (50, 256, 256, 1) -0.131\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.195.npy (50, 256, 256, 1) -0.195\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.08.npy (50, 256, 256, 1) -0.08\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.083.npy (50, 256, 256, 1) -0.083\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.137.npy (50, 256, 256, 1) -0.137\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.1.npy (50, 256, 256, 1) -0.1\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-16_-0.073.npy (50, 256, 256, 1) -0.073\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.131.npy (50, 256, 256, 1) -0.131\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.084.npy (50, 256, 256, 1) -0.084\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.018.npy (50, 256, 256, 1) -0.018\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.159.npy (50, 256, 256, 1) -0.159\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.124.npy (50, 256, 256, 1) -0.124\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.172.npy (50, 256, 256, 1) -0.172\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-17_-0.09.npy (50, 256, 256, 1) -0.09\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.029.npy (50, 256, 256, 1) -0.029\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.141.npy (50, 256, 256, 1) -0.141\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.022.npy (50, 256, 256, 1) -0.022\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.012.npy (50, 256, 256, 1) -0.012\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.191.npy (50, 256, 256, 1) -0.191\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.162.npy (50, 256, 256, 1) -0.162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.182.npy (50, 256, 256, 1) -0.182\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-31_-0.137.npy (50, 256, 256, 1) -0.137\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.133.npy (50, 256, 256, 1) -0.133\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.102.npy (50, 256, 256, 1) -0.102\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.177.npy (50, 256, 256, 1) -0.177\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.047.npy (50, 256, 256, 1) -0.047\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.03.npy (50, 256, 256, 1) -0.03\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.167.npy (50, 256, 256, 1) -0.167\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-33_-0.156.npy (50, 256, 256, 1) -0.156\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.126.npy (50, 256, 256, 1) -0.126\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.042.npy (50, 256, 256, 1) -0.042\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.121.npy (50, 256, 256, 1) -0.121\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.085.npy (50, 256, 256, 1) -0.085\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.129.npy (50, 256, 256, 1) -0.129\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.052.npy (50, 256, 256, 1) -0.052\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.041.npy (50, 256, 256, 1) -0.041\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-35_-0.098.npy (50, 256, 256, 1) -0.098\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.077.npy (50, 256, 256, 1) -0.077\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.082.npy (50, 256, 256, 1) -0.082\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.089.npy (50, 256, 256, 1) -0.089\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.115.npy (50, 256, 256, 1) -0.115\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.062.npy (50, 256, 256, 1) -0.062\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.078.npy (50, 256, 256, 1) -0.078\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.081.npy (50, 256, 256, 1) -0.081\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-37_-0.172.npy (50, 256, 256, 1) -0.172\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.051.npy (50, 256, 256, 1) -0.051\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.111.npy (50, 256, 256, 1) -0.111\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.057.npy (50, 256, 256, 1) -0.057\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.121.npy (50, 256, 256, 1) -0.121\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.043.npy (50, 256, 256, 1) -0.043\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.146.npy (50, 256, 256, 1) -0.146\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.06.npy (50, 256, 256, 1) -0.06\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-39_-0.168.npy (50, 256, 256, 1) -0.168\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.07.npy (50, 256, 256, 1) -0.07\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.2.npy (50, 256, 256, 1) -0.2\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.116.npy (50, 256, 256, 1) -0.116\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.13.npy (50, 256, 256, 1) -0.13\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.104.npy (50, 256, 256, 1) -0.104\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.157.npy (50, 256, 256, 1) -0.157\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.141.npy (50, 256, 256, 1) -0.141\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-41_-0.169.npy (50, 256, 256, 1) -0.169\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.179.npy (50, 256, 256, 1) -0.179\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.075.npy (50, 256, 256, 1) -0.075\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.165.npy (50, 256, 256, 1) -0.165\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.03.npy (50, 256, 256, 1) -0.03\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.116.npy (50, 256, 256, 1) -0.116\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.062.npy (50, 256, 256, 1) -0.062\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-43_-0.072.npy (50, 256, 256, 1) -0.072\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.125.npy (50, 256, 256, 1) -0.125\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.054.npy (50, 256, 256, 1) -0.054\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.165.npy (50, 256, 256, 1) -0.165\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.196.npy (50, 256, 256, 1) -0.196\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.079.npy (50, 256, 256, 1) -0.079\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.022.npy (50, 256, 256, 1) -0.022\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.031.npy (50, 256, 256, 1) -0.031\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-50_-0.148.npy (50, 256, 256, 1) -0.148\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.18.npy (50, 256, 256, 1) -0.18\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.167.npy (50, 256, 256, 1) -0.167\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.058.npy (50, 256, 256, 1) -0.058\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.163.npy (50, 256, 256, 1) -0.163\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.068.npy (50, 256, 256, 1) -0.068\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.097.npy (50, 256, 256, 1) -0.097\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.178.npy (50, 256, 256, 1) -0.178\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-52_-0.156.npy (50, 256, 256, 1) -0.156\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.195.npy (50, 256, 256, 1) -0.195\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.156.npy (50, 256, 256, 1) -0.156\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.157.npy (50, 256, 256, 1) -0.157\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.162.npy (50, 256, 256, 1) -0.162\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.117.npy (50, 256, 256, 1) -0.117\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.12.npy (50, 256, 256, 1) -0.12\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.196.npy (50, 256, 256, 1) -0.196\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-55_-0.05.npy (50, 256, 256, 1) -0.05\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.115.npy (50, 256, 256, 1) -0.115\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.012.npy (50, 256, 256, 1) -0.012\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.087.npy (50, 256, 256, 1) -0.087\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.013.npy (50, 256, 256, 1) -0.013\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.068.npy (50, 256, 256, 1) -0.068\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.11.npy (50, 256, 256, 1) -0.11\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.151.npy (50, 256, 256, 1) -0.151\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-68_-0.02.npy (50, 256, 256, 1) -0.02\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.124.npy (50, 256, 256, 1) -0.124\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.095.npy (50, 256, 256, 1) -0.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.152.npy (50, 256, 256, 1) -0.152\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.164.npy (50, 256, 256, 1) -0.164\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.082.npy (50, 256, 256, 1) -0.082\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.118.npy (50, 256, 256, 1) -0.118\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.014.npy (50, 256, 256, 1) -0.014\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-69_-0.023.npy (50, 256, 256, 1) -0.023\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.056.npy (50, 256, 256, 1) -0.056\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.179.npy (50, 256, 256, 1) -0.179\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.15.npy (50, 256, 256, 1) -0.15\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.2.npy (50, 256, 256, 1) -0.2\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.138.npy (50, 256, 256, 1) -0.138\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.185.npy (50, 256, 256, 1) -0.185\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.02.npy (50, 256, 256, 1) -0.02\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-70_-0.023.npy (50, 256, 256, 1) -0.023\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.018.npy (50, 256, 256, 1) -0.018\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.021.npy (50, 256, 256, 1) -0.021\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.149.npy (50, 256, 256, 1) -0.149\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.049.npy (50, 256, 256, 1) -0.049\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.199.npy (50, 256, 256, 1) -0.199\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.189.npy (50, 256, 256, 1) -0.189\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-71_-0.017.npy (50, 256, 256, 1) -0.017\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.116.npy (50, 256, 256, 1) -0.116\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.014.npy (50, 256, 256, 1) -0.014\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.117.npy (50, 256, 256, 1) -0.117\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.195.npy (50, 256, 256, 1) -0.195\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.075.npy (50, 256, 256, 1) -0.075\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.029.npy (50, 256, 256, 1) -0.029\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.169.npy (50, 256, 256, 1) -0.169\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-72_-0.161.npy (50, 256, 256, 1) -0.161\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.161.npy (50, 256, 256, 1) -0.161\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.148.npy (50, 256, 256, 1) -0.148\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.183.npy (50, 256, 256, 1) -0.183\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.026.npy (50, 256, 256, 1) -0.026\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.056.npy (50, 256, 256, 1) -0.056\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.137.npy (50, 256, 256, 1) -0.137\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-73_-0.013.npy (50, 256, 256, 1) -0.013\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.067.npy (50, 256, 256, 1) -0.067\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.159.npy (50, 256, 256, 1) -0.159\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.149.npy (50, 256, 256, 1) -0.149\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.147.npy (50, 256, 256, 1) -0.147\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.114.npy (50, 256, 256, 1) -0.114\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.011.npy (50, 256, 256, 1) -0.011\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-76_-0.116.npy (50, 256, 256, 1) -0.116\n",
      "(10100, 1, 256, 256) (10100, 1, 256, 256) (10100, 1) 10100\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.021.npy (50, 256, 256, 1) -0.021\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.146.npy (50, 256, 256, 1) -0.146\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.169.npy (50, 256, 256, 1) -0.169\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.082.npy (50, 256, 256, 1) -0.082\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.014.npy (50, 256, 256, 1) -0.014\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.057.npy (50, 256, 256, 1) -0.057\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.072.npy (50, 256, 256, 1) -0.072\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-19_-0.073.npy (50, 256, 256, 1) -0.073\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.067.npy (50, 256, 256, 1) -0.067\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.193.npy (50, 256, 256, 1) -0.193\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.053.npy (50, 256, 256, 1) -0.053\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.103.npy (50, 256, 256, 1) -0.103\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.014.npy (50, 256, 256, 1) -0.014\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.171.npy (50, 256, 256, 1) -0.171\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.026.npy (50, 256, 256, 1) -0.026\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-21_-0.074.npy (50, 256, 256, 1) -0.074\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.024.npy (50, 256, 256, 1) -0.024\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.103.npy (50, 256, 256, 1) -0.103\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.149.npy (50, 256, 256, 1) -0.149\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.137.npy (50, 256, 256, 1) -0.137\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.19.npy (50, 256, 256, 1) -0.19\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.129.npy (50, 256, 256, 1) -0.129\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.12.npy (50, 256, 256, 1) -0.12\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-23_-0.016.npy (50, 256, 256, 1) -0.016\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.105.npy (50, 256, 256, 1) -0.105\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.078.npy (50, 256, 256, 1) -0.078\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.13.npy (50, 256, 256, 1) -0.13\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.075.npy (50, 256, 256, 1) -0.075\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.046.npy (50, 256, 256, 1) -0.046\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.024.npy (50, 256, 256, 1) -0.024\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.079.npy (50, 256, 256, 1) -0.079\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-25_-0.064.npy (50, 256, 256, 1) -0.064\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.071.npy (50, 256, 256, 1) -0.071\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.085.npy (50, 256, 256, 1) -0.085\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.171.npy (50, 256, 256, 1) -0.171\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.099.npy (50, 256, 256, 1) -0.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.049.npy (50, 256, 256, 1) -0.049\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.059.npy (50, 256, 256, 1) -0.059\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.192.npy (50, 256, 256, 1) -0.192\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-27_-0.145.npy (50, 256, 256, 1) -0.145\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.171.npy (50, 256, 256, 1) -0.171\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.097.npy (50, 256, 256, 1) -0.097\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.184.npy (50, 256, 256, 1) -0.184\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.1.npy (50, 256, 256, 1) -0.1\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.028.npy (50, 256, 256, 1) -0.028\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.104.npy (50, 256, 256, 1) -0.104\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.042.npy (50, 256, 256, 1) -0.042\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-29_-0.08.npy (50, 256, 256, 1) -0.08\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.131.npy (50, 256, 256, 1) -0.131\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.012.npy (50, 256, 256, 1) -0.012\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.157.npy (50, 256, 256, 1) -0.157\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.198.npy (50, 256, 256, 1) -0.198\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.038.npy (50, 256, 256, 1) -0.038\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.108.npy (50, 256, 256, 1) -0.108\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.175.npy (50, 256, 256, 1) -0.175\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-61_-0.013.npy (50, 256, 256, 1) -0.013\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.112.npy (50, 256, 256, 1) -0.112\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.188.npy (50, 256, 256, 1) -0.188\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.179.npy (50, 256, 256, 1) -0.179\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.068.npy (50, 256, 256, 1) -0.068\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.169.npy (50, 256, 256, 1) -0.169\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.015.npy (50, 256, 256, 1) -0.015\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.166.npy (50, 256, 256, 1) -0.166\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-62_-0.194.npy (50, 256, 256, 1) -0.194\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.146.npy (50, 256, 256, 1) -0.146\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.098.npy (50, 256, 256, 1) -0.098\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.182.npy (50, 256, 256, 1) -0.182\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.061.npy (50, 256, 256, 1) -0.061\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.026.npy (50, 256, 256, 1) -0.026\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.038.npy (50, 256, 256, 1) -0.038\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.16.npy (50, 256, 256, 1) -0.16\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-64_-0.011.npy (50, 256, 256, 1) -0.011\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.042.npy (50, 256, 256, 1) -0.042\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.098.npy (50, 256, 256, 1) -0.098\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.039.npy (50, 256, 256, 1) -0.039\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.103.npy (50, 256, 256, 1) -0.103\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.143.npy (50, 256, 256, 1) -0.143\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.092.npy (50, 256, 256, 1) -0.092\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.156.npy (50, 256, 256, 1) -0.156\n",
      "/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-65_-0.038.npy (50, 256, 256, 1) -0.038\n",
      "(4000, 1, 256, 256) (4000, 1, 256, 256) (4000, 1) 4000\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For reading the training data\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "# 10650, 3950\n",
    "# 8200, 3160\n",
    "# 10250, 3950\n",
    "\n",
    "#11700\n",
    "#10400\n",
    "train_size = 10100\n",
    "x_array = np.zeros([train_size, 1, 256, 256], dtype='float16')\n",
    "z_array = np.zeros([train_size, 1], dtype='float16')\n",
    "v_array = np.zeros([train_size, 1], dtype='float16')\n",
    "y_array = np.zeros([train_size, 1, 256, 256], dtype='float16')\n",
    "\n",
    "# 4500\n",
    "# 3950\n",
    "val_size = 4000\n",
    "x_val_array = np.zeros([val_size, 1, 256, 256], dtype='float16')\n",
    "z_val_array = np.zeros([val_size, 1], dtype='float16')\n",
    "v_val_array = np.zeros([val_size, 1], dtype='float16')\n",
    "y_val_array = np.zeros([val_size, 1, 256, 256], dtype='float16')\n",
    "\n",
    "count = 0\n",
    "for t in train_list:\n",
    "    #print(t)\n",
    "    maintemp = np.load(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-\"+str(t)+\"_-0.0.npy\")\n",
    "    #maintemp = np.load(mainfile)\n",
    "    \n",
    "    allfiles = glob.glob(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-\"+str(t)+\"_*.npy\")\n",
    "    for f in allfiles:\n",
    "        if '-0.0.npy' in f:\n",
    "            continue\n",
    "        temp  = np.load(f)\n",
    "        temp1 = np.load(f.replace('imgarray', 'zvalue')) \n",
    "        #print(temp.shape)\n",
    "        print(f, temp.shape, float(f.split(\"/\")[-1].split(\"_\")[1][:-4]))\n",
    "        y_array[count: count+50, 0, :, :] = temp[:, :, :, 0]\n",
    "        x_array[count: count+50, 0, :, :] = maintemp[:, :, :, 0]\n",
    "        z_array[count: count+50, :]       = -np.ones([50, 1])*float(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "        v_array[count: count+50, :]       = np.expand_dims(temp1, axis=1)\n",
    "        count = count+50\n",
    "\n",
    "print(x_array.shape, y_array.shape, z_array.shape, count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for t in val_list:\n",
    "    #print(t)\n",
    "    maintemp = np.load(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-\"+str(t)+\"_-0.0.npy\")\n",
    "    #maintemp = np.load(mainfile)\n",
    "    \n",
    "    allfiles = glob.glob(\"/media/drilnvm/ubuntudata1/REAL-DBT-PROJECTIONS/PATCHES-NEW-NORMAL/imgarray-\"+str(t)+\"_*.npy\")\n",
    "    for f in allfiles:\n",
    "        if '-0.0.npy' in f:\n",
    "            continue\n",
    "        temp  = np.load(f)\n",
    "        temp1 = np.load(f.replace('imgarray', 'zvalue'))\n",
    "        \n",
    "        print(f, temp.shape, float(f.split(\"/\")[-1].split(\"_\")[1][:-4]))\n",
    "        y_val_array[count: count+50, 0, :, :] = temp[:50, :, :, 0]\n",
    "        x_val_array[count: count+50, 0, :, :] = maintemp[:50, :, :, 0]\n",
    "        z_val_array[count: count+50, :]       = -np.ones([50, 1])*float(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "        v_val_array[count: count+50, :]           = np.expand_dims(temp1, axis=1)\n",
    "        count = count+50\n",
    "        \n",
    "print(x_val_array.shape, y_val_array.shape, z_val_array.shape, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN pytorch\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(rating_cnn.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min = 1000\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    rating_cnn.train()\n",
    "    loss_array = []\n",
    "    \n",
    "    for i in range(len(trainx)//32):\n",
    "        x = trainx[i*32:(i+1)*32, :, :, :]\n",
    "        y = trainy[i*32:(i+1)*32, :]\n",
    "        #z = z_array[i*8:(i+1)*8, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        #z = torch.tensor(z, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = rating_cnn(x)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape, y.data.shape)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i %100 == 0:\n",
    "            rating_cnn.eval()\n",
    "            loss_array_val = []\n",
    "            for ik in range(len(valx)//8):\n",
    "                x = valx[ik*8:(ik+1)*8, :, :, :]\n",
    "                y = valy[ik*8:(ik+1)*8, :]\n",
    "                #z = z_val_array[i*8:(i+1)*8, :]\n",
    "\n",
    "                x = torch.tensor(x, device=device).float()\n",
    "                y = torch.tensor(y, device=device).float()\n",
    "                #z = torch.tensor(z, device=device).float()\n",
    "\n",
    "                output = rating_cnn(x)\n",
    "\n",
    "                loss = criterion(output, y)\n",
    "                loss_array_val.append(loss.item())\n",
    "\n",
    "            val_loss = np.mean(loss_array_val)\n",
    "            print(\"Val loss \", val_loss)\n",
    "\n",
    "            if val_loss < prev_min:\n",
    "                prev_min = val_loss\n",
    "                torch.save(rating_cnn.state_dict(), \"rating_pytorch.pt\")\n",
    "            rating_cnn.train()\n",
    "    print(np.mean(loss_array))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For training the Pytorch Model for Imitating the result with volume Slice Huber\n",
    "\n",
    "import torch.optim as optim\n",
    "from skimage import measure\n",
    "\n",
    "def get_ssim(pred, ground):\n",
    "    ssim_array = []\n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        t1 = np.min(ground[i].flatten())\n",
    "        t2 = np.max(ground[i].flatten())\n",
    "        reference_image = (ground[i, 0]-t1)*255/(t2-t1)\n",
    "        \n",
    "        t1 = np.min(pred[i, 0, :, :].flatten())\n",
    "        t2 = np.max(pred[i, 0, :, :].flatten())\n",
    "        distorted_image = (pred[i, 0]-t1)*255/(t2-t1)\n",
    "        \n",
    "        ssim_temp = measure.compare_ssim(distorted_image, reference_image, data_range=255)\n",
    "        ssim_array.append(ssim_temp)\n",
    "    \n",
    "    return ssim_array\n",
    "\n",
    "def get_ssim_distribution(ssim_input_array, value_array):\n",
    "    ssim_array = {}\n",
    "    ssim_array[0.1] = []\n",
    "    ssim_array[0.2] = []\n",
    "    ssim_array[0.3] = []\n",
    "    ssim_array[0.4] = []\n",
    "    ssim_array[0.5] = []\n",
    "    ssim_array[0.6] = []\n",
    "    \n",
    "    for i in range(len(value_array)):\n",
    "        value     = value_array[i]\n",
    "        ssim_temp = ssim_input_array[i]\n",
    "        \n",
    "        if value < 0.1:\n",
    "            ssim_array[0.1].append(ssim_temp)\n",
    "            #mae_array[0.1].append(mae_temp)\n",
    "        elif value < 0.2:\n",
    "            ssim_array[0.2].append(ssim_temp)\n",
    "            #mae_array[0.2].append(mae_temp)    \n",
    "        elif  value < 0.3:\n",
    "            ssim_array[0.3].append(ssim_temp)\n",
    "            #mae_array[0.3].append(mae_temp)    \n",
    "        elif  value < 0.4:\n",
    "            ssim_array[0.4].append(ssim_temp)\n",
    "            #mae_array[0.4].append(mae_temp)    \n",
    "        elif value < 0.5:\n",
    "            ssim_array[0.5].append(ssim_temp)\n",
    "            #mae_array[0.5].append(mae_temp)    \n",
    "        elif value < 0.6:\n",
    "            ssim_array[0.6].append(ssim_temp)\n",
    "            #mae_array[0.6].append(mae_temp)\n",
    "    \n",
    "    mean_ssim_array = []\n",
    "    for k in ssim_array.keys():\n",
    "        mean_ssim_array.append(np.mean(ssim_array[k]))\n",
    "    mean_ssim_array = [str(round(x, 3)) for x in mean_ssim_array]\n",
    "    \n",
    "    return \", \".join(mean_ssim_array)\n",
    "\n",
    "model = MyUnet_half()#_half()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "mse_criterion  = nn.MSELoss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min   = 1000\n",
    "batch_size = 8\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    ssim_array = []\n",
    "    \n",
    "    ssim_z_array = []\n",
    "    value_array  = []\n",
    "    \n",
    "    idx     = np.random.permutation(len(x_array))\n",
    "    x_array = x_array[idx]\n",
    "    y_array = y_array[idx]\n",
    "    z_array = z_array[idx]\n",
    "    v_array = v_array[idx]\n",
    "    \n",
    "    for i in range(len(x_array)//batch_size):\n",
    "        x = x_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        v = v_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        v = torch.tensor(v, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, z)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape)\n",
    "        \n",
    "        loss1  = my_loss(output, y)\n",
    "        #loss2  = mse_criterion(output, y)\n",
    "        \n",
    "        loss   = loss1#+10*loss2\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        y      = y.data.cpu().numpy()\n",
    "        z      = -1*z.data.cpu().numpy()\n",
    "        \n",
    "        ssim_values = get_ssim(output, y)\n",
    "        \n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        for vt in ssim_values:\n",
    "            ssim_array.append(vt)\n",
    "        for vt in z:\n",
    "            value_array.append(vt)\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ssim_string = get_ssim_distribution(ssim_array, value_array)\n",
    "    \n",
    "    print('Loss ', np.mean(loss_array), ' SSIM ', ssim_string)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    ssim_array = []\n",
    "    value_array  = []\n",
    "    \n",
    "    for i in range(len(x_val_array)//batch_size):\n",
    "        x = x_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        v = v_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        v = torch.tensor(v, device=device).float()\n",
    "\n",
    "        output = model(x, z)\n",
    "\n",
    "        loss1 = my_loss(output, y)\n",
    "        #loss2 = mse_criterion(output, y)\n",
    "        loss  = loss1#+10*loss2\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        y      = y.data.cpu().numpy()\n",
    "        z      = -1*z.data.cpu().numpy()\n",
    "        \n",
    "        ssim_values = get_ssim(output, y)\n",
    "        \n",
    "        for vt in ssim_values:\n",
    "            ssim_array.append(vt)\n",
    "        for vt in z:\n",
    "            value_array.append(vt)\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "    \n",
    "    \n",
    "    ssim_string = get_ssim_distribution(ssim_array, value_array)\n",
    "        \n",
    "    val_loss = np.mean(loss_array)\n",
    "    print(\"Val loss \", val_loss, ' SSIM ', ssim_string)\n",
    "    \n",
    "    if val_loss < prev_min:\n",
    "        prev_min = val_loss\n",
    "        print('saving the model ', prev_min)\n",
    "        torch.save(model.state_dict(), \"unethalf-quadratic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "code_folding": [
     0,
     5,
     154
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.00300698963818  SSIM  0.876, 0.763, 0.673, 0.606, 0.555, 0.514, 0.48, 0.452\n",
      "Val loss  0.0017596587718  SSIM  0.791, 0.733, 0.673, 0.619, 0.573, 0.535, 0.502, 0.473\n",
      "saving the model  0.0017596587718\n",
      "Loss  0.00146336323197  SSIM  0.771, 0.719, 0.663, 0.612, 0.572, 0.537, 0.509, 0.484\n",
      "Val loss  0.0013765427866  SSIM  0.747, 0.696, 0.637, 0.582, 0.535, 0.493, 0.459, 0.43\n",
      "saving the model  0.0013765427866\n",
      "Loss  0.00105698365472  SSIM  0.816, 0.773, 0.715, 0.663, 0.616, 0.579, 0.544, 0.518\n",
      "Val loss  0.000860645759152  SSIM  0.82, 0.774, 0.711, 0.653, 0.601, 0.554, 0.515, 0.478\n",
      "saving the model  0.000860645759152\n",
      "Loss  0.000695652931978  SSIM  0.87, 0.828, 0.772, 0.722, 0.679, 0.641, 0.608, 0.579\n",
      "Val loss  0.000660059814516  SSIM  0.861, 0.793, 0.709, 0.654, 0.603, 0.563, 0.527, 0.494\n",
      "saving the model  0.000660059814516\n",
      "Loss  0.000592863810844  SSIM  0.89, 0.837, 0.778, 0.731, 0.69, 0.656, 0.625, 0.597\n",
      "Val loss  0.000603298912465  SSIM  0.868, 0.795, 0.713, 0.655, 0.604, 0.567, 0.532, 0.5\n",
      "saving the model  0.000603298912465\n",
      "Loss  0.000559861338921  SSIM  0.902, 0.837, 0.778, 0.732, 0.691, 0.661, 0.631, 0.603\n",
      "Val loss  0.000576206278405  SSIM  0.905, 0.808, 0.726, 0.669, 0.619, 0.582, 0.549, 0.518\n",
      "saving the model  0.000576206278405\n",
      "Loss  0.00053760055372  SSIM  0.909, 0.838, 0.78, 0.733, 0.693, 0.662, 0.633, 0.605\n",
      "Val loss  0.000599528846797  SSIM  0.892, 0.787, 0.715, 0.654, 0.606, 0.568, 0.535, 0.504\n",
      "Loss  0.000523685044519  SSIM  0.914, 0.839, 0.781, 0.732, 0.695, 0.663, 0.634, 0.606\n",
      "Val loss  0.000553159098024  SSIM  0.889, 0.801, 0.741, 0.682, 0.639, 0.601, 0.567, 0.536\n",
      "saving the model  0.000553159098024\n",
      "Loss  0.000512988423602  SSIM  0.918, 0.84, 0.783, 0.732, 0.696, 0.664, 0.636, 0.608\n",
      "Val loss  0.000573796666809  SSIM  0.898, 0.81, 0.742, 0.674, 0.629, 0.588, 0.552, 0.518\n",
      "Loss  0.000503526173617  SSIM  0.922, 0.842, 0.782, 0.731, 0.698, 0.665, 0.636, 0.607\n",
      "Val loss  0.000536358714278  SSIM  0.911, 0.82, 0.74, 0.675, 0.633, 0.594, 0.557, 0.525\n",
      "saving the model  0.000536358714278\n",
      "Loss  0.00049588251297  SSIM  0.925, 0.843, 0.784, 0.733, 0.698, 0.666, 0.636, 0.608\n",
      "Val loss  0.000533877504698  SSIM  0.915, 0.813, 0.742, 0.683, 0.643, 0.606, 0.571, 0.539\n",
      "saving the model  0.000533877504698\n",
      "Loss  0.000485982375954  SSIM  0.928, 0.844, 0.783, 0.734, 0.7, 0.667, 0.637, 0.609\n",
      "Val loss  0.000526959337294  SSIM  0.91, 0.804, 0.732, 0.672, 0.632, 0.595, 0.561, 0.53\n",
      "saving the model  0.000526959337294\n",
      "Loss  0.000481305500233  SSIM  0.93, 0.845, 0.782, 0.735, 0.7, 0.669, 0.638, 0.61\n",
      "Val loss  0.000537190220784  SSIM  0.921, 0.807, 0.727, 0.669, 0.627, 0.588, 0.552, 0.518\n",
      "Loss  0.000475045321039  SSIM  0.932, 0.846, 0.782, 0.735, 0.701, 0.668, 0.639, 0.611\n",
      "Val loss  0.000520904708595  SSIM  0.915, 0.815, 0.742, 0.685, 0.642, 0.601, 0.562, 0.527\n",
      "saving the model  0.000520904708595\n",
      "Loss  0.000474594417789  SSIM  0.932, 0.847, 0.782, 0.736, 0.702, 0.669, 0.64, 0.611\n",
      "Val loss  0.000514368183503  SSIM  0.922, 0.818, 0.743, 0.69, 0.65, 0.614, 0.58, 0.547\n",
      "saving the model  0.000514368183503\n",
      "Loss  0.000465215562682  SSIM  0.933, 0.848, 0.782, 0.736, 0.702, 0.67, 0.641, 0.613\n",
      "Val loss  0.00051423298294  SSIM  0.922, 0.811, 0.727, 0.673, 0.635, 0.599, 0.564, 0.531\n",
      "saving the model  0.00051423298294\n",
      "Loss  0.000464856854568  SSIM  0.935, 0.848, 0.782, 0.736, 0.702, 0.67, 0.641, 0.614\n",
      "Val loss  0.000508042603265  SSIM  0.924, 0.817, 0.733, 0.679, 0.64, 0.603, 0.569, 0.536\n",
      "saving the model  0.000508042603265\n",
      "Loss  0.000459571872086  SSIM  0.935, 0.849, 0.782, 0.736, 0.703, 0.672, 0.642, 0.614\n",
      "Val loss  0.000510097641614  SSIM  0.922, 0.819, 0.74, 0.685, 0.646, 0.611, 0.579, 0.548\n",
      "Loss  0.000456536981331  SSIM  0.936, 0.85, 0.783, 0.737, 0.703, 0.672, 0.643, 0.616\n",
      "Val loss  0.000528307037137  SSIM  0.918, 0.799, 0.721, 0.663, 0.621, 0.583, 0.549, 0.518\n",
      "Loss  0.000451647593268  SSIM  0.937, 0.85, 0.784, 0.737, 0.704, 0.673, 0.644, 0.616\n",
      "Val loss  0.000505821500905  SSIM  0.927, 0.818, 0.738, 0.679, 0.639, 0.603, 0.569, 0.538\n",
      "saving the model  0.000505821500905\n",
      "Loss  0.000451737329959  SSIM  0.937, 0.85, 0.785, 0.737, 0.704, 0.673, 0.645, 0.617\n",
      "Val loss  0.000509637540265  SSIM  0.922, 0.812, 0.728, 0.672, 0.634, 0.597, 0.563, 0.533\n",
      "Loss  0.000447749681659  SSIM  0.938, 0.851, 0.787, 0.739, 0.704, 0.674, 0.644, 0.618\n",
      "Val loss  0.000509231742006  SSIM  0.927, 0.816, 0.733, 0.675, 0.632, 0.596, 0.561, 0.529\n",
      "Loss  0.000444303571376  SSIM  0.939, 0.852, 0.788, 0.74, 0.705, 0.674, 0.645, 0.619\n",
      "Val loss  0.000504545909236  SSIM  0.931, 0.827, 0.75, 0.692, 0.651, 0.616, 0.583, 0.552\n",
      "saving the model  0.000504545909236\n",
      "Loss  0.000442662208807  SSIM  0.94, 0.852, 0.788, 0.741, 0.705, 0.675, 0.646, 0.619\n",
      "Val loss  0.000500677191536  SSIM  0.929, 0.816, 0.73, 0.667, 0.624, 0.588, 0.556, 0.525\n",
      "saving the model  0.000500677191536\n",
      "Loss  0.000440196466426  SSIM  0.94, 0.853, 0.789, 0.741, 0.706, 0.676, 0.647, 0.62\n",
      "Val loss  0.000500985252846  SSIM  0.927, 0.809, 0.726, 0.665, 0.622, 0.584, 0.549, 0.518\n",
      "Loss  0.000438847245778  SSIM  0.941, 0.854, 0.79, 0.741, 0.706, 0.676, 0.648, 0.621\n",
      "Val loss  0.000497566229373  SSIM  0.93, 0.816, 0.735, 0.675, 0.633, 0.598, 0.565, 0.534\n",
      "saving the model  0.000497566229373\n",
      "Loss  0.000435851037753  SSIM  0.942, 0.854, 0.791, 0.742, 0.707, 0.677, 0.648, 0.621\n",
      "Val loss  0.000498846468399  SSIM  0.933, 0.824, 0.742, 0.68, 0.639, 0.603, 0.571, 0.541\n",
      "Loss  0.000433906113545  SSIM  0.942, 0.855, 0.793, 0.743, 0.708, 0.678, 0.649, 0.623\n",
      "Val loss  0.000495784621045  SSIM  0.932, 0.822, 0.742, 0.68, 0.637, 0.601, 0.568, 0.538\n",
      "saving the model  0.000495784621045\n",
      "Loss  0.000433673768779  SSIM  0.942, 0.856, 0.794, 0.744, 0.709, 0.678, 0.65, 0.623\n",
      "Val loss  0.000504500503186  SSIM  0.928, 0.812, 0.738, 0.677, 0.634, 0.599, 0.567, 0.537\n",
      "Loss  0.000431605667847  SSIM  0.943, 0.857, 0.794, 0.745, 0.709, 0.679, 0.651, 0.624\n",
      "Val loss  0.000491183604812  SSIM  0.933, 0.823, 0.746, 0.685, 0.641, 0.604, 0.571, 0.54\n",
      "saving the model  0.000491183604812\n",
      "Loss  0.000430009767744  SSIM  0.944, 0.857, 0.795, 0.746, 0.71, 0.679, 0.651, 0.624\n",
      "Val loss  0.00050219305919  SSIM  0.931, 0.827, 0.757, 0.699, 0.656, 0.619, 0.588, 0.558\n",
      "Loss  0.00042805457284  SSIM  0.944, 0.858, 0.796, 0.746, 0.711, 0.679, 0.652, 0.625\n",
      "Val loss  0.000498673399328  SSIM  0.926, 0.816, 0.742, 0.68, 0.637, 0.601, 0.569, 0.539\n",
      "Loss  0.000428009649398  SSIM  0.945, 0.859, 0.796, 0.747, 0.711, 0.68, 0.653, 0.626\n",
      "Val loss  0.000488056300674  SSIM  0.933, 0.822, 0.746, 0.685, 0.643, 0.609, 0.578, 0.549\n",
      "saving the model  0.000488056300674\n",
      "Loss  0.000427386820666  SSIM  0.945, 0.859, 0.797, 0.748, 0.712, 0.681, 0.653, 0.627\n",
      "Val loss  0.000490410003404  SSIM  0.932, 0.829, 0.753, 0.694, 0.651, 0.615, 0.584, 0.553\n",
      "Loss  0.000424405266889  SSIM  0.946, 0.861, 0.798, 0.749, 0.714, 0.682, 0.654, 0.627\n",
      "Val loss  0.000487007963471  SSIM  0.932, 0.82, 0.742, 0.685, 0.643, 0.609, 0.579, 0.549\n",
      "saving the model  0.000487007963471\n",
      "Loss  0.000424645923172  SSIM  0.946, 0.861, 0.8, 0.749, 0.714, 0.683, 0.655, 0.628\n",
      "Val loss  0.000496982475859  SSIM  0.94, 0.835, 0.757, 0.696, 0.652, 0.617, 0.584, 0.553\n",
      "Loss  0.000423671185652  SSIM  0.947, 0.862, 0.801, 0.751, 0.714, 0.683, 0.656, 0.629\n",
      "Val loss  0.000493769037013  SSIM  0.932, 0.829, 0.75, 0.684, 0.638, 0.596, 0.563, 0.532\n",
      "Loss  0.000421686341691  SSIM  0.947, 0.863, 0.802, 0.751, 0.715, 0.684, 0.656, 0.629\n",
      "Val loss  0.000488320364151  SSIM  0.937, 0.831, 0.754, 0.691, 0.647, 0.61, 0.577, 0.546\n",
      "Loss  0.000422729149935  SSIM  0.948, 0.864, 0.803, 0.752, 0.716, 0.686, 0.657, 0.63\n",
      "Val loss  0.000499041659699  SSIM  0.934, 0.819, 0.738, 0.669, 0.623, 0.587, 0.553, 0.52\n",
      "Loss  0.000418800501189  SSIM  0.948, 0.865, 0.804, 0.753, 0.717, 0.686, 0.657, 0.631\n",
      "Val loss  0.00049144829897  SSIM  0.939, 0.835, 0.76, 0.701, 0.661, 0.624, 0.593, 0.564\n",
      "Loss  0.000419840489519  SSIM  0.948, 0.865, 0.805, 0.754, 0.718, 0.686, 0.658, 0.631\n",
      "Val loss  0.000487380339007  SSIM  0.938, 0.835, 0.758, 0.696, 0.652, 0.614, 0.583, 0.553\n",
      "Loss  0.000419025708062  SSIM  0.949, 0.866, 0.805, 0.755, 0.719, 0.687, 0.659, 0.632\n",
      "Val loss  0.000484335038636  SSIM  0.937, 0.832, 0.755, 0.692, 0.647, 0.607, 0.577, 0.548\n",
      "saving the model  0.000484335038636\n",
      "Loss  0.000416742723252  SSIM  0.949, 0.867, 0.806, 0.756, 0.719, 0.687, 0.66, 0.633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000483761687647  SSIM  0.942, 0.84, 0.766, 0.705, 0.66, 0.621, 0.588, 0.556\n",
      "saving the model  0.000483761687647\n",
      "Loss  0.000417757957005  SSIM  0.95, 0.868, 0.807, 0.757, 0.721, 0.688, 0.661, 0.634\n",
      "Val loss  0.000483732846333  SSIM  0.94, 0.835, 0.76, 0.698, 0.655, 0.618, 0.587, 0.556\n",
      "saving the model  0.000483732846333\n",
      "Loss  0.000414859702735  SSIM  0.95, 0.869, 0.809, 0.758, 0.721, 0.689, 0.661, 0.634\n",
      "Val loss  0.000483477513946  SSIM  0.94, 0.841, 0.767, 0.706, 0.663, 0.625, 0.594, 0.565\n",
      "saving the model  0.000483477513946\n",
      "Loss  0.000414947952847  SSIM  0.951, 0.87, 0.809, 0.759, 0.723, 0.69, 0.662, 0.635\n",
      "Val loss  0.000485747249972  SSIM  0.94, 0.833, 0.757, 0.696, 0.654, 0.619, 0.589, 0.559\n",
      "Loss  0.000413192230156  SSIM  0.952, 0.871, 0.81, 0.76, 0.724, 0.691, 0.663, 0.636\n",
      "Val loss  0.000482312209497  SSIM  0.942, 0.838, 0.757, 0.691, 0.644, 0.603, 0.569, 0.537\n",
      "saving the model  0.000482312209497\n",
      "Loss  0.000413380085262  SSIM  0.952, 0.872, 0.812, 0.761, 0.725, 0.692, 0.664, 0.637\n",
      "Val loss  0.000485141500423  SSIM  0.948, 0.845, 0.766, 0.704, 0.66, 0.622, 0.59, 0.56\n",
      "Loss  0.000412023751571  SSIM  0.954, 0.873, 0.814, 0.763, 0.726, 0.693, 0.665, 0.638\n",
      "Val loss  0.000481698199408  SSIM  0.951, 0.847, 0.771, 0.71, 0.669, 0.632, 0.6, 0.569\n",
      "saving the model  0.000481698199408\n",
      "Loss  0.000410843431265  SSIM  0.96, 0.891, 0.834, 0.784, 0.745, 0.712, 0.683, 0.655\n",
      "Val loss  0.000482408001146  SSIM  0.953, 0.868, 0.798, 0.738, 0.693, 0.655, 0.621, 0.588\n",
      "Loss  0.000409060968131  SSIM  0.961, 0.894, 0.838, 0.789, 0.751, 0.717, 0.688, 0.658\n",
      "Val loss  0.000477997061738  SSIM  0.955, 0.87, 0.798, 0.736, 0.688, 0.649, 0.614, 0.58\n",
      "saving the model  0.000477997061738\n",
      "Loss  0.000409442188796  SSIM  0.961, 0.895, 0.839, 0.791, 0.752, 0.718, 0.688, 0.66\n",
      "Val loss  0.000483916384168  SSIM  0.956, 0.879, 0.812, 0.753, 0.706, 0.666, 0.629, 0.595\n",
      "Loss  0.000406799970884  SSIM  0.962, 0.896, 0.84, 0.792, 0.753, 0.719, 0.69, 0.661\n",
      "Val loss  0.000480209357862  SSIM  0.954, 0.87, 0.8, 0.738, 0.692, 0.651, 0.616, 0.581\n",
      "Loss  0.000408210489214  SSIM  0.962, 0.897, 0.841, 0.793, 0.755, 0.72, 0.691, 0.661\n",
      "Val loss  0.000477812896774  SSIM  0.956, 0.87, 0.797, 0.734, 0.687, 0.645, 0.611, 0.578\n",
      "saving the model  0.000477812896774\n",
      "Loss  0.000405848738043  SSIM  0.962, 0.898, 0.842, 0.795, 0.756, 0.721, 0.692, 0.663\n",
      "Val loss  0.000477435242676  SSIM  0.956, 0.875, 0.805, 0.745, 0.697, 0.654, 0.619, 0.584\n",
      "saving the model  0.000477435242676\n",
      "Loss  0.000406279845069  SSIM  0.962, 0.899, 0.844, 0.796, 0.757, 0.722, 0.693, 0.664\n",
      "Val loss  0.000483952307375  SSIM  0.959, 0.883, 0.816, 0.757, 0.709, 0.665, 0.63, 0.595\n",
      "Loss  0.000404885687055  SSIM  0.963, 0.9, 0.845, 0.797, 0.759, 0.724, 0.695, 0.665\n",
      "Val loss  0.000477283607586  SSIM  0.958, 0.879, 0.811, 0.752, 0.704, 0.66, 0.624, 0.589\n",
      "saving the model  0.000477283607586\n",
      "Loss  0.000404582064881  SSIM  0.963, 0.901, 0.846, 0.799, 0.761, 0.725, 0.696, 0.666\n",
      "Val loss  0.000477371394285  SSIM  0.955, 0.881, 0.813, 0.753, 0.706, 0.665, 0.63, 0.596\n",
      "Loss  0.000403493887122  SSIM  0.964, 0.902, 0.848, 0.8, 0.762, 0.726, 0.696, 0.667\n",
      "Val loss  0.000477263557608  SSIM  0.958, 0.88, 0.811, 0.749, 0.702, 0.662, 0.626, 0.592\n",
      "saving the model  0.000477263557608\n",
      "Loss  0.000404078827728  SSIM  0.964, 0.903, 0.849, 0.801, 0.763, 0.728, 0.698, 0.668\n",
      "Val loss  0.000473169269622  SSIM  0.959, 0.883, 0.816, 0.755, 0.707, 0.664, 0.629, 0.594\n",
      "saving the model  0.000473169269622\n",
      "Loss  0.000402541487487  SSIM  0.964, 0.904, 0.85, 0.803, 0.764, 0.728, 0.699, 0.669\n",
      "Val loss  0.000475764496718  SSIM  0.959, 0.885, 0.819, 0.758, 0.71, 0.664, 0.629, 0.594\n",
      "Loss  0.000404822185653  SSIM  0.965, 0.905, 0.851, 0.803, 0.765, 0.73, 0.7, 0.67\n",
      "Val loss  0.000482479123166  SSIM  0.958, 0.881, 0.812, 0.75, 0.701, 0.656, 0.619, 0.584\n",
      "Loss  0.000400964411965  SSIM  0.965, 0.906, 0.852, 0.806, 0.767, 0.731, 0.702, 0.671\n",
      "Val loss  0.00048262571753  SSIM  0.96, 0.882, 0.812, 0.752, 0.704, 0.66, 0.625, 0.59\n",
      "Loss  0.000401675111946  SSIM  0.965, 0.907, 0.854, 0.806, 0.768, 0.733, 0.703, 0.673\n",
      "Val loss  0.000471449110715  SSIM  0.959, 0.887, 0.82, 0.759, 0.71, 0.667, 0.631, 0.595\n",
      "saving the model  0.000471449110715\n",
      "Loss  0.000401406572402  SSIM  0.965, 0.907, 0.855, 0.807, 0.768, 0.734, 0.704, 0.674\n",
      "Val loss  0.000473489665485  SSIM  0.958, 0.886, 0.819, 0.759, 0.711, 0.666, 0.63, 0.593\n",
      "Loss  0.000402257274881  SSIM  0.966, 0.908, 0.856, 0.809, 0.77, 0.734, 0.705, 0.675\n",
      "Val loss  0.000474030095793  SSIM  0.959, 0.883, 0.816, 0.758, 0.713, 0.667, 0.632, 0.596\n",
      "Loss  0.000400076418927  SSIM  0.966, 0.909, 0.857, 0.81, 0.771, 0.736, 0.706, 0.676\n",
      "Val loss  0.00047707825352  SSIM  0.963, 0.891, 0.825, 0.766, 0.716, 0.67, 0.633, 0.596\n",
      "Loss  0.000400172611497  SSIM  0.966, 0.909, 0.858, 0.812, 0.773, 0.737, 0.707, 0.677\n",
      "Val loss  0.000473334237118  SSIM  0.962, 0.895, 0.831, 0.774, 0.727, 0.684, 0.65, 0.615\n",
      "Loss  0.000400268947616  SSIM  0.967, 0.91, 0.859, 0.812, 0.773, 0.738, 0.708, 0.678\n",
      "Val loss  0.000484809193411  SSIM  0.962, 0.89, 0.823, 0.762, 0.714, 0.67, 0.633, 0.596\n",
      "Loss  0.000398909128652  SSIM  0.967, 0.911, 0.86, 0.814, 0.774, 0.739, 0.71, 0.679\n",
      "Val loss  0.00047888935433  SSIM  0.963, 0.897, 0.835, 0.777, 0.73, 0.684, 0.647, 0.612\n",
      "Loss  0.000399219535936  SSIM  0.967, 0.912, 0.861, 0.815, 0.776, 0.74, 0.71, 0.68\n",
      "Val loss  0.000476101724664  SSIM  0.962, 0.892, 0.826, 0.768, 0.718, 0.677, 0.64, 0.603\n",
      "Loss  0.000399016057983  SSIM  0.967, 0.912, 0.862, 0.815, 0.777, 0.741, 0.711, 0.681\n",
      "Val loss  0.000474657259416  SSIM  0.962, 0.894, 0.828, 0.769, 0.721, 0.673, 0.637, 0.601\n",
      "Loss  0.000398315167717  SSIM  0.967, 0.913, 0.862, 0.816, 0.778, 0.743, 0.713, 0.682\n",
      "Val loss  0.000472358448198  SSIM  0.963, 0.899, 0.836, 0.778, 0.729, 0.684, 0.646, 0.61\n",
      "Loss  0.000396821936212  SSIM  0.968, 0.914, 0.863, 0.818, 0.779, 0.743, 0.713, 0.683\n",
      "Val loss  0.000478239829012  SSIM  0.963, 0.899, 0.836, 0.778, 0.73, 0.685, 0.649, 0.612\n",
      "Loss  0.000396956863271  SSIM  0.968, 0.914, 0.864, 0.818, 0.78, 0.745, 0.714, 0.684\n",
      "Val loss  0.000483112070826  SSIM  0.964, 0.9, 0.84, 0.784, 0.736, 0.693, 0.657, 0.621\n",
      "Loss  0.000396475625972  SSIM  0.968, 0.915, 0.865, 0.819, 0.781, 0.745, 0.715, 0.685\n",
      "Val loss  0.000472376014572  SSIM  0.964, 0.897, 0.832, 0.773, 0.724, 0.676, 0.638, 0.601\n",
      "Loss  0.000396051384943  SSIM  0.968, 0.915, 0.866, 0.821, 0.782, 0.746, 0.716, 0.686\n",
      "Val loss  0.00047700203635  SSIM  0.963, 0.898, 0.834, 0.778, 0.729, 0.679, 0.641, 0.604\n",
      "Loss  0.000395775402766  SSIM  0.968, 0.916, 0.866, 0.822, 0.783, 0.747, 0.717, 0.687\n",
      "Val loss  0.000469426507771  SSIM  0.964, 0.902, 0.842, 0.785, 0.736, 0.691, 0.655, 0.619\n",
      "saving the model  0.000469426507771\n",
      "Loss  0.000395148622785  SSIM  0.969, 0.916, 0.867, 0.822, 0.784, 0.748, 0.718, 0.688\n",
      "Val loss  0.000473669400322  SSIM  0.965, 0.902, 0.842, 0.786, 0.738, 0.694, 0.658, 0.622\n",
      "Loss  0.000395481019245  SSIM  0.969, 0.917, 0.868, 0.824, 0.785, 0.749, 0.719, 0.689\n",
      "Val loss  0.000470258874586  SSIM  0.965, 0.903, 0.844, 0.788, 0.741, 0.697, 0.661, 0.625\n",
      "Loss  0.000394377368614  SSIM  0.969, 0.918, 0.869, 0.824, 0.785, 0.751, 0.72, 0.69\n",
      "Val loss  0.000472589895537  SSIM  0.964, 0.902, 0.84, 0.783, 0.735, 0.69, 0.653, 0.616\n",
      "Loss  0.000395084981865  SSIM  0.969, 0.918, 0.869, 0.825, 0.787, 0.751, 0.72, 0.69\n",
      "Val loss  0.000470058109961  SSIM  0.965, 0.903, 0.843, 0.786, 0.739, 0.694, 0.658, 0.622\n",
      "Loss  0.000393893319102  SSIM  0.969, 0.919, 0.87, 0.826, 0.788, 0.752, 0.721, 0.691\n",
      "Val loss  0.000473247940303  SSIM  0.965, 0.908, 0.849, 0.793, 0.744, 0.697, 0.658, 0.62\n",
      "Loss  0.00039345415777  SSIM  0.969, 0.919, 0.871, 0.826, 0.788, 0.753, 0.723, 0.692\n",
      "Val loss  0.000470982456289  SSIM  0.966, 0.905, 0.845, 0.789, 0.74, 0.697, 0.66, 0.624\n",
      "Loss  0.000392974247538  SSIM  0.97, 0.919, 0.872, 0.827, 0.789, 0.753, 0.723, 0.692\n",
      "Val loss  0.000474537188478  SSIM  0.965, 0.904, 0.844, 0.787, 0.738, 0.692, 0.655, 0.617\n",
      "Loss  0.000392541738849  SSIM  0.97, 0.92, 0.872, 0.828, 0.79, 0.754, 0.724, 0.693\n",
      "Val loss  0.000478565924044  SSIM  0.965, 0.908, 0.85, 0.795, 0.747, 0.702, 0.666, 0.63\n",
      "Loss  0.000393133287726  SSIM  0.97, 0.92, 0.872, 0.828, 0.79, 0.755, 0.724, 0.694\n",
      "Val loss  0.000472983729793  SSIM  0.965, 0.902, 0.841, 0.784, 0.737, 0.694, 0.657, 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000392319491993  SSIM  0.97, 0.921, 0.873, 0.829, 0.791, 0.756, 0.725, 0.695\n",
      "Val loss  0.0004748604786  SSIM  0.967, 0.91, 0.852, 0.798, 0.751, 0.707, 0.67, 0.634\n",
      "Loss  0.000391854488519  SSIM  0.97, 0.921, 0.874, 0.829, 0.792, 0.756, 0.726, 0.695\n",
      "Val loss  0.000478897131106  SSIM  0.966, 0.903, 0.842, 0.788, 0.743, 0.701, 0.663, 0.626\n",
      "Loss  0.000393025127817  SSIM  0.97, 0.921, 0.874, 0.83, 0.792, 0.757, 0.727, 0.696\n",
      "Val loss  0.00047194972646  SSIM  0.964, 0.906, 0.846, 0.79, 0.74, 0.693, 0.655, 0.617\n",
      "Loss  0.000392294212764  SSIM  0.97, 0.922, 0.874, 0.831, 0.793, 0.757, 0.727, 0.696\n",
      "Val loss  0.000473059800279  SSIM  0.966, 0.907, 0.849, 0.793, 0.744, 0.698, 0.66, 0.623\n",
      "Loss  0.000390617652939  SSIM  0.97, 0.922, 0.875, 0.832, 0.794, 0.759, 0.728, 0.698\n",
      "Val loss  0.000468712059548  SSIM  0.967, 0.912, 0.857, 0.804, 0.757, 0.714, 0.677, 0.64\n",
      "saving the model  0.000468712059548\n",
      "Loss  0.000391798791086  SSIM  0.97, 0.922, 0.876, 0.832, 0.794, 0.759, 0.728, 0.697\n",
      "Val loss  0.000473086694081  SSIM  0.966, 0.905, 0.843, 0.785, 0.734, 0.688, 0.648, 0.609\n",
      "Loss  0.000391043499135  SSIM  0.971, 0.923, 0.876, 0.832, 0.794, 0.76, 0.729, 0.698\n",
      "Val loss  0.000476633427024  SSIM  0.967, 0.907, 0.847, 0.791, 0.742, 0.7, 0.663, 0.625\n",
      "Loss  0.000390021594291  SSIM  0.971, 0.923, 0.877, 0.833, 0.795, 0.76, 0.73, 0.699\n",
      "Val loss  0.00047066348209  SSIM  0.967, 0.913, 0.859, 0.806, 0.757, 0.712, 0.673, 0.635\n",
      "Loss  0.000389535326103  SSIM  0.971, 0.923, 0.877, 0.834, 0.796, 0.761, 0.73, 0.7\n",
      "Val loss  0.000474400365842  SSIM  0.967, 0.91, 0.853, 0.798, 0.75, 0.708, 0.671, 0.634\n",
      "Loss  0.000390080298933  SSIM  0.971, 0.924, 0.878, 0.834, 0.797, 0.762, 0.731, 0.7\n",
      "Val loss  0.000468811367697  SSIM  0.967, 0.912, 0.858, 0.806, 0.76, 0.716, 0.68, 0.644\n",
      "Loss  0.00038988397488  SSIM  0.971, 0.924, 0.878, 0.835, 0.797, 0.762, 0.731, 0.7\n",
      "Val loss  0.00046924170485  SSIM  0.967, 0.911, 0.853, 0.799, 0.751, 0.708, 0.671, 0.634\n",
      "Loss  0.000389660631347  SSIM  0.971, 0.924, 0.879, 0.836, 0.798, 0.763, 0.732, 0.701\n",
      "Val loss  0.000475750357378  SSIM  0.966, 0.909, 0.851, 0.795, 0.745, 0.697, 0.657, 0.619\n",
      "Loss  0.000388284545535  SSIM  0.971, 0.925, 0.879, 0.836, 0.798, 0.763, 0.733, 0.702\n",
      "Val loss  0.0004684997687  SSIM  0.967, 0.913, 0.857, 0.802, 0.754, 0.711, 0.673, 0.636\n",
      "saving the model  0.0004684997687\n",
      "Loss  0.000389342776683  SSIM  0.971, 0.925, 0.88, 0.836, 0.798, 0.764, 0.733, 0.702\n",
      "Val loss  0.000477281377127  SSIM  0.967, 0.912, 0.856, 0.804, 0.759, 0.717, 0.681, 0.645\n",
      "Loss  0.000388198689437  SSIM  0.971, 0.925, 0.88, 0.837, 0.799, 0.765, 0.733, 0.703\n",
      "Val loss  0.000469319176744  SSIM  0.967, 0.914, 0.859, 0.807, 0.76, 0.717, 0.68, 0.643\n",
      "Loss  0.000388203339042  SSIM  0.971, 0.925, 0.88, 0.838, 0.8, 0.764, 0.734, 0.703\n",
      "Val loss  0.000468547133671  SSIM  0.967, 0.912, 0.857, 0.803, 0.756, 0.709, 0.671, 0.634\n",
      "Loss  0.000387924116647  SSIM  0.971, 0.925, 0.88, 0.838, 0.801, 0.764, 0.734, 0.703\n",
      "Val loss  0.000475007733505  SSIM  0.966, 0.908, 0.85, 0.795, 0.748, 0.702, 0.665, 0.627\n",
      "Loss  0.000387742289526  SSIM  0.971, 0.926, 0.881, 0.838, 0.801, 0.765, 0.735, 0.704\n",
      "Val loss  0.000470448645065  SSIM  0.967, 0.913, 0.858, 0.805, 0.757, 0.712, 0.674, 0.637\n",
      "Loss  0.00038771338078  SSIM  0.971, 0.926, 0.881, 0.839, 0.801, 0.766, 0.736, 0.705\n",
      "Val loss  0.000471574131516  SSIM  0.968, 0.915, 0.862, 0.811, 0.766, 0.724, 0.687, 0.651\n",
      "Loss  0.000387483286322  SSIM  0.971, 0.926, 0.881, 0.84, 0.801, 0.767, 0.736, 0.705\n",
      "Val loss  0.000472087196773  SSIM  0.967, 0.911, 0.854, 0.802, 0.755, 0.712, 0.674, 0.636\n",
      "Loss  0.000387181337283  SSIM  0.971, 0.926, 0.882, 0.84, 0.802, 0.766, 0.736, 0.705\n",
      "Val loss  0.000470144682447  SSIM  0.967, 0.911, 0.854, 0.801, 0.753, 0.712, 0.675, 0.637\n",
      "Loss  0.000386559431611  SSIM  0.971, 0.927, 0.882, 0.841, 0.803, 0.767, 0.737, 0.706\n",
      "Val loss  0.000472593366459  SSIM  0.967, 0.912, 0.852, 0.797, 0.75, 0.708, 0.672, 0.637\n",
      "Loss  0.000387161717562  SSIM  0.972, 0.927, 0.882, 0.841, 0.802, 0.768, 0.738, 0.707\n",
      "Val loss  0.000470511744672  SSIM  0.968, 0.915, 0.86, 0.808, 0.76, 0.717, 0.679, 0.641\n",
      "Loss  0.000386278188604  SSIM  0.972, 0.927, 0.883, 0.841, 0.803, 0.769, 0.738, 0.706\n",
      "Val loss  0.000473605267063  SSIM  0.967, 0.912, 0.855, 0.8, 0.751, 0.708, 0.67, 0.631\n",
      "Loss  0.000386247789429  SSIM  0.972, 0.927, 0.883, 0.841, 0.804, 0.769, 0.738, 0.707\n",
      "Val loss  0.000471015751245  SSIM  0.968, 0.915, 0.862, 0.81, 0.764, 0.721, 0.684, 0.647\n",
      "Loss  0.000385990765308  SSIM  0.972, 0.927, 0.884, 0.842, 0.804, 0.769, 0.739, 0.708\n",
      "Val loss  0.000478692630248  SSIM  0.966, 0.913, 0.858, 0.805, 0.755, 0.709, 0.669, 0.629\n",
      "Loss  0.000385124674492  SSIM  0.972, 0.928, 0.884, 0.842, 0.805, 0.77, 0.74, 0.708\n",
      "Val loss  0.00047141107457  SSIM  0.968, 0.916, 0.863, 0.812, 0.764, 0.721, 0.683, 0.643\n",
      "Loss  0.000386274935669  SSIM  0.972, 0.928, 0.884, 0.843, 0.805, 0.771, 0.74, 0.709\n",
      "Val loss  0.000469952839892  SSIM  0.968, 0.917, 0.865, 0.815, 0.769, 0.727, 0.69, 0.653\n",
      "Loss  0.000383899596591  SSIM  0.972, 0.928, 0.885, 0.843, 0.806, 0.772, 0.741, 0.71\n",
      "Val loss  0.000471790745913  SSIM  0.968, 0.915, 0.862, 0.81, 0.764, 0.724, 0.688, 0.651\n",
      "Loss  0.000386630657863  SSIM  0.972, 0.928, 0.885, 0.844, 0.806, 0.772, 0.741, 0.71\n",
      "Val loss  0.000467845027742  SSIM  0.968, 0.916, 0.864, 0.812, 0.765, 0.72, 0.681, 0.642\n",
      "saving the model  0.000467845027742\n",
      "Loss  0.000384291208152  SSIM  0.972, 0.929, 0.885, 0.844, 0.807, 0.773, 0.742, 0.711\n",
      "Val loss  0.000469274753937  SSIM  0.969, 0.917, 0.865, 0.814, 0.767, 0.725, 0.686, 0.648\n",
      "Loss  0.000384290138967  SSIM  0.972, 0.929, 0.886, 0.845, 0.808, 0.773, 0.743, 0.712\n",
      "Val loss  0.000471498399391  SSIM  0.968, 0.915, 0.861, 0.809, 0.762, 0.716, 0.677, 0.639\n",
      "Loss  0.000384488379686  SSIM  0.972, 0.929, 0.886, 0.845, 0.808, 0.774, 0.743, 0.712\n",
      "Val loss  0.000467098595691  SSIM  0.969, 0.917, 0.865, 0.814, 0.766, 0.723, 0.684, 0.645\n",
      "saving the model  0.000467098595691\n",
      "Loss  0.000384273011699  SSIM  0.972, 0.93, 0.887, 0.847, 0.81, 0.775, 0.745, 0.714\n",
      "Val loss  0.00047252521175  SSIM  0.968, 0.916, 0.864, 0.814, 0.767, 0.722, 0.685, 0.646\n",
      "Loss  0.000384074713377  SSIM  0.972, 0.93, 0.888, 0.847, 0.81, 0.776, 0.745, 0.714\n",
      "Val loss  0.000466339027567  SSIM  0.968, 0.918, 0.867, 0.816, 0.769, 0.727, 0.689, 0.651\n",
      "saving the model  0.000466339027567\n",
      "Loss  0.000383791318253  SSIM  0.972, 0.93, 0.888, 0.848, 0.811, 0.776, 0.746, 0.715\n",
      "Val loss  0.000467473443132  SSIM  0.968, 0.916, 0.863, 0.811, 0.763, 0.72, 0.681, 0.64\n",
      "Loss  0.000383201576165  SSIM  0.972, 0.93, 0.889, 0.848, 0.811, 0.777, 0.747, 0.715\n",
      "Val loss  0.000465384724084  SSIM  0.969, 0.92, 0.869, 0.819, 0.774, 0.731, 0.693, 0.655\n",
      "saving the model  0.000465384724084\n",
      "Loss  0.000383402879636  SSIM  0.972, 0.931, 0.889, 0.848, 0.811, 0.778, 0.747, 0.716\n",
      "Val loss  0.000472308318596  SSIM  0.969, 0.922, 0.872, 0.823, 0.778, 0.734, 0.697, 0.659\n",
      "Loss  0.000383246807301  SSIM  0.972, 0.931, 0.889, 0.849, 0.812, 0.777, 0.747, 0.716\n",
      "Val loss  0.000466502170137  SSIM  0.969, 0.92, 0.869, 0.819, 0.773, 0.73, 0.692, 0.653\n",
      "Loss  0.00038292679076  SSIM  0.973, 0.931, 0.889, 0.849, 0.812, 0.778, 0.747, 0.716\n",
      "Val loss  0.000471027677238  SSIM  0.969, 0.918, 0.866, 0.817, 0.771, 0.728, 0.689, 0.649\n",
      "Loss  0.000382856232642  SSIM  0.972, 0.931, 0.889, 0.85, 0.813, 0.778, 0.748, 0.716\n",
      "Val loss  0.000465264600934  SSIM  0.969, 0.919, 0.866, 0.817, 0.771, 0.728, 0.691, 0.653\n",
      "saving the model  0.000465264600934\n",
      "Loss  0.000382727950547  SSIM  0.972, 0.931, 0.889, 0.85, 0.813, 0.778, 0.748, 0.717\n",
      "Val loss  0.000473297536839  SSIM  0.968, 0.919, 0.869, 0.817, 0.771, 0.73, 0.692, 0.655\n",
      "Loss  0.000381908266259  SSIM  0.973, 0.931, 0.89, 0.85, 0.813, 0.779, 0.748, 0.717\n",
      "Val loss  0.000466212159197  SSIM  0.969, 0.921, 0.872, 0.823, 0.777, 0.734, 0.697, 0.658\n",
      "Loss  0.000381595666874  SSIM  0.972, 0.931, 0.89, 0.85, 0.813, 0.78, 0.749, 0.717\n",
      "Val loss  0.000469405962212  SSIM  0.969, 0.92, 0.87, 0.821, 0.776, 0.733, 0.696, 0.658\n",
      "Loss  0.000382617853152  SSIM  0.973, 0.931, 0.89, 0.85, 0.813, 0.779, 0.749, 0.717\n",
      "Val loss  0.000469731058634  SSIM  0.969, 0.922, 0.873, 0.824, 0.778, 0.738, 0.701, 0.665\n",
      "Loss  0.000381622895948  SSIM  0.973, 0.932, 0.89, 0.85, 0.814, 0.78, 0.749, 0.718\n",
      "Val loss  0.000470427179942  SSIM  0.969, 0.921, 0.872, 0.824, 0.779, 0.737, 0.7, 0.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000381094301612  SSIM  0.973, 0.932, 0.891, 0.851, 0.814, 0.78, 0.749, 0.718\n",
      "Val loss  0.000468830291589  SSIM  0.969, 0.922, 0.872, 0.823, 0.778, 0.735, 0.696, 0.658\n",
      "Loss  0.000381096877144  SSIM  0.973, 0.932, 0.891, 0.851, 0.815, 0.78, 0.75, 0.719\n",
      "Val loss  0.000470723516482  SSIM  0.969, 0.92, 0.869, 0.819, 0.772, 0.729, 0.691, 0.653\n",
      "Loss  0.00038192267655  SSIM  0.972, 0.932, 0.891, 0.851, 0.814, 0.78, 0.75, 0.718\n",
      "Val loss  0.000467566820269  SSIM  0.969, 0.92, 0.868, 0.819, 0.773, 0.729, 0.691, 0.651\n",
      "Loss  0.000380448178688  SSIM  0.973, 0.932, 0.891, 0.851, 0.815, 0.781, 0.75, 0.719\n",
      "Val loss  0.000466943892068  SSIM  0.969, 0.922, 0.873, 0.825, 0.781, 0.74, 0.703, 0.666\n",
      "Loss  0.000380774947542  SSIM  0.973, 0.932, 0.891, 0.852, 0.815, 0.78, 0.75, 0.719\n",
      "Val loss  0.000472872769518  SSIM  0.969, 0.923, 0.875, 0.827, 0.782, 0.742, 0.705, 0.668\n",
      "Loss  0.000380639463927  SSIM  0.973, 0.932, 0.891, 0.852, 0.815, 0.781, 0.751, 0.719\n",
      "Val loss  0.000472282081202  SSIM  0.969, 0.919, 0.867, 0.816, 0.769, 0.725, 0.686, 0.645\n",
      "Loss  0.00038050978149  SSIM  0.973, 0.932, 0.891, 0.852, 0.815, 0.781, 0.75, 0.719\n",
      "Val loss  0.000468004200608  SSIM  0.969, 0.921, 0.873, 0.825, 0.78, 0.737, 0.7, 0.662\n",
      "Loss  0.000380371951973  SSIM  0.973, 0.932, 0.892, 0.852, 0.816, 0.781, 0.751, 0.72\n",
      "Val loss  0.000467690241116  SSIM  0.969, 0.92, 0.869, 0.819, 0.772, 0.73, 0.691, 0.652\n",
      "Loss  0.000379587860662  SSIM  0.973, 0.933, 0.892, 0.852, 0.816, 0.782, 0.751, 0.72\n",
      "Val loss  0.000466492654814  SSIM  0.969, 0.92, 0.869, 0.82, 0.775, 0.731, 0.694, 0.654\n",
      "Loss  0.000380179068665  SSIM  0.973, 0.933, 0.892, 0.852, 0.816, 0.782, 0.751, 0.72\n",
      "Val loss  0.000467593270121  SSIM  0.969, 0.922, 0.873, 0.824, 0.778, 0.736, 0.698, 0.659\n",
      "Loss  0.000379670912427  SSIM  0.973, 0.933, 0.892, 0.853, 0.816, 0.782, 0.751, 0.72\n",
      "Val loss  0.000473532786942  SSIM  0.969, 0.919, 0.867, 0.816, 0.769, 0.727, 0.689, 0.65\n",
      "Loss  0.000379451212357  SSIM  0.973, 0.933, 0.892, 0.853, 0.816, 0.782, 0.752, 0.72\n",
      "Val loss  0.00046802117757  SSIM  0.97, 0.924, 0.876, 0.828, 0.784, 0.744, 0.707, 0.67\n",
      "Loss  0.00037858687583  SSIM  0.973, 0.933, 0.892, 0.853, 0.816, 0.783, 0.752, 0.721\n",
      "Val loss  0.000468325493333  SSIM  0.969, 0.922, 0.872, 0.822, 0.775, 0.732, 0.693, 0.653\n",
      "Loss  0.000379216300185  SSIM  0.973, 0.933, 0.892, 0.853, 0.816, 0.783, 0.752, 0.721\n",
      "Val loss  0.000477216166269  SSIM  0.969, 0.923, 0.876, 0.828, 0.783, 0.743, 0.706, 0.67\n",
      "Loss  0.00037958768221  SSIM  0.973, 0.933, 0.892, 0.853, 0.817, 0.783, 0.752, 0.721\n",
      "Val loss  0.000466063742759  SSIM  0.97, 0.922, 0.871, 0.823, 0.778, 0.737, 0.699, 0.661\n",
      "Loss  0.000378745370388  SSIM  0.973, 0.933, 0.892, 0.853, 0.817, 0.783, 0.752, 0.721\n",
      "Val loss  0.000464194055879  SSIM  0.969, 0.922, 0.874, 0.825, 0.779, 0.736, 0.698, 0.66\n",
      "saving the model  0.000464194055879\n",
      "Loss  0.000377867235556  SSIM  0.973, 0.933, 0.893, 0.853, 0.817, 0.783, 0.752, 0.721\n",
      "Val loss  0.000467960803537  SSIM  0.97, 0.923, 0.874, 0.825, 0.779, 0.735, 0.697, 0.658\n",
      "Loss  0.000378824417175  SSIM  0.973, 0.933, 0.893, 0.853, 0.817, 0.783, 0.753, 0.722\n",
      "Val loss  0.000467128454475  SSIM  0.969, 0.924, 0.876, 0.828, 0.784, 0.742, 0.705, 0.668\n",
      "Loss  0.000377433661264  SSIM  0.973, 0.933, 0.893, 0.854, 0.817, 0.784, 0.753, 0.722\n",
      "Val loss  0.000476886176213  SSIM  0.97, 0.924, 0.876, 0.83, 0.786, 0.745, 0.709, 0.673\n",
      "Loss  0.000378042783167  SSIM  0.973, 0.933, 0.893, 0.854, 0.817, 0.784, 0.753, 0.722\n",
      "Val loss  0.000474099169718  SSIM  0.97, 0.924, 0.876, 0.829, 0.784, 0.741, 0.702, 0.664\n",
      "Loss  0.000378250602964  SSIM  0.973, 0.933, 0.893, 0.854, 0.818, 0.783, 0.753, 0.722\n",
      "Val loss  0.000471358238719  SSIM  0.969, 0.923, 0.876, 0.828, 0.783, 0.74, 0.701, 0.663\n",
      "Loss  0.000378148693484  SSIM  0.973, 0.933, 0.893, 0.854, 0.818, 0.784, 0.753, 0.722\n",
      "Val loss  0.000465809019748  SSIM  0.97, 0.923, 0.874, 0.826, 0.781, 0.738, 0.7, 0.661\n",
      "Loss  0.000377795781197  SSIM  0.973, 0.933, 0.893, 0.854, 0.818, 0.783, 0.753, 0.722\n",
      "Val loss  0.000467645716795  SSIM  0.969, 0.923, 0.874, 0.825, 0.779, 0.735, 0.696, 0.657\n",
      "Loss  0.000377984637632  SSIM  0.973, 0.933, 0.893, 0.854, 0.817, 0.784, 0.753, 0.722\n",
      "Val loss  0.000469918460178  SSIM  0.969, 0.922, 0.873, 0.823, 0.776, 0.733, 0.695, 0.657\n",
      "Loss  0.000376978714731  SSIM  0.973, 0.934, 0.894, 0.854, 0.818, 0.784, 0.754, 0.723\n",
      "Val loss  0.000469534398988  SSIM  0.969, 0.923, 0.874, 0.826, 0.781, 0.741, 0.704, 0.666\n",
      "Loss  0.000377243012347  SSIM  0.973, 0.934, 0.893, 0.854, 0.818, 0.784, 0.754, 0.723\n",
      "Val loss  0.000466191090818  SSIM  0.97, 0.924, 0.876, 0.829, 0.784, 0.744, 0.708, 0.67\n",
      "Loss  0.000376822316544  SSIM  0.973, 0.934, 0.893, 0.854, 0.818, 0.784, 0.754, 0.723\n",
      "Val loss  0.000465008175699  SSIM  0.969, 0.923, 0.874, 0.826, 0.781, 0.74, 0.702, 0.665\n",
      "Loss  0.00037681127182  SSIM  0.973, 0.934, 0.893, 0.855, 0.818, 0.784, 0.754, 0.723\n",
      "Val loss  0.000468191059015  SSIM  0.969, 0.922, 0.872, 0.824, 0.779, 0.737, 0.699, 0.662\n",
      "Loss  0.000376313278371  SSIM  0.973, 0.934, 0.893, 0.855, 0.818, 0.784, 0.754, 0.723\n",
      "Val loss  0.000465178258775  SSIM  0.97, 0.924, 0.876, 0.827, 0.781, 0.738, 0.701, 0.664\n",
      "Loss  0.000376773000372  SSIM  0.973, 0.934, 0.894, 0.854, 0.818, 0.784, 0.754, 0.723\n",
      "Val loss  0.000466869827651  SSIM  0.97, 0.923, 0.875, 0.826, 0.781, 0.738, 0.701, 0.662\n",
      "Loss  0.000375802749119  SSIM  0.973, 0.934, 0.894, 0.855, 0.818, 0.785, 0.755, 0.724\n",
      "Val loss  0.000466967566346  SSIM  0.971, 0.924, 0.876, 0.828, 0.782, 0.74, 0.701, 0.663\n",
      "Loss  0.000376507707495  SSIM  0.973, 0.934, 0.894, 0.854, 0.819, 0.785, 0.754, 0.724\n",
      "Val loss  0.000466946041095  SSIM  0.969, 0.924, 0.876, 0.829, 0.784, 0.742, 0.703, 0.665\n",
      "Loss  0.000377168135221  SSIM  0.973, 0.934, 0.894, 0.855, 0.818, 0.785, 0.754, 0.723\n",
      "Val loss  0.000466612870921  SSIM  0.969, 0.923, 0.875, 0.826, 0.78, 0.736, 0.698, 0.659\n",
      "Loss  0.000375545340201  SSIM  0.973, 0.934, 0.894, 0.855, 0.818, 0.785, 0.755, 0.724\n",
      "Val loss  0.00046690193523  SSIM  0.969, 0.924, 0.876, 0.829, 0.784, 0.741, 0.703, 0.666\n",
      "Loss  0.000376251521229  SSIM  0.973, 0.934, 0.894, 0.855, 0.819, 0.785, 0.755, 0.724\n",
      "Val loss  0.000467283465841  SSIM  0.969, 0.922, 0.872, 0.824, 0.778, 0.735, 0.697, 0.657\n",
      "Loss  0.000376025774883  SSIM  0.973, 0.934, 0.894, 0.855, 0.819, 0.785, 0.755, 0.724\n",
      "Val loss  0.000466691397771  SSIM  0.969, 0.922, 0.874, 0.826, 0.78, 0.737, 0.7, 0.662\n",
      "Loss  0.00037646836843  SSIM  0.973, 0.934, 0.894, 0.855, 0.819, 0.786, 0.755, 0.724\n",
      "Val loss  0.000467276688374  SSIM  0.969, 0.923, 0.876, 0.829, 0.785, 0.744, 0.708, 0.671\n",
      "Loss  0.000375316006808  SSIM  0.973, 0.934, 0.894, 0.855, 0.819, 0.786, 0.755, 0.724\n",
      "Val loss  0.000464002424269  SSIM  0.97, 0.924, 0.876, 0.828, 0.784, 0.742, 0.704, 0.665\n",
      "saving the model  0.000464002424269\n",
      "Loss  0.000375633090891  SSIM  0.973, 0.934, 0.894, 0.855, 0.82, 0.786, 0.755, 0.724\n",
      "Val loss  0.000468549093814  SSIM  0.97, 0.925, 0.878, 0.831, 0.787, 0.745, 0.708, 0.67\n",
      "Loss  0.000375423633623  SSIM  0.973, 0.934, 0.894, 0.855, 0.819, 0.785, 0.756, 0.724\n",
      "Val loss  0.000465554572875  SSIM  0.97, 0.924, 0.875, 0.827, 0.782, 0.74, 0.702, 0.663\n",
      "Loss  0.000374059527777  SSIM  0.973, 0.934, 0.894, 0.855, 0.82, 0.786, 0.756, 0.725\n",
      "Val loss  0.000467033069173  SSIM  0.97, 0.924, 0.876, 0.828, 0.782, 0.739, 0.701, 0.664\n",
      "Loss  0.00037526803024  SSIM  0.973, 0.934, 0.894, 0.855, 0.82, 0.786, 0.756, 0.725\n",
      "Val loss  0.000466841536574  SSIM  0.97, 0.923, 0.874, 0.825, 0.779, 0.739, 0.701, 0.662\n",
      "Loss  0.000375164471916  SSIM  0.973, 0.934, 0.894, 0.855, 0.819, 0.786, 0.756, 0.725\n",
      "Val loss  0.000466049059818  SSIM  0.969, 0.923, 0.875, 0.826, 0.78, 0.738, 0.7, 0.661\n",
      "Loss  0.000373968467846  SSIM  0.973, 0.934, 0.895, 0.856, 0.82, 0.786, 0.756, 0.725\n",
      "Val loss  0.000469796073623  SSIM  0.97, 0.925, 0.878, 0.831, 0.786, 0.743, 0.706, 0.67\n",
      "Loss  0.00037477798057  SSIM  0.973, 0.934, 0.894, 0.856, 0.82, 0.786, 0.756, 0.725\n",
      "Val loss  0.000470903287816  SSIM  0.97, 0.923, 0.874, 0.824, 0.778, 0.735, 0.697, 0.658\n",
      "Loss  0.000374120827809  SSIM  0.973, 0.934, 0.894, 0.856, 0.82, 0.786, 0.757, 0.725\n",
      "Val loss  0.000464354791096  SSIM  0.97, 0.924, 0.877, 0.83, 0.786, 0.746, 0.709, 0.672\n",
      "Loss  0.000374708954164  SSIM  0.973, 0.934, 0.894, 0.856, 0.82, 0.786, 0.756, 0.725\n",
      "Val loss  0.000467888373882  SSIM  0.969, 0.923, 0.874, 0.825, 0.78, 0.738, 0.699, 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000373799147559  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.786, 0.757, 0.726\n",
      "Val loss  0.000467884431418  SSIM  0.97, 0.924, 0.876, 0.829, 0.785, 0.745, 0.709, 0.672\n",
      "Loss  0.000373492398201  SSIM  0.974, 0.935, 0.894, 0.856, 0.82, 0.787, 0.757, 0.726\n",
      "Val loss  0.000478042422328  SSIM  0.97, 0.922, 0.871, 0.823, 0.779, 0.74, 0.704, 0.666\n",
      "Loss  0.00037452472685  SSIM  0.973, 0.934, 0.895, 0.856, 0.82, 0.787, 0.757, 0.726\n",
      "Val loss  0.000467852215457  SSIM  0.969, 0.923, 0.875, 0.827, 0.78, 0.74, 0.702, 0.663\n",
      "Loss  0.000373772008618  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.757, 0.726\n",
      "Val loss  0.000468383471482  SSIM  0.969, 0.923, 0.874, 0.825, 0.779, 0.736, 0.698, 0.657\n",
      "Loss  0.000373413304355  SSIM  0.973, 0.934, 0.895, 0.856, 0.82, 0.787, 0.757, 0.726\n",
      "Val loss  0.000470041779801  SSIM  0.969, 0.924, 0.876, 0.827, 0.78, 0.738, 0.7, 0.66\n",
      "Loss  0.000373305060963  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.757, 0.726\n",
      "Val loss  0.000466973445087  SSIM  0.97, 0.924, 0.876, 0.827, 0.783, 0.743, 0.706, 0.667\n",
      "Loss  0.000373385023626  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.757, 0.726\n",
      "Val loss  0.000465697067499  SSIM  0.97, 0.925, 0.878, 0.831, 0.788, 0.747, 0.709, 0.671\n",
      "Loss  0.000372609283748  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.758, 0.727\n",
      "Val loss  0.000464795497886  SSIM  0.97, 0.924, 0.876, 0.827, 0.783, 0.741, 0.703, 0.663\n",
      "Loss  0.000372796655821  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.758, 0.726\n",
      "Val loss  0.000464597003185  SSIM  0.97, 0.924, 0.877, 0.829, 0.784, 0.742, 0.705, 0.667\n",
      "Loss  0.000373149801341  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.757, 0.727\n",
      "Val loss  0.000467023815494  SSIM  0.97, 0.925, 0.878, 0.831, 0.786, 0.744, 0.708, 0.673\n",
      "Loss  0.000373183821234  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.787, 0.758, 0.727\n",
      "Val loss  0.000465218875092  SSIM  0.97, 0.924, 0.876, 0.827, 0.782, 0.741, 0.703, 0.663\n",
      "Loss  0.000371975334218  SSIM  0.973, 0.935, 0.895, 0.856, 0.82, 0.788, 0.758, 0.727\n",
      "Val loss  0.000466985456995  SSIM  0.969, 0.923, 0.875, 0.828, 0.783, 0.743, 0.707, 0.668\n",
      "Loss  0.000372824369204  SSIM  0.973, 0.935, 0.895, 0.857, 0.82, 0.787, 0.758, 0.727\n",
      "Val loss  0.000471897635318  SSIM  0.97, 0.924, 0.877, 0.829, 0.785, 0.745, 0.707, 0.667\n",
      "Loss  0.000373324013087  SSIM  0.973, 0.935, 0.895, 0.856, 0.821, 0.788, 0.758, 0.726\n",
      "Val loss  0.000474137693644  SSIM  0.97, 0.924, 0.877, 0.83, 0.787, 0.747, 0.711, 0.675\n",
      "Loss  0.000372478309414  SSIM  0.973, 0.935, 0.895, 0.856, 0.821, 0.788, 0.758, 0.726\n",
      "Val loss  0.000465327311715  SSIM  0.97, 0.924, 0.877, 0.831, 0.786, 0.746, 0.711, 0.673\n",
      "Loss  0.000372437665288  SSIM  0.973, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.000467271711619  SSIM  0.97, 0.925, 0.878, 0.831, 0.787, 0.748, 0.711, 0.674\n",
      "Loss  0.000371733050583  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.00047899169632  SSIM  0.969, 0.925, 0.878, 0.832, 0.789, 0.749, 0.713, 0.676\n",
      "Loss  0.000371749863239  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.000469660551636  SSIM  0.969, 0.923, 0.875, 0.824, 0.775, 0.727, 0.689, 0.649\n",
      "Loss  0.000371341138962  SSIM  0.973, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.000467000487086  SSIM  0.97, 0.924, 0.876, 0.83, 0.787, 0.746, 0.708, 0.67\n",
      "Loss  0.000371665233598  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.000466104728577  SSIM  0.97, 0.923, 0.875, 0.827, 0.782, 0.742, 0.707, 0.669\n",
      "Loss  0.000371525838541  SSIM  0.973, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.000465676270891  SSIM  0.97, 0.925, 0.877, 0.83, 0.787, 0.747, 0.71, 0.671\n",
      "Loss  0.000371027055953  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.758, 0.727\n",
      "Val loss  0.000468166524312  SSIM  0.969, 0.924, 0.875, 0.828, 0.783, 0.745, 0.708, 0.669\n",
      "Loss  0.000371646862858  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000466863483831  SSIM  0.97, 0.925, 0.879, 0.833, 0.791, 0.749, 0.711, 0.674\n",
      "Loss  0.000371016573358  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000466973707604  SSIM  0.97, 0.924, 0.875, 0.826, 0.781, 0.737, 0.702, 0.667\n",
      "Loss  0.000371178435498  SSIM  0.974, 0.935, 0.895, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000464515623928  SSIM  0.97, 0.925, 0.876, 0.828, 0.784, 0.743, 0.706, 0.667\n",
      "Loss  0.000370896634279  SSIM  0.974, 0.935, 0.896, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000469675199594  SSIM  0.97, 0.925, 0.879, 0.832, 0.788, 0.747, 0.712, 0.676\n",
      "Loss  0.000371130922263  SSIM  0.974, 0.935, 0.896, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000465132542187  SSIM  0.97, 0.925, 0.878, 0.831, 0.786, 0.745, 0.708, 0.669\n",
      "Loss  0.000370716813531  SSIM  0.974, 0.935, 0.896, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000470573206316  SSIM  0.969, 0.923, 0.874, 0.827, 0.783, 0.741, 0.703, 0.664\n",
      "Loss  0.000371061720115  SSIM  0.973, 0.935, 0.896, 0.857, 0.822, 0.789, 0.759, 0.728\n",
      "Val loss  0.000469846858119  SSIM  0.97, 0.925, 0.878, 0.831, 0.787, 0.747, 0.71, 0.673\n",
      "Loss  0.000369865272548  SSIM  0.974, 0.935, 0.896, 0.857, 0.822, 0.789, 0.759, 0.728\n",
      "Val loss  0.000471355753078  SSIM  0.97, 0.926, 0.879, 0.832, 0.788, 0.746, 0.71, 0.671\n",
      "Loss  0.000371286152065  SSIM  0.974, 0.935, 0.896, 0.857, 0.821, 0.788, 0.759, 0.728\n",
      "Val loss  0.000468191003252  SSIM  0.97, 0.925, 0.879, 0.832, 0.788, 0.744, 0.705, 0.664\n",
      "Loss  0.000370114594698  SSIM  0.974, 0.935, 0.896, 0.857, 0.822, 0.789, 0.759, 0.728\n",
      "Val loss  0.000466826128599  SSIM  0.97, 0.923, 0.873, 0.824, 0.777, 0.734, 0.696, 0.654\n",
      "Loss  0.000370700720568  SSIM  0.974, 0.935, 0.896, 0.857, 0.821, 0.789, 0.759, 0.728\n",
      "Val loss  0.000478489937203  SSIM  0.97, 0.925, 0.879, 0.833, 0.79, 0.75, 0.715, 0.679\n",
      "Loss  0.000370421236976  SSIM  0.974, 0.935, 0.896, 0.857, 0.822, 0.789, 0.759, 0.728\n",
      "Val loss  0.000463405943068  SSIM  0.97, 0.925, 0.878, 0.83, 0.786, 0.747, 0.711, 0.673\n",
      "saving the model  0.000463405943068\n",
      "Loss  0.000369888371385  SSIM  0.974, 0.935, 0.896, 0.857, 0.822, 0.789, 0.759, 0.729\n",
      "Val loss  0.000476901038608  SSIM  0.97, 0.925, 0.878, 0.832, 0.787, 0.744, 0.707, 0.671\n",
      "Loss  0.000369790760563  SSIM  0.974, 0.935, 0.896, 0.858, 0.822, 0.789, 0.759, 0.729\n",
      "Val loss  0.000468400329293  SSIM  0.97, 0.925, 0.877, 0.832, 0.789, 0.747, 0.71, 0.672\n",
      "Loss  0.000369903298538  SSIM  0.974, 0.935, 0.896, 0.858, 0.822, 0.789, 0.76, 0.729\n",
      "Val loss  0.0004643177978  SSIM  0.97, 0.926, 0.879, 0.832, 0.787, 0.745, 0.709, 0.672\n",
      "Loss  0.000369926474165  SSIM  0.974, 0.935, 0.896, 0.858, 0.822, 0.789, 0.76, 0.729\n",
      "Val loss  0.000467350287596  SSIM  0.97, 0.926, 0.88, 0.834, 0.791, 0.751, 0.715, 0.678\n",
      "Loss  0.000369671317211  SSIM  0.974, 0.935, 0.896, 0.858, 0.822, 0.789, 0.76, 0.729\n",
      "Val loss  0.000463405888178  SSIM  0.97, 0.925, 0.878, 0.832, 0.787, 0.748, 0.712, 0.674\n",
      "saving the model  0.000463405888178\n",
      "Loss  0.000370367319153  SSIM  0.974, 0.935, 0.896, 0.858, 0.822, 0.789, 0.76, 0.728\n",
      "Val loss  0.000469680040784  SSIM  0.97, 0.926, 0.88, 0.833, 0.791, 0.751, 0.714, 0.677\n",
      "Loss  0.000369419999859  SSIM  0.974, 0.936, 0.896, 0.858, 0.823, 0.789, 0.76, 0.729\n",
      "Val loss  0.000467480071762  SSIM  0.97, 0.924, 0.875, 0.827, 0.785, 0.743, 0.705, 0.665\n",
      "Loss  0.000369945239755  SSIM  0.974, 0.935, 0.896, 0.858, 0.822, 0.79, 0.76, 0.729\n",
      "Val loss  0.000467077662295  SSIM  0.97, 0.925, 0.878, 0.831, 0.788, 0.747, 0.709, 0.669\n",
      "Loss  0.000369308639492  SSIM  0.974, 0.936, 0.896, 0.858, 0.822, 0.79, 0.76, 0.729\n",
      "Val loss  0.000468078069622  SSIM  0.97, 0.925, 0.877, 0.831, 0.787, 0.746, 0.708, 0.668\n",
      "Loss  0.000368485300748  SSIM  0.974, 0.936, 0.896, 0.858, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.000466872791061  SSIM  0.97, 0.926, 0.878, 0.831, 0.786, 0.746, 0.709, 0.669\n",
      "Loss  0.000368336188325  SSIM  0.974, 0.936, 0.896, 0.858, 0.823, 0.79, 0.76, 0.729\n",
      "Val loss  0.000466224278673  SSIM  0.97, 0.925, 0.877, 0.829, 0.785, 0.745, 0.708, 0.669\n",
      "Loss  0.000370064018352  SSIM  0.974, 0.935, 0.897, 0.858, 0.822, 0.79, 0.76, 0.729\n",
      "Val loss  0.000465199507657  SSIM  0.97, 0.925, 0.879, 0.831, 0.787, 0.746, 0.71, 0.672\n",
      "Loss  0.000368862843271  SSIM  0.974, 0.936, 0.897, 0.858, 0.823, 0.79, 0.76, 0.729\n",
      "Val loss  0.00046594206593  SSIM  0.97, 0.926, 0.88, 0.834, 0.79, 0.75, 0.714, 0.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000369021353925  SSIM  0.974, 0.935, 0.897, 0.858, 0.823, 0.79, 0.761, 0.729\n",
      "Val loss  0.000465352256957  SSIM  0.97, 0.926, 0.879, 0.833, 0.79, 0.75, 0.714, 0.677\n",
      "Loss  0.000368395417351  SSIM  0.974, 0.936, 0.897, 0.858, 0.823, 0.79, 0.761, 0.729\n",
      "Val loss  0.0004720626403  SSIM  0.97, 0.926, 0.881, 0.836, 0.793, 0.754, 0.719, 0.683\n",
      "Loss  0.000368935490394  SSIM  0.974, 0.936, 0.897, 0.858, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.000465643693111  SSIM  0.97, 0.925, 0.877, 0.829, 0.785, 0.746, 0.711, 0.673\n",
      "Loss  0.000368332534249  SSIM  0.974, 0.936, 0.897, 0.858, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.00046670158155  SSIM  0.97, 0.925, 0.877, 0.83, 0.785, 0.745, 0.708, 0.669\n",
      "Loss  0.00036913311794  SSIM  0.974, 0.936, 0.897, 0.858, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.000466500859649  SSIM  0.971, 0.926, 0.88, 0.833, 0.79, 0.75, 0.713, 0.675\n",
      "Loss  0.000367516221214  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.761, 0.73\n",
      "Val loss  0.000469251644739  SSIM  0.97, 0.926, 0.88, 0.833, 0.788, 0.747, 0.712, 0.675\n",
      "Loss  0.000371892351138  SSIM  0.974, 0.936, 0.896, 0.858, 0.823, 0.79, 0.76, 0.73\n",
      "Val loss  0.000462361175509  SSIM  0.97, 0.926, 0.88, 0.833, 0.79, 0.75, 0.712, 0.673\n",
      "saving the model  0.000462361175509\n",
      "Loss  0.000367364100798  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.000466379238642  SSIM  0.971, 0.924, 0.875, 0.827, 0.785, 0.745, 0.708, 0.67\n",
      "Loss  0.000368685614219  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.000466507975827  SSIM  0.97, 0.925, 0.879, 0.832, 0.788, 0.749, 0.713, 0.676\n",
      "Loss  0.00036801029028  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.79, 0.761, 0.73\n",
      "Val loss  0.000464322749001  SSIM  0.971, 0.925, 0.878, 0.831, 0.786, 0.748, 0.71, 0.671\n",
      "Loss  0.00036830043615  SSIM  0.974, 0.936, 0.897, 0.858, 0.823, 0.791, 0.761, 0.73\n",
      "Val loss  0.00046618850634  SSIM  0.97, 0.926, 0.88, 0.834, 0.79, 0.749, 0.713, 0.678\n",
      "Loss  0.000367654204848  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.762, 0.73\n",
      "Val loss  0.000466898443527  SSIM  0.97, 0.926, 0.879, 0.832, 0.787, 0.745, 0.708, 0.669\n",
      "Loss  0.000367477178359  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.762, 0.73\n",
      "Val loss  0.000468203355442  SSIM  0.97, 0.925, 0.879, 0.832, 0.787, 0.744, 0.707, 0.667\n",
      "Loss  0.000368151046569  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.761, 0.73\n",
      "Val loss  0.000464615965728  SSIM  0.971, 0.926, 0.88, 0.833, 0.789, 0.749, 0.713, 0.676\n",
      "Loss  0.000367752028486  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.761, 0.73\n",
      "Val loss  0.000472775158065  SSIM  0.97, 0.926, 0.88, 0.833, 0.789, 0.749, 0.713, 0.675\n",
      "Loss  0.000367488582001  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.762, 0.73\n",
      "Val loss  0.000470011024154  SSIM  0.97, 0.926, 0.88, 0.834, 0.791, 0.752, 0.715, 0.678\n",
      "Loss  0.000367248923867  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.761, 0.73\n",
      "Val loss  0.00047451918287  SSIM  0.971, 0.927, 0.881, 0.836, 0.793, 0.753, 0.718, 0.682\n",
      "Loss  0.000367266610332  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.762, 0.73\n",
      "Val loss  0.00047199772048  SSIM  0.97, 0.924, 0.876, 0.828, 0.785, 0.742, 0.703, 0.662\n",
      "Loss  0.000367984834794  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.761, 0.73\n",
      "Val loss  0.000465931124869  SSIM  0.97, 0.925, 0.877, 0.831, 0.788, 0.747, 0.709, 0.671\n",
      "Loss  0.000366817664158  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000466088069428  SSIM  0.971, 0.926, 0.88, 0.833, 0.79, 0.749, 0.713, 0.675\n",
      "Loss  0.000367546249494  SSIM  0.974, 0.936, 0.897, 0.859, 0.823, 0.791, 0.762, 0.73\n",
      "Val loss  0.000467318497249  SSIM  0.971, 0.926, 0.879, 0.831, 0.785, 0.742, 0.705, 0.667\n",
      "Loss  0.000367083377138  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.761, 0.731\n",
      "Val loss  0.000465147935203  SSIM  0.971, 0.926, 0.88, 0.834, 0.789, 0.745, 0.71, 0.673\n",
      "Loss  0.00036714515201  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000464958827011  SSIM  0.97, 0.925, 0.877, 0.829, 0.783, 0.74, 0.704, 0.666\n",
      "Loss  0.000366621340867  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000464816335705  SSIM  0.971, 0.926, 0.88, 0.834, 0.791, 0.753, 0.717, 0.681\n",
      "Loss  0.00036768856474  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000470935479796  SSIM  0.969, 0.924, 0.875, 0.825, 0.78, 0.738, 0.699, 0.659\n",
      "Loss  0.00036686687381  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000471694348031  SSIM  0.971, 0.926, 0.878, 0.831, 0.788, 0.747, 0.709, 0.669\n",
      "Loss  0.00036614921985  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.792, 0.762, 0.731\n",
      "Val loss  0.000464463820215  SSIM  0.971, 0.926, 0.88, 0.833, 0.789, 0.748, 0.711, 0.672\n",
      "Loss  0.00036652077323  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000467596822244  SSIM  0.97, 0.926, 0.88, 0.834, 0.791, 0.751, 0.714, 0.677\n",
      "Loss  0.000367388443623  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000473672670196  SSIM  0.97, 0.924, 0.876, 0.831, 0.788, 0.749, 0.711, 0.672\n",
      "Loss  0.000366837932625  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.792, 0.762, 0.731\n",
      "Val loss  0.000464523974515  SSIM  0.97, 0.926, 0.88, 0.833, 0.789, 0.749, 0.712, 0.673\n",
      "Loss  0.000366520785767  SSIM  0.974, 0.936, 0.897, 0.859, 0.824, 0.792, 0.762, 0.731\n",
      "Val loss  0.000465733535471  SSIM  0.971, 0.927, 0.881, 0.834, 0.79, 0.751, 0.713, 0.675\n",
      "Loss  0.000365851033757  SSIM  0.974, 0.936, 0.897, 0.86, 0.824, 0.792, 0.763, 0.731\n",
      "Val loss  0.000466151900531  SSIM  0.97, 0.926, 0.88, 0.834, 0.79, 0.749, 0.713, 0.674\n",
      "Loss  0.000366591830904  SSIM  0.974, 0.936, 0.897, 0.86, 0.824, 0.791, 0.762, 0.731\n",
      "Val loss  0.000467370381579  SSIM  0.97, 0.926, 0.88, 0.832, 0.787, 0.743, 0.707, 0.67\n",
      "Loss  0.000366251405749  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.792, 0.762, 0.731\n",
      "Val loss  0.000467912701075  SSIM  0.97, 0.925, 0.876, 0.828, 0.782, 0.741, 0.703, 0.662\n",
      "Loss  0.00036587950187  SSIM  0.974, 0.936, 0.898, 0.859, 0.824, 0.792, 0.763, 0.731\n",
      "Val loss  0.000465935567627  SSIM  0.971, 0.926, 0.879, 0.832, 0.787, 0.745, 0.709, 0.672\n",
      "Loss  0.000366085284757  SSIM  0.974, 0.936, 0.898, 0.859, 0.825, 0.792, 0.762, 0.731\n",
      "Val loss  0.000464108795626  SSIM  0.971, 0.926, 0.879, 0.831, 0.786, 0.746, 0.71, 0.671\n",
      "Loss  0.000367139753742  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.792, 0.763, 0.732\n",
      "Val loss  0.000466476326925  SSIM  0.971, 0.927, 0.881, 0.836, 0.793, 0.753, 0.716, 0.68\n",
      "Loss  0.000365887489819  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.792, 0.763, 0.731\n",
      "Val loss  0.000466716362105  SSIM  0.97, 0.926, 0.88, 0.834, 0.791, 0.751, 0.715, 0.678\n",
      "Loss  0.000365189361014  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.793, 0.763, 0.732\n",
      "Val loss  0.000473451212863  SSIM  0.97, 0.926, 0.881, 0.836, 0.793, 0.754, 0.718, 0.682\n",
      "Loss  0.000366115270388  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.792, 0.763, 0.731\n",
      "Val loss  0.000466511210077  SSIM  0.97, 0.926, 0.881, 0.835, 0.793, 0.753, 0.716, 0.678\n",
      "Loss  0.000365336463773  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.792, 0.763, 0.732\n",
      "Val loss  0.00046582567913  SSIM  0.97, 0.926, 0.879, 0.833, 0.79, 0.75, 0.712, 0.673\n",
      "Loss  0.000366141765105  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.792, 0.763, 0.732\n",
      "Val loss  0.000465974658262  SSIM  0.97, 0.926, 0.879, 0.833, 0.79, 0.751, 0.714, 0.677\n",
      "Loss  0.000365365212627  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.792, 0.763, 0.732\n",
      "Val loss  0.00046740682458  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.75, 0.714, 0.677\n",
      "Loss  0.000365524666558  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.792, 0.763, 0.731\n",
      "Val loss  0.000465181165549  SSIM  0.97, 0.926, 0.878, 0.831, 0.787, 0.748, 0.712, 0.673\n",
      "Loss  0.000365616931925  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.792, 0.763, 0.732\n",
      "Val loss  0.000466497430112  SSIM  0.97, 0.926, 0.88, 0.832, 0.786, 0.743, 0.707, 0.667\n",
      "Loss  0.000365768817965  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.792, 0.763, 0.732\n",
      "Val loss  0.000465919161856  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.747, 0.71, 0.675\n",
      "Loss  0.00036467324958  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.792, 0.763, 0.732\n",
      "Val loss  0.000465059047041  SSIM  0.971, 0.926, 0.88, 0.833, 0.789, 0.749, 0.711, 0.672\n",
      "Loss  0.000365750312183  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.792, 0.763, 0.732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000463984261907  SSIM  0.97, 0.926, 0.88, 0.832, 0.789, 0.749, 0.712, 0.674\n",
      "Loss  0.000364564299055  SSIM  0.974, 0.936, 0.898, 0.86, 0.824, 0.793, 0.763, 0.732\n",
      "Val loss  0.000466061697807  SSIM  0.971, 0.926, 0.879, 0.831, 0.787, 0.747, 0.71, 0.672\n",
      "Loss  0.000365519689983  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.000467885219085  SSIM  0.971, 0.927, 0.881, 0.834, 0.791, 0.751, 0.714, 0.676\n",
      "Loss  0.000364978855359  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.000476648355776  SSIM  0.97, 0.924, 0.876, 0.828, 0.781, 0.74, 0.701, 0.659\n",
      "Loss  0.000364720542611  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.00046862661757  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.749, 0.713, 0.678\n",
      "Loss  0.000364369585698  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.000466919216968  SSIM  0.97, 0.927, 0.881, 0.835, 0.793, 0.753, 0.717, 0.679\n",
      "Loss  0.000365147011986  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.764, 0.732\n",
      "Val loss  0.000470889198012  SSIM  0.97, 0.926, 0.88, 0.835, 0.791, 0.752, 0.716, 0.679\n",
      "Loss  0.000365023076145  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.000464698452328  SSIM  0.97, 0.926, 0.88, 0.833, 0.789, 0.749, 0.712, 0.674\n",
      "Loss  0.000364943335007  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.000463347745535  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.751, 0.716, 0.678\n",
      "Loss  0.000364112555197  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.764, 0.733\n",
      "Val loss  0.000468421781901  SSIM  0.971, 0.925, 0.878, 0.832, 0.788, 0.748, 0.709, 0.669\n",
      "Loss  0.000365115106486  SSIM  0.974, 0.936, 0.898, 0.86, 0.825, 0.793, 0.763, 0.732\n",
      "Val loss  0.000472161840356  SSIM  0.97, 0.925, 0.878, 0.831, 0.789, 0.747, 0.71, 0.671\n",
      "Loss  0.000364394297067  SSIM  0.974, 0.937, 0.898, 0.86, 0.825, 0.793, 0.764, 0.732\n",
      "Val loss  0.000466151506989  SSIM  0.971, 0.926, 0.878, 0.831, 0.787, 0.745, 0.707, 0.667\n",
      "Loss  0.000364257085289  SSIM  0.974, 0.937, 0.898, 0.861, 0.825, 0.793, 0.763, 0.733\n",
      "Val loss  0.000471783329791  SSIM  0.97, 0.926, 0.881, 0.835, 0.793, 0.755, 0.72, 0.684\n",
      "Loss  0.00036480744535  SSIM  0.974, 0.937, 0.898, 0.86, 0.825, 0.793, 0.763, 0.733\n",
      "Val loss  0.000466380287893  SSIM  0.971, 0.927, 0.881, 0.836, 0.793, 0.753, 0.717, 0.68\n",
      "Loss  0.000364430266356  SSIM  0.974, 0.937, 0.898, 0.861, 0.825, 0.793, 0.764, 0.733\n",
      "Val loss  0.000463758017519  SSIM  0.971, 0.927, 0.88, 0.833, 0.789, 0.749, 0.713, 0.675\n",
      "Loss  0.000364496169294  SSIM  0.974, 0.937, 0.898, 0.86, 0.825, 0.793, 0.764, 0.733\n",
      "Val loss  0.00048143410607  SSIM  0.97, 0.924, 0.876, 0.828, 0.785, 0.743, 0.705, 0.665\n",
      "Loss  0.000364502928703  SSIM  0.974, 0.937, 0.898, 0.86, 0.825, 0.793, 0.764, 0.733\n",
      "Val loss  0.000465950919606  SSIM  0.971, 0.926, 0.878, 0.831, 0.787, 0.747, 0.709, 0.668\n",
      "Loss  0.000364160538526  SSIM  0.974, 0.937, 0.898, 0.861, 0.826, 0.794, 0.764, 0.733\n",
      "Val loss  0.000465676733118  SSIM  0.971, 0.927, 0.881, 0.835, 0.793, 0.753, 0.716, 0.679\n",
      "Loss  0.000363766250845  SSIM  0.974, 0.937, 0.898, 0.861, 0.825, 0.794, 0.764, 0.733\n",
      "Val loss  0.0004700474813  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.752, 0.715, 0.677\n",
      "Loss  0.000364914732255  SSIM  0.974, 0.937, 0.898, 0.861, 0.825, 0.793, 0.764, 0.733\n",
      "Val loss  0.000466473239823  SSIM  0.971, 0.927, 0.881, 0.834, 0.788, 0.745, 0.708, 0.673\n",
      "Loss  0.000363902065348  SSIM  0.974, 0.937, 0.898, 0.861, 0.826, 0.793, 0.764, 0.733\n",
      "Val loss  0.000469269695808  SSIM  0.97, 0.926, 0.88, 0.835, 0.792, 0.751, 0.712, 0.673\n",
      "Loss  0.000363896494673  SSIM  0.974, 0.937, 0.898, 0.861, 0.825, 0.793, 0.764, 0.733\n",
      "Val loss  0.000465278342483  SSIM  0.971, 0.927, 0.881, 0.835, 0.792, 0.752, 0.715, 0.677\n",
      "Loss  0.000363994241253  SSIM  0.974, 0.937, 0.898, 0.861, 0.826, 0.793, 0.764, 0.733\n",
      "Val loss  0.000472172308771  SSIM  0.97, 0.926, 0.879, 0.832, 0.786, 0.744, 0.708, 0.669\n",
      "Loss  0.000362967344386  SSIM  0.974, 0.937, 0.898, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000464759819326  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.753, 0.718, 0.681\n",
      "Loss  0.000364614788447  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.793, 0.764, 0.733\n",
      "Val loss  0.000467418773216  SSIM  0.971, 0.926, 0.88, 0.833, 0.79, 0.751, 0.714, 0.676\n",
      "Loss  0.000363013081862  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000465178658429  SSIM  0.971, 0.926, 0.88, 0.834, 0.79, 0.75, 0.713, 0.674\n",
      "Loss  0.000363505953686  SSIM  0.974, 0.937, 0.898, 0.861, 0.826, 0.794, 0.764, 0.733\n",
      "Val loss  0.000469348229584  SSIM  0.97, 0.926, 0.88, 0.833, 0.79, 0.751, 0.714, 0.675\n",
      "Loss  0.000363232834296  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.764, 0.734\n",
      "Val loss  0.000464584881789  SSIM  0.971, 0.927, 0.881, 0.834, 0.79, 0.749, 0.714, 0.676\n",
      "Loss  0.000363654515039  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.764, 0.734\n",
      "Val loss  0.000465717541927  SSIM  0.971, 0.926, 0.879, 0.831, 0.788, 0.747, 0.709, 0.67\n",
      "Loss  0.000363328209026  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000470562364906  SSIM  0.97, 0.924, 0.876, 0.828, 0.785, 0.744, 0.706, 0.667\n",
      "Loss  0.000362934026455  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000466177207883  SSIM  0.971, 0.926, 0.879, 0.831, 0.787, 0.745, 0.709, 0.67\n",
      "Loss  0.000363866991225  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.793, 0.764, 0.734\n",
      "Val loss  0.000465993155667  SSIM  0.971, 0.927, 0.88, 0.833, 0.79, 0.75, 0.712, 0.673\n",
      "Loss  0.000363522751409  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000467985680152  SSIM  0.971, 0.926, 0.879, 0.831, 0.789, 0.75, 0.713, 0.674\n",
      "Loss  0.000363302574932  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000468160492193  SSIM  0.97, 0.927, 0.882, 0.837, 0.794, 0.754, 0.719, 0.683\n",
      "Loss  0.000363240145492  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.00046431937936  SSIM  0.97, 0.927, 0.881, 0.836, 0.793, 0.753, 0.717, 0.679\n",
      "Loss  0.000362989751985  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000463427723327  SSIM  0.971, 0.927, 0.882, 0.836, 0.794, 0.753, 0.716, 0.678\n",
      "Loss  0.000363003321556  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000468219341885  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.753, 0.716, 0.678\n",
      "Loss  0.000363260055735  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000465384382464  SSIM  0.971, 0.926, 0.879, 0.832, 0.788, 0.748, 0.71, 0.671\n",
      "Loss  0.000363205570925  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000466606846428  SSIM  0.97, 0.926, 0.88, 0.833, 0.788, 0.747, 0.711, 0.672\n",
      "Loss  0.00036319227878  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.794, 0.765, 0.734\n",
      "Val loss  0.000463737477083  SSIM  0.971, 0.927, 0.881, 0.835, 0.793, 0.753, 0.716, 0.677\n",
      "Loss  0.00036251082947  SSIM  0.974, 0.937, 0.899, 0.861, 0.827, 0.794, 0.765, 0.735\n",
      "Val loss  0.000466988763481  SSIM  0.971, 0.927, 0.881, 0.834, 0.789, 0.749, 0.714, 0.677\n",
      "Loss  0.000362969298305  SSIM  0.974, 0.937, 0.899, 0.861, 0.827, 0.794, 0.765, 0.735\n",
      "Val loss  0.000465867752326  SSIM  0.97, 0.926, 0.88, 0.834, 0.79, 0.749, 0.712, 0.672\n",
      "Loss  0.000362336445743  SSIM  0.974, 0.937, 0.899, 0.861, 0.826, 0.795, 0.765, 0.735\n",
      "Val loss  0.000464887528331  SSIM  0.97, 0.926, 0.88, 0.834, 0.79, 0.751, 0.716, 0.678\n",
      "Loss  0.000362700237781  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.794, 0.765, 0.735\n",
      "Val loss  0.000470744655933  SSIM  0.971, 0.927, 0.881, 0.835, 0.793, 0.754, 0.718, 0.681\n",
      "Loss  0.000362440907674  SSIM  0.974, 0.937, 0.899, 0.861, 0.827, 0.794, 0.765, 0.735\n",
      "Val loss  0.000463853892521  SSIM  0.971, 0.927, 0.88, 0.835, 0.792, 0.753, 0.716, 0.679\n",
      "Loss  0.000362648396404  SSIM  0.974, 0.937, 0.899, 0.861, 0.827, 0.794, 0.765, 0.735\n",
      "Val loss  0.000464008927753  SSIM  0.971, 0.927, 0.881, 0.835, 0.792, 0.753, 0.717, 0.679\n",
      "Loss  0.000362425224806  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.794, 0.765, 0.735\n",
      "Val loss  0.000464742654585  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.755, 0.718, 0.681\n",
      "Loss  0.000362603596743  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.794, 0.765, 0.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000465531597263  SSIM  0.971, 0.926, 0.88, 0.834, 0.79, 0.749, 0.713, 0.675\n",
      "Loss  0.000362008179341  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.765, 0.735\n",
      "Val loss  0.00046958488971  SSIM  0.971, 0.927, 0.881, 0.834, 0.789, 0.749, 0.712, 0.673\n",
      "Loss  0.00036215229786  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000468188182276  SSIM  0.971, 0.927, 0.883, 0.837, 0.795, 0.757, 0.721, 0.685\n",
      "Loss  0.000362403361069  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000474366767332  SSIM  0.971, 0.927, 0.882, 0.837, 0.795, 0.757, 0.721, 0.685\n",
      "Loss  0.000362150935801  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.765, 0.735\n",
      "Val loss  0.000464976577496  SSIM  0.971, 0.927, 0.882, 0.837, 0.794, 0.751, 0.716, 0.68\n",
      "Loss  0.000361926768114  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000465786607238  SSIM  0.971, 0.926, 0.88, 0.833, 0.788, 0.748, 0.711, 0.671\n",
      "Loss  0.000361720063083  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000464369663037  SSIM  0.971, 0.927, 0.882, 0.837, 0.794, 0.754, 0.718, 0.681\n",
      "Loss  0.000362527239978  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000464909637347  SSIM  0.971, 0.927, 0.881, 0.836, 0.793, 0.753, 0.715, 0.676\n",
      "Loss  0.00036247548336  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000465786223474  SSIM  0.971, 0.927, 0.882, 0.836, 0.794, 0.754, 0.717, 0.679\n",
      "Loss  0.000362408658682  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000464689500688  SSIM  0.971, 0.927, 0.881, 0.834, 0.791, 0.753, 0.715, 0.677\n",
      "Loss  0.000361193023183  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.736\n",
      "Val loss  0.000465703426977  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.755, 0.72, 0.684\n",
      "Loss  0.000361377255602  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.00046635885979  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.753, 0.716, 0.678\n",
      "Loss  0.000361992988641  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.736\n",
      "Val loss  0.000464047571877  SSIM  0.971, 0.927, 0.883, 0.838, 0.795, 0.756, 0.72, 0.683\n",
      "Loss  0.000361771704069  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.736\n",
      "Val loss  0.000467609489453  SSIM  0.97, 0.926, 0.88, 0.834, 0.789, 0.746, 0.709, 0.669\n",
      "Loss  0.000361914100291  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.736\n",
      "Val loss  0.000466908546456  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.754, 0.718, 0.68\n",
      "Loss  0.000362389863384  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.766, 0.735\n",
      "Val loss  0.000471192145546  SSIM  0.971, 0.927, 0.882, 0.836, 0.791, 0.75, 0.712, 0.673\n",
      "Loss  0.000360975587302  SSIM  0.974, 0.937, 0.899, 0.862, 0.828, 0.796, 0.766, 0.736\n",
      "Val loss  0.000469126427022  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.756, 0.72, 0.683\n",
      "Loss  0.000361508713037  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.767, 0.736\n",
      "Val loss  0.000464202455769  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.755, 0.719, 0.682\n",
      "Loss  0.000361325528311  SSIM  0.974, 0.937, 0.9, 0.862, 0.827, 0.796, 0.766, 0.736\n",
      "Val loss  0.000468999896199  SSIM  0.971, 0.926, 0.879, 0.832, 0.789, 0.75, 0.713, 0.675\n",
      "Loss  0.000361005142891  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.795, 0.767, 0.736\n",
      "Val loss  0.000465907733189  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.753, 0.718, 0.681\n",
      "Loss  0.000362067962571  SSIM  0.974, 0.937, 0.899, 0.862, 0.827, 0.796, 0.767, 0.736\n",
      "Val loss  0.000466106045875  SSIM  0.971, 0.927, 0.88, 0.833, 0.789, 0.749, 0.712, 0.673\n",
      "Loss  0.00036132722596  SSIM  0.974, 0.937, 0.9, 0.862, 0.828, 0.796, 0.766, 0.736\n",
      "Val loss  0.000464648500551  SSIM  0.971, 0.927, 0.882, 0.835, 0.791, 0.75, 0.715, 0.677\n",
      "Loss  0.000361483990945  SSIM  0.974, 0.937, 0.9, 0.862, 0.828, 0.795, 0.767, 0.736\n",
      "Val loss  0.000466844245791  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.754, 0.718, 0.68\n",
      "Loss  0.000361805224227  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.000467286252067  SSIM  0.971, 0.928, 0.882, 0.835, 0.791, 0.75, 0.714, 0.676\n",
      "Loss  0.000360708907515  SSIM  0.974, 0.937, 0.9, 0.862, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.000472743763588  SSIM  0.971, 0.925, 0.878, 0.83, 0.786, 0.747, 0.71, 0.671\n",
      "Loss  0.000361314881302  SSIM  0.974, 0.937, 0.9, 0.862, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.000464691535046  SSIM  0.971, 0.927, 0.882, 0.836, 0.794, 0.755, 0.719, 0.681\n",
      "Loss  0.000361118198265  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.000467525127227  SSIM  0.97, 0.927, 0.881, 0.833, 0.787, 0.745, 0.708, 0.667\n",
      "Loss  0.000361349282298  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.00046447124664  SSIM  0.971, 0.927, 0.881, 0.833, 0.788, 0.748, 0.711, 0.67\n",
      "Loss  0.000361217733499  SSIM  0.974, 0.937, 0.9, 0.862, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.000467667290242  SSIM  0.971, 0.927, 0.88, 0.834, 0.792, 0.754, 0.718, 0.68\n",
      "Loss  0.000361109011753  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.736\n",
      "Val loss  0.000465792299714  SSIM  0.971, 0.927, 0.882, 0.837, 0.793, 0.753, 0.718, 0.681\n",
      "Loss  0.000360472458818  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.737\n",
      "Val loss  0.000465491251962  SSIM  0.971, 0.927, 0.882, 0.837, 0.794, 0.755, 0.718, 0.68\n",
      "Loss  0.000361169562071  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.737\n",
      "Val loss  0.0004746602542  SSIM  0.97, 0.926, 0.88, 0.832, 0.787, 0.745, 0.706, 0.664\n",
      "Loss  0.000361506373133  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.796, 0.767, 0.737\n",
      "Val loss  0.000469319373718  SSIM  0.971, 0.928, 0.883, 0.837, 0.793, 0.753, 0.717, 0.679\n",
      "Loss  0.000360104704809  SSIM  0.974, 0.938, 0.9, 0.863, 0.828, 0.796, 0.768, 0.737\n",
      "Val loss  0.000462451990228  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.753, 0.718, 0.682\n",
      "Loss  0.000360886625668  SSIM  0.974, 0.937, 0.9, 0.863, 0.828, 0.797, 0.767, 0.737\n",
      "Val loss  0.000465116093168  SSIM  0.971, 0.928, 0.882, 0.837, 0.793, 0.754, 0.718, 0.681\n",
      "Loss  0.000360610181434  SSIM  0.974, 0.938, 0.9, 0.863, 0.828, 0.797, 0.767, 0.737\n",
      "Val loss  0.000469949922001  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.758, 0.722, 0.686\n",
      "Loss  0.000360561263156  SSIM  0.974, 0.937, 0.9, 0.863, 0.829, 0.796, 0.767, 0.737\n",
      "Val loss  0.000466116287687  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.752, 0.716, 0.682\n",
      "Loss  0.000360773225593  SSIM  0.974, 0.938, 0.9, 0.863, 0.829, 0.797, 0.768, 0.737\n",
      "Val loss  0.000464967788314  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.755, 0.718, 0.679\n",
      "Loss  0.00036022272158  SSIM  0.974, 0.937, 0.9, 0.863, 0.829, 0.797, 0.768, 0.737\n",
      "Val loss  0.000465752527409  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.722, 0.686\n",
      "Loss  0.00036056825112  SSIM  0.974, 0.938, 0.9, 0.863, 0.829, 0.797, 0.768, 0.737\n",
      "Val loss  0.000465149878059  SSIM  0.971, 0.927, 0.881, 0.835, 0.793, 0.754, 0.717, 0.677\n",
      "Loss  0.000360577647606  SSIM  0.974, 0.938, 0.9, 0.863, 0.829, 0.797, 0.768, 0.738\n",
      "Val loss  0.000463930757658  SSIM  0.971, 0.928, 0.883, 0.837, 0.795, 0.755, 0.72, 0.683\n",
      "Loss  0.000360567624  SSIM  0.974, 0.938, 0.9, 0.863, 0.829, 0.797, 0.768, 0.738\n",
      "Val loss  0.000463956769323  SSIM  0.971, 0.928, 0.883, 0.837, 0.793, 0.751, 0.715, 0.677\n",
      "Loss  0.000361006901299  SSIM  0.974, 0.937, 0.9, 0.863, 0.829, 0.797, 0.768, 0.737\n",
      "Val loss  0.000466909180861  SSIM  0.971, 0.926, 0.878, 0.831, 0.788, 0.748, 0.71, 0.67\n",
      "Loss  0.000360235225794  SSIM  0.974, 0.938, 0.9, 0.864, 0.829, 0.797, 0.768, 0.738\n",
      "Val loss  0.000464222959476  SSIM  0.971, 0.927, 0.882, 0.836, 0.794, 0.755, 0.719, 0.681\n",
      "Loss  0.000360497276729  SSIM  0.974, 0.938, 0.9, 0.864, 0.829, 0.797, 0.769, 0.738\n",
      "Val loss  0.000463567416358  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.72, 0.683\n",
      "Loss  0.000360650089771  SSIM  0.974, 0.938, 0.9, 0.864, 0.829, 0.797, 0.768, 0.738\n",
      "Val loss  0.000468379073951  SSIM  0.971, 0.927, 0.882, 0.837, 0.794, 0.754, 0.717, 0.678\n",
      "Loss  0.000360221378349  SSIM  0.974, 0.938, 0.9, 0.864, 0.829, 0.797, 0.768, 0.738\n",
      "Val loss  0.000469939596602  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.752, 0.715, 0.676\n",
      "Loss  0.000360606459771  SSIM  0.974, 0.938, 0.901, 0.864, 0.829, 0.797, 0.769, 0.738\n",
      "Val loss  0.000464626885077  SSIM  0.971, 0.928, 0.883, 0.837, 0.793, 0.752, 0.717, 0.681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000359811204051  SSIM  0.974, 0.938, 0.9, 0.864, 0.829, 0.798, 0.769, 0.739\n",
      "Val loss  0.000463937183551  SSIM  0.97, 0.927, 0.882, 0.837, 0.793, 0.752, 0.717, 0.68\n",
      "Loss  0.000360927442648  SSIM  0.974, 0.938, 0.9, 0.864, 0.829, 0.798, 0.769, 0.738\n",
      "Val loss  0.000470811249514  SSIM  0.971, 0.927, 0.881, 0.837, 0.795, 0.757, 0.721, 0.685\n",
      "Loss  0.000359902918124  SSIM  0.974, 0.938, 0.901, 0.864, 0.829, 0.798, 0.769, 0.738\n",
      "Val loss  0.000466064132925  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.72, 0.683\n",
      "Loss  0.000359774076429  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000464171751111  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.754, 0.718, 0.681\n",
      "Loss  0.000360188997203  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000463757547725  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.755, 0.718, 0.68\n",
      "Loss  0.000360189236795  SSIM  0.974, 0.938, 0.901, 0.864, 0.829, 0.798, 0.769, 0.739\n",
      "Val loss  0.000466208972153  SSIM  0.971, 0.928, 0.884, 0.838, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000360412568329  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.00046498101321  SSIM  0.971, 0.928, 0.884, 0.839, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000359572207201  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000466808053257  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.753, 0.717, 0.68\n",
      "Loss  0.000360828446283  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.738\n",
      "Val loss  0.000470540618757  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.751, 0.713, 0.673\n",
      "Loss  0.000359054327754  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000465431813966  SSIM  0.971, 0.928, 0.882, 0.837, 0.793, 0.752, 0.715, 0.674\n",
      "Loss  0.000360320885397  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000471426222823  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.759, 0.724, 0.688\n",
      "Loss  0.000359760340249  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.77, 0.739\n",
      "Val loss  0.000465102384682  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.721, 0.684\n",
      "Loss  0.000359868262178  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000464037575875  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.719, 0.68\n",
      "Loss  0.000359426417316  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.739\n",
      "Val loss  0.000468816879438  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.755, 0.718, 0.679\n",
      "Loss  0.000360067936663  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.769, 0.739\n",
      "Val loss  0.000466739565483  SSIM  0.971, 0.927, 0.881, 0.834, 0.789, 0.745, 0.709, 0.671\n",
      "Loss  0.000359426664632  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.798, 0.77, 0.74\n",
      "Val loss  0.000468390732014  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.759, 0.724, 0.687\n",
      "Loss  0.000359608573915  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.00047254384699  SSIM  0.971, 0.928, 0.884, 0.841, 0.799, 0.761, 0.726, 0.692\n",
      "Loss  0.000359663407838  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.799, 0.769, 0.739\n",
      "Val loss  0.000470501622243  SSIM  0.971, 0.928, 0.883, 0.838, 0.797, 0.757, 0.722, 0.685\n",
      "Loss  0.000359057947375  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466568038741  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.721, 0.683\n",
      "Loss  0.000359602408269  SSIM  0.974, 0.938, 0.901, 0.864, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000464490498416  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.755, 0.719, 0.681\n",
      "Loss  0.000359610736464  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.00048443968728  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.759, 0.723, 0.688\n",
      "Loss  0.000359057070499  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000468054232013  SSIM  0.971, 0.927, 0.882, 0.837, 0.795, 0.756, 0.718, 0.679\n",
      "Loss  0.000359473566261  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000465138690372  SSIM  0.971, 0.928, 0.883, 0.837, 0.795, 0.755, 0.719, 0.681\n",
      "Loss  0.000359238836077  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000468354175915  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.754, 0.718, 0.678\n",
      "Loss  0.00036009822643  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.739\n",
      "Val loss  0.000466516232642  SSIM  0.971, 0.928, 0.882, 0.836, 0.794, 0.754, 0.716, 0.676\n",
      "Loss  0.000358894767235  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000465634763765  SSIM  0.971, 0.928, 0.884, 0.838, 0.796, 0.756, 0.719, 0.68\n",
      "Loss  0.000359561889065  SSIM  0.974, 0.938, 0.901, 0.865, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.000464842726069  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.754, 0.718, 0.68\n",
      "Loss  0.000359028046324  SSIM  0.975, 0.938, 0.901, 0.864, 0.83, 0.799, 0.77, 0.74\n",
      "Val loss  0.00046524419653  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.758, 0.722, 0.685\n",
      "Loss  0.000358923867708  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000462944716215  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.754, 0.718, 0.682\n",
      "Loss  0.00035910000944  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000464284536836  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.722, 0.686\n",
      "Loss  0.000359123007891  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000464942882187  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.758, 0.723, 0.686\n",
      "Loss  0.000358527094963  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466855706647  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.757, 0.721, 0.683\n",
      "Loss  0.000359161653413  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466182005417  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.721, 0.684\n",
      "Loss  0.000358610315777  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.771, 0.74\n",
      "Val loss  0.000464934042771  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.755, 0.719, 0.682\n",
      "Loss  0.0003585936447  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000467071375519  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.75, 0.714, 0.677\n",
      "Loss  0.000358740969968  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466094983334  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.723, 0.688\n",
      "Loss  0.000359002900077  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000465097125445  SSIM  0.971, 0.928, 0.882, 0.837, 0.795, 0.755, 0.718, 0.68\n",
      "Loss  0.000358815284741  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000464671890484  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.754, 0.718, 0.681\n",
      "Loss  0.000358524517752  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466749412881  SSIM  0.971, 0.928, 0.883, 0.838, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000359060251056  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000465544829727  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.721, 0.685\n",
      "Loss  0.0003592281153  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000468258059293  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.683\n",
      "Loss  0.000358344048212  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.8, 0.771, 0.74\n",
      "Val loss  0.000467065259116  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.724, 0.688\n",
      "Loss  0.000358276865669  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466683656676  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.00035822240094  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.741\n",
      "Val loss  0.000464675305702  SSIM  0.971, 0.928, 0.883, 0.839, 0.798, 0.759, 0.723, 0.685\n",
      "Loss  0.000358913841416  SSIM  0.975, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000464552500809  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.721, 0.684\n",
      "Loss  0.00035853505851  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000466618852923  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.72, 0.681\n",
      "Loss  0.000359277311811  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.77, 0.74\n",
      "Val loss  0.000463137765706  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.757, 0.72, 0.682\n",
      "Loss  0.000358189838791  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.799, 0.771, 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000464378354838  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.758, 0.722, 0.684\n",
      "Loss  0.000358232624712  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.8, 0.771, 0.74\n",
      "Val loss  0.000464202630392  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.758, 0.721, 0.683\n",
      "Loss  0.00035806460868  SSIM  0.975, 0.938, 0.901, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000464164872654  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.757, 0.722, 0.685\n",
      "Loss  0.000358024273659  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.799, 0.77, 0.741\n",
      "Val loss  0.000467752557015  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.721, 0.683\n",
      "Loss  0.000358898331201  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.74\n",
      "Val loss  0.000466412214912  SSIM  0.971, 0.927, 0.882, 0.836, 0.795, 0.756, 0.719, 0.682\n",
      "Loss  0.00035858151841  SSIM  0.975, 0.938, 0.901, 0.865, 0.831, 0.8, 0.77, 0.74\n",
      "Val loss  0.00046478581347  SSIM  0.971, 0.928, 0.884, 0.838, 0.796, 0.757, 0.722, 0.685\n",
      "Loss  0.000358328209617  SSIM  0.974, 0.938, 0.901, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000468261438073  SSIM  0.971, 0.928, 0.882, 0.836, 0.791, 0.75, 0.713, 0.675\n",
      "Loss  0.000357669479138  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.799, 0.771, 0.741\n",
      "Val loss  0.00046675529395  SSIM  0.971, 0.928, 0.884, 0.838, 0.796, 0.756, 0.718, 0.679\n",
      "Loss  0.000358366758289  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.74\n",
      "Val loss  0.000465711003286  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.72, 0.682\n",
      "Loss  0.000358143532671  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.74\n",
      "Val loss  0.000467187644972  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.72, 0.683\n",
      "Loss  0.000358011580045  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466406869527  SSIM  0.971, 0.928, 0.883, 0.838, 0.797, 0.758, 0.722, 0.684\n",
      "Loss  0.000357760698669  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.00046956723975  SSIM  0.971, 0.927, 0.881, 0.834, 0.79, 0.751, 0.715, 0.677\n",
      "Loss  0.000358362182294  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.74\n",
      "Val loss  0.000468044933339  SSIM  0.971, 0.928, 0.882, 0.836, 0.793, 0.752, 0.715, 0.677\n",
      "Loss  0.000358516202899  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.77, 0.74\n",
      "Val loss  0.000466008348507  SSIM  0.971, 0.928, 0.882, 0.836, 0.794, 0.754, 0.715, 0.675\n",
      "Loss  0.000357709103801  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465627063881  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000358227819245  SSIM  0.975, 0.939, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465443526453  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.687\n",
      "Loss  0.000357816870069  SSIM  0.974, 0.939, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000468671630602  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.76, 0.725, 0.69\n",
      "Loss  0.00035752741011  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466407054686  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.755, 0.719, 0.684\n",
      "Loss  0.000357926153721  SSIM  0.975, 0.939, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466590971744  SSIM  0.971, 0.927, 0.883, 0.838, 0.796, 0.758, 0.722, 0.685\n",
      "Loss  0.000357135531891  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465503769869  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.754, 0.718, 0.679\n",
      "Loss  0.000357786813581  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000467873434303  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.721, 0.685\n",
      "Loss  0.000357601883857  SSIM  0.974, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000473811143485  SSIM  0.971, 0.927, 0.881, 0.834, 0.789, 0.748, 0.709, 0.667\n",
      "Loss  0.000357854918313  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000472323049034  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000357071378877  SSIM  0.975, 0.938, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466404050647  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.756, 0.72, 0.682\n",
      "Loss  0.000357829980718  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466052017582  SSIM  0.971, 0.928, 0.884, 0.839, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000357589670636  SSIM  0.974, 0.938, 0.902, 0.866, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466585733753  SSIM  0.971, 0.928, 0.882, 0.838, 0.796, 0.757, 0.72, 0.681\n",
      "Loss  0.000357637434052  SSIM  0.974, 0.938, 0.902, 0.865, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000464995227871  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000357060341294  SSIM  0.974, 0.939, 0.902, 0.866, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000467578598938  SSIM  0.97, 0.927, 0.883, 0.837, 0.795, 0.755, 0.718, 0.68\n",
      "Loss  0.000357838495939  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.0004689050694  SSIM  0.971, 0.927, 0.882, 0.837, 0.793, 0.753, 0.716, 0.677\n",
      "Loss  0.000357390901839  SSIM  0.975, 0.938, 0.902, 0.866, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000468275890802  SSIM  0.971, 0.928, 0.884, 0.839, 0.795, 0.753, 0.715, 0.681\n",
      "Loss  0.000358116088162  SSIM  0.975, 0.939, 0.902, 0.866, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000468758929055  SSIM  0.971, 0.928, 0.885, 0.84, 0.798, 0.758, 0.721, 0.683\n",
      "Loss  0.000357112772248  SSIM  0.974, 0.939, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465907232254  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.683\n",
      "Loss  0.000357740565893  SSIM  0.975, 0.938, 0.902, 0.865, 0.831, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465064803779  SSIM  0.971, 0.928, 0.883, 0.838, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000357198304421  SSIM  0.974, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465356533299  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000356936297993  SSIM  0.975, 0.938, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000471310669091  SSIM  0.971, 0.927, 0.883, 0.837, 0.795, 0.756, 0.719, 0.681\n",
      "Loss  0.000357309305176  SSIM  0.974, 0.938, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000464692611597  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.721, 0.685\n",
      "Loss  0.000357663381236  SSIM  0.974, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465337379312  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.721, 0.683\n",
      "Loss  0.000356667724868  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466956841934  SSIM  0.971, 0.928, 0.884, 0.839, 0.795, 0.754, 0.718, 0.682\n",
      "Loss  0.000357052113776  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466245053511  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.759, 0.724, 0.688\n",
      "Loss  0.000357499553491  SSIM  0.975, 0.938, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000468658006634  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.754, 0.717, 0.681\n",
      "Loss  0.000357404168015  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465164966707  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000356384176971  SSIM  0.975, 0.939, 0.902, 0.866, 0.831, 0.8, 0.771, 0.742\n",
      "Val loss  0.000467806893983  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.758, 0.721, 0.684\n",
      "Loss  0.000357349806514  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466105617699  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.722, 0.685\n",
      "Loss  0.000356766034428  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.00046606497257  SSIM  0.971, 0.927, 0.882, 0.837, 0.794, 0.755, 0.719, 0.681\n",
      "Loss  0.000356516739994  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.741\n",
      "Val loss  0.000465744241956  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.721, 0.684\n",
      "Loss  0.000356831828047  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.742\n",
      "Val loss  0.000471612717549  SSIM  0.971, 0.928, 0.884, 0.841, 0.799, 0.761, 0.725, 0.689\n",
      "Loss  0.000356446930449  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.742\n",
      "Val loss  0.000472378138511  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.726, 0.691\n",
      "Loss  0.000357273666058  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000468988709385  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.759, 0.724, 0.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000357012672354  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465327796934  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.755, 0.719, 0.682\n",
      "Loss  0.000357030653059  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000466566652816  SSIM  0.971, 0.928, 0.882, 0.837, 0.793, 0.752, 0.717, 0.679\n",
      "Loss  0.000357014708593  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.741\n",
      "Val loss  0.000465752927936  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.756, 0.72, 0.683\n",
      "Loss  0.000356833809257  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.771, 0.741\n",
      "Val loss  0.00046790056501  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.758, 0.721, 0.684\n",
      "Loss  0.000356921592678  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.771, 0.741\n",
      "Val loss  0.000465313834138  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000356496445042  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465032069478  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.756, 0.72, 0.682\n",
      "Loss  0.00035653812119  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.742\n",
      "Val loss  0.000465415413608  SSIM  0.971, 0.928, 0.882, 0.837, 0.795, 0.756, 0.72, 0.682\n",
      "Loss  0.000356057487571  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.742\n",
      "Val loss  0.000465964306204  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.721, 0.684\n",
      "Loss  0.000356603657218  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.742\n",
      "Val loss  0.000468065513473  SSIM  0.97, 0.928, 0.883, 0.839, 0.798, 0.759, 0.722, 0.686\n",
      "Loss  0.000356290319223  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000466210220533  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.761, 0.725, 0.689\n",
      "Loss  0.000356788862644  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.741\n",
      "Val loss  0.000464975868934  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.721, 0.684\n",
      "Loss  0.000356202851175  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.771, 0.742\n",
      "Val loss  0.000464974461298  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.685\n",
      "Loss  0.000356133371242  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000466454144567  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000356609445186  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000470711863891  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.754, 0.717, 0.679\n",
      "Loss  0.000356797035716  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.741\n",
      "Val loss  0.000468667262059  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.718, 0.678\n",
      "Loss  0.000356535194576  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.771, 0.742\n",
      "Val loss  0.000474255254725  SSIM  0.971, 0.927, 0.883, 0.839, 0.797, 0.758, 0.722, 0.687\n",
      "Loss  0.000356282934327  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465245820058  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.758, 0.722, 0.685\n",
      "Loss  0.000356252604307  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.771, 0.742\n",
      "Val loss  0.000465180160245  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.755, 0.72, 0.683\n",
      "Loss  0.000356851837423  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.8, 0.772, 0.742\n",
      "Val loss  0.00046596459829  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.724, 0.689\n",
      "Loss  0.000355788659945  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465232907969  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.721, 0.684\n",
      "Loss  0.000356912113269  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.741\n",
      "Val loss  0.000467978627305  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.756, 0.719, 0.681\n",
      "Loss  0.000355864255935  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000464571531047  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000356183886694  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465710840828  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000356194128802  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465082510433  SSIM  0.971, 0.929, 0.884, 0.84, 0.799, 0.76, 0.723, 0.686\n",
      "Loss  0.000355728433597  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000464508676494  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.72, 0.682\n",
      "Loss  0.000356272121403  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000466870419215  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.756, 0.719, 0.68\n",
      "Loss  0.000356190854464  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000471710991114  SSIM  0.971, 0.928, 0.883, 0.836, 0.791, 0.749, 0.712, 0.673\n",
      "Loss  0.00035582764213  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000467310261971  SSIM  0.971, 0.928, 0.883, 0.838, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000356321220752  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000470511518361  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.756, 0.719, 0.682\n",
      "Loss  0.000356230477717  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000468884693983  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.758, 0.719, 0.68\n",
      "Loss  0.00035525199899  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000467675544263  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.758, 0.722, 0.688\n",
      "Loss  0.000355709497615  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465867608669  SSIM  0.971, 0.927, 0.882, 0.836, 0.791, 0.75, 0.713, 0.675\n",
      "Loss  0.000356668082778  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000468885068083  SSIM  0.971, 0.927, 0.882, 0.836, 0.792, 0.749, 0.71, 0.675\n",
      "Loss  0.000355812608726  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465183692344  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.758, 0.722, 0.687\n",
      "Loss  0.000355716842571  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465751793236  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.753, 0.717, 0.68\n",
      "Loss  0.000355612262524  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000467512443254  SSIM  0.971, 0.927, 0.881, 0.835, 0.791, 0.749, 0.712, 0.673\n",
      "Loss  0.000355837709235  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000467100668815  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.754, 0.718, 0.681\n",
      "Loss  0.000355649174173  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000464828549884  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.00035629735935  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000467983158713  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.758, 0.721, 0.683\n",
      "Loss  0.000354957185739  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000469347822538  SSIM  0.971, 0.928, 0.885, 0.84, 0.797, 0.757, 0.721, 0.685\n",
      "Loss  0.000355643889455  SSIM  0.975, 0.939, 0.902, 0.866, 0.833, 0.801, 0.772, 0.742\n",
      "Val loss  0.000471729430079  SSIM  0.971, 0.928, 0.885, 0.84, 0.798, 0.76, 0.724, 0.688\n",
      "Loss  0.000355519379753  SSIM  0.975, 0.939, 0.903, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000469241290353  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.752, 0.717, 0.682\n",
      "Loss  0.000355797670289  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465611618012  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.721, 0.687\n",
      "Loss  0.000355258063467  SSIM  0.975, 0.939, 0.902, 0.866, 0.833, 0.801, 0.772, 0.743\n",
      "Val loss  0.000466321190004  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000355730664048  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465911953535  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.753, 0.717, 0.681\n",
      "Loss  0.000355157960708  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.743\n",
      "Val loss  0.000465539231955  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.758, 0.721, 0.684\n",
      "Loss  0.000355626195893  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000468301849556  SSIM  0.971, 0.928, 0.884, 0.839, 0.795, 0.755, 0.719, 0.681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.00035530401199  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.743\n",
      "Val loss  0.000466036935395  SSIM  0.971, 0.927, 0.882, 0.836, 0.793, 0.754, 0.719, 0.682\n",
      "Loss  0.000355542537112  SSIM  0.975, 0.939, 0.902, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000464789176651  SSIM  0.971, 0.928, 0.884, 0.839, 0.798, 0.759, 0.723, 0.685\n",
      "Loss  0.000355554032296  SSIM  0.975, 0.939, 0.903, 0.866, 0.833, 0.801, 0.772, 0.742\n",
      "Val loss  0.000465480327548  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000355500762145  SSIM  0.975, 0.939, 0.903, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000467322512763  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.759, 0.722, 0.685\n",
      "Loss  0.000355162450533  SSIM  0.975, 0.939, 0.902, 0.867, 0.832, 0.801, 0.772, 0.743\n",
      "Val loss  0.000465844769788  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.684\n",
      "Loss  0.000355158586709  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.772, 0.743\n",
      "Val loss  0.000468346619746  SSIM  0.971, 0.928, 0.882, 0.836, 0.793, 0.753, 0.715, 0.677\n",
      "Loss  0.000355247765278  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.772, 0.743\n",
      "Val loss  0.000466747230443  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.684\n",
      "Loss  0.000354974563972  SSIM  0.975, 0.939, 0.903, 0.867, 0.832, 0.801, 0.772, 0.743\n",
      "Val loss  0.000465853810543  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.686\n",
      "Loss  0.000355491874126  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.772, 0.743\n",
      "Val loss  0.000464492750936  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000355571528422  SSIM  0.975, 0.939, 0.903, 0.866, 0.832, 0.801, 0.772, 0.742\n",
      "Val loss  0.000466796729539  SSIM  0.971, 0.928, 0.882, 0.836, 0.794, 0.756, 0.72, 0.683\n",
      "Loss  0.000354888205676  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.743\n",
      "Val loss  0.000464655424177  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000355634647735  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.772, 0.742\n",
      "Val loss  0.000468260289112  SSIM  0.971, 0.928, 0.882, 0.836, 0.793, 0.754, 0.719, 0.681\n",
      "Loss  0.000355276626002  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.772, 0.743\n",
      "Val loss  0.000465273628361  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000354696179857  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.773, 0.743\n",
      "Val loss  0.000465208999114  SSIM  0.971, 0.928, 0.883, 0.839, 0.798, 0.76, 0.723, 0.686\n",
      "Loss  0.000355314751147  SSIM  0.975, 0.939, 0.902, 0.866, 0.833, 0.801, 0.773, 0.742\n",
      "Val loss  0.000467265767045  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000355108267641  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.743\n",
      "Val loss  0.000463870549342  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.682\n",
      "Loss  0.000355040560871  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.772, 0.743\n",
      "Val loss  0.000464570278069  SSIM  0.971, 0.928, 0.883, 0.839, 0.796, 0.755, 0.72, 0.684\n",
      "Loss  0.000354838851871  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.773, 0.743\n",
      "Val loss  0.000468248345191  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000354993979608  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.773, 0.743\n",
      "Val loss  0.000465536169824  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.721, 0.683\n",
      "Loss  0.000355149806285  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.743\n",
      "Val loss  0.00046618333715  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.724, 0.688\n",
      "Loss  0.000354712456778  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000466028865951  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.72, 0.683\n",
      "Loss  0.000354963300275  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.00046455642872  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.758, 0.721, 0.684\n",
      "Loss  0.000354901608393  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465450810501  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.758, 0.722, 0.685\n",
      "Loss  0.000354504058196  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000468496573158  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.718, 0.679\n",
      "Loss  0.000355751955335  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.743\n",
      "Val loss  0.000466781355324  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.758, 0.723, 0.689\n",
      "Loss  0.000354476928433  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000467729701952  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.755, 0.717, 0.681\n",
      "Loss  0.000354588521519  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.773, 0.743\n",
      "Val loss  0.000469993407547  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.69\n",
      "Loss  0.000355412720237  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.743\n",
      "Val loss  0.000466731166118  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.686\n",
      "Loss  0.000354553530454  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000464760770381  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.758, 0.721, 0.685\n",
      "Loss  0.000354454384696  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000466678256926  SSIM  0.971, 0.928, 0.883, 0.837, 0.795, 0.757, 0.72, 0.682\n",
      "Loss  0.000355130926182  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.801, 0.773, 0.743\n",
      "Val loss  0.000465215702076  SSIM  0.971, 0.928, 0.884, 0.84, 0.797, 0.759, 0.722, 0.686\n",
      "Loss  0.000354174913306  SSIM  0.975, 0.939, 0.903, 0.866, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000466195371468  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.682\n",
      "Loss  0.00035503299983  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000469674234977  SSIM  0.971, 0.928, 0.882, 0.836, 0.792, 0.752, 0.715, 0.677\n",
      "Loss  0.000354572474339  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000464781667455  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.754, 0.718, 0.68\n",
      "Loss  0.000354624302865  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000471009770816  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.761, 0.725, 0.69\n",
      "Loss  0.000355053806091  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000470944165718  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000354303572945  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000466285418428  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.754, 0.718, 0.68\n",
      "Loss  0.000354838263212  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.743\n",
      "Val loss  0.00046471140621  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.724, 0.689\n",
      "Loss  0.000354358202648  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000471664847282  SSIM  0.971, 0.927, 0.882, 0.836, 0.795, 0.757, 0.72, 0.682\n",
      "Loss  0.00035439220087  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465754605189  SSIM  0.971, 0.928, 0.883, 0.837, 0.795, 0.757, 0.721, 0.683\n",
      "Loss  0.000354248757537  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.00046533754596  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000354695490723  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000464708108804  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.721, 0.685\n",
      "Loss  0.000354776042334  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465952669911  SSIM  0.971, 0.928, 0.884, 0.838, 0.796, 0.757, 0.721, 0.683\n",
      "Loss  0.000354694224079  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465473815857  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.684\n",
      "Loss  0.000354469822644  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000469080329989  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.755, 0.718, 0.679\n",
      "Loss  0.000354187243233  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.00046593487775  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.76, 0.724, 0.687\n",
      "Loss  0.000354187290404  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000464537687891  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.761, 0.725, 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.00035414997148  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465514735901  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.686\n",
      "Loss  0.000354220041481  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465613915352  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.755, 0.719, 0.684\n",
      "Loss  0.000354755855537  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000463692964695  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.72, 0.682\n",
      "Loss  0.000354669481234  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.772, 0.742\n",
      "Val loss  0.000466786555829  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.722, 0.686\n",
      "Loss  0.0003544635415  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000467411862162  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.752, 0.714, 0.676\n",
      "Loss  0.000354439028575  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465901756776  SSIM  0.971, 0.928, 0.884, 0.839, 0.795, 0.755, 0.718, 0.682\n",
      "Loss  0.00035432654574  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467643172247  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.758, 0.721, 0.684\n",
      "Loss  0.000353702022627  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.00046708452329  SSIM  0.971, 0.928, 0.882, 0.836, 0.793, 0.754, 0.718, 0.681\n",
      "Loss  0.000354332628687  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000466841838905  SSIM  0.971, 0.928, 0.884, 0.839, 0.798, 0.759, 0.722, 0.686\n",
      "Loss  0.000354594253698  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000465285560407  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000353727059779  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465804209292  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000354266376324  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464869975112  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000353716393651  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000469665619428  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000354269639468  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464897567465  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.725, 0.689\n",
      "Loss  0.000353943196824  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000468326980073  SSIM  0.971, 0.928, 0.884, 0.839, 0.795, 0.754, 0.718, 0.682\n",
      "Loss  0.000353968546909  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464543631533  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.721, 0.685\n",
      "Loss  0.000353683061884  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467694692197  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.724, 0.688\n",
      "Loss  0.000353981295887  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.00048095599201  SSIM  0.972, 0.929, 0.885, 0.841, 0.799, 0.761, 0.725, 0.69\n",
      "Loss  0.000354252064471  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465552772279  SSIM  0.971, 0.929, 0.885, 0.842, 0.8, 0.762, 0.727, 0.692\n",
      "Loss  0.000354061580371  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.743\n",
      "Val loss  0.000467785191606  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.758, 0.721, 0.685\n",
      "Loss  0.00035400338218  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465254830255  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.756, 0.718, 0.679\n",
      "Loss  0.000353848844467  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000468300210487  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000353511222929  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464766208606  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.724, 0.688\n",
      "Loss  0.000354188761871  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000466722506215  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.756, 0.719, 0.683\n",
      "Loss  0.000353771067883  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467751065036  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.757, 0.72, 0.683\n",
      "Loss  0.000353813963123  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000463931750506  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.759, 0.723, 0.688\n",
      "Loss  0.000353542617701  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000463917294401  SSIM  0.971, 0.929, 0.884, 0.839, 0.797, 0.759, 0.723, 0.688\n",
      "Loss  0.000353951515706  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.00046703679557  SSIM  0.971, 0.928, 0.883, 0.839, 0.797, 0.759, 0.723, 0.687\n",
      "Loss  0.000353733942298  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465555647621  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.76, 0.724, 0.688\n",
      "Loss  0.000353763633443  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.0004686791079  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.00035389514631  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000466333234275  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000353389097279  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000466160275275  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000353508232846  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465380287555  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000354094904368  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467021089105  SSIM  0.971, 0.928, 0.884, 0.84, 0.796, 0.757, 0.72, 0.686\n",
      "Loss  0.000353583784577  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465825263876  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.688\n",
      "Loss  0.000353975043914  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467445608519  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000353274951832  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464845961076  SSIM  0.971, 0.928, 0.883, 0.839, 0.796, 0.758, 0.721, 0.683\n",
      "Loss  0.000354007647659  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467921049334  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.719, 0.681\n",
      "Loss  0.000353282936849  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467019115342  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.755, 0.718, 0.681\n",
      "Loss  0.000353643287269  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.00046491141076  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000353375196439  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.803, 0.773, 0.744\n",
      "Val loss  0.000465714175662  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.76, 0.724, 0.688\n",
      "Loss  0.0003530609183  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.803, 0.773, 0.744\n",
      "Val loss  0.000467199702049  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.76, 0.724, 0.688\n",
      "Loss  0.000353601268367  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464888490853  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.757, 0.72, 0.682\n",
      "Loss  0.000352923437984  SSIM  0.975, 0.939, 0.903, 0.867, 0.833, 0.802, 0.774, 0.744\n",
      "Val loss  0.000466421858117  SSIM  0.971, 0.928, 0.883, 0.837, 0.794, 0.754, 0.717, 0.681\n",
      "Loss  0.000353457517474  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000465625312878  SSIM  0.971, 0.928, 0.884, 0.84, 0.798, 0.76, 0.723, 0.687\n",
      "Loss  0.000353261167967  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000464260921406  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.756, 0.72, 0.684\n",
      "Loss  0.000353760090321  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.773, 0.744\n",
      "Val loss  0.000467826783657  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.726, 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000353109098908  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.773, 0.744\n",
      "Val loss  0.000467036186892  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.76, 0.723, 0.688\n",
      "Loss  0.000353321011442  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.803, 0.773, 0.744\n",
      "Val loss  0.000471160590299  SSIM  0.97, 0.928, 0.884, 0.84, 0.799, 0.761, 0.726, 0.691\n",
      "Loss  0.000353472115888  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.774, 0.744\n",
      "Val loss  0.000464682258782  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.723, 0.687\n",
      "Loss  0.000353571808642  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.803, 0.773, 0.744\n",
      "Val loss  0.000473682960786  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.76, 0.723, 0.687\n",
      "Loss  0.000353056666253  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.000465323527809  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.757, 0.722, 0.686\n",
      "Loss  0.000353099643589  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.802, 0.774, 0.744\n",
      "Val loss  0.000465468042414  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.759, 0.722, 0.685\n",
      "Loss  0.000353260738327  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.773, 0.744\n",
      "Val loss  0.000465343729709  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.759, 0.723, 0.688\n",
      "Loss  0.000353137014832  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.773, 0.744\n",
      "Val loss  0.000465678808221  SSIM  0.971, 0.928, 0.883, 0.837, 0.793, 0.752, 0.715, 0.678\n",
      "Loss  0.000352818506385  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.000465071680548  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000353018386209  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.773, 0.745\n",
      "Val loss  0.000466954768519  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000353376154224  SSIM  0.975, 0.939, 0.903, 0.867, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.000468079030805  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000352862756005  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465158323641  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.757, 0.721, 0.685\n",
      "Loss  0.000353056326746  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.00046411012602  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.722, 0.686\n",
      "Loss  0.000352825458551  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466080203827  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.721, 0.684\n",
      "Loss  0.000352920117864  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.000463727620372  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000352754784332  SSIM  0.975, 0.939, 0.904, 0.867, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466032561089  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.76, 0.724, 0.688\n",
      "Loss  0.000353362412693  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.000465824376675  SSIM  0.971, 0.928, 0.883, 0.839, 0.796, 0.758, 0.722, 0.685\n",
      "Loss  0.000352792410972  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000464614341967  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000352770716015  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.744\n",
      "Val loss  0.000466058214195  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.755, 0.718, 0.682\n",
      "Loss  0.00035282650461  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465598478273  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000352637244393  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465364228818  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.000352845283857  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466570424906  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.757, 0.72, 0.684\n",
      "Loss  0.000353123726359  SSIM  0.975, 0.939, 0.904, 0.868, 0.834, 0.802, 0.774, 0.745\n",
      "Val loss  0.000467758391344  SSIM  0.971, 0.928, 0.882, 0.837, 0.794, 0.754, 0.718, 0.681\n",
      "Loss  0.000352655092787  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.802, 0.774, 0.745\n",
      "Val loss  0.000465658521221  SSIM  0.971, 0.929, 0.884, 0.839, 0.797, 0.759, 0.722, 0.686\n",
      "Loss  0.000352576328061  SSIM  0.975, 0.939, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467196992831  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.756, 0.719, 0.682\n",
      "Loss  0.00035260260338  SSIM  0.975, 0.939, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000475294151402  SSIM  0.971, 0.928, 0.883, 0.837, 0.793, 0.753, 0.714, 0.675\n",
      "Loss  0.000352814258748  SSIM  0.975, 0.939, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000471449634118  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.685\n",
      "Loss  0.000352806721595  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466491509695  SSIM  0.971, 0.928, 0.883, 0.838, 0.795, 0.755, 0.718, 0.681\n",
      "Loss  0.000352876388172  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000472029356926  SSIM  0.972, 0.929, 0.885, 0.84, 0.796, 0.755, 0.718, 0.681\n",
      "Loss  0.000352617719282  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467494410521  SSIM  0.971, 0.928, 0.884, 0.838, 0.795, 0.756, 0.719, 0.682\n",
      "Loss  0.000352532076112  SSIM  0.975, 0.939, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000464588129718  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.722, 0.685\n",
      "Loss  0.000352526118648  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.00046487288014  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.759, 0.723, 0.688\n",
      "Loss  0.000352685028427  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465958483284  SSIM  0.971, 0.928, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000352390811716  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467238033772  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.72, 0.685\n",
      "Loss  0.000352597404294  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466896794445  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.755, 0.719, 0.684\n",
      "Loss  0.000353289755809  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465430610348  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.688\n",
      "Loss  0.000352135563713  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000468841880618  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.761, 0.725, 0.69\n",
      "Loss  0.000352544700816  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000476930753444  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.757, 0.72, 0.682\n",
      "Loss  0.000352697119524  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467053354834  SSIM  0.971, 0.929, 0.884, 0.839, 0.794, 0.754, 0.716, 0.68\n",
      "Loss  0.000352665264822  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466449170606  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.757, 0.721, 0.684\n",
      "Loss  0.000352351213067  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465648930345  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.688\n",
      "Loss  0.000352969622808  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000464833472914  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.00035244723464  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000469027311134  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.758, 0.721, 0.686\n",
      "Loss  0.000351977712372  SSIM  0.975, 0.939, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467015496339  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.719, 0.681\n",
      "Loss  0.000352932390502  SSIM  0.975, 0.94, 0.903, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466155788046  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.757, 0.721, 0.685\n",
      "Loss  0.000351863181053  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465078832174  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.756, 0.721, 0.686\n",
      "Loss  0.000352705563531  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465672942461  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000352556153935  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465295361471  SSIM  0.972, 0.929, 0.885, 0.841, 0.8, 0.762, 0.725, 0.689\n",
      "Loss  0.000352365762407  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000468330152624  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.759, 0.722, 0.686\n",
      "Loss  0.000352485919206  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467417937936  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.758, 0.721, 0.685\n",
      "Loss  0.000352207001661  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466105641273  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000352012611335  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.746\n",
      "Val loss  0.000467737024592  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.725, 0.69\n",
      "Loss  0.000352564156548  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466937061923  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.756, 0.72, 0.685\n",
      "Loss  0.000352237333427  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.746\n",
      "Val loss  0.000467227976304  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.756, 0.719, 0.685\n",
      "Loss  0.000352291621317  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000467260431556  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.756, 0.719, 0.684\n",
      "Loss  0.000352588189215  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000471811173542  SSIM  0.971, 0.928, 0.883, 0.838, 0.794, 0.752, 0.716, 0.681\n",
      "Loss  0.000352103338519  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465544903534  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.76, 0.724, 0.688\n",
      "Loss  0.000351709148157  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.803, 0.774, 0.746\n",
      "Val loss  0.000465927105979  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.688\n",
      "Loss  0.000352709060714  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000466639038874  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.756, 0.719, 0.683\n",
      "Loss  0.00035247749208  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.745\n",
      "Val loss  0.000465756688092  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.758, 0.722, 0.686\n",
      "Loss  0.000351879839078  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.803, 0.774, 0.746\n",
      "Val loss  0.000464730926265  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.00035274126117  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.803, 0.774, 0.746\n",
      "Val loss  0.000466206373065  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.685\n",
      "Loss  0.000351731556696  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466126584855  SSIM  0.971, 0.928, 0.885, 0.841, 0.799, 0.76, 0.724, 0.688\n",
      "Loss  0.000352294978287  SSIM  0.975, 0.94, 0.904, 0.868, 0.834, 0.804, 0.774, 0.746\n",
      "Val loss  0.000465655473061  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.723, 0.687\n",
      "Loss  0.000352018778011  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.803, 0.775, 0.746\n",
      "Val loss  0.000467056543857  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.757, 0.721, 0.686\n",
      "Loss  0.000351839927092  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466551626683  SSIM  0.971, 0.929, 0.884, 0.84, 0.798, 0.76, 0.723, 0.685\n",
      "Loss  0.000352082003709  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000469359027455  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.762, 0.727, 0.692\n",
      "Loss  0.000351926770952  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000465537550335  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.758, 0.721, 0.683\n",
      "Loss  0.000351884066141  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000469723103568  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.69\n",
      "Loss  0.000352183227123  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000464825570874  SSIM  0.972, 0.929, 0.885, 0.841, 0.799, 0.761, 0.725, 0.69\n",
      "Loss  0.000351720512554  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000467010376218  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.723, 0.686\n",
      "Loss  0.000352471239256  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.774, 0.745\n",
      "Val loss  0.000466276088788  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.758, 0.722, 0.686\n",
      "Loss  0.000351818800107  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000465390064637  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.758, 0.723, 0.687\n",
      "Loss  0.000351717486248  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466640640923  SSIM  0.972, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000352165732183  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000467270893278  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.757, 0.721, 0.686\n",
      "Loss  0.000351547456029  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000464184465411  SSIM  0.971, 0.929, 0.884, 0.839, 0.796, 0.757, 0.721, 0.685\n",
      "Loss  0.000352362244874  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.00046962022112  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.757, 0.721, 0.685\n",
      "Loss  0.000352192198267  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000464386514563  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.761, 0.724, 0.688\n",
      "Loss  0.000352046359599  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.0004657562059  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.726, 0.691\n",
      "Loss  0.000352037622607  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000465041834977  SSIM  0.971, 0.929, 0.885, 0.842, 0.8, 0.76, 0.724, 0.69\n",
      "Loss  0.000351639520937  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000467865364684  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000351499604384  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466131227731  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.761, 0.725, 0.688\n",
      "Loss  0.000351956280513  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000467484953115  SSIM  0.971, 0.928, 0.884, 0.839, 0.798, 0.759, 0.722, 0.685\n",
      "Loss  0.000351441677306  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000468457014067  SSIM  0.971, 0.928, 0.883, 0.837, 0.793, 0.752, 0.715, 0.677\n",
      "Loss  0.000352161548777  SSIM  0.975, 0.94, 0.904, 0.868, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466487878468  SSIM  0.971, 0.929, 0.885, 0.84, 0.799, 0.76, 0.723, 0.688\n",
      "Loss  0.000351625205949  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000470369611401  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.719, 0.683\n",
      "Loss  0.0003517025764  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000465575289039  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000351951953556  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.747\n",
      "Val loss  0.000465140651504  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.757, 0.72, 0.685\n",
      "Loss  0.000351606641108  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000470056254417  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.76, 0.723, 0.687\n",
      "Loss  0.000351528263552  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000465470135852  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.758, 0.722, 0.686\n",
      "Loss  0.000351268349869  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466532124963  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000351580484936  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000469637425849  SSIM  0.971, 0.927, 0.882, 0.835, 0.79, 0.75, 0.709, 0.669\n",
      "Loss  0.000351979191518  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000465986770112  SSIM  0.971, 0.929, 0.884, 0.84, 0.799, 0.759, 0.723, 0.687\n",
      "Loss  0.000351384814197  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466958367324  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.726, 0.691\n",
      "Loss  0.000351480528547  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000468755441427  SSIM  0.971, 0.928, 0.883, 0.838, 0.796, 0.757, 0.718, 0.681\n",
      "Loss  0.000351598506274  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.746\n",
      "Val loss  0.000466071603005  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000351721595104  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.747\n",
      "Val loss  0.000466778106114  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000351686516213  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.747\n",
      "Val loss  0.000466618604609  SSIM  0.972, 0.929, 0.885, 0.841, 0.799, 0.76, 0.723, 0.688\n",
      "Loss  0.000351441883272  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.776, 0.747\n",
      "Val loss  0.000465995405684  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.725, 0.689\n",
      "Loss  0.000351849613205  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.776, 0.747\n",
      "Val loss  0.000465458287741  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.762, 0.726, 0.691\n",
      "Loss  0.00035101239218  SSIM  0.975, 0.94, 0.904, 0.869, 0.836, 0.804, 0.776, 0.747\n",
      "Val loss  0.000465758753126  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000351729417565  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.776, 0.746\n",
      "Val loss  0.000465856936353  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000351239330037  SSIM  0.975, 0.94, 0.904, 0.869, 0.836, 0.804, 0.776, 0.747\n",
      "Val loss  0.000468274872168  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000351317325885  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.805, 0.776, 0.747\n",
      "Val loss  0.000467732703371  SSIM  0.971, 0.929, 0.886, 0.842, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000351418557111  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.804, 0.775, 0.747\n",
      "Val loss  0.000466224406438  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000351488539197  SSIM  0.975, 0.94, 0.904, 0.869, 0.835, 0.805, 0.776, 0.747\n",
      "Val loss  0.000467391345766  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.76, 0.725, 0.691\n",
      "Loss  0.000351029787696  SSIM  0.975, 0.94, 0.904, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000469412898587  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.687\n",
      "Loss  0.000351623254783  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000466601889464  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.762, 0.726, 0.689\n",
      "Loss  0.000351734568763  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.00046672039642  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.686\n",
      "Loss  0.00035142610304  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000466412590351  SSIM  0.971, 0.929, 0.884, 0.84, 0.799, 0.76, 0.724, 0.687\n",
      "Loss  0.000351676204076  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000465418813925  SSIM  0.972, 0.929, 0.886, 0.842, 0.799, 0.759, 0.724, 0.689\n",
      "Loss  0.000350811258249  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000466950140253  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.758, 0.722, 0.685\n",
      "Loss  0.000351483964164  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000465894672729  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.728, 0.692\n",
      "Loss  0.00035103374819  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.748\n",
      "Val loss  0.000466623662505  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.762, 0.725, 0.691\n",
      "Loss  0.000351483511264  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000465852912166  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.688\n",
      "Loss  0.000350544915038  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.776, 0.748\n",
      "Val loss  0.000467813961208  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.757, 0.72, 0.683\n",
      "Loss  0.00035176304113  SSIM  0.975, 0.94, 0.904, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000465844441729  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.758, 0.724, 0.687\n",
      "Loss  0.000351005323151  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000468658322701  SSIM  0.971, 0.929, 0.884, 0.84, 0.797, 0.757, 0.722, 0.685\n",
      "Loss  0.000351153791685  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.776, 0.748\n",
      "Val loss  0.000466379010933  SSIM  0.971, 0.929, 0.886, 0.842, 0.802, 0.763, 0.727, 0.691\n",
      "Loss  0.000351096662635  SSIM  0.975, 0.94, 0.905, 0.869, 0.836, 0.805, 0.777, 0.748\n",
      "Val loss  0.000465114920284  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000351138777153  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.776, 0.748\n",
      "Val loss  0.000470055135724  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.758, 0.72, 0.684\n",
      "Loss  0.000350978539433  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.776, 0.747\n",
      "Val loss  0.000464621079911  SSIM  0.972, 0.929, 0.886, 0.842, 0.801, 0.763, 0.728, 0.692\n",
      "Loss  0.000351013486014  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.776, 0.748\n",
      "Val loss  0.00046707385208  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.725, 0.69\n",
      "Loss  0.000351386475825  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.777, 0.747\n",
      "Val loss  0.000466370854818  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.727, 0.691\n",
      "Loss  0.000351277981446  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.806, 0.777, 0.747\n",
      "Val loss  0.000468304432638  SSIM  0.972, 0.929, 0.885, 0.841, 0.799, 0.76, 0.722, 0.684\n",
      "Loss  0.000350685510784  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.777, 0.748\n",
      "Val loss  0.00046615817491  SSIM  0.972, 0.929, 0.886, 0.843, 0.801, 0.764, 0.728, 0.693\n",
      "Loss  0.000350887991775  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.806, 0.777, 0.748\n",
      "Val loss  0.000471386607562  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000351271128949  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.805, 0.777, 0.748\n",
      "Val loss  0.000469236476813  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.765, 0.73, 0.695\n",
      "Loss  0.000350902396178  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.748\n",
      "Val loss  0.000465069918253  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.762, 0.726, 0.69\n",
      "Loss  0.000350997591942  SSIM  0.975, 0.94, 0.905, 0.87, 0.836, 0.806, 0.777, 0.748\n",
      "Val loss  0.000467073403532  SSIM  0.972, 0.929, 0.885, 0.841, 0.8, 0.762, 0.727, 0.692\n",
      "Loss  0.000351014358681  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.748\n",
      "Val loss  0.000465437808656  SSIM  0.971, 0.929, 0.885, 0.84, 0.798, 0.759, 0.723, 0.687\n",
      "Loss  0.000350787623365  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000467646638921  SSIM  0.971, 0.928, 0.884, 0.839, 0.796, 0.757, 0.721, 0.683\n",
      "Loss  0.000351011077426  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.748\n",
      "Val loss  0.00046761595906  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.000350874526193  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.748\n",
      "Val loss  0.000465551873611  SSIM  0.971, 0.929, 0.885, 0.842, 0.801, 0.763, 0.728, 0.693\n",
      "Loss  0.000351017246408  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.748\n",
      "Val loss  0.000464346019842  SSIM  0.972, 0.929, 0.886, 0.842, 0.801, 0.762, 0.725, 0.69\n",
      "Loss  0.000350636229716  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000467222203151  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.726, 0.69\n",
      "Loss  0.000350666701247  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000467996558  SSIM  0.972, 0.929, 0.887, 0.843, 0.802, 0.764, 0.729, 0.695\n",
      "Loss  0.000351030864314  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000478761784034  SSIM  0.971, 0.928, 0.884, 0.838, 0.794, 0.752, 0.714, 0.676\n",
      "Loss  0.000350687187702  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000468454188784  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.686\n",
      "Loss  0.000350701561748  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000467578738811  SSIM  0.972, 0.93, 0.887, 0.843, 0.801, 0.763, 0.728, 0.694\n",
      "Loss  0.000350791068385  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000467088158359  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.762, 0.726, 0.69\n",
      "Loss  0.000350763008666  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.806, 0.778, 0.749\n",
      "Val loss  0.000466818046116  SSIM  0.971, 0.929, 0.886, 0.843, 0.803, 0.765, 0.73, 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000350295180509  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.778, 0.749\n",
      "Val loss  0.000468055969512  SSIM  0.971, 0.929, 0.886, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.00035131213103  SSIM  0.975, 0.94, 0.905, 0.87, 0.837, 0.806, 0.777, 0.749\n",
      "Val loss  0.000464669668057  SSIM  0.972, 0.93, 0.887, 0.843, 0.802, 0.763, 0.727, 0.693\n",
      "Loss  0.000350672463448  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.807, 0.777, 0.749\n",
      "Val loss  0.000465947257238  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.726, 0.69\n",
      "Loss  0.000350628185708  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000466662665538  SSIM  0.972, 0.93, 0.887, 0.843, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000350666404254  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.806, 0.778, 0.749\n",
      "Val loss  0.000466070665047  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.762, 0.727, 0.693\n",
      "Loss  0.000350982524486  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.806, 0.778, 0.749\n",
      "Val loss  0.000464519589848  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.693\n",
      "Loss  0.000350758919309  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.806, 0.778, 0.749\n",
      "Val loss  0.000466541901696  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.000350498581493  SSIM  0.975, 0.941, 0.905, 0.87, 0.838, 0.806, 0.778, 0.749\n",
      "Val loss  0.000464880445041  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000350489862948  SSIM  0.975, 0.941, 0.906, 0.87, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000468157981639  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.727, 0.693\n",
      "Loss  0.000350280415195  SSIM  0.975, 0.941, 0.906, 0.871, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000467436338076  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.000350646196412  SSIM  0.975, 0.941, 0.906, 0.87, 0.837, 0.806, 0.778, 0.749\n",
      "Val loss  0.000468469281972  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.765, 0.729, 0.694\n",
      "Loss  0.000350723866834  SSIM  0.975, 0.941, 0.905, 0.87, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000466010064294  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.724, 0.688\n",
      "Loss  0.000350706428133  SSIM  0.975, 0.941, 0.906, 0.87, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.00046768505103  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.764, 0.729, 0.695\n",
      "Loss  0.000350534380279  SSIM  0.975, 0.941, 0.906, 0.87, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000467955951695  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.728, 0.692\n",
      "Loss  0.000350473400635  SSIM  0.975, 0.941, 0.906, 0.87, 0.837, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467648021586  SSIM  0.971, 0.929, 0.887, 0.843, 0.801, 0.763, 0.727, 0.693\n",
      "Loss  0.000350609258972  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.000465976894717  SSIM  0.971, 0.929, 0.885, 0.842, 0.8, 0.762, 0.727, 0.691\n",
      "Loss  0.000350824954893  SSIM  0.975, 0.941, 0.905, 0.871, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.000466915501514  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.728, 0.691\n",
      "Loss  0.000350699886711  SSIM  0.975, 0.941, 0.906, 0.871, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000465461758897  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000350404537726  SSIM  0.975, 0.941, 0.906, 0.87, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000465014842513  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.727, 0.692\n",
      "Loss  0.000350583844702  SSIM  0.975, 0.941, 0.906, 0.871, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000466325277928  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.73, 0.696\n",
      "Loss  0.000350226135723  SSIM  0.975, 0.941, 0.905, 0.871, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000465052137326  SSIM  0.972, 0.93, 0.886, 0.843, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000350421506491  SSIM  0.975, 0.941, 0.906, 0.871, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000470179031428  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.762, 0.726, 0.69\n",
      "Loss  0.000350255006074  SSIM  0.975, 0.941, 0.906, 0.871, 0.837, 0.807, 0.778, 0.749\n",
      "Val loss  0.000467063900025  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000350195360146  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466753646848  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.69\n",
      "Loss  0.000350469833132  SSIM  0.975, 0.941, 0.906, 0.87, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.000465987651318  SSIM  0.972, 0.93, 0.887, 0.844, 0.803, 0.764, 0.729, 0.695\n",
      "Loss  0.000350500623821  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.000464951779053  SSIM  0.972, 0.929, 0.886, 0.842, 0.801, 0.762, 0.726, 0.691\n",
      "Loss  0.000350569896713  SSIM  0.975, 0.941, 0.906, 0.87, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468516820692  SSIM  0.971, 0.929, 0.885, 0.84, 0.797, 0.757, 0.721, 0.684\n",
      "Loss  0.000350183118336  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467462317494  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.691\n",
      "Loss  0.000350877720943  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.00046793022973  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.726, 0.691\n",
      "Loss  0.000349927904765  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466131654044  SSIM  0.972, 0.929, 0.886, 0.843, 0.802, 0.763, 0.727, 0.693\n",
      "Loss  0.000350497198345  SSIM  0.975, 0.941, 0.906, 0.871, 0.837, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467289498774  SSIM  0.972, 0.929, 0.886, 0.842, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000349994739943  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466970173642  SSIM  0.971, 0.93, 0.887, 0.843, 0.802, 0.765, 0.73, 0.695\n",
      "Loss  0.000350242734108  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467156750034  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.69\n",
      "Loss  0.000350433721726  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465723926667  SSIM  0.971, 0.929, 0.886, 0.843, 0.8, 0.761, 0.725, 0.691\n",
      "Loss  0.00035025799103  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467695158208  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.757, 0.722, 0.687\n",
      "Loss  0.000350570446395  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000470865802839  SSIM  0.971, 0.929, 0.886, 0.843, 0.803, 0.765, 0.729, 0.695\n",
      "Loss  0.000349935949556  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466720824188  SSIM  0.971, 0.93, 0.887, 0.843, 0.802, 0.764, 0.73, 0.695\n",
      "Loss  0.000350296090339  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.000466376574594  SSIM  0.971, 0.93, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000350353025872  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.749\n",
      "Val loss  0.00046533546655  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.727, 0.692\n",
      "Loss  0.000349834023017  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468154243426  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.731, 0.697\n",
      "Loss  0.000350328029084  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467143658607  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.728, 0.694\n",
      "Loss  0.000349983033599  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467427079915  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000350705894951  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465001389151  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000349568888979  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466943950974  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.757, 0.722, 0.687\n",
      "Loss  0.000350294465853  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466135135212  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000350698192196  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468788009952  SSIM  0.971, 0.928, 0.883, 0.839, 0.798, 0.759, 0.723, 0.685\n",
      "Loss  0.000350057487667  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466080353246  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.76, 0.724, 0.689\n",
      "Loss  0.000350344195881  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000465572659858  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000349709641954  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000469918107323  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000349676988911  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467306261591  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.756, 0.722, 0.686\n",
      "Loss  0.000350391264745  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466070138791  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000350314788274  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466480510484  SSIM  0.972, 0.929, 0.885, 0.842, 0.8, 0.761, 0.724, 0.689\n",
      "Loss  0.000350166971621  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468046820606  SSIM  0.972, 0.93, 0.887, 0.844, 0.803, 0.765, 0.728, 0.694\n",
      "Loss  0.000349654505083  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465403849666  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.727, 0.693\n",
      "Loss  0.000349898818755  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465069806261  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.725, 0.69\n",
      "Loss  0.00034998163901  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466607679555  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.00035012734033  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468501143332  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.763, 0.726, 0.691\n",
      "Loss  0.000349648781322  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468668938847  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.762, 0.726, 0.69\n",
      "Loss  0.000350175796104  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467158717685  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.73, 0.695\n",
      "Loss  0.000350013495951  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466735022899  SSIM  0.971, 0.929, 0.887, 0.844, 0.802, 0.764, 0.728, 0.694\n",
      "Loss  0.000350023891437  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465902654163  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000350558751446  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466732340981  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.762, 0.726, 0.688\n",
      "Loss  0.00034976272143  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466456503025  SSIM  0.971, 0.929, 0.886, 0.843, 0.803, 0.765, 0.73, 0.696\n",
      "Loss  0.000349606239738  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466107082146  SSIM  0.971, 0.929, 0.885, 0.842, 0.801, 0.762, 0.726, 0.691\n",
      "Loss  0.000349939927804  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000470515762223  SSIM  0.971, 0.929, 0.885, 0.841, 0.798, 0.759, 0.721, 0.685\n",
      "Loss  0.000350270139483  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466595402744  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.69\n",
      "Loss  0.000350162582651  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466688564746  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.764, 0.728, 0.693\n",
      "Loss  0.000349776498982  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000464657817676  SSIM  0.971, 0.93, 0.887, 0.843, 0.802, 0.764, 0.729, 0.693\n",
      "Loss  0.000349795655504  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000469178411877  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.73, 0.696\n",
      "Loss  0.000349485582197  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000469435179606  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.764, 0.729, 0.694\n",
      "Loss  0.000349364319498  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.00046607792133  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000349735125626  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000469516304438  SSIM  0.971, 0.93, 0.887, 0.844, 0.804, 0.766, 0.731, 0.697\n",
      "Loss  0.000350383144844  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466632179217  SSIM  0.971, 0.93, 0.886, 0.843, 0.801, 0.763, 0.728, 0.692\n",
      "Loss  0.000349526880443  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466336936108  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.765, 0.729, 0.695\n",
      "Loss  0.000349579317486  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466873173194  SSIM  0.971, 0.93, 0.887, 0.844, 0.804, 0.766, 0.73, 0.696\n",
      "Loss  0.000350098011505  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467397685919  SSIM  0.972, 0.93, 0.886, 0.843, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000349949991841  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467217543919  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.763, 0.728, 0.693\n",
      "Loss  0.000349660614313  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466927771107  SSIM  0.972, 0.929, 0.886, 0.842, 0.8, 0.762, 0.726, 0.692\n",
      "Loss  0.000349861968089  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.00046547779761  SSIM  0.972, 0.929, 0.885, 0.842, 0.801, 0.762, 0.725, 0.69\n",
      "Loss  0.000349775443722  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000468457314244  SSIM  0.971, 0.93, 0.886, 0.843, 0.802, 0.763, 0.728, 0.694\n",
      "Loss  0.000348983148153  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465863105608  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000349815256464  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466427046282  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.000349419921807  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466211959196  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.727, 0.692\n",
      "Loss  0.000349809047721  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000464688890788  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.762, 0.728, 0.693\n",
      "Loss  0.000349660712236  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000464301669039  SSIM  0.972, 0.93, 0.887, 0.843, 0.802, 0.763, 0.728, 0.692\n",
      "Loss  0.000349600617528  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466388791509  SSIM  0.972, 0.93, 0.886, 0.843, 0.801, 0.762, 0.727, 0.692\n",
      "Loss  0.000349630440178  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467653466854  SSIM  0.972, 0.93, 0.887, 0.844, 0.803, 0.765, 0.729, 0.695\n",
      "Loss  0.000349487556803  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467839618505  SSIM  0.972, 0.93, 0.887, 0.843, 0.803, 0.765, 0.73, 0.696\n",
      "Loss  0.000349483948913  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466888385708  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.763, 0.726, 0.691\n",
      "Loss  0.000349787534371  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000467826579814  SSIM  0.971, 0.929, 0.887, 0.843, 0.803, 0.764, 0.727, 0.693\n",
      "Loss  0.000349455566141  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465299558069  SSIM  0.972, 0.93, 0.887, 0.843, 0.802, 0.764, 0.728, 0.694\n",
      "Loss  0.000349431432282  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466116888041  SSIM  0.971, 0.929, 0.887, 0.843, 0.802, 0.764, 0.728, 0.694\n",
      "Loss  0.000349740145679  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467406348558  SSIM  0.972, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.69\n",
      "Loss  0.000349242793768  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000468032388075  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.762, 0.726, 0.692\n",
      "Loss  0.000349674550861  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000471605500847  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000349371849309  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465743142471  SSIM  0.971, 0.929, 0.886, 0.842, 0.802, 0.763, 0.728, 0.691\n",
      "Loss  0.000349666315552  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466798093985  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000349248064046  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465080359136  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.728, 0.693\n",
      "Loss  0.000349760891986  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467441129207  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.726, 0.69\n",
      "Loss  0.000349131575539  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000468219828152  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.761, 0.725, 0.689\n",
      "Loss  0.000349769279374  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000469808390655  SSIM  0.971, 0.929, 0.886, 0.842, 0.799, 0.759, 0.722, 0.687\n",
      "Loss  0.00034971433376  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000465151222714  SSIM  0.972, 0.929, 0.886, 0.843, 0.802, 0.763, 0.728, 0.693\n",
      "Loss  0.000349080451012  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466289113974  SSIM  0.972, 0.929, 0.886, 0.843, 0.801, 0.762, 0.726, 0.692\n",
      "Loss  0.000349080637881  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467339546361  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.727, 0.691\n",
      "Loss  0.000349592936601  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000469424339186  SSIM  0.971, 0.929, 0.885, 0.842, 0.799, 0.76, 0.722, 0.687\n",
      "Loss  0.000349578014575  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466627597867  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.766, 0.731, 0.698\n",
      "Loss  0.000349595747718  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.778, 0.75\n",
      "Val loss  0.000466557738837  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.727, 0.691\n",
      "Loss  0.000348995380963  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466021599132  SSIM  0.972, 0.929, 0.886, 0.843, 0.801, 0.763, 0.728, 0.693\n",
      "Loss  0.000349278941106  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466914326826  SSIM  0.972, 0.93, 0.886, 0.843, 0.802, 0.763, 0.728, 0.693\n",
      "Loss  0.000349386076089  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465985451359  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.762, 0.726, 0.691\n",
      "Loss  0.000349468112287  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466298685817  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.727, 0.691\n",
      "Loss  0.00034922875755  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.00046579778794  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000349224979022  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000464852341858  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.763, 0.728, 0.693\n",
      "Loss  0.000349294197087  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.00046695956547  SSIM  0.972, 0.929, 0.886, 0.843, 0.803, 0.765, 0.729, 0.694\n",
      "Loss  0.000349124241934  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.00046825665189  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.727, 0.692\n",
      "Loss  0.000349124912486  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000468100241967  SSIM  0.971, 0.929, 0.885, 0.841, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000349271188786  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.00046612786589  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.724, 0.689\n",
      "Loss  0.000348697887004  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466619101062  SSIM  0.972, 0.929, 0.886, 0.842, 0.8, 0.761, 0.726, 0.69\n",
      "Loss  0.00034910232516  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.00046534402715  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.724, 0.689\n",
      "Loss  0.00034915257308  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465202459134  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.763, 0.728, 0.693\n",
      "Loss  0.000349474411185  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466180058778  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.000349172136025  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000468428521825  SSIM  0.972, 0.93, 0.887, 0.843, 0.802, 0.764, 0.729, 0.695\n",
      "Loss  0.000349363191546  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465864041122  SSIM  0.972, 0.93, 0.887, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.00034882152171  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.778, 0.75\n",
      "Val loss  0.000472059016814  SSIM  0.971, 0.928, 0.884, 0.839, 0.797, 0.757, 0.72, 0.683\n",
      "Loss  0.00034933464286  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000464545212395  SSIM  0.972, 0.929, 0.886, 0.841, 0.799, 0.76, 0.724, 0.689\n",
      "Loss  0.000348559017204  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467384391348  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.763, 0.729, 0.694\n",
      "Loss  0.000349535773969  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465719220054  SSIM  0.972, 0.929, 0.886, 0.842, 0.801, 0.762, 0.727, 0.691\n",
      "Loss  0.000348730310686  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000470901326044  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.725, 0.687\n",
      "Loss  0.000348927923411  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465972790727  SSIM  0.972, 0.93, 0.886, 0.843, 0.803, 0.765, 0.73, 0.694\n",
      "Loss  0.000348859132165  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465895719884  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000349030036976  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465634432039  SSIM  0.971, 0.929, 0.886, 0.843, 0.803, 0.764, 0.729, 0.695\n",
      "Loss  0.000349838874513  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465268844855  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.693\n",
      "Loss  0.000348559880401  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000465938663867  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.765, 0.73, 0.696\n",
      "Loss  0.000349207110367  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467474854318  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.727, 0.691\n",
      "Loss  0.00034925074377  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465037937043  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.762, 0.727, 0.692\n",
      "Loss  0.000348853525871  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467490807292  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000348973925709  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000469670334074  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000348797282428  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000466779169859  SSIM  0.972, 0.93, 0.887, 0.843, 0.803, 0.764, 0.729, 0.695\n",
      "Loss  0.000349494034644  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466950348055  SSIM  0.971, 0.93, 0.886, 0.843, 0.801, 0.763, 0.727, 0.691\n",
      "Loss  0.000348682649984  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466496275621  SSIM  0.971, 0.929, 0.887, 0.844, 0.803, 0.765, 0.73, 0.694\n",
      "Loss  0.000348757335495  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.751\n",
      "Val loss  0.000468748376996  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.726, 0.691\n",
      "Loss  0.000348827392691  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466627855669  SSIM  0.972, 0.93, 0.887, 0.843, 0.801, 0.763, 0.727, 0.692\n",
      "Loss  0.00034915238245  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000465669542144  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.000348678304715  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000466055506142  SSIM  0.971, 0.929, 0.886, 0.842, 0.8, 0.761, 0.725, 0.688\n",
      "Loss  0.000348822005662  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000466058618331  SSIM  0.971, 0.929, 0.886, 0.844, 0.803, 0.765, 0.73, 0.695\n",
      "Loss  0.000349128490735  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.751\n",
      "Val loss  0.00046523479803  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000348790839131  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000465946909564  SSIM  0.972, 0.929, 0.886, 0.843, 0.801, 0.762, 0.727, 0.693\n",
      "Loss  0.000349107552812  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467234870535  SSIM  0.971, 0.929, 0.887, 0.843, 0.802, 0.763, 0.727, 0.694\n",
      "Loss  0.000348353517273  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.751\n",
      "Val loss  0.000465694469516  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.726, 0.692\n",
      "Loss  0.000348939513877  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000464847633266  SSIM  0.972, 0.93, 0.887, 0.843, 0.802, 0.763, 0.727, 0.692\n",
      "Loss  0.000349056024883  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000468265513482  SSIM  0.971, 0.929, 0.885, 0.842, 0.8, 0.761, 0.725, 0.689\n",
      "Loss  0.000348659549737  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000465719577798  SSIM  0.971, 0.93, 0.887, 0.844, 0.802, 0.764, 0.73, 0.695\n",
      "Loss  0.000348909903461  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.75\n",
      "Val loss  0.000467493553879  SSIM  0.971, 0.93, 0.887, 0.843, 0.801, 0.763, 0.725, 0.689\n",
      "Loss  0.000348719810113  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000466897384904  SSIM  0.971, 0.929, 0.886, 0.843, 0.801, 0.762, 0.727, 0.691\n",
      "Loss  0.000348818040556  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000466520271148  SSIM  0.971, 0.93, 0.886, 0.843, 0.802, 0.763, 0.727, 0.693\n",
      "Loss  0.000348491788206  SSIM  0.975, 0.941, 0.906, 0.871, 0.839, 0.808, 0.779, 0.75\n",
      "Val loss  0.000464743730379  SSIM  0.972, 0.929, 0.886, 0.841, 0.799, 0.761, 0.725, 0.689\n",
      "Loss  0.000348929264404  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000470759022865  SSIM  0.971, 0.929, 0.886, 0.843, 0.803, 0.765, 0.73, 0.696\n",
      "Loss  0.000348348475684  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000466676934389  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.695\n",
      "Loss  0.000348925675252  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000466189448081  SSIM  0.971, 0.929, 0.885, 0.841, 0.799, 0.76, 0.725, 0.689\n",
      "Loss  0.000348407560467  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.000466813393694  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.728, 0.693\n",
      "Loss  0.000348890080081  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.75\n",
      "Val loss  0.00046648742567  SSIM  0.971, 0.929, 0.887, 0.844, 0.802, 0.763, 0.729, 0.695\n",
      "Loss  0.000348509218759  SSIM  0.975, 0.941, 0.906, 0.872, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000468774219509  SSIM  0.971, 0.929, 0.886, 0.842, 0.801, 0.762, 0.725, 0.691\n",
      "Loss  0.000348398475348  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000466033409524  SSIM  0.971, 0.929, 0.886, 0.843, 0.802, 0.764, 0.729, 0.694\n",
      "Loss  0.000348890455722  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.807, 0.779, 0.751\n",
      "Val loss  0.000467181211687  SSIM  0.971, 0.929, 0.885, 0.842, 0.799, 0.759, 0.723, 0.688\n",
      "Loss  0.000348665422196  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000466125642532  SSIM  0.972, 0.929, 0.886, 0.843, 0.801, 0.762, 0.727, 0.693\n",
      "Loss  0.00034873559865  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000467997544154  SSIM  0.971, 0.93, 0.887, 0.844, 0.803, 0.764, 0.729, 0.695\n",
      "Loss  0.000348161547915  SSIM  0.975, 0.941, 0.906, 0.871, 0.838, 0.808, 0.779, 0.751\n",
      "Val loss  0.000467607527273  SSIM  0.971, 0.929, 0.886, 0.842, 0.802, 0.765, 0.729, 0.694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-ae617a0644a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mz\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mssim_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m#if i % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-ae617a0644a6>\u001b[0m in \u001b[0;36mget_ssim\u001b[0;34m(pred, ground)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdistorted_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mssim_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistorted_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mssim_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssim_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.6/site-packages/skimage/measure/_structural_similarity.py\u001b[0m in \u001b[0;36mcompare_ssim\u001b[0;34m(X, Y, win_size, gradient, data_range, multichannel, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# compute (weighted) variances and covariances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0muxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0muyy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0muxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfilter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mvx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov_norm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muxx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mux\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36muniform_filter\u001b[0;34m(input, size, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             uniform_filter1d(input, int(size), axis, output, mode,\n\u001b[0;32m--> 853\u001b[0;31m                              cval, origin)\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36muniform_filter1d\u001b[0;34m(input, size, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     _nd_image.uniform_filter1d(input, size, axis, output, mode, cval,\n\u001b[0;32m--> 794\u001b[0;31m                                origin)\n\u001b[0m\u001b[1;32m    795\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# [STAR] For training the Pytorch Model for Imitating the result with volume Slice Quadratic Linear\n",
    "\n",
    "import torch.optim as optim\n",
    "from skimage import measure\n",
    "\n",
    "def get_ssim(pred, ground):\n",
    "    ssim_array = []\n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        t1 = np.min(ground[i].flatten())\n",
    "        t2 = np.max(ground[i].flatten())\n",
    "        reference_image = (ground[i, 0]-t1)*255/(t2-t1)\n",
    "        \n",
    "        t1 = np.min(pred[i, 0, :, :].flatten())\n",
    "        t2 = np.max(pred[i, 0, :, :].flatten())\n",
    "        distorted_image = (pred[i, 0]-t1)*255/(t2-t1)\n",
    "        \n",
    "        ssim_temp = measure.compare_ssim(distorted_image, reference_image, data_range=255)\n",
    "        ssim_array.append(ssim_temp)\n",
    "    \n",
    "    return ssim_array\n",
    "\n",
    "def get_ssim_distribution(ssim_input_array, value_array):\n",
    "    ssim_array = {}\n",
    "    ssim_array[0.025] = []\n",
    "    ssim_array[0.050] = []\n",
    "    ssim_array[0.075] = []\n",
    "    ssim_array[0.100] = []\n",
    "    ssim_array[0.125] = []\n",
    "    ssim_array[0.150] = []\n",
    "    ssim_array[0.175] = []\n",
    "    ssim_array[0.200] = []\n",
    "    \n",
    "    for i in range(len(value_array)):\n",
    "        value     = value_array[i]\n",
    "        ssim_temp = ssim_input_array[i]\n",
    "        \n",
    "        #print('value is ', value)\n",
    "        if np.isclose(-value, 0.025, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.025].append(ssim_temp)\n",
    "            #mae_array[0.1].append(mae_temp)\n",
    "        elif np.isclose(-value, 0.050, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.050].append(ssim_temp)\n",
    "            #mae_array[0.2].append(mae_temp)    \n",
    "        elif  np.isclose(-value, 0.075, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.075].append(ssim_temp)\n",
    "            #mae_array[0.3].append(mae_temp)    \n",
    "        elif  np.isclose(-value, 0.100, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.100].append(ssim_temp)\n",
    "            #mae_array[0.4].append(mae_temp)    \n",
    "        elif np.isclose(-value, 0.125, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.125].append(ssim_temp)\n",
    "            #mae_array[0.5].append(mae_temp)    \n",
    "        elif np.isclose(-value, 0.150, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.150].append(ssim_temp)\n",
    "        elif np.isclose(-value, 0.175, rtol=1e-02, atol=1e-02, equal_nan=False):\n",
    "            ssim_array[0.175].append(ssim_temp)\n",
    "        else:\n",
    "            ssim_array[0.200].append(ssim_temp)\n",
    "            #mae_array[0.6].append(mae_temp)\n",
    "    \n",
    "    mean_ssim_array = []\n",
    "    for k in ssim_array.keys():\n",
    "        mean_ssim_array.append(np.mean(ssim_array[k]))\n",
    "    mean_ssim_array = [str(round(x, 3)) for x in mean_ssim_array]\n",
    "    \n",
    "    return \", \".join(mean_ssim_array)\n",
    "\n",
    "model = MyUnet_half()#_half()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "mse_criterion  = nn.MSELoss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min   = 1000\n",
    "batch_size = 8\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    ssim_array = []\n",
    "    \n",
    "    ssim_z_array = []\n",
    "    value_array  = []\n",
    "    \n",
    "    idx     = np.random.permutation(len(x_array))\n",
    "    x_array = x_array[idx]\n",
    "    y_array = y_array[idx]\n",
    "    z_array = z_array[idx]\n",
    "    v_array = v_array[idx]\n",
    "    \n",
    "    for i in range(len(x_array)//batch_size):\n",
    "        x = x_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        v = v_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        v = torch.tensor(v, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, z)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape)\n",
    "        \n",
    "        loss1  = my_loss(output, y)\n",
    "        #loss2  = mse_criterion(output, y)\n",
    "        \n",
    "        loss   = loss1#+10*loss2\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        y      = y.data.cpu().numpy()\n",
    "        z      = -1*z.data.cpu().numpy()\n",
    "        \n",
    "        ssim_values = get_ssim(output, y)\n",
    "        \n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        for vt in ssim_values:\n",
    "            ssim_array.append(vt)\n",
    "        for vt in z:\n",
    "            value_array.append(vt)\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ssim_string = get_ssim_distribution(ssim_array, value_array)\n",
    "    \n",
    "    print('Loss ', np.mean(loss_array), ' SSIM ', ssim_string)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    ssim_array = []\n",
    "    value_array  = []\n",
    "    \n",
    "    for i in range(len(x_val_array)//batch_size):\n",
    "        x = x_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        v = v_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        v = torch.tensor(v, device=device).float()\n",
    "\n",
    "        output = model(x, z)\n",
    "\n",
    "        loss1 = my_loss(output, y)\n",
    "        #loss2 = mse_criterion(output, y)\n",
    "        loss  = loss1#+10*loss2\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        y      = y.data.cpu().numpy()\n",
    "        z      = -1*z.data.cpu().numpy()\n",
    "        \n",
    "        ssim_values = get_ssim(output, y)\n",
    "        \n",
    "        for vt in ssim_values:\n",
    "            ssim_array.append(vt)\n",
    "        for vt in z:\n",
    "            value_array.append(vt)\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "    \n",
    "    \n",
    "    ssim_string = get_ssim_distribution(ssim_array, value_array)\n",
    "        \n",
    "    val_loss = np.mean(loss_array)\n",
    "    print(\"Val loss \", val_loss, ' SSIM ', ssim_string)\n",
    "    \n",
    "    if val_loss < prev_min:\n",
    "        prev_min = val_loss\n",
    "        print('saving the model ', prev_min)\n",
    "        torch.save(model.state_dict(), \"unethalf-quadratic-linear.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     5,
     22,
     99,
     154
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.00456042334374  SSIM  0.894, 0.82, 0.722, 0.65, 0.587, 0.548, 0.503, 0.49\n",
      "Val loss  0.00336096807336  SSIM  0.94, 0.839, 0.721, 0.635, 0.614, 0.539, 0.481, 0.452\n",
      "saving the model  0.00336096807336\n",
      "Loss  0.00315674805291  SSIM  0.926, 0.827, 0.707, 0.629, 0.556, 0.519, 0.474, 0.464\n",
      "Val loss  0.00334302216931  SSIM  0.942, 0.838, 0.717, 0.63, 0.609, 0.534, 0.475, 0.446\n",
      "saving the model  0.00334302216931\n",
      "Loss  0.00314462537307  SSIM  0.926, 0.825, 0.704, 0.626, 0.552, 0.516, 0.471, 0.461\n",
      "Val loss  0.003300043253  SSIM  0.943, 0.837, 0.715, 0.629, 0.608, 0.532, 0.474, 0.444\n",
      "saving the model  0.003300043253\n",
      "Loss  0.00281248033149  SSIM  0.914, 0.818, 0.703, 0.628, 0.557, 0.525, 0.477, 0.469\n",
      "Val loss  0.00234727367689  SSIM  0.859, 0.78, 0.691, 0.622, 0.59, 0.531, 0.484, 0.456\n",
      "saving the model  0.00234727367689\n",
      "Loss  0.00185747458015  SSIM  0.83, 0.769, 0.699, 0.637, 0.586, 0.561, 0.51, 0.5\n",
      "Val loss  0.00169854700333  SSIM  0.795, 0.754, 0.701, 0.647, 0.604, 0.554, 0.517, 0.488\n",
      "saving the model  0.00169854700333\n",
      "Loss  0.00143923059284  SSIM  0.815, 0.777, 0.721, 0.665, 0.625, 0.601, 0.543, 0.532\n",
      "Val loss  0.00141553458781  SSIM  0.799, 0.763, 0.722, 0.668, 0.621, 0.573, 0.538, 0.508\n",
      "saving the model  0.00141553458781\n",
      "Loss  0.00121194961218  SSIM  0.799, 0.765, 0.718, 0.661, 0.625, 0.604, 0.541, 0.528\n",
      "Val loss  0.00118237130949  SSIM  0.782, 0.751, 0.717, 0.665, 0.608, 0.562, 0.527, 0.494\n",
      "saving the model  0.00118237130949\n",
      "Loss  0.00100524088891  SSIM  0.83, 0.793, 0.749, 0.689, 0.65, 0.624, 0.555, 0.536\n",
      "Val loss  0.00100782251975  SSIM  0.804, 0.772, 0.733, 0.68, 0.61, 0.559, 0.523, 0.484\n",
      "saving the model  0.00100782251975\n",
      "Loss  0.000870619567376  SSIM  0.858, 0.819, 0.777, 0.716, 0.678, 0.646, 0.572, 0.546\n",
      "Val loss  0.000885446747299  SSIM  0.84, 0.807, 0.761, 0.709, 0.634, 0.581, 0.543, 0.496\n",
      "saving the model  0.000885446747299\n",
      "Loss  0.000791451655059  SSIM  0.873, 0.837, 0.794, 0.733, 0.694, 0.661, 0.584, 0.554\n",
      "Val loss  0.000819149433984  SSIM  0.877, 0.843, 0.79, 0.738, 0.661, 0.605, 0.571, 0.525\n",
      "saving the model  0.000819149433984\n",
      "Loss  0.000736240964546  SSIM  0.887, 0.847, 0.803, 0.742, 0.706, 0.671, 0.594, 0.559\n",
      "Val loss  0.000814453176456  SSIM  0.871, 0.834, 0.774, 0.719, 0.639, 0.586, 0.549, 0.498\n",
      "saving the model  0.000814453176456\n",
      "Loss  0.000698978767799  SSIM  0.899, 0.854, 0.806, 0.745, 0.713, 0.679, 0.601, 0.566\n",
      "Val loss  0.000735085933877  SSIM  0.888, 0.845, 0.78, 0.734, 0.658, 0.607, 0.57, 0.521\n",
      "saving the model  0.000735085933877\n",
      "Loss  0.000662976511273  SSIM  0.913, 0.86, 0.805, 0.746, 0.716, 0.684, 0.607, 0.574\n",
      "Val loss  0.000697050867369  SSIM  0.9, 0.84, 0.778, 0.734, 0.657, 0.609, 0.576, 0.529\n",
      "saving the model  0.000697050867369\n",
      "Loss  0.000636306963086  SSIM  0.926, 0.861, 0.801, 0.745, 0.719, 0.688, 0.616, 0.585\n",
      "Val loss  0.000722989573376  SSIM  0.921, 0.849, 0.759, 0.712, 0.63, 0.585, 0.554, 0.509\n",
      "Loss  0.000618847603007  SSIM  0.933, 0.862, 0.802, 0.747, 0.721, 0.692, 0.621, 0.592\n",
      "Val loss  0.000665531766776  SSIM  0.921, 0.836, 0.757, 0.706, 0.623, 0.577, 0.546, 0.5\n",
      "saving the model  0.000665531766776\n",
      "Loss  0.000606199441743  SSIM  0.939, 0.864, 0.804, 0.75, 0.725, 0.695, 0.625, 0.596\n",
      "Val loss  0.000632356279239  SSIM  0.94, 0.865, 0.775, 0.727, 0.648, 0.602, 0.573, 0.526\n",
      "saving the model  0.000632356279239\n",
      "Loss  0.000590437212131  SSIM  0.944, 0.867, 0.806, 0.751, 0.727, 0.698, 0.627, 0.598\n",
      "Val loss  0.000626896836446  SSIM  0.932, 0.845, 0.789, 0.741, 0.663, 0.617, 0.586, 0.538\n",
      "saving the model  0.000626896836446\n",
      "Loss  0.000579641453081  SSIM  0.947, 0.869, 0.81, 0.753, 0.729, 0.7, 0.629, 0.6\n",
      "Val loss  0.000636973302229  SSIM  0.947, 0.873, 0.787, 0.74, 0.662, 0.617, 0.589, 0.543\n",
      "Loss  0.000572082629896  SSIM  0.949, 0.87, 0.811, 0.756, 0.731, 0.702, 0.631, 0.601\n",
      "Val loss  0.000602983258665  SSIM  0.948, 0.866, 0.797, 0.749, 0.672, 0.626, 0.596, 0.551\n",
      "saving the model  0.000602983258665\n",
      "Loss  0.000564943655618  SSIM  0.95, 0.872, 0.813, 0.757, 0.732, 0.703, 0.632, 0.601\n",
      "Val loss  0.000625126828556  SSIM  0.945, 0.856, 0.788, 0.739, 0.658, 0.614, 0.584, 0.538\n",
      "Loss  0.000559468568059  SSIM  0.951, 0.873, 0.814, 0.757, 0.733, 0.703, 0.632, 0.601\n",
      "Val loss  0.000591286761628  SSIM  0.953, 0.877, 0.785, 0.736, 0.656, 0.611, 0.582, 0.537\n",
      "saving the model  0.000591286761628\n",
      "Loss  0.000551562097889  SSIM  0.953, 0.871, 0.815, 0.758, 0.733, 0.704, 0.631, 0.601\n",
      "Val loss  0.000604004668188  SSIM  0.954, 0.88, 0.803, 0.754, 0.677, 0.633, 0.605, 0.56\n",
      "Loss  0.000548269499934  SSIM  0.955, 0.871, 0.813, 0.755, 0.732, 0.703, 0.631, 0.602\n",
      "Val loss  0.000582020452246  SSIM  0.957, 0.874, 0.806, 0.757, 0.682, 0.638, 0.611, 0.567\n",
      "saving the model  0.000582020452246\n",
      "Loss  0.000541102930635  SSIM  0.957, 0.873, 0.813, 0.756, 0.732, 0.703, 0.631, 0.601\n",
      "Val loss  0.000569791806047  SSIM  0.956, 0.861, 0.794, 0.743, 0.664, 0.619, 0.59, 0.544\n",
      "saving the model  0.000569791806047\n",
      "Loss  0.000537066768763  SSIM  0.959, 0.874, 0.814, 0.756, 0.731, 0.702, 0.631, 0.599\n",
      "Val loss  0.000565154435171  SSIM  0.964, 0.873, 0.791, 0.74, 0.66, 0.616, 0.588, 0.542\n",
      "saving the model  0.000565154435171\n",
      "Loss  0.00052987831373  SSIM  0.961, 0.874, 0.815, 0.756, 0.731, 0.702, 0.631, 0.601\n",
      "Val loss  0.000556161065877  SSIM  0.962, 0.86, 0.789, 0.736, 0.655, 0.61, 0.581, 0.534\n",
      "saving the model  0.000556161065877\n",
      "Loss  0.000525772185511  SSIM  0.962, 0.873, 0.814, 0.755, 0.732, 0.701, 0.631, 0.6\n",
      "Val loss  0.000617065579398  SSIM  0.965, 0.869, 0.791, 0.74, 0.661, 0.617, 0.589, 0.543\n",
      "Loss  0.000523476166292  SSIM  0.963, 0.875, 0.815, 0.756, 0.733, 0.702, 0.632, 0.601\n",
      "Val loss  0.000558121903974  SSIM  0.961, 0.858, 0.791, 0.737, 0.657, 0.614, 0.585, 0.539\n",
      "Loss  0.000521877335097  SSIM  0.964, 0.877, 0.817, 0.757, 0.733, 0.703, 0.633, 0.601\n",
      "Val loss  0.000549892285548  SSIM  0.965, 0.867, 0.795, 0.743, 0.664, 0.62, 0.592, 0.546\n",
      "saving the model  0.000549892285548\n",
      "Loss  0.000516896693413  SSIM  0.965, 0.876, 0.817, 0.758, 0.733, 0.704, 0.633, 0.601\n",
      "Val loss  0.000571926848555  SSIM  0.961, 0.857, 0.784, 0.726, 0.642, 0.595, 0.563, 0.514\n",
      "Loss  0.000512653619635  SSIM  0.966, 0.878, 0.818, 0.758, 0.734, 0.704, 0.633, 0.601\n",
      "Val loss  0.000560356422269  SSIM  0.969, 0.877, 0.798, 0.748, 0.67, 0.626, 0.598, 0.554\n",
      "Loss  0.000508688114161  SSIM  0.967, 0.88, 0.818, 0.758, 0.734, 0.705, 0.634, 0.604\n",
      "Val loss  0.00054003434052  SSIM  0.969, 0.874, 0.795, 0.744, 0.665, 0.621, 0.591, 0.546\n",
      "saving the model  0.00054003434052\n",
      "Loss  0.000508516923562  SSIM  0.967, 0.881, 0.819, 0.759, 0.735, 0.706, 0.635, 0.603\n",
      "Val loss  0.000561183931131  SSIM  0.972, 0.878, 0.795, 0.742, 0.663, 0.618, 0.589, 0.543\n",
      "Loss  0.00050679315352  SSIM  0.967, 0.881, 0.819, 0.759, 0.735, 0.706, 0.635, 0.604\n",
      "Val loss  0.000538751425804  SSIM  0.969, 0.871, 0.788, 0.734, 0.653, 0.609, 0.579, 0.534\n",
      "saving the model  0.000538751425804\n",
      "Loss  0.000501825318006  SSIM  0.968, 0.882, 0.82, 0.759, 0.736, 0.707, 0.636, 0.605\n",
      "Val loss  0.000537157997605  SSIM  0.97, 0.876, 0.788, 0.735, 0.654, 0.611, 0.581, 0.536\n",
      "saving the model  0.000537157997605\n",
      "Loss  0.000501043623343  SSIM  0.968, 0.883, 0.821, 0.759, 0.736, 0.708, 0.636, 0.606\n",
      "Val loss  0.000536210289632  SSIM  0.971, 0.891, 0.81, 0.759, 0.684, 0.64, 0.612, 0.567\n",
      "saving the model  0.000536210289632\n",
      "Loss  0.000496434630448  SSIM  0.969, 0.884, 0.821, 0.759, 0.737, 0.707, 0.636, 0.607\n",
      "Val loss  0.000531873266795  SSIM  0.97, 0.876, 0.801, 0.749, 0.672, 0.628, 0.6, 0.556\n",
      "saving the model  0.000531873266795\n",
      "Loss  0.000497053748047  SSIM  0.968, 0.884, 0.821, 0.76, 0.737, 0.707, 0.637, 0.607\n",
      "Val loss  0.000551931430236  SSIM  0.969, 0.88, 0.781, 0.724, 0.641, 0.596, 0.565, 0.518\n",
      "Loss  0.000493295700119  SSIM  0.969, 0.885, 0.822, 0.76, 0.737, 0.708, 0.638, 0.608\n",
      "Val loss  0.000530424263328  SSIM  0.972, 0.885, 0.8, 0.746, 0.667, 0.624, 0.595, 0.55\n",
      "saving the model  0.000530424263328\n",
      "Loss  0.000491112746744  SSIM  0.97, 0.885, 0.822, 0.76, 0.738, 0.709, 0.639, 0.609\n",
      "Val loss  0.000554908273567  SSIM  0.963, 0.875, 0.8, 0.747, 0.669, 0.627, 0.599, 0.553\n",
      "Loss  0.000490661109352  SSIM  0.969, 0.886, 0.823, 0.76, 0.738, 0.709, 0.639, 0.609\n",
      "Val loss  0.000524909713422  SSIM  0.972, 0.884, 0.808, 0.757, 0.682, 0.639, 0.613, 0.569\n",
      "saving the model  0.000524909713422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000488615883744  SSIM  0.97, 0.887, 0.824, 0.761, 0.739, 0.71, 0.639, 0.61\n",
      "Val loss  0.000527775598981  SSIM  0.973, 0.884, 0.806, 0.756, 0.681, 0.64, 0.613, 0.57\n",
      "Loss  0.000486771666739  SSIM  0.971, 0.888, 0.824, 0.761, 0.738, 0.71, 0.64, 0.612\n",
      "Val loss  0.000527460626501  SSIM  0.972, 0.89, 0.81, 0.756, 0.68, 0.638, 0.61, 0.567\n",
      "Loss  0.000484448050124  SSIM  0.971, 0.889, 0.825, 0.762, 0.739, 0.711, 0.641, 0.613\n",
      "Val loss  0.000523011854151  SSIM  0.974, 0.891, 0.797, 0.741, 0.663, 0.621, 0.594, 0.55\n",
      "saving the model  0.000523011854151\n",
      "Loss  0.000483867630888  SSIM  0.971, 0.889, 0.825, 0.762, 0.74, 0.712, 0.641, 0.613\n",
      "Val loss  0.000524709755206  SSIM  0.97, 0.885, 0.805, 0.75, 0.674, 0.631, 0.604, 0.559\n",
      "Loss  0.000482233800953  SSIM  0.972, 0.89, 0.826, 0.763, 0.741, 0.713, 0.642, 0.614\n",
      "Val loss  0.000529546395061  SSIM  0.974, 0.893, 0.803, 0.748, 0.67, 0.626, 0.6, 0.554\n",
      "Loss  0.000482349657837  SSIM  0.972, 0.891, 0.828, 0.764, 0.741, 0.713, 0.643, 0.615\n",
      "Val loss  0.000551678889897  SSIM  0.974, 0.897, 0.817, 0.765, 0.691, 0.649, 0.622, 0.579\n",
      "Loss  0.000480216516245  SSIM  0.972, 0.892, 0.828, 0.764, 0.742, 0.714, 0.643, 0.615\n",
      "Val loss  0.000532988383027  SSIM  0.974, 0.893, 0.809, 0.755, 0.678, 0.636, 0.608, 0.562\n",
      "Loss  0.00047897498399  SSIM  0.972, 0.892, 0.829, 0.765, 0.742, 0.714, 0.645, 0.617\n",
      "Val loss  0.000521353151998  SSIM  0.974, 0.892, 0.8, 0.744, 0.666, 0.624, 0.598, 0.553\n",
      "saving the model  0.000521353151998\n",
      "Loss  0.000478239609157  SSIM  0.973, 0.893, 0.831, 0.765, 0.743, 0.715, 0.646, 0.618\n",
      "Val loss  0.00051859180897  SSIM  0.975, 0.892, 0.805, 0.748, 0.67, 0.629, 0.602, 0.558\n",
      "saving the model  0.00051859180897\n",
      "Loss  0.000475056903876  SSIM  0.973, 0.894, 0.831, 0.767, 0.743, 0.715, 0.646, 0.619\n",
      "Val loss  0.000520546278916  SSIM  0.972, 0.886, 0.801, 0.744, 0.665, 0.625, 0.598, 0.554\n",
      "Loss  0.000475068289862  SSIM  0.973, 0.895, 0.832, 0.767, 0.745, 0.716, 0.647, 0.62\n",
      "Val loss  0.000524203027831  SSIM  0.976, 0.891, 0.808, 0.753, 0.677, 0.635, 0.61, 0.565\n",
      "Loss  0.00047271013182  SSIM  0.973, 0.896, 0.833, 0.768, 0.744, 0.717, 0.648, 0.62\n",
      "Val loss  0.000519738020317  SSIM  0.974, 0.9, 0.805, 0.742, 0.661, 0.618, 0.59, 0.545\n",
      "Loss  0.000470577375081  SSIM  0.974, 0.896, 0.834, 0.768, 0.746, 0.717, 0.649, 0.622\n",
      "Val loss  0.00052447021706  SSIM  0.976, 0.903, 0.818, 0.762, 0.687, 0.644, 0.618, 0.575\n",
      "Loss  0.000470673233275  SSIM  0.974, 0.898, 0.835, 0.769, 0.746, 0.718, 0.65, 0.622\n",
      "Val loss  0.000515888459457  SSIM  0.974, 0.886, 0.799, 0.74, 0.66, 0.619, 0.592, 0.547\n",
      "saving the model  0.000515888459457\n",
      "Loss  0.000466664411085  SSIM  0.974, 0.898, 0.836, 0.77, 0.747, 0.719, 0.651, 0.623\n",
      "Val loss  0.000549682395591  SSIM  0.975, 0.888, 0.793, 0.735, 0.657, 0.617, 0.593, 0.551\n",
      "Loss  0.000467582282685  SSIM  0.974, 0.899, 0.837, 0.771, 0.747, 0.719, 0.651, 0.625\n",
      "Val loss  0.000510848915321  SSIM  0.975, 0.892, 0.805, 0.746, 0.667, 0.626, 0.598, 0.554\n",
      "saving the model  0.000510848915321\n",
      "Loss  0.000466390957559  SSIM  0.974, 0.9, 0.838, 0.772, 0.748, 0.72, 0.652, 0.625\n",
      "Val loss  0.000516396698018  SSIM  0.976, 0.893, 0.806, 0.747, 0.668, 0.627, 0.602, 0.558\n",
      "Loss  0.000463468641943  SSIM  0.974, 0.901, 0.838, 0.772, 0.748, 0.72, 0.653, 0.625\n",
      "Val loss  0.000523655114695  SSIM  0.976, 0.897, 0.812, 0.757, 0.681, 0.641, 0.616, 0.573\n",
      "Loss  0.000463579411144  SSIM  0.974, 0.901, 0.839, 0.773, 0.748, 0.721, 0.653, 0.627\n",
      "Val loss  0.000519879444444  SSIM  0.976, 0.896, 0.805, 0.745, 0.665, 0.623, 0.595, 0.549\n",
      "Loss  0.000460401250604  SSIM  0.975, 0.902, 0.839, 0.773, 0.749, 0.722, 0.654, 0.628\n",
      "Val loss  0.000524860399775  SSIM  0.977, 0.897, 0.799, 0.737, 0.655, 0.613, 0.585, 0.54\n",
      "Loss  0.000458914211073  SSIM  0.975, 0.902, 0.84, 0.774, 0.75, 0.723, 0.654, 0.628\n",
      "Val loss  0.000518741114938  SSIM  0.976, 0.895, 0.806, 0.747, 0.668, 0.627, 0.599, 0.552\n",
      "Loss  0.000458595180626  SSIM  0.975, 0.903, 0.841, 0.774, 0.75, 0.723, 0.655, 0.629\n",
      "Val loss  0.000536480844428  SSIM  0.974, 0.897, 0.813, 0.755, 0.678, 0.638, 0.611, 0.567\n",
      "Loss  0.000457443357146  SSIM  0.975, 0.904, 0.841, 0.774, 0.751, 0.724, 0.656, 0.628\n",
      "Val loss  0.000540449434833  SSIM  0.974, 0.892, 0.815, 0.759, 0.683, 0.645, 0.619, 0.576\n",
      "Loss  0.000455893552138  SSIM  0.975, 0.904, 0.841, 0.776, 0.751, 0.724, 0.656, 0.631\n",
      "Val loss  0.000509884394007  SSIM  0.976, 0.899, 0.812, 0.754, 0.675, 0.634, 0.608, 0.564\n",
      "saving the model  0.000509884394007\n",
      "Loss  0.000452686107333  SSIM  0.975, 0.904, 0.842, 0.776, 0.752, 0.724, 0.657, 0.63\n",
      "Val loss  0.000511560345301  SSIM  0.976, 0.904, 0.824, 0.772, 0.698, 0.658, 0.633, 0.592\n",
      "Loss  0.000453117208421  SSIM  0.976, 0.906, 0.843, 0.777, 0.753, 0.726, 0.658, 0.631\n",
      "Val loss  0.000508226679347  SSIM  0.974, 0.898, 0.822, 0.769, 0.695, 0.657, 0.632, 0.59\n",
      "saving the model  0.000508226679347\n",
      "Loss  0.000453187411887  SSIM  0.976, 0.906, 0.844, 0.779, 0.754, 0.726, 0.658, 0.632\n",
      "Val loss  0.000532094533206  SSIM  0.977, 0.9, 0.813, 0.757, 0.68, 0.639, 0.613, 0.569\n",
      "Loss  0.000452048466668  SSIM  0.976, 0.907, 0.844, 0.779, 0.754, 0.726, 0.659, 0.632\n",
      "Val loss  0.000510182319791  SSIM  0.976, 0.905, 0.82, 0.765, 0.69, 0.649, 0.623, 0.578\n",
      "Loss  0.000450811216897  SSIM  0.976, 0.907, 0.845, 0.779, 0.755, 0.727, 0.659, 0.632\n",
      "Val loss  0.000510921466921  SSIM  0.977, 0.904, 0.82, 0.764, 0.689, 0.648, 0.621, 0.578\n",
      "Loss  0.000447497991752  SSIM  0.976, 0.908, 0.845, 0.78, 0.755, 0.728, 0.66, 0.633\n",
      "Val loss  0.000510222170444  SSIM  0.977, 0.907, 0.822, 0.767, 0.691, 0.65, 0.623, 0.579\n",
      "Loss  0.000448320814093  SSIM  0.976, 0.908, 0.846, 0.781, 0.756, 0.728, 0.661, 0.634\n",
      "Val loss  0.000509848389076  SSIM  0.976, 0.901, 0.822, 0.769, 0.694, 0.654, 0.627, 0.584\n",
      "Loss  0.000446533957602  SSIM  0.976, 0.909, 0.846, 0.782, 0.757, 0.728, 0.66, 0.634\n",
      "Val loss  0.000512808463769  SSIM  0.977, 0.906, 0.822, 0.767, 0.692, 0.651, 0.623, 0.58\n",
      "Loss  0.000445646553814  SSIM  0.976, 0.909, 0.847, 0.782, 0.757, 0.729, 0.661, 0.634\n",
      "Val loss  0.00051244892017  SSIM  0.977, 0.905, 0.817, 0.76, 0.682, 0.64, 0.613, 0.569\n",
      "Loss  0.000444009668508  SSIM  0.976, 0.909, 0.847, 0.782, 0.757, 0.73, 0.662, 0.636\n",
      "Val loss  0.000505969323101  SSIM  0.977, 0.903, 0.819, 0.763, 0.685, 0.644, 0.616, 0.572\n",
      "saving the model  0.000505969323101\n",
      "Loss  0.000444462593894  SSIM  0.976, 0.91, 0.848, 0.784, 0.758, 0.73, 0.662, 0.636\n",
      "Val loss  0.000516837334144  SSIM  0.977, 0.906, 0.824, 0.767, 0.69, 0.648, 0.619, 0.575\n",
      "Loss  0.000442873997862  SSIM  0.976, 0.91, 0.848, 0.784, 0.758, 0.731, 0.662, 0.636\n",
      "Val loss  0.00050523682317  SSIM  0.979, 0.91, 0.821, 0.764, 0.686, 0.643, 0.614, 0.57\n",
      "saving the model  0.00050523682317\n",
      "Loss  0.000441160625129  SSIM  0.976, 0.911, 0.849, 0.785, 0.758, 0.731, 0.663, 0.637\n",
      "Val loss  0.000507076113834  SSIM  0.977, 0.902, 0.819, 0.765, 0.687, 0.645, 0.619, 0.575\n",
      "Loss  0.000440037238305  SSIM  0.976, 0.911, 0.849, 0.785, 0.759, 0.732, 0.663, 0.637\n",
      "Val loss  0.000508795567497  SSIM  0.978, 0.91, 0.829, 0.775, 0.699, 0.657, 0.629, 0.586\n",
      "Loss  0.00044011363081  SSIM  0.976, 0.911, 0.849, 0.786, 0.76, 0.732, 0.663, 0.638\n",
      "Val loss  0.000512536350812  SSIM  0.977, 0.91, 0.829, 0.777, 0.701, 0.66, 0.633, 0.589\n",
      "Loss  0.000437198979925  SSIM  0.977, 0.912, 0.85, 0.787, 0.76, 0.732, 0.665, 0.638\n",
      "Val loss  0.000502518199268  SSIM  0.978, 0.912, 0.831, 0.778, 0.704, 0.663, 0.636, 0.594\n",
      "saving the model  0.000502518199268\n",
      "Loss  0.000437821325996  SSIM  0.977, 0.912, 0.85, 0.787, 0.76, 0.733, 0.664, 0.639\n",
      "Val loss  0.000510923040856  SSIM  0.976, 0.906, 0.825, 0.769, 0.691, 0.65, 0.621, 0.577\n",
      "Loss  0.000436818136932  SSIM  0.977, 0.912, 0.851, 0.788, 0.76, 0.733, 0.666, 0.639\n",
      "Val loss  0.000503589032276  SSIM  0.977, 0.909, 0.829, 0.773, 0.696, 0.655, 0.627, 0.583\n",
      "Loss  0.000436020593135  SSIM  0.977, 0.913, 0.851, 0.789, 0.761, 0.734, 0.665, 0.639\n",
      "Val loss  0.000503360830364  SSIM  0.977, 0.912, 0.831, 0.778, 0.704, 0.664, 0.636, 0.594\n",
      "Loss  0.000434541508797  SSIM  0.977, 0.913, 0.852, 0.789, 0.761, 0.735, 0.666, 0.639\n",
      "Val loss  0.000503817425517  SSIM  0.977, 0.911, 0.835, 0.782, 0.708, 0.668, 0.641, 0.599\n",
      "Loss  0.000434305079725  SSIM  0.977, 0.914, 0.852, 0.79, 0.762, 0.736, 0.666, 0.64\n",
      "Val loss  0.000503880582866  SSIM  0.977, 0.91, 0.83, 0.776, 0.7, 0.661, 0.634, 0.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000433296232733  SSIM  0.977, 0.914, 0.853, 0.79, 0.762, 0.735, 0.667, 0.641\n",
      "Val loss  0.000497012193198  SSIM  0.977, 0.909, 0.83, 0.774, 0.697, 0.657, 0.628, 0.585\n",
      "saving the model  0.000497012193198\n",
      "Loss  0.000432026448016  SSIM  0.977, 0.914, 0.853, 0.79, 0.762, 0.736, 0.667, 0.642\n",
      "Val loss  0.000505030870496  SSIM  0.978, 0.905, 0.824, 0.767, 0.688, 0.648, 0.619, 0.575\n",
      "Loss  0.000431241515863  SSIM  0.977, 0.915, 0.853, 0.791, 0.762, 0.736, 0.668, 0.642\n",
      "Val loss  0.00050565356639  SSIM  0.977, 0.911, 0.835, 0.781, 0.706, 0.667, 0.639, 0.598\n",
      "Loss  0.000430742102711  SSIM  0.977, 0.914, 0.854, 0.791, 0.763, 0.737, 0.668, 0.642\n",
      "Val loss  0.00049757106381  SSIM  0.978, 0.909, 0.83, 0.774, 0.696, 0.655, 0.627, 0.584\n",
      "Loss  0.000429786194042  SSIM  0.977, 0.915, 0.854, 0.792, 0.763, 0.737, 0.668, 0.643\n",
      "Val loss  0.00050265251071  SSIM  0.978, 0.91, 0.83, 0.774, 0.695, 0.654, 0.625, 0.582\n",
      "Loss  0.00042865015351  SSIM  0.977, 0.915, 0.854, 0.793, 0.763, 0.738, 0.669, 0.643\n",
      "Val loss  0.000501856350456  SSIM  0.978, 0.913, 0.832, 0.777, 0.7, 0.66, 0.632, 0.59\n",
      "Loss  0.000427553460433  SSIM  0.977, 0.916, 0.855, 0.793, 0.764, 0.738, 0.669, 0.644\n",
      "Val loss  0.000496467556339  SSIM  0.978, 0.912, 0.836, 0.781, 0.706, 0.666, 0.638, 0.596\n",
      "saving the model  0.000496467556339\n",
      "Loss  0.000426245188714  SSIM  0.977, 0.916, 0.855, 0.793, 0.764, 0.738, 0.669, 0.644\n",
      "Val loss  0.000497332402563  SSIM  0.978, 0.911, 0.833, 0.777, 0.7, 0.66, 0.631, 0.588\n",
      "Loss  0.000426529557006  SSIM  0.977, 0.916, 0.856, 0.794, 0.764, 0.739, 0.67, 0.644\n",
      "Val loss  0.000497330131126  SSIM  0.979, 0.915, 0.835, 0.778, 0.701, 0.661, 0.632, 0.589\n",
      "Loss  0.00042583800876  SSIM  0.978, 0.916, 0.856, 0.794, 0.764, 0.738, 0.67, 0.646\n",
      "Val loss  0.000513161061972  SSIM  0.979, 0.913, 0.831, 0.774, 0.695, 0.653, 0.623, 0.58\n",
      "Loss  0.00042486394638  SSIM  0.978, 0.917, 0.856, 0.795, 0.765, 0.739, 0.67, 0.645\n",
      "Val loss  0.000495612438128  SSIM  0.979, 0.913, 0.833, 0.776, 0.697, 0.657, 0.628, 0.585\n",
      "saving the model  0.000495612438128\n",
      "Loss  0.000424396156662  SSIM  0.978, 0.917, 0.857, 0.795, 0.765, 0.74, 0.671, 0.646\n",
      "Val loss  0.000495830808359  SSIM  0.977, 0.909, 0.832, 0.774, 0.695, 0.656, 0.627, 0.584\n",
      "Loss  0.000423860861831  SSIM  0.978, 0.917, 0.857, 0.796, 0.765, 0.74, 0.671, 0.646\n",
      "Val loss  0.000500343995518  SSIM  0.979, 0.913, 0.832, 0.775, 0.695, 0.653, 0.623, 0.579\n",
      "Loss  0.000423822494542  SSIM  0.978, 0.917, 0.857, 0.796, 0.766, 0.74, 0.672, 0.647\n",
      "Val loss  0.000497208740679  SSIM  0.978, 0.911, 0.834, 0.778, 0.701, 0.662, 0.633, 0.591\n",
      "Loss  0.00042107284109  SSIM  0.978, 0.918, 0.858, 0.796, 0.766, 0.74, 0.672, 0.646\n",
      "Val loss  0.000496884770866  SSIM  0.979, 0.916, 0.841, 0.786, 0.712, 0.672, 0.642, 0.601\n",
      "Loss  0.000421131289054  SSIM  0.978, 0.918, 0.858, 0.796, 0.766, 0.741, 0.672, 0.648\n",
      "Val loss  0.000492801181099  SSIM  0.978, 0.914, 0.835, 0.778, 0.701, 0.661, 0.633, 0.592\n",
      "saving the model  0.000492801181099\n",
      "Loss  0.000421310783007  SSIM  0.978, 0.918, 0.858, 0.797, 0.767, 0.742, 0.673, 0.649\n",
      "Val loss  0.000495885723329  SSIM  0.979, 0.911, 0.83, 0.773, 0.694, 0.653, 0.624, 0.581\n",
      "Loss  0.000420380903402  SSIM  0.978, 0.918, 0.859, 0.797, 0.767, 0.741, 0.673, 0.649\n",
      "Val loss  0.000492488529708  SSIM  0.979, 0.915, 0.838, 0.784, 0.708, 0.669, 0.641, 0.601\n",
      "saving the model  0.000492488529708\n",
      "Loss  0.000419593410366  SSIM  0.978, 0.919, 0.859, 0.798, 0.767, 0.742, 0.674, 0.649\n",
      "Val loss  0.000500761052012  SSIM  0.979, 0.915, 0.837, 0.78, 0.701, 0.66, 0.63, 0.587\n",
      "Loss  0.000420511396214  SSIM  0.978, 0.919, 0.859, 0.798, 0.768, 0.742, 0.674, 0.649\n",
      "Val loss  0.0004941442298  SSIM  0.978, 0.916, 0.839, 0.783, 0.706, 0.666, 0.637, 0.596\n",
      "Loss  0.000417555208582  SSIM  0.978, 0.919, 0.86, 0.799, 0.768, 0.743, 0.674, 0.649\n",
      "Val loss  0.000493514411442  SSIM  0.979, 0.916, 0.839, 0.783, 0.705, 0.665, 0.636, 0.595\n",
      "Loss  0.000418333747555  SSIM  0.978, 0.919, 0.86, 0.799, 0.768, 0.743, 0.675, 0.65\n",
      "Val loss  0.000492562069558  SSIM  0.979, 0.916, 0.839, 0.783, 0.705, 0.666, 0.638, 0.596\n",
      "Loss  0.000417738673064  SSIM  0.978, 0.92, 0.861, 0.799, 0.768, 0.743, 0.675, 0.65\n",
      "Val loss  0.000499886769219  SSIM  0.978, 0.914, 0.837, 0.78, 0.7, 0.661, 0.633, 0.591\n",
      "Loss  0.000418276525988  SSIM  0.978, 0.92, 0.861, 0.8, 0.769, 0.744, 0.675, 0.65\n",
      "Val loss  0.000493267414568  SSIM  0.979, 0.918, 0.845, 0.79, 0.715, 0.677, 0.649, 0.609\n",
      "Loss  0.000415867059623  SSIM  0.979, 0.92, 0.861, 0.8, 0.769, 0.743, 0.676, 0.651\n",
      "Val loss  0.000491713781958  SSIM  0.979, 0.917, 0.839, 0.781, 0.704, 0.666, 0.637, 0.595\n",
      "saving the model  0.000491713781958\n",
      "Loss  0.000416335673081  SSIM  0.978, 0.92, 0.861, 0.801, 0.769, 0.744, 0.676, 0.652\n",
      "Val loss  0.000499530938338  SSIM  0.979, 0.92, 0.846, 0.789, 0.712, 0.673, 0.644, 0.601\n",
      "Loss  0.000414686655328  SSIM  0.979, 0.921, 0.862, 0.801, 0.769, 0.745, 0.676, 0.652\n",
      "Val loss  0.000507204318186  SSIM  0.979, 0.92, 0.842, 0.785, 0.707, 0.666, 0.637, 0.595\n",
      "Loss  0.000414589576873  SSIM  0.979, 0.921, 0.862, 0.801, 0.77, 0.745, 0.677, 0.652\n",
      "Val loss  0.000492122481985  SSIM  0.979, 0.918, 0.843, 0.786, 0.709, 0.671, 0.642, 0.6\n",
      "Loss  0.000414782852044  SSIM  0.979, 0.921, 0.862, 0.801, 0.77, 0.745, 0.677, 0.653\n",
      "Val loss  0.000491532274813  SSIM  0.979, 0.92, 0.844, 0.787, 0.709, 0.669, 0.641, 0.599\n",
      "saving the model  0.000491532274813\n",
      "Loss  0.000414440126927  SSIM  0.979, 0.921, 0.863, 0.802, 0.77, 0.746, 0.678, 0.652\n",
      "Val loss  0.000505515891942  SSIM  0.977, 0.918, 0.844, 0.789, 0.713, 0.674, 0.647, 0.606\n",
      "Loss  0.000414036318982  SSIM  0.979, 0.922, 0.862, 0.802, 0.771, 0.746, 0.678, 0.653\n",
      "Val loss  0.00048933726683  SSIM  0.98, 0.92, 0.845, 0.791, 0.715, 0.676, 0.648, 0.607\n",
      "saving the model  0.00048933726683\n",
      "Loss  0.000413468868363  SSIM  0.979, 0.922, 0.863, 0.803, 0.77, 0.745, 0.678, 0.654\n",
      "Val loss  0.000490524729481  SSIM  0.979, 0.918, 0.842, 0.785, 0.707, 0.668, 0.639, 0.598\n",
      "Loss  0.000411906330751  SSIM  0.979, 0.921, 0.863, 0.803, 0.771, 0.746, 0.678, 0.654\n",
      "Val loss  0.000490686036646  SSIM  0.979, 0.918, 0.844, 0.787, 0.709, 0.671, 0.642, 0.6\n",
      "Loss  0.000411745262082  SSIM  0.979, 0.922, 0.864, 0.803, 0.771, 0.747, 0.679, 0.654\n",
      "Val loss  0.000495803573867  SSIM  0.98, 0.92, 0.844, 0.789, 0.711, 0.671, 0.642, 0.601\n",
      "Loss  0.00041145863988  SSIM  0.979, 0.922, 0.864, 0.804, 0.771, 0.747, 0.679, 0.654\n",
      "Val loss  0.000497111244535  SSIM  0.979, 0.916, 0.838, 0.78, 0.698, 0.658, 0.629, 0.587\n",
      "Loss  0.000411774651485  SSIM  0.979, 0.922, 0.864, 0.804, 0.772, 0.747, 0.679, 0.655\n",
      "Val loss  0.000496220619127  SSIM  0.979, 0.918, 0.841, 0.785, 0.705, 0.667, 0.637, 0.596\n",
      "Loss  0.000409891162297  SSIM  0.979, 0.923, 0.865, 0.804, 0.772, 0.747, 0.68, 0.656\n",
      "Val loss  0.000487983334751  SSIM  0.979, 0.92, 0.845, 0.791, 0.713, 0.675, 0.647, 0.606\n",
      "saving the model  0.000487983334751\n",
      "Loss  0.000410619170401  SSIM  0.979, 0.923, 0.865, 0.805, 0.772, 0.748, 0.68, 0.655\n",
      "Val loss  0.000489618232183  SSIM  0.98, 0.92, 0.843, 0.787, 0.708, 0.669, 0.639, 0.598\n",
      "Loss  0.000409898906014  SSIM  0.979, 0.923, 0.865, 0.805, 0.773, 0.748, 0.68, 0.656\n",
      "Val loss  0.000486756661907  SSIM  0.979, 0.92, 0.844, 0.789, 0.711, 0.673, 0.644, 0.604\n",
      "saving the model  0.000486756661907\n",
      "Loss  0.000409698062925  SSIM  0.979, 0.923, 0.865, 0.805, 0.773, 0.747, 0.68, 0.656\n",
      "Val loss  0.000497828301508  SSIM  0.98, 0.919, 0.843, 0.786, 0.706, 0.668, 0.638, 0.596\n",
      "Loss  0.000408767620522  SSIM  0.979, 0.923, 0.866, 0.806, 0.773, 0.748, 0.681, 0.657\n",
      "Val loss  0.000489604111121  SSIM  0.98, 0.921, 0.846, 0.79, 0.712, 0.673, 0.643, 0.602\n",
      "Loss  0.000409046190026  SSIM  0.979, 0.923, 0.866, 0.806, 0.773, 0.748, 0.681, 0.657\n",
      "Val loss  0.000501553401584  SSIM  0.979, 0.917, 0.838, 0.777, 0.694, 0.654, 0.622, 0.579\n",
      "Loss  0.000408815156463  SSIM  0.979, 0.924, 0.867, 0.806, 0.774, 0.748, 0.682, 0.657\n",
      "Val loss  0.000491656066268  SSIM  0.979, 0.922, 0.847, 0.792, 0.714, 0.676, 0.647, 0.606\n",
      "Loss  0.000408323981218  SSIM  0.979, 0.924, 0.867, 0.807, 0.774, 0.749, 0.682, 0.658\n",
      "Val loss  0.000491437266755  SSIM  0.98, 0.921, 0.846, 0.79, 0.711, 0.671, 0.641, 0.599\n",
      "Loss  0.000406993253656  SSIM  0.979, 0.924, 0.867, 0.807, 0.775, 0.749, 0.682, 0.657\n",
      "Val loss  0.000485398197314  SSIM  0.98, 0.921, 0.846, 0.791, 0.714, 0.675, 0.646, 0.605\n",
      "saving the model  0.000485398197314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000407725944686  SSIM  0.979, 0.925, 0.868, 0.807, 0.775, 0.75, 0.682, 0.659\n",
      "Val loss  0.000490193436039  SSIM  0.979, 0.918, 0.842, 0.786, 0.707, 0.669, 0.64, 0.599\n",
      "Loss  0.000407548948242  SSIM  0.979, 0.925, 0.868, 0.808, 0.775, 0.75, 0.683, 0.658\n",
      "Val loss  0.000504446831241  SSIM  0.98, 0.922, 0.847, 0.791, 0.712, 0.673, 0.644, 0.603\n",
      "Loss  0.00040537846496  SSIM  0.979, 0.925, 0.868, 0.808, 0.776, 0.751, 0.683, 0.659\n",
      "Val loss  0.000492410199309  SSIM  0.979, 0.917, 0.84, 0.781, 0.699, 0.66, 0.629, 0.587\n",
      "Loss  0.00040653523782  SSIM  0.98, 0.926, 0.869, 0.809, 0.775, 0.751, 0.684, 0.659\n",
      "Val loss  0.000489134092233  SSIM  0.98, 0.922, 0.849, 0.794, 0.716, 0.677, 0.647, 0.606\n",
      "Loss  0.000405886721225  SSIM  0.98, 0.926, 0.869, 0.81, 0.776, 0.752, 0.684, 0.66\n",
      "Val loss  0.000493420627783  SSIM  0.98, 0.922, 0.847, 0.79, 0.709, 0.67, 0.641, 0.598\n",
      "Loss  0.000404845039278  SSIM  0.98, 0.926, 0.87, 0.81, 0.777, 0.752, 0.684, 0.66\n",
      "Val loss  0.000503685448028  SSIM  0.98, 0.922, 0.847, 0.79, 0.71, 0.671, 0.641, 0.6\n",
      "Loss  0.000404044630022  SSIM  0.98, 0.927, 0.87, 0.81, 0.777, 0.752, 0.685, 0.66\n",
      "Val loss  0.000488225493813  SSIM  0.98, 0.92, 0.843, 0.784, 0.702, 0.662, 0.631, 0.589\n",
      "Loss  0.000406034533284  SSIM  0.98, 0.927, 0.871, 0.811, 0.777, 0.752, 0.685, 0.661\n",
      "Val loss  0.000490049146989  SSIM  0.979, 0.919, 0.843, 0.784, 0.703, 0.663, 0.633, 0.59\n",
      "Loss  0.000404194651412  SSIM  0.98, 0.927, 0.87, 0.811, 0.778, 0.753, 0.685, 0.661\n",
      "Val loss  0.00048908633372  SSIM  0.981, 0.923, 0.847, 0.79, 0.71, 0.671, 0.64, 0.598\n",
      "Loss  0.000404336459042  SSIM  0.98, 0.927, 0.871, 0.811, 0.778, 0.753, 0.686, 0.661\n",
      "Val loss  0.000487493311055  SSIM  0.98, 0.925, 0.853, 0.798, 0.722, 0.682, 0.652, 0.611\n",
      "Loss  0.000404059783316  SSIM  0.98, 0.927, 0.871, 0.812, 0.778, 0.753, 0.686, 0.662\n",
      "Val loss  0.000491637381958  SSIM  0.98, 0.924, 0.851, 0.796, 0.718, 0.678, 0.648, 0.606\n",
      "Loss  0.00040378337845  SSIM  0.98, 0.928, 0.872, 0.812, 0.778, 0.754, 0.686, 0.662\n",
      "Val loss  0.000491685042449  SSIM  0.979, 0.924, 0.852, 0.797, 0.722, 0.683, 0.654, 0.613\n",
      "Loss  0.000402459616159  SSIM  0.98, 0.928, 0.872, 0.812, 0.779, 0.754, 0.687, 0.663\n",
      "Val loss  0.000494578498008  SSIM  0.98, 0.925, 0.851, 0.793, 0.714, 0.674, 0.644, 0.602\n",
      "Loss  0.000402581159589  SSIM  0.98, 0.928, 0.872, 0.813, 0.779, 0.755, 0.687, 0.662\n",
      "Val loss  0.000490328469023  SSIM  0.981, 0.924, 0.851, 0.796, 0.717, 0.676, 0.646, 0.605\n",
      "Loss  0.000402468663276  SSIM  0.98, 0.928, 0.873, 0.813, 0.78, 0.755, 0.688, 0.663\n",
      "Val loss  0.000497886080237  SSIM  0.98, 0.922, 0.847, 0.791, 0.712, 0.67, 0.64, 0.598\n",
      "Loss  0.000401928295016  SSIM  0.98, 0.928, 0.873, 0.814, 0.78, 0.755, 0.688, 0.663\n",
      "Val loss  0.000488428698445  SSIM  0.981, 0.926, 0.854, 0.801, 0.725, 0.684, 0.654, 0.612\n",
      "Loss  0.000402430866071  SSIM  0.98, 0.928, 0.873, 0.814, 0.78, 0.755, 0.688, 0.664\n",
      "Val loss  0.000483876948536  SSIM  0.98, 0.924, 0.851, 0.797, 0.72, 0.679, 0.649, 0.609\n",
      "saving the model  0.000483876948536\n",
      "Loss  0.000401606789082  SSIM  0.98, 0.929, 0.874, 0.814, 0.781, 0.755, 0.689, 0.664\n",
      "Val loss  0.000483648260182  SSIM  0.981, 0.926, 0.856, 0.802, 0.725, 0.685, 0.656, 0.615\n",
      "saving the model  0.000483648260182\n",
      "Loss  0.000401231310188  SSIM  0.98, 0.929, 0.874, 0.815, 0.781, 0.755, 0.689, 0.665\n",
      "Val loss  0.000485416020383  SSIM  0.98, 0.927, 0.856, 0.802, 0.724, 0.684, 0.654, 0.612\n",
      "Loss  0.000400093466302  SSIM  0.98, 0.929, 0.874, 0.815, 0.782, 0.756, 0.689, 0.665\n",
      "Val loss  0.000492342610727  SSIM  0.981, 0.928, 0.857, 0.804, 0.728, 0.687, 0.657, 0.617\n",
      "Loss  0.000400941113796  SSIM  0.981, 0.929, 0.875, 0.816, 0.782, 0.757, 0.69, 0.665\n",
      "Val loss  0.00048993054044  SSIM  0.981, 0.927, 0.856, 0.803, 0.726, 0.686, 0.656, 0.616\n",
      "Loss  0.000400238198867  SSIM  0.981, 0.93, 0.875, 0.816, 0.782, 0.757, 0.69, 0.666\n",
      "Val loss  0.000486112703686  SSIM  0.98, 0.927, 0.855, 0.801, 0.723, 0.683, 0.654, 0.613\n",
      "Loss  0.000399754398767  SSIM  0.981, 0.93, 0.875, 0.817, 0.782, 0.757, 0.69, 0.666\n",
      "Val loss  0.000486998081382  SSIM  0.981, 0.927, 0.856, 0.801, 0.724, 0.684, 0.654, 0.613\n",
      "Loss  0.000399334784905  SSIM  0.981, 0.93, 0.876, 0.817, 0.782, 0.757, 0.691, 0.666\n",
      "Val loss  0.000484499497339  SSIM  0.981, 0.927, 0.856, 0.801, 0.723, 0.685, 0.655, 0.614\n",
      "Loss  0.000398694154848  SSIM  0.981, 0.93, 0.876, 0.817, 0.783, 0.758, 0.691, 0.667\n",
      "Val loss  0.000486413836421  SSIM  0.981, 0.927, 0.856, 0.801, 0.722, 0.682, 0.651, 0.609\n",
      "Loss  0.000398846296529  SSIM  0.981, 0.93, 0.876, 0.818, 0.783, 0.758, 0.692, 0.668\n",
      "Val loss  0.000484068144171  SSIM  0.981, 0.927, 0.858, 0.805, 0.729, 0.687, 0.657, 0.617\n",
      "Loss  0.000398908804269  SSIM  0.981, 0.93, 0.877, 0.818, 0.783, 0.759, 0.692, 0.667\n",
      "Val loss  0.000489012424485  SSIM  0.981, 0.927, 0.856, 0.802, 0.725, 0.685, 0.655, 0.615\n",
      "Loss  0.000397591269506  SSIM  0.981, 0.931, 0.877, 0.819, 0.784, 0.759, 0.693, 0.668\n",
      "Val loss  0.000485629755189  SSIM  0.98, 0.928, 0.858, 0.804, 0.726, 0.686, 0.657, 0.616\n",
      "Loss  0.000397887212336  SSIM  0.981, 0.931, 0.877, 0.819, 0.784, 0.759, 0.693, 0.669\n",
      "Val loss  0.000485478157585  SSIM  0.981, 0.928, 0.858, 0.804, 0.727, 0.685, 0.655, 0.614\n",
      "Loss  0.000397066927148  SSIM  0.981, 0.931, 0.878, 0.819, 0.785, 0.76, 0.694, 0.669\n",
      "Val loss  0.000485765164194  SSIM  0.98, 0.926, 0.854, 0.799, 0.72, 0.679, 0.649, 0.607\n",
      "Loss  0.000398435153473  SSIM  0.981, 0.931, 0.878, 0.82, 0.785, 0.76, 0.694, 0.669\n",
      "Val loss  0.000489167845692  SSIM  0.98, 0.924, 0.853, 0.798, 0.718, 0.679, 0.649, 0.608\n",
      "Loss  0.000396965689174  SSIM  0.981, 0.932, 0.878, 0.82, 0.785, 0.761, 0.694, 0.67\n",
      "Val loss  0.000486707610951  SSIM  0.981, 0.928, 0.858, 0.805, 0.727, 0.685, 0.656, 0.615\n",
      "Loss  0.000397396839153  SSIM  0.981, 0.932, 0.878, 0.821, 0.786, 0.761, 0.695, 0.67\n",
      "Val loss  0.000499838208489  SSIM  0.981, 0.929, 0.86, 0.808, 0.73, 0.688, 0.657, 0.616\n",
      "Loss  0.000395660889596  SSIM  0.981, 0.932, 0.879, 0.821, 0.787, 0.761, 0.695, 0.671\n",
      "Val loss  0.000483258395514  SSIM  0.981, 0.929, 0.858, 0.804, 0.726, 0.683, 0.651, 0.609\n",
      "saving the model  0.000483258395514\n",
      "Loss  0.000396882454755  SSIM  0.981, 0.932, 0.88, 0.823, 0.788, 0.763, 0.697, 0.672\n",
      "Val loss  0.000486638629693  SSIM  0.981, 0.931, 0.863, 0.811, 0.734, 0.691, 0.66, 0.617\n",
      "Loss  0.000396526444225  SSIM  0.981, 0.933, 0.881, 0.824, 0.789, 0.764, 0.698, 0.672\n",
      "Val loss  0.000485036386584  SSIM  0.981, 0.93, 0.862, 0.81, 0.734, 0.691, 0.661, 0.62\n",
      "Loss  0.000395948786486  SSIM  0.981, 0.933, 0.881, 0.824, 0.789, 0.764, 0.698, 0.673\n",
      "Val loss  0.000483339524479  SSIM  0.981, 0.929, 0.858, 0.804, 0.725, 0.682, 0.65, 0.608\n",
      "Loss  0.00039570075963  SSIM  0.981, 0.934, 0.882, 0.825, 0.79, 0.765, 0.699, 0.674\n",
      "Val loss  0.000483834184241  SSIM  0.981, 0.928, 0.857, 0.804, 0.726, 0.683, 0.652, 0.609\n",
      "Loss  0.00039605726737  SSIM  0.981, 0.934, 0.882, 0.826, 0.79, 0.765, 0.699, 0.674\n",
      "Val loss  0.000488138847577  SSIM  0.981, 0.929, 0.859, 0.806, 0.727, 0.684, 0.653, 0.61\n",
      "Loss  0.000394750581832  SSIM  0.981, 0.934, 0.882, 0.826, 0.79, 0.765, 0.7, 0.675\n",
      "Val loss  0.000493534543435  SSIM  0.981, 0.929, 0.858, 0.804, 0.725, 0.68, 0.649, 0.606\n",
      "Loss  0.000395605282139  SSIM  0.981, 0.934, 0.883, 0.827, 0.791, 0.766, 0.701, 0.676\n",
      "Val loss  0.000484340897587  SSIM  0.981, 0.93, 0.862, 0.81, 0.733, 0.691, 0.661, 0.619\n",
      "Loss  0.000395172832658  SSIM  0.981, 0.934, 0.883, 0.827, 0.792, 0.767, 0.701, 0.676\n",
      "Val loss  0.000482397264161  SSIM  0.981, 0.929, 0.86, 0.808, 0.732, 0.688, 0.656, 0.613\n",
      "saving the model  0.000482397264161\n",
      "Loss  0.000395058011174  SSIM  0.981, 0.935, 0.884, 0.828, 0.792, 0.767, 0.702, 0.677\n",
      "Val loss  0.000494431019877  SSIM  0.981, 0.933, 0.867, 0.817, 0.743, 0.699, 0.669, 0.628\n",
      "Loss  0.000394105354546  SSIM  0.981, 0.935, 0.884, 0.828, 0.792, 0.768, 0.702, 0.677\n",
      "Val loss  0.000484197269543  SSIM  0.981, 0.93, 0.862, 0.809, 0.732, 0.69, 0.659, 0.618\n",
      "Loss  0.000394558095001  SSIM  0.981, 0.935, 0.885, 0.829, 0.793, 0.768, 0.703, 0.678\n",
      "Val loss  0.000484204454813  SSIM  0.981, 0.932, 0.865, 0.815, 0.741, 0.698, 0.667, 0.626\n",
      "Loss  0.000393764333803  SSIM  0.981, 0.936, 0.885, 0.83, 0.794, 0.769, 0.704, 0.679\n",
      "Val loss  0.000483637317957  SSIM  0.982, 0.932, 0.864, 0.812, 0.735, 0.691, 0.659, 0.616\n",
      "Loss  0.000393490191609  SSIM  0.981, 0.936, 0.885, 0.83, 0.795, 0.77, 0.704, 0.679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000482963435526  SSIM  0.981, 0.932, 0.863, 0.81, 0.733, 0.69, 0.658, 0.615\n",
      "Loss  0.000393424693439  SSIM  0.981, 0.936, 0.886, 0.831, 0.795, 0.77, 0.705, 0.68\n",
      "Val loss  0.000482140164415  SSIM  0.981, 0.932, 0.864, 0.812, 0.736, 0.691, 0.659, 0.617\n",
      "saving the model  0.000482140164415\n",
      "Loss  0.000392950549077  SSIM  0.981, 0.936, 0.886, 0.831, 0.795, 0.771, 0.706, 0.681\n",
      "Val loss  0.000482876322174  SSIM  0.982, 0.932, 0.862, 0.809, 0.73, 0.687, 0.657, 0.614\n",
      "Loss  0.0003927607954  SSIM  0.982, 0.937, 0.887, 0.832, 0.796, 0.772, 0.706, 0.681\n",
      "Val loss  0.000484145652677  SSIM  0.982, 0.934, 0.867, 0.816, 0.741, 0.697, 0.666, 0.624\n",
      "Loss  0.000393214046763  SSIM  0.981, 0.937, 0.887, 0.833, 0.796, 0.772, 0.707, 0.682\n",
      "Val loss  0.000484318568604  SSIM  0.981, 0.932, 0.865, 0.813, 0.737, 0.695, 0.665, 0.622\n",
      "Loss  0.000392423102179  SSIM  0.982, 0.937, 0.888, 0.834, 0.797, 0.773, 0.708, 0.683\n",
      "Val loss  0.000481458971393  SSIM  0.982, 0.934, 0.868, 0.819, 0.745, 0.7, 0.669, 0.626\n",
      "saving the model  0.000481458971393\n",
      "Loss  0.000392071722548  SSIM  0.982, 0.937, 0.888, 0.834, 0.798, 0.774, 0.708, 0.683\n",
      "Val loss  0.00049085375946  SSIM  0.981, 0.933, 0.865, 0.814, 0.738, 0.694, 0.664, 0.621\n",
      "Loss  0.000392502885534  SSIM  0.982, 0.938, 0.889, 0.834, 0.799, 0.774, 0.709, 0.684\n",
      "Val loss  0.000483532680315  SSIM  0.982, 0.933, 0.867, 0.817, 0.741, 0.698, 0.668, 0.626\n",
      "Loss  0.000391891953722  SSIM  0.982, 0.938, 0.889, 0.835, 0.799, 0.775, 0.71, 0.685\n",
      "Val loss  0.000482869625674  SSIM  0.981, 0.934, 0.868, 0.817, 0.742, 0.699, 0.669, 0.626\n",
      "Loss  0.000391434482373  SSIM  0.982, 0.938, 0.889, 0.836, 0.799, 0.776, 0.71, 0.686\n",
      "Val loss  0.000486769636045  SSIM  0.982, 0.933, 0.868, 0.817, 0.741, 0.698, 0.666, 0.623\n",
      "Loss  0.000391206346278  SSIM  0.982, 0.939, 0.89, 0.837, 0.8, 0.776, 0.711, 0.686\n",
      "Val loss  0.000485596552899  SSIM  0.982, 0.936, 0.872, 0.823, 0.75, 0.704, 0.672, 0.629\n",
      "Loss  0.000391107255369  SSIM  0.982, 0.939, 0.89, 0.837, 0.801, 0.776, 0.712, 0.687\n",
      "Val loss  0.000481004187546  SSIM  0.982, 0.935, 0.87, 0.819, 0.745, 0.701, 0.67, 0.628\n",
      "saving the model  0.000481004187546\n",
      "Loss  0.000391165282964  SSIM  0.982, 0.939, 0.891, 0.838, 0.801, 0.777, 0.712, 0.688\n",
      "Val loss  0.000480703897309  SSIM  0.982, 0.935, 0.871, 0.822, 0.749, 0.704, 0.673, 0.631\n",
      "saving the model  0.000480703897309\n",
      "Loss  0.000391578040891  SSIM  0.982, 0.939, 0.891, 0.839, 0.802, 0.778, 0.713, 0.689\n",
      "Val loss  0.00049351742951  SSIM  0.982, 0.932, 0.865, 0.814, 0.737, 0.692, 0.66, 0.615\n",
      "Loss  0.000389547707796  SSIM  0.982, 0.94, 0.892, 0.839, 0.803, 0.779, 0.714, 0.69\n",
      "Val loss  0.000485621549655  SSIM  0.982, 0.937, 0.874, 0.825, 0.753, 0.71, 0.679, 0.638\n",
      "Loss  0.000390733208697  SSIM  0.982, 0.94, 0.892, 0.84, 0.803, 0.779, 0.715, 0.69\n",
      "Val loss  0.000481462299882  SSIM  0.982, 0.935, 0.872, 0.823, 0.75, 0.707, 0.676, 0.634\n",
      "Loss  0.000389907058302  SSIM  0.982, 0.94, 0.892, 0.841, 0.804, 0.78, 0.716, 0.691\n",
      "Val loss  0.000483152278408  SSIM  0.982, 0.937, 0.874, 0.825, 0.754, 0.708, 0.676, 0.633\n",
      "Loss  0.000389857062003  SSIM  0.982, 0.94, 0.893, 0.841, 0.805, 0.781, 0.716, 0.691\n",
      "Val loss  0.000484617173963  SSIM  0.982, 0.937, 0.875, 0.827, 0.756, 0.712, 0.68, 0.639\n",
      "Loss  0.000389613486188  SSIM  0.982, 0.941, 0.894, 0.842, 0.806, 0.782, 0.718, 0.693\n",
      "Val loss  0.000491279933951  SSIM  0.982, 0.937, 0.876, 0.826, 0.755, 0.708, 0.674, 0.629\n",
      "Loss  0.000389046907692  SSIM  0.982, 0.941, 0.895, 0.843, 0.807, 0.783, 0.719, 0.693\n",
      "Val loss  0.000482280641794  SSIM  0.982, 0.936, 0.873, 0.824, 0.753, 0.707, 0.675, 0.632\n",
      "Loss  0.000388424196555  SSIM  0.982, 0.942, 0.895, 0.844, 0.808, 0.784, 0.72, 0.695\n",
      "Val loss  0.000481830990466  SSIM  0.982, 0.939, 0.878, 0.83, 0.76, 0.715, 0.683, 0.64\n",
      "Loss  0.000390023437209  SSIM  0.982, 0.942, 0.896, 0.845, 0.809, 0.785, 0.72, 0.695\n",
      "Val loss  0.00048656907375  SSIM  0.982, 0.939, 0.88, 0.833, 0.766, 0.722, 0.691, 0.65\n",
      "Loss  0.000389109240694  SSIM  0.982, 0.942, 0.896, 0.845, 0.809, 0.785, 0.722, 0.696\n",
      "Val loss  0.000481385295046  SSIM  0.982, 0.939, 0.877, 0.828, 0.758, 0.713, 0.681, 0.637\n",
      "Loss  0.000388581567907  SSIM  0.982, 0.942, 0.897, 0.846, 0.81, 0.785, 0.722, 0.697\n",
      "Val loss  0.000481357466255  SSIM  0.982, 0.939, 0.88, 0.832, 0.764, 0.718, 0.686, 0.643\n",
      "Loss  0.000387670327598  SSIM  0.982, 0.943, 0.897, 0.847, 0.811, 0.786, 0.723, 0.698\n",
      "Val loss  0.00048126634612  SSIM  0.983, 0.94, 0.881, 0.834, 0.765, 0.718, 0.685, 0.641\n",
      "Loss  0.000388710754876  SSIM  0.982, 0.943, 0.897, 0.847, 0.811, 0.787, 0.724, 0.699\n",
      "Val loss  0.000484277681739  SSIM  0.982, 0.939, 0.88, 0.832, 0.764, 0.72, 0.688, 0.645\n",
      "Loss  0.000387961516311  SSIM  0.982, 0.943, 0.898, 0.849, 0.812, 0.787, 0.725, 0.699\n",
      "Val loss  0.000481437130016  SSIM  0.983, 0.94, 0.882, 0.835, 0.768, 0.722, 0.69, 0.647\n",
      "Loss  0.000387866234844  SSIM  0.982, 0.944, 0.898, 0.849, 0.812, 0.788, 0.726, 0.7\n",
      "Val loss  0.000479117526149  SSIM  0.982, 0.941, 0.884, 0.836, 0.769, 0.724, 0.691, 0.649\n",
      "saving the model  0.000479117526149\n",
      "Loss  0.00038729944621  SSIM  0.982, 0.944, 0.899, 0.85, 0.813, 0.789, 0.726, 0.701\n",
      "Val loss  0.000481577622297  SSIM  0.982, 0.942, 0.884, 0.837, 0.77, 0.725, 0.693, 0.65\n",
      "Loss  0.000387660733412  SSIM  0.982, 0.944, 0.899, 0.851, 0.814, 0.79, 0.727, 0.702\n",
      "Val loss  0.000479570109979  SSIM  0.983, 0.941, 0.882, 0.834, 0.767, 0.72, 0.687, 0.644\n",
      "Loss  0.000387237045107  SSIM  0.982, 0.945, 0.9, 0.851, 0.815, 0.791, 0.728, 0.703\n",
      "Val loss  0.000480826418789  SSIM  0.982, 0.941, 0.883, 0.835, 0.768, 0.723, 0.691, 0.647\n",
      "Loss  0.000387528077046  SSIM  0.982, 0.945, 0.9, 0.851, 0.815, 0.791, 0.729, 0.704\n",
      "Val loss  0.00048082974006  SSIM  0.983, 0.941, 0.883, 0.835, 0.768, 0.721, 0.687, 0.642\n",
      "Loss  0.000386562265372  SSIM  0.982, 0.945, 0.901, 0.852, 0.816, 0.792, 0.729, 0.705\n",
      "Val loss  0.00048076841596  SSIM  0.982, 0.942, 0.885, 0.838, 0.773, 0.727, 0.694, 0.651\n",
      "Loss  0.000387140067846  SSIM  0.982, 0.945, 0.901, 0.853, 0.816, 0.792, 0.73, 0.705\n",
      "Val loss  0.000480966185103  SSIM  0.982, 0.942, 0.886, 0.84, 0.776, 0.73, 0.698, 0.655\n",
      "Loss  0.000386708397734  SSIM  0.983, 0.945, 0.901, 0.853, 0.817, 0.793, 0.73, 0.705\n",
      "Val loss  0.000477381603094  SSIM  0.983, 0.943, 0.886, 0.839, 0.774, 0.728, 0.694, 0.651\n",
      "saving the model  0.000477381603094\n",
      "Loss  0.000385975090703  SSIM  0.982, 0.945, 0.902, 0.853, 0.817, 0.793, 0.731, 0.706\n",
      "Val loss  0.000480696338753  SSIM  0.982, 0.94, 0.882, 0.832, 0.763, 0.716, 0.682, 0.636\n",
      "Loss  0.000385659215323  SSIM  0.983, 0.946, 0.902, 0.854, 0.818, 0.794, 0.732, 0.707\n",
      "Val loss  0.000478374969796  SSIM  0.983, 0.943, 0.887, 0.84, 0.776, 0.731, 0.698, 0.656\n",
      "Loss  0.000386995096385  SSIM  0.983, 0.946, 0.902, 0.854, 0.818, 0.794, 0.733, 0.707\n",
      "Val loss  0.000480643393064  SSIM  0.983, 0.941, 0.884, 0.836, 0.77, 0.722, 0.687, 0.641\n",
      "Loss  0.000385352163386  SSIM  0.983, 0.946, 0.903, 0.855, 0.819, 0.794, 0.733, 0.708\n",
      "Val loss  0.000479253382771  SSIM  0.983, 0.942, 0.887, 0.84, 0.776, 0.729, 0.696, 0.653\n",
      "Loss  0.000385726670461  SSIM  0.983, 0.946, 0.903, 0.855, 0.819, 0.795, 0.733, 0.708\n",
      "Val loss  0.000486685756769  SSIM  0.982, 0.942, 0.887, 0.839, 0.772, 0.724, 0.688, 0.642\n",
      "Loss  0.000386241141409  SSIM  0.983, 0.946, 0.903, 0.856, 0.82, 0.795, 0.734, 0.708\n",
      "Val loss  0.000480726228387  SSIM  0.983, 0.942, 0.887, 0.839, 0.774, 0.728, 0.695, 0.65\n",
      "Loss  0.000385174096211  SSIM  0.983, 0.947, 0.903, 0.856, 0.82, 0.796, 0.735, 0.709\n",
      "Val loss  0.000478970065597  SSIM  0.983, 0.943, 0.887, 0.84, 0.776, 0.728, 0.694, 0.649\n",
      "Loss  0.00038460422068  SSIM  0.983, 0.946, 0.904, 0.856, 0.82, 0.796, 0.735, 0.71\n",
      "Val loss  0.000481834138802  SSIM  0.982, 0.942, 0.887, 0.839, 0.774, 0.727, 0.693, 0.649\n",
      "Loss  0.000385049500176  SSIM  0.983, 0.947, 0.904, 0.857, 0.821, 0.797, 0.735, 0.71\n",
      "Val loss  0.000479853230412  SSIM  0.983, 0.942, 0.887, 0.841, 0.776, 0.73, 0.696, 0.652\n",
      "Loss  0.000384716006048  SSIM  0.983, 0.947, 0.904, 0.857, 0.821, 0.797, 0.736, 0.71\n",
      "Val loss  0.000478146581969  SSIM  0.982, 0.943, 0.889, 0.842, 0.777, 0.732, 0.698, 0.654\n",
      "Loss  0.000384663157251  SSIM  0.983, 0.947, 0.904, 0.858, 0.821, 0.797, 0.736, 0.71\n",
      "Val loss  0.000487215883739  SSIM  0.983, 0.943, 0.888, 0.843, 0.78, 0.734, 0.7, 0.657\n",
      "Loss  0.000384161025428  SSIM  0.983, 0.947, 0.904, 0.858, 0.822, 0.798, 0.737, 0.711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000483178589086  SSIM  0.983, 0.942, 0.887, 0.841, 0.776, 0.729, 0.695, 0.652\n",
      "Loss  0.000384889146188  SSIM  0.983, 0.947, 0.905, 0.858, 0.822, 0.798, 0.737, 0.711\n",
      "Val loss  0.000477750684659  SSIM  0.983, 0.944, 0.891, 0.846, 0.784, 0.737, 0.703, 0.659\n",
      "Loss  0.000385066080942  SSIM  0.983, 0.947, 0.905, 0.858, 0.822, 0.798, 0.737, 0.711\n",
      "Val loss  0.000478176252218  SSIM  0.982, 0.944, 0.89, 0.845, 0.782, 0.735, 0.7, 0.656\n",
      "Loss  0.000384193675936  SSIM  0.983, 0.947, 0.905, 0.859, 0.823, 0.798, 0.738, 0.712\n",
      "Val loss  0.00048993863049  SSIM  0.982, 0.943, 0.89, 0.844, 0.78, 0.734, 0.699, 0.654\n",
      "Loss  0.000383279732568  SSIM  0.983, 0.947, 0.905, 0.859, 0.823, 0.799, 0.738, 0.713\n",
      "Val loss  0.000480439016013  SSIM  0.982, 0.942, 0.887, 0.84, 0.774, 0.727, 0.692, 0.647\n",
      "Loss  0.000383832364749  SSIM  0.983, 0.948, 0.905, 0.859, 0.823, 0.799, 0.738, 0.713\n",
      "Val loss  0.000482546288578  SSIM  0.983, 0.943, 0.889, 0.842, 0.778, 0.732, 0.698, 0.653\n",
      "Loss  0.000383657162388  SSIM  0.983, 0.948, 0.905, 0.859, 0.823, 0.799, 0.739, 0.713\n",
      "Val loss  0.000479489806457  SSIM  0.983, 0.944, 0.891, 0.845, 0.783, 0.736, 0.7, 0.656\n",
      "Loss  0.000383365841393  SSIM  0.983, 0.948, 0.906, 0.86, 0.823, 0.8, 0.739, 0.714\n",
      "Val loss  0.000480567666935  SSIM  0.983, 0.944, 0.89, 0.844, 0.781, 0.733, 0.697, 0.651\n",
      "Loss  0.000382994760106  SSIM  0.983, 0.948, 0.906, 0.86, 0.823, 0.8, 0.739, 0.713\n",
      "Val loss  0.000480011554959  SSIM  0.983, 0.943, 0.888, 0.842, 0.778, 0.732, 0.697, 0.653\n",
      "Loss  0.000383098129371  SSIM  0.983, 0.948, 0.906, 0.86, 0.824, 0.8, 0.739, 0.714\n",
      "Val loss  0.000480450813484  SSIM  0.983, 0.944, 0.891, 0.846, 0.784, 0.737, 0.701, 0.656\n",
      "Loss  0.000383186134765  SSIM  0.983, 0.948, 0.906, 0.86, 0.824, 0.8, 0.739, 0.714\n",
      "Val loss  0.000476702746644  SSIM  0.983, 0.945, 0.893, 0.849, 0.788, 0.742, 0.708, 0.665\n",
      "saving the model  0.000476702746644\n",
      "Loss  0.000383109575778  SSIM  0.983, 0.948, 0.906, 0.861, 0.824, 0.8, 0.74, 0.714\n",
      "Val loss  0.000483364689397  SSIM  0.983, 0.944, 0.893, 0.848, 0.787, 0.74, 0.703, 0.659\n",
      "Loss  0.000382534158066  SSIM  0.983, 0.948, 0.906, 0.861, 0.824, 0.8, 0.74, 0.715\n",
      "Val loss  0.000479253480793  SSIM  0.983, 0.944, 0.891, 0.845, 0.782, 0.736, 0.701, 0.657\n",
      "Loss  0.000383180130866  SSIM  0.983, 0.948, 0.906, 0.861, 0.824, 0.801, 0.74, 0.715\n",
      "Val loss  0.000476194262621  SSIM  0.983, 0.945, 0.893, 0.848, 0.787, 0.74, 0.705, 0.662\n",
      "saving the model  0.000476194262621\n",
      "Loss  0.000382077271422  SSIM  0.983, 0.948, 0.907, 0.861, 0.825, 0.801, 0.741, 0.715\n",
      "Val loss  0.000481135774986  SSIM  0.983, 0.945, 0.894, 0.85, 0.79, 0.743, 0.708, 0.665\n",
      "Loss  0.000382113977256  SSIM  0.983, 0.948, 0.907, 0.861, 0.825, 0.801, 0.741, 0.715\n",
      "Val loss  0.000477015930053  SSIM  0.983, 0.944, 0.892, 0.846, 0.784, 0.737, 0.702, 0.657\n",
      "Loss  0.000382229989944  SSIM  0.983, 0.948, 0.907, 0.861, 0.825, 0.801, 0.741, 0.716\n",
      "Val loss  0.000481985271384  SSIM  0.983, 0.944, 0.892, 0.847, 0.785, 0.737, 0.702, 0.658\n",
      "Loss  0.00038195163037  SSIM  0.983, 0.948, 0.907, 0.862, 0.825, 0.801, 0.741, 0.716\n",
      "Val loss  0.000476506652485  SSIM  0.983, 0.944, 0.891, 0.846, 0.784, 0.737, 0.702, 0.658\n",
      "Loss  0.000382261651798  SSIM  0.983, 0.948, 0.907, 0.862, 0.825, 0.802, 0.741, 0.716\n",
      "Val loss  0.000483447780367  SSIM  0.983, 0.944, 0.892, 0.848, 0.788, 0.741, 0.706, 0.662\n",
      "Loss  0.000381520125218  SSIM  0.983, 0.948, 0.907, 0.862, 0.825, 0.802, 0.742, 0.716\n",
      "Val loss  0.00048174131976  SSIM  0.983, 0.944, 0.89, 0.844, 0.781, 0.734, 0.698, 0.652\n",
      "Loss  0.00038188581584  SSIM  0.983, 0.949, 0.907, 0.862, 0.825, 0.802, 0.742, 0.717\n",
      "Val loss  0.000477542610548  SSIM  0.983, 0.945, 0.893, 0.848, 0.787, 0.74, 0.705, 0.662\n",
      "Loss  0.000381737319564  SSIM  0.983, 0.948, 0.907, 0.862, 0.826, 0.803, 0.742, 0.717\n",
      "Val loss  0.000477260884189  SSIM  0.983, 0.945, 0.895, 0.851, 0.791, 0.745, 0.71, 0.668\n",
      "Loss  0.000381859098385  SSIM  0.983, 0.949, 0.907, 0.862, 0.826, 0.802, 0.742, 0.717\n",
      "Val loss  0.000475071093359  SSIM  0.983, 0.945, 0.894, 0.85, 0.79, 0.743, 0.709, 0.666\n",
      "saving the model  0.000475071093359\n",
      "Loss  0.000381238653633  SSIM  0.983, 0.949, 0.907, 0.862, 0.826, 0.803, 0.743, 0.717\n",
      "Val loss  0.00047910827148  SSIM  0.983, 0.944, 0.893, 0.847, 0.786, 0.738, 0.701, 0.655\n",
      "Loss  0.000381118935949  SSIM  0.983, 0.949, 0.908, 0.862, 0.826, 0.803, 0.743, 0.717\n",
      "Val loss  0.000475490322802  SSIM  0.983, 0.945, 0.893, 0.85, 0.789, 0.743, 0.708, 0.665\n",
      "Loss  0.000381233845851  SSIM  0.983, 0.949, 0.908, 0.863, 0.826, 0.803, 0.743, 0.717\n",
      "Val loss  0.000480089701945  SSIM  0.983, 0.945, 0.894, 0.849, 0.788, 0.743, 0.708, 0.664\n",
      "Loss  0.000381350322425  SSIM  0.983, 0.949, 0.908, 0.863, 0.827, 0.803, 0.743, 0.717\n",
      "Val loss  0.000498480266891  SSIM  0.983, 0.946, 0.895, 0.851, 0.793, 0.748, 0.714, 0.673\n",
      "Loss  0.000380990212936  SSIM  0.983, 0.949, 0.908, 0.863, 0.827, 0.803, 0.743, 0.718\n",
      "Val loss  0.00047717044095  SSIM  0.983, 0.945, 0.893, 0.848, 0.787, 0.74, 0.705, 0.66\n",
      "Loss  0.000380740367967  SSIM  0.983, 0.949, 0.908, 0.863, 0.827, 0.803, 0.743, 0.718\n",
      "Val loss  0.000487580631219  SSIM  0.983, 0.944, 0.892, 0.846, 0.782, 0.734, 0.698, 0.651\n",
      "Loss  0.000381733157047  SSIM  0.983, 0.949, 0.908, 0.863, 0.827, 0.803, 0.743, 0.718\n",
      "Val loss  0.000478045201336  SSIM  0.983, 0.944, 0.891, 0.845, 0.783, 0.736, 0.7, 0.656\n",
      "Loss  0.00038026617732  SSIM  0.983, 0.949, 0.908, 0.863, 0.827, 0.804, 0.743, 0.719\n",
      "Val loss  0.000476452867209  SSIM  0.983, 0.945, 0.894, 0.85, 0.788, 0.742, 0.707, 0.663\n",
      "Loss  0.00038130029294  SSIM  0.983, 0.949, 0.908, 0.864, 0.827, 0.804, 0.743, 0.719\n",
      "Val loss  0.000476393578283  SSIM  0.983, 0.945, 0.893, 0.849, 0.788, 0.742, 0.707, 0.663\n",
      "Loss  0.000380070072297  SSIM  0.983, 0.949, 0.908, 0.863, 0.827, 0.804, 0.744, 0.719\n",
      "Val loss  0.000477640169323  SSIM  0.983, 0.945, 0.894, 0.85, 0.789, 0.742, 0.706, 0.662\n",
      "Loss  0.000381159940133  SSIM  0.983, 0.949, 0.908, 0.864, 0.827, 0.804, 0.744, 0.719\n",
      "Val loss  0.000484728147392  SSIM  0.983, 0.944, 0.891, 0.846, 0.784, 0.737, 0.701, 0.657\n",
      "Loss  0.00038034755216  SSIM  0.983, 0.949, 0.908, 0.864, 0.827, 0.804, 0.744, 0.719\n",
      "Val loss  0.000476151069102  SSIM  0.983, 0.945, 0.894, 0.85, 0.789, 0.741, 0.706, 0.661\n",
      "Loss  0.000379546784665  SSIM  0.983, 0.949, 0.908, 0.864, 0.827, 0.805, 0.744, 0.719\n",
      "Val loss  0.000475543878565  SSIM  0.983, 0.946, 0.895, 0.851, 0.791, 0.745, 0.709, 0.666\n",
      "Loss  0.000380290103344  SSIM  0.983, 0.949, 0.908, 0.864, 0.827, 0.804, 0.744, 0.72\n",
      "Val loss  0.000480387419753  SSIM  0.983, 0.945, 0.895, 0.85, 0.789, 0.742, 0.706, 0.662\n",
      "Loss  0.000380682004686  SSIM  0.983, 0.949, 0.908, 0.864, 0.827, 0.805, 0.744, 0.719\n",
      "Val loss  0.000475747305667  SSIM  0.983, 0.945, 0.895, 0.851, 0.791, 0.746, 0.711, 0.668\n",
      "Loss  0.000379379952007  SSIM  0.983, 0.949, 0.908, 0.864, 0.828, 0.805, 0.745, 0.72\n",
      "Val loss  0.000476116486301  SSIM  0.983, 0.945, 0.894, 0.85, 0.789, 0.743, 0.708, 0.664\n",
      "Loss  0.000380469038767  SSIM  0.983, 0.949, 0.908, 0.864, 0.828, 0.805, 0.745, 0.72\n",
      "Val loss  0.000479835477541  SSIM  0.983, 0.945, 0.894, 0.849, 0.788, 0.741, 0.705, 0.661\n",
      "Loss  0.000379820693174  SSIM  0.983, 0.949, 0.908, 0.864, 0.828, 0.805, 0.745, 0.72\n",
      "Val loss  0.000477861616877  SSIM  0.983, 0.945, 0.893, 0.847, 0.785, 0.738, 0.702, 0.657\n",
      "Loss  0.000379034888322  SSIM  0.983, 0.949, 0.908, 0.864, 0.828, 0.805, 0.745, 0.72\n",
      "Val loss  0.000474929190241  SSIM  0.983, 0.945, 0.894, 0.85, 0.79, 0.743, 0.708, 0.664\n",
      "saving the model  0.000474929190241\n",
      "Loss  0.0003794787534  SSIM  0.983, 0.949, 0.909, 0.865, 0.828, 0.805, 0.745, 0.721\n",
      "Val loss  0.000474647834373  SSIM  0.983, 0.945, 0.894, 0.85, 0.79, 0.743, 0.708, 0.664\n",
      "saving the model  0.000474647834373\n",
      "Loss  0.000379894509321  SSIM  0.983, 0.949, 0.909, 0.865, 0.828, 0.805, 0.745, 0.721\n",
      "Val loss  0.000479279197985  SSIM  0.983, 0.946, 0.896, 0.851, 0.792, 0.747, 0.713, 0.67\n",
      "Loss  0.000378938012094  SSIM  0.983, 0.949, 0.909, 0.865, 0.828, 0.806, 0.746, 0.721\n",
      "Val loss  0.000483842335176  SSIM  0.983, 0.946, 0.897, 0.853, 0.793, 0.747, 0.712, 0.669\n",
      "Loss  0.000379157781483  SSIM  0.983, 0.949, 0.909, 0.865, 0.828, 0.806, 0.745, 0.721\n",
      "Val loss  0.000476463073457  SSIM  0.983, 0.945, 0.895, 0.852, 0.791, 0.746, 0.711, 0.668\n",
      "Loss  0.000378795115815  SSIM  0.983, 0.949, 0.909, 0.865, 0.828, 0.806, 0.746, 0.722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000476925356081  SSIM  0.983, 0.946, 0.896, 0.852, 0.793, 0.747, 0.712, 0.669\n",
      "Loss  0.000379297681521  SSIM  0.983, 0.949, 0.909, 0.865, 0.828, 0.806, 0.746, 0.722\n",
      "Val loss  0.000475178795401  SSIM  0.983, 0.945, 0.894, 0.849, 0.788, 0.741, 0.704, 0.66\n",
      "Loss  0.000378854845938  SSIM  0.983, 0.949, 0.909, 0.865, 0.829, 0.806, 0.746, 0.722\n",
      "Val loss  0.00047719523398  SSIM  0.983, 0.946, 0.896, 0.852, 0.793, 0.747, 0.711, 0.669\n",
      "Loss  0.000379027945398  SSIM  0.983, 0.95, 0.909, 0.865, 0.829, 0.807, 0.746, 0.722\n",
      "Val loss  0.000476945031318  SSIM  0.983, 0.946, 0.896, 0.852, 0.792, 0.745, 0.708, 0.664\n",
      "Loss  0.000378382762829  SSIM  0.983, 0.95, 0.909, 0.866, 0.829, 0.807, 0.747, 0.722\n",
      "Val loss  0.000474417398567  SSIM  0.983, 0.946, 0.895, 0.851, 0.791, 0.743, 0.707, 0.662\n",
      "saving the model  0.000474417398567\n",
      "Loss  0.000378950297993  SSIM  0.983, 0.95, 0.909, 0.865, 0.829, 0.807, 0.746, 0.723\n",
      "Val loss  0.00047519569943  SSIM  0.983, 0.946, 0.896, 0.852, 0.792, 0.746, 0.71, 0.668\n",
      "Loss  0.000378318592665  SSIM  0.983, 0.95, 0.909, 0.866, 0.829, 0.807, 0.746, 0.723\n",
      "Val loss  0.000477026809938  SSIM  0.983, 0.946, 0.896, 0.851, 0.792, 0.746, 0.71, 0.667\n",
      "Loss  0.000378563221683  SSIM  0.983, 0.95, 0.909, 0.866, 0.829, 0.807, 0.747, 0.723\n",
      "Val loss  0.000477593079209  SSIM  0.983, 0.946, 0.896, 0.851, 0.791, 0.744, 0.707, 0.662\n",
      "Loss  0.000378076115716  SSIM  0.983, 0.95, 0.909, 0.866, 0.829, 0.807, 0.747, 0.724\n",
      "Val loss  0.000476976265432  SSIM  0.984, 0.946, 0.896, 0.852, 0.793, 0.747, 0.711, 0.667\n",
      "Loss  0.000378164195437  SSIM  0.983, 0.95, 0.909, 0.866, 0.829, 0.807, 0.747, 0.724\n",
      "Val loss  0.000478274451685  SSIM  0.983, 0.946, 0.896, 0.852, 0.793, 0.747, 0.711, 0.668\n",
      "Loss  0.000377837280228  SSIM  0.983, 0.95, 0.909, 0.866, 0.83, 0.807, 0.747, 0.724\n",
      "Val loss  0.000478428919683  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.75, 0.714, 0.672\n",
      "Loss  0.000378109655366  SSIM  0.983, 0.95, 0.909, 0.866, 0.83, 0.807, 0.748, 0.724\n",
      "Val loss  0.000478133430297  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.751, 0.716, 0.674\n",
      "Loss  0.000378093945571  SSIM  0.983, 0.95, 0.909, 0.866, 0.83, 0.807, 0.748, 0.724\n",
      "Val loss  0.000474882508337  SSIM  0.984, 0.946, 0.896, 0.851, 0.791, 0.745, 0.709, 0.665\n",
      "Loss  0.000377220860038  SSIM  0.983, 0.95, 0.909, 0.866, 0.829, 0.808, 0.748, 0.725\n",
      "Val loss  0.000476817916206  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.751, 0.716, 0.675\n",
      "Loss  0.000377915950418  SSIM  0.983, 0.95, 0.91, 0.866, 0.83, 0.807, 0.748, 0.725\n",
      "Val loss  0.000476698489219  SSIM  0.983, 0.946, 0.896, 0.851, 0.791, 0.745, 0.708, 0.664\n",
      "Loss  0.000377908306419  SSIM  0.983, 0.95, 0.91, 0.866, 0.83, 0.808, 0.748, 0.725\n",
      "Val loss  0.000475442182273  SSIM  0.983, 0.946, 0.897, 0.852, 0.791, 0.745, 0.709, 0.666\n",
      "Loss  0.000377706881922  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.808, 0.748, 0.725\n",
      "Val loss  0.00047727603931  SSIM  0.983, 0.946, 0.897, 0.853, 0.793, 0.747, 0.711, 0.668\n",
      "Loss  0.000377546691164  SSIM  0.983, 0.95, 0.91, 0.866, 0.83, 0.808, 0.749, 0.725\n",
      "Val loss  0.000478118560161  SSIM  0.983, 0.945, 0.896, 0.852, 0.792, 0.746, 0.71, 0.666\n",
      "Loss  0.000377121011921  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.808, 0.749, 0.726\n",
      "Val loss  0.000478158487938  SSIM  0.983, 0.946, 0.897, 0.853, 0.794, 0.748, 0.711, 0.668\n",
      "Loss  0.000377916013284  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.808, 0.749, 0.725\n",
      "Val loss  0.000476932698803  SSIM  0.983, 0.946, 0.897, 0.853, 0.794, 0.748, 0.711, 0.668\n",
      "Loss  0.000377034107123  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.808, 0.749, 0.726\n",
      "Val loss  0.000475969955034  SSIM  0.983, 0.946, 0.897, 0.852, 0.792, 0.746, 0.709, 0.665\n",
      "Loss  0.000376039980857  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.808, 0.749, 0.726\n",
      "Val loss  0.000479110165208  SSIM  0.983, 0.945, 0.895, 0.85, 0.789, 0.743, 0.707, 0.663\n",
      "Loss  0.000378099123954  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.808, 0.749, 0.726\n",
      "Val loss  0.000479081350437  SSIM  0.984, 0.946, 0.896, 0.85, 0.789, 0.743, 0.706, 0.661\n",
      "Loss  0.000376423859551  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.809, 0.749, 0.726\n",
      "Val loss  0.000477195749234  SSIM  0.983, 0.945, 0.896, 0.851, 0.792, 0.746, 0.711, 0.668\n",
      "Loss  0.000376875657014  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.808, 0.749, 0.726\n",
      "Val loss  0.000477609469148  SSIM  0.983, 0.946, 0.897, 0.854, 0.795, 0.749, 0.714, 0.672\n",
      "Loss  0.000377297457722  SSIM  0.983, 0.95, 0.91, 0.867, 0.83, 0.809, 0.749, 0.726\n",
      "Val loss  0.00047702296474  SSIM  0.983, 0.946, 0.897, 0.852, 0.793, 0.747, 0.711, 0.667\n",
      "Loss  0.000376788058912  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000474489289743  SSIM  0.983, 0.946, 0.897, 0.854, 0.796, 0.751, 0.715, 0.672\n",
      "Loss  0.000376627451384  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000478177444544  SSIM  0.983, 0.946, 0.898, 0.854, 0.795, 0.75, 0.714, 0.67\n",
      "Loss  0.000376187425567  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000475423020252  SSIM  0.983, 0.946, 0.896, 0.852, 0.793, 0.747, 0.711, 0.666\n",
      "Loss  0.000376230770395  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.727\n",
      "Val loss  0.000474669859279  SSIM  0.984, 0.946, 0.897, 0.851, 0.792, 0.746, 0.711, 0.667\n",
      "Loss  0.000376657781565  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000479048967478  SSIM  0.983, 0.946, 0.897, 0.853, 0.793, 0.748, 0.712, 0.667\n",
      "Loss  0.000376425872766  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000475374820002  SSIM  0.983, 0.946, 0.897, 0.853, 0.794, 0.749, 0.712, 0.668\n",
      "Loss  0.0003764603912  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000474979949999  SSIM  0.983, 0.946, 0.897, 0.853, 0.793, 0.748, 0.711, 0.667\n",
      "Loss  0.000376191706897  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000476007331919  SSIM  0.983, 0.946, 0.898, 0.855, 0.796, 0.751, 0.716, 0.673\n",
      "Loss  0.000376229558758  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000476818111143  SSIM  0.983, 0.946, 0.897, 0.852, 0.792, 0.747, 0.712, 0.668\n",
      "Loss  0.000377206991255  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.726\n",
      "Val loss  0.000477379236079  SSIM  0.984, 0.946, 0.897, 0.853, 0.794, 0.748, 0.712, 0.668\n",
      "Loss  0.000375539162373  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.809, 0.75, 0.727\n",
      "Val loss  0.000478198589932  SSIM  0.983, 0.946, 0.898, 0.855, 0.796, 0.751, 0.715, 0.672\n",
      "Loss  0.000375825265849  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000479288984381  SSIM  0.984, 0.945, 0.895, 0.849, 0.788, 0.74, 0.7, 0.654\n",
      "Loss  0.000375853103524  SSIM  0.983, 0.95, 0.91, 0.867, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000478026595607  SSIM  0.983, 0.946, 0.898, 0.854, 0.796, 0.751, 0.715, 0.672\n",
      "Loss  0.000375425167835  SSIM  0.983, 0.95, 0.91, 0.868, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000477429618128  SSIM  0.983, 0.946, 0.898, 0.854, 0.795, 0.751, 0.716, 0.672\n",
      "Loss  0.000375597457991  SSIM  0.983, 0.951, 0.91, 0.868, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000475014231808  SSIM  0.984, 0.947, 0.898, 0.854, 0.795, 0.75, 0.715, 0.672\n",
      "Loss  0.000375597080518  SSIM  0.983, 0.95, 0.91, 0.868, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000477269583731  SSIM  0.984, 0.945, 0.895, 0.85, 0.79, 0.744, 0.707, 0.661\n",
      "Loss  0.000375421496209  SSIM  0.983, 0.951, 0.91, 0.868, 0.831, 0.809, 0.751, 0.727\n",
      "Val loss  0.000473043164762  SSIM  0.984, 0.946, 0.898, 0.853, 0.795, 0.749, 0.714, 0.669\n",
      "saving the model  0.000473043164762\n",
      "Loss  0.000375531672288  SSIM  0.983, 0.95, 0.91, 0.868, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000479227072792  SSIM  0.983, 0.945, 0.897, 0.853, 0.795, 0.75, 0.714, 0.669\n",
      "Loss  0.0003753945358  SSIM  0.983, 0.95, 0.91, 0.868, 0.831, 0.81, 0.751, 0.727\n",
      "Val loss  0.000475352391659  SSIM  0.983, 0.946, 0.897, 0.854, 0.795, 0.75, 0.714, 0.671\n",
      "Loss  0.000375359618053  SSIM  0.983, 0.95, 0.911, 0.868, 0.832, 0.81, 0.751, 0.727\n",
      "Val loss  0.000473721496295  SSIM  0.983, 0.946, 0.898, 0.853, 0.795, 0.751, 0.715, 0.672\n",
      "Loss  0.000374826265084  SSIM  0.983, 0.95, 0.911, 0.868, 0.832, 0.81, 0.751, 0.727\n",
      "Val loss  0.000475495554507  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.747, 0.711, 0.666\n",
      "Loss  0.000374945259139  SSIM  0.983, 0.95, 0.911, 0.868, 0.832, 0.81, 0.751, 0.727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000475683801342  SSIM  0.983, 0.946, 0.898, 0.855, 0.798, 0.753, 0.717, 0.675\n",
      "Loss  0.000375337106447  SSIM  0.983, 0.95, 0.91, 0.868, 0.832, 0.81, 0.751, 0.727\n",
      "Val loss  0.000479090491135  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.000374511117185  SSIM  0.983, 0.951, 0.91, 0.868, 0.832, 0.81, 0.751, 0.727\n",
      "Val loss  0.000483513763116  SSIM  0.983, 0.945, 0.896, 0.849, 0.787, 0.74, 0.702, 0.654\n",
      "Loss  0.000374948920733  SSIM  0.983, 0.95, 0.911, 0.868, 0.832, 0.81, 0.752, 0.727\n",
      "Val loss  0.000476163823623  SSIM  0.983, 0.946, 0.899, 0.855, 0.797, 0.75, 0.713, 0.669\n",
      "Loss  0.000375213520099  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.81, 0.751, 0.726\n",
      "Val loss  0.000478797481977  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.752, 0.716, 0.671\n",
      "Loss  0.000374688678732  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.727\n",
      "Val loss  0.000474576184643  SSIM  0.984, 0.946, 0.898, 0.854, 0.796, 0.75, 0.714, 0.669\n",
      "Loss  0.000374517223293  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.81, 0.752, 0.727\n",
      "Val loss  0.000481594138546  SSIM  0.983, 0.946, 0.896, 0.85, 0.79, 0.745, 0.708, 0.662\n",
      "Loss  0.000375562458998  SSIM  0.983, 0.95, 0.911, 0.868, 0.832, 0.81, 0.751, 0.727\n",
      "Val loss  0.000475463163981  SSIM  0.983, 0.946, 0.898, 0.853, 0.794, 0.748, 0.711, 0.666\n",
      "Loss  0.000374703834609  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.81, 0.751, 0.727\n",
      "Val loss  0.00047516979475  SSIM  0.983, 0.946, 0.896, 0.851, 0.791, 0.745, 0.708, 0.661\n",
      "Loss  0.000374474449403  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.727\n",
      "Val loss  0.000473568705551  SSIM  0.983, 0.947, 0.899, 0.856, 0.799, 0.754, 0.719, 0.677\n",
      "Loss  0.000374358912846  SSIM  0.983, 0.95, 0.911, 0.868, 0.832, 0.811, 0.752, 0.727\n",
      "Val loss  0.000476931938436  SSIM  0.984, 0.946, 0.896, 0.85, 0.79, 0.743, 0.706, 0.66\n",
      "Loss  0.000374558192054  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.81, 0.752, 0.727\n",
      "Val loss  0.000476550022897  SSIM  0.984, 0.946, 0.897, 0.852, 0.792, 0.746, 0.709, 0.663\n",
      "Loss  0.000374377499424  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.811, 0.751, 0.728\n",
      "Val loss  0.000477155772212  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.000374005104198  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000472428101173  SSIM  0.984, 0.946, 0.897, 0.853, 0.795, 0.749, 0.712, 0.669\n",
      "saving the model  0.000472428101173\n",
      "Loss  0.000374005328864  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.81, 0.752, 0.728\n",
      "Val loss  0.000474417872494  SSIM  0.984, 0.946, 0.898, 0.854, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.00037423644681  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000474983601365  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.753, 0.717, 0.673\n",
      "Loss  0.00037386264722  SSIM  0.983, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000478986978007  SSIM  0.983, 0.946, 0.898, 0.854, 0.795, 0.75, 0.714, 0.67\n",
      "Loss  0.00037456569194  SSIM  0.983, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.00048553886282  SSIM  0.984, 0.946, 0.898, 0.853, 0.795, 0.749, 0.713, 0.667\n",
      "Loss  0.000373764251321  SSIM  0.984, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.00047448446817  SSIM  0.983, 0.946, 0.897, 0.854, 0.796, 0.751, 0.715, 0.67\n",
      "Loss  0.000373179417435  SSIM  0.983, 0.951, 0.911, 0.869, 0.833, 0.811, 0.752, 0.728\n",
      "Val loss  0.000476388164097  SSIM  0.983, 0.946, 0.896, 0.852, 0.792, 0.748, 0.712, 0.667\n",
      "Loss  0.000373983184147  SSIM  0.983, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.727\n",
      "Val loss  0.000476057880034  SSIM  0.984, 0.946, 0.899, 0.855, 0.797, 0.752, 0.717, 0.673\n",
      "Loss  0.000373354264439  SSIM  0.983, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000475495238905  SSIM  0.984, 0.946, 0.897, 0.853, 0.794, 0.748, 0.712, 0.668\n",
      "Loss  0.000373893028391  SSIM  0.983, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000477883292537  SSIM  0.984, 0.946, 0.898, 0.855, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.000373369378736  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000476401486958  SSIM  0.983, 0.946, 0.899, 0.855, 0.797, 0.751, 0.716, 0.672\n",
      "Loss  0.000373671140026  SSIM  0.984, 0.951, 0.911, 0.868, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000473794734397  SSIM  0.984, 0.946, 0.897, 0.852, 0.792, 0.746, 0.709, 0.664\n",
      "Loss  0.000373757158657  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000474363642104  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.747, 0.711, 0.665\n",
      "Loss  0.000373322864819  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000477422558295  SSIM  0.984, 0.945, 0.896, 0.85, 0.791, 0.745, 0.708, 0.662\n",
      "Loss  0.000373516950585  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.729\n",
      "Val loss  0.000475137718604  SSIM  0.984, 0.947, 0.899, 0.856, 0.799, 0.753, 0.718, 0.674\n",
      "Loss  0.000373315684659  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.729\n",
      "Val loss  0.000474484915554  SSIM  0.984, 0.946, 0.898, 0.855, 0.796, 0.751, 0.715, 0.67\n",
      "Loss  0.00037282964172  SSIM  0.983, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.729\n",
      "Val loss  0.000476778051525  SSIM  0.984, 0.946, 0.897, 0.851, 0.791, 0.744, 0.705, 0.658\n",
      "Loss  0.000373252805834  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.729\n",
      "Val loss  0.000474042957649  SSIM  0.984, 0.946, 0.898, 0.854, 0.795, 0.749, 0.713, 0.669\n",
      "Loss  0.00037251209453  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.752, 0.728\n",
      "Val loss  0.000474328462034  SSIM  0.983, 0.946, 0.899, 0.856, 0.798, 0.753, 0.717, 0.674\n",
      "Loss  0.000372995103684  SSIM  0.983, 0.951, 0.911, 0.869, 0.832, 0.811, 0.753, 0.728\n",
      "Val loss  0.000474463594961  SSIM  0.984, 0.946, 0.898, 0.855, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.000372908263135  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.753, 0.728\n",
      "Val loss  0.000474804698373  SSIM  0.984, 0.947, 0.899, 0.855, 0.798, 0.752, 0.716, 0.672\n",
      "Loss  0.000373332690267  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.752, 0.728\n",
      "Val loss  0.00047447983193  SSIM  0.984, 0.947, 0.899, 0.855, 0.797, 0.751, 0.716, 0.673\n",
      "Loss  0.000373249657316  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.752, 0.728\n",
      "Val loss  0.000474330494995  SSIM  0.984, 0.946, 0.898, 0.853, 0.794, 0.748, 0.712, 0.667\n",
      "Loss  0.00037229310172  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.753, 0.728\n",
      "Val loss  0.000480450952426  SSIM  0.984, 0.946, 0.898, 0.853, 0.793, 0.746, 0.709, 0.663\n",
      "Loss  0.000373018518799  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.752, 0.728\n",
      "Val loss  0.000477036813158  SSIM  0.983, 0.946, 0.898, 0.855, 0.797, 0.752, 0.718, 0.673\n",
      "Loss  0.000372903296112  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.752, 0.729\n",
      "Val loss  0.000477291219111  SSIM  0.984, 0.947, 0.898, 0.855, 0.797, 0.751, 0.714, 0.669\n",
      "Loss  0.000371893651555  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.753, 0.728\n",
      "Val loss  0.000478849137784  SSIM  0.983, 0.946, 0.899, 0.855, 0.797, 0.752, 0.717, 0.673\n",
      "Loss  0.000372744736691  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.811, 0.753, 0.729\n",
      "Val loss  0.000474753024057  SSIM  0.984, 0.947, 0.899, 0.856, 0.797, 0.752, 0.717, 0.672\n",
      "Loss  0.000372466167902  SSIM  0.984, 0.951, 0.911, 0.869, 0.832, 0.811, 0.753, 0.728\n",
      "Val loss  0.000475943000522  SSIM  0.983, 0.946, 0.897, 0.854, 0.795, 0.749, 0.713, 0.667\n",
      "Loss  0.000372957668893  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.752, 0.729\n",
      "Val loss  0.000473766942741  SSIM  0.983, 0.946, 0.899, 0.855, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.000371996097038  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.752, 0.729\n",
      "Val loss  0.000474497921765  SSIM  0.984, 0.946, 0.898, 0.854, 0.795, 0.75, 0.715, 0.671\n",
      "Loss  0.000372520709933  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.753, 0.728\n",
      "Val loss  0.000475772940554  SSIM  0.983, 0.946, 0.898, 0.854, 0.795, 0.749, 0.713, 0.668\n",
      "Loss  0.000372200470524  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.00047927135491  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.747, 0.711, 0.665\n",
      "Loss  0.000372274412103  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.753, 0.729\n",
      "Val loss  0.000472339404339  SSIM  0.984, 0.946, 0.899, 0.856, 0.799, 0.754, 0.719, 0.676\n",
      "saving the model  0.000472339404339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000372104141826  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.000473914434959  SSIM  0.984, 0.947, 0.899, 0.857, 0.799, 0.754, 0.719, 0.676\n",
      "Loss  0.000372459745964  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.753, 0.729\n",
      "Val loss  0.000475682108779  SSIM  0.983, 0.946, 0.899, 0.855, 0.797, 0.752, 0.716, 0.671\n",
      "Loss  0.000371629651331  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.811, 0.753, 0.729\n",
      "Val loss  0.000473654221743  SSIM  0.984, 0.946, 0.898, 0.854, 0.796, 0.751, 0.715, 0.67\n",
      "Loss  0.000372198682091  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.000477367843036  SSIM  0.984, 0.946, 0.897, 0.853, 0.793, 0.746, 0.709, 0.663\n",
      "Loss  0.000372217747983  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.000474680850108  SSIM  0.984, 0.947, 0.899, 0.855, 0.798, 0.752, 0.715, 0.67\n",
      "Loss  0.00037293486625  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.00047539910354  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.755, 0.72, 0.676\n",
      "Loss  0.000371793418516  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.000474844999029  SSIM  0.984, 0.947, 0.899, 0.856, 0.8, 0.754, 0.719, 0.676\n",
      "Loss  0.000371232655966  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.0004748281379  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.755, 0.72, 0.677\n",
      "Loss  0.000371953711921  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.000480930075631  SSIM  0.984, 0.947, 0.9, 0.857, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000370995430667  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000475176943757  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.746, 0.711, 0.665\n",
      "Loss  0.000371860836871  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.729\n",
      "Val loss  0.000475529350515  SSIM  0.984, 0.946, 0.899, 0.855, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.000371046195012  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000472622949223  SSIM  0.984, 0.947, 0.899, 0.855, 0.797, 0.751, 0.716, 0.673\n",
      "Loss  0.000371765592095  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000475602055085  SSIM  0.984, 0.947, 0.899, 0.856, 0.799, 0.753, 0.717, 0.674\n",
      "Loss  0.00037143793024  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000476368330186  SSIM  0.984, 0.946, 0.898, 0.854, 0.795, 0.749, 0.714, 0.669\n",
      "Loss  0.000371856694441  SSIM  0.984, 0.951, 0.911, 0.869, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000473174977815  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.748, 0.712, 0.666\n",
      "Loss  0.0003709520866  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000475289410504  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.746, 0.711, 0.666\n",
      "Loss  0.000370886360649  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000475120649673  SSIM  0.983, 0.946, 0.898, 0.853, 0.795, 0.75, 0.713, 0.668\n",
      "Loss  0.000370690992078  SSIM  0.984, 0.951, 0.912, 0.869, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000472940808861  SSIM  0.984, 0.947, 0.899, 0.855, 0.798, 0.752, 0.716, 0.673\n",
      "Loss  0.000371411176487  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000474479979661  SSIM  0.984, 0.946, 0.898, 0.854, 0.795, 0.749, 0.714, 0.67\n",
      "Loss  0.000371290779313  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000474991677271  SSIM  0.984, 0.947, 0.899, 0.855, 0.797, 0.752, 0.716, 0.673\n",
      "Loss  0.000371178497035  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000476314439264  SSIM  0.984, 0.946, 0.897, 0.854, 0.796, 0.75, 0.715, 0.671\n",
      "Loss  0.000371129908905  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.00047500287235  SSIM  0.983, 0.946, 0.898, 0.854, 0.795, 0.75, 0.715, 0.671\n",
      "Loss  0.000370717173948  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000474476104544  SSIM  0.984, 0.946, 0.898, 0.854, 0.796, 0.75, 0.714, 0.67\n",
      "Loss  0.000370988345729  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000476692098484  SSIM  0.984, 0.946, 0.898, 0.855, 0.798, 0.753, 0.718, 0.674\n",
      "Loss  0.000370815454701  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.813, 0.754, 0.73\n",
      "Val loss  0.000478866818477  SSIM  0.984, 0.946, 0.899, 0.856, 0.799, 0.754, 0.718, 0.674\n",
      "Loss  0.000370839859508  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000474653564626  SSIM  0.984, 0.946, 0.898, 0.854, 0.796, 0.75, 0.715, 0.67\n",
      "Loss  0.000370804599826  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.813, 0.753, 0.73\n",
      "Val loss  0.000478213972528  SSIM  0.984, 0.946, 0.898, 0.854, 0.796, 0.751, 0.716, 0.672\n",
      "Loss  0.000370455517575  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.813, 0.753, 0.73\n",
      "Val loss  0.000475545761641  SSIM  0.983, 0.947, 0.9, 0.856, 0.8, 0.754, 0.72, 0.677\n",
      "Loss  0.00037082360322  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.754, 0.73\n",
      "Val loss  0.000474539041985  SSIM  0.984, 0.946, 0.898, 0.853, 0.794, 0.749, 0.713, 0.669\n",
      "Loss  0.00037034591225  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.73\n",
      "Val loss  0.000478074419429  SSIM  0.984, 0.947, 0.899, 0.857, 0.8, 0.755, 0.721, 0.679\n",
      "Loss  0.000370369243282  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.812, 0.753, 0.73\n",
      "Val loss  0.000473701588809  SSIM  0.984, 0.947, 0.899, 0.856, 0.798, 0.753, 0.718, 0.674\n",
      "Loss  0.000370521186056  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.813, 0.754, 0.73\n",
      "Val loss  0.000482162451313  SSIM  0.983, 0.947, 0.899, 0.857, 0.801, 0.755, 0.721, 0.68\n",
      "Loss  0.000370554782738  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.753, 0.73\n",
      "Val loss  0.000480249698565  SSIM  0.984, 0.946, 0.898, 0.853, 0.794, 0.748, 0.712, 0.667\n",
      "Loss  0.000370109753945  SSIM  0.984, 0.951, 0.912, 0.87, 0.833, 0.813, 0.754, 0.731\n",
      "Val loss  0.000474511420005  SSIM  0.984, 0.947, 0.899, 0.855, 0.797, 0.751, 0.716, 0.672\n",
      "Loss  0.000370242633156  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.812, 0.754, 0.73\n",
      "Val loss  0.000474673586432  SSIM  0.984, 0.947, 0.9, 0.857, 0.8, 0.755, 0.72, 0.678\n",
      "Loss  0.000370362264682  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.753, 0.73\n",
      "Val loss  0.000475992475578  SSIM  0.984, 0.946, 0.898, 0.855, 0.797, 0.751, 0.714, 0.668\n",
      "Loss  0.000369817937655  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.73\n",
      "Val loss  0.000474369191972  SSIM  0.984, 0.947, 0.899, 0.856, 0.798, 0.752, 0.716, 0.672\n",
      "Loss  0.000370198898816  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.73\n",
      "Val loss  0.000473799026688  SSIM  0.984, 0.946, 0.898, 0.853, 0.795, 0.75, 0.715, 0.671\n",
      "Loss  0.000369835388422  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000474317769287  SSIM  0.984, 0.946, 0.899, 0.855, 0.797, 0.751, 0.716, 0.673\n",
      "Loss  0.00037028378023  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.73\n",
      "Val loss  0.000473813666729  SSIM  0.984, 0.946, 0.899, 0.855, 0.798, 0.751, 0.716, 0.672\n",
      "Loss  0.000370074900609  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.73\n",
      "Val loss  0.00047609886009  SSIM  0.984, 0.946, 0.897, 0.852, 0.793, 0.747, 0.71, 0.663\n",
      "Loss  0.000369607818999  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000474919450353  SSIM  0.984, 0.947, 0.899, 0.856, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000369773199141  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000473584754858  SSIM  0.984, 0.947, 0.9, 0.857, 0.8, 0.754, 0.72, 0.678\n",
      "Loss  0.000370208811253  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000478066412557  SSIM  0.984, 0.946, 0.898, 0.853, 0.794, 0.747, 0.711, 0.668\n",
      "Loss  0.000369067944836  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000477665867191  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.756, 0.721, 0.679\n",
      "Loss  0.000370124904749  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000474374095269  SSIM  0.984, 0.946, 0.898, 0.855, 0.797, 0.751, 0.715, 0.671\n",
      "Loss  0.000369504873147  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000473989099497  SSIM  0.984, 0.946, 0.899, 0.855, 0.796, 0.751, 0.716, 0.672\n",
      "Loss  0.000369473035009  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000475056944764  SSIM  0.984, 0.946, 0.898, 0.853, 0.796, 0.75, 0.714, 0.67\n",
      "Loss  0.000369865573914  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000474512358254  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.753, 0.717, 0.674\n",
      "Loss  0.000369399160609  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000473993899301  SSIM  0.983, 0.946, 0.898, 0.854, 0.796, 0.751, 0.716, 0.673\n",
      "Loss  0.000369507980131  SSIM  0.984, 0.952, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000474936035287  SSIM  0.984, 0.947, 0.899, 0.856, 0.799, 0.753, 0.717, 0.674\n",
      "Loss  0.000369917204248  SSIM  0.984, 0.952, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000473221942375  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000368785845581  SSIM  0.984, 0.952, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000476209420536  SSIM  0.984, 0.947, 0.899, 0.855, 0.798, 0.752, 0.716, 0.673\n",
      "Loss  0.000369505374739  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000472536853689  SSIM  0.984, 0.947, 0.899, 0.854, 0.796, 0.75, 0.715, 0.671\n",
      "Loss  0.000368820626157  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.813, 0.754, 0.732\n",
      "Val loss  0.000473624144041  SSIM  0.983, 0.947, 0.899, 0.856, 0.8, 0.754, 0.718, 0.674\n",
      "Loss  0.000368989537502  SSIM  0.984, 0.951, 0.912, 0.87, 0.834, 0.814, 0.754, 0.731\n",
      "Val loss  0.000474094927951  SSIM  0.984, 0.947, 0.899, 0.856, 0.8, 0.754, 0.72, 0.677\n",
      "Loss  0.000368827152265  SSIM  0.984, 0.951, 0.912, 0.871, 0.834, 0.814, 0.754, 0.731\n",
      "Val loss  0.000474774978007  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.751, 0.714, 0.669\n",
      "Loss  0.000369080611713  SSIM  0.984, 0.951, 0.912, 0.871, 0.834, 0.814, 0.754, 0.731\n",
      "Val loss  0.00047450064501  SSIM  0.984, 0.947, 0.899, 0.856, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000368956040907  SSIM  0.984, 0.952, 0.913, 0.871, 0.834, 0.813, 0.754, 0.732\n",
      "Val loss  0.00047351917479  SSIM  0.984, 0.947, 0.899, 0.855, 0.798, 0.752, 0.716, 0.671\n",
      "Loss  0.000369190601199  SSIM  0.984, 0.951, 0.912, 0.871, 0.834, 0.813, 0.754, 0.731\n",
      "Val loss  0.000476732986863  SSIM  0.983, 0.946, 0.899, 0.856, 0.799, 0.753, 0.718, 0.674\n",
      "Loss  0.000368691786775  SSIM  0.984, 0.952, 0.913, 0.871, 0.834, 0.814, 0.755, 0.732\n",
      "Val loss  0.00047892446263  SSIM  0.984, 0.946, 0.898, 0.853, 0.794, 0.748, 0.71, 0.664\n",
      "Loss  0.000368887847888  SSIM  0.984, 0.951, 0.912, 0.871, 0.834, 0.814, 0.754, 0.732\n",
      "Val loss  0.000477372173569  SSIM  0.984, 0.947, 0.9, 0.856, 0.799, 0.753, 0.718, 0.675\n",
      "Loss  0.000369131512629  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.754, 0.732\n",
      "Val loss  0.000477377359581  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.753, 0.717, 0.674\n",
      "Loss  0.000368847694749  SSIM  0.984, 0.951, 0.912, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000478260789241  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.754, 0.719, 0.677\n",
      "Loss  0.000368986555259  SSIM  0.984, 0.951, 0.913, 0.871, 0.835, 0.814, 0.754, 0.732\n",
      "Val loss  0.000473896569689  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.755, 0.721, 0.679\n",
      "Loss  0.000368780733823  SSIM  0.984, 0.951, 0.913, 0.871, 0.835, 0.814, 0.755, 0.731\n",
      "Val loss  0.00047530947777  SSIM  0.984, 0.947, 0.9, 0.858, 0.803, 0.757, 0.722, 0.68\n",
      "Loss  0.000368661714354  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000485640082683  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.752, 0.716, 0.673\n",
      "Loss  0.000368414751587  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.00047366775712  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.757, 0.722, 0.68\n",
      "Loss  0.000368511228594  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000473823860462  SSIM  0.984, 0.947, 0.9, 0.856, 0.799, 0.754, 0.718, 0.675\n",
      "Loss  0.000368082182347  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.733\n",
      "Val loss  0.000475916220865  SSIM  0.984, 0.947, 0.899, 0.856, 0.8, 0.753, 0.717, 0.673\n",
      "Loss  0.000368425222601  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000473947055929  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.751, 0.715, 0.672\n",
      "Loss  0.000368623721171  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000478884685785  SSIM  0.984, 0.946, 0.898, 0.854, 0.797, 0.752, 0.716, 0.671\n",
      "Loss  0.00036803566587  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000472835895023  SSIM  0.984, 0.947, 0.899, 0.856, 0.8, 0.754, 0.719, 0.676\n",
      "Loss  0.000368473129028  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000474151057482  SSIM  0.984, 0.947, 0.9, 0.856, 0.799, 0.753, 0.718, 0.676\n",
      "Loss  0.000368076689725  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000478081902897  SSIM  0.984, 0.947, 0.9, 0.855, 0.799, 0.753, 0.717, 0.674\n",
      "Loss  0.000368616446759  SSIM  0.984, 0.952, 0.912, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000473161879869  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.75, 0.713, 0.67\n",
      "Loss  0.000368263048539  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000474367100105  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.752, 0.716, 0.672\n",
      "Loss  0.00036781363028  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000472100209794  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.753, 0.717, 0.674\n",
      "saving the model  0.000472100209794\n",
      "Loss  0.000368018882738  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.000476260785363  SSIM  0.984, 0.946, 0.898, 0.853, 0.796, 0.749, 0.712, 0.665\n",
      "Loss  0.000367911486629  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.755, 0.732\n",
      "Val loss  0.000472918003798  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.753, 0.716, 0.672\n",
      "Loss  0.000367820017325  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.000475052314287  SSIM  0.984, 0.946, 0.898, 0.853, 0.796, 0.751, 0.715, 0.672\n",
      "Loss  0.000367842643593  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.000475849216862  SSIM  0.983, 0.946, 0.899, 0.855, 0.798, 0.752, 0.715, 0.671\n",
      "Loss  0.000367938858412  SSIM  0.984, 0.952, 0.913, 0.871, 0.835, 0.814, 0.756, 0.733\n",
      "Val loss  0.000474290677521  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.753, 0.716, 0.673\n",
      "Loss  0.000367532406654  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.000474692503631  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.758, 0.724, 0.684\n",
      "Loss  0.000367419408288  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.756, 0.733\n",
      "Val loss  0.000474708772032  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.751, 0.715, 0.672\n",
      "Loss  0.000367642777396  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.000476672018005  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.754, 0.718, 0.676\n",
      "Loss  0.000368134394434  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.756, 0.733\n",
      "Val loss  0.000476060257584  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.755, 0.72, 0.678\n",
      "Loss  0.000367398874244  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.000474032769969  SSIM  0.984, 0.946, 0.898, 0.853, 0.795, 0.749, 0.712, 0.668\n",
      "Loss  0.000368149394184  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.755, 0.733\n",
      "Val loss  0.00047357690183  SSIM  0.984, 0.947, 0.899, 0.855, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000367691945781  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000476588518824  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.756, 0.721, 0.679\n",
      "Loss  0.000367555991849  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000474123212101  SSIM  0.984, 0.947, 0.899, 0.854, 0.798, 0.753, 0.717, 0.674\n",
      "Loss  0.000367517635238  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.00047620117612  SSIM  0.984, 0.946, 0.899, 0.855, 0.798, 0.752, 0.715, 0.672\n",
      "Loss  0.000367225434533  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000475756791711  SSIM  0.984, 0.946, 0.899, 0.854, 0.799, 0.753, 0.716, 0.674\n",
      "Loss  0.000366726941219  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.734\n",
      "Val loss  0.000474847374659  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.754, 0.718, 0.676\n",
      "Loss  0.00036754223201  SSIM  0.984, 0.952, 0.913, 0.872, 0.835, 0.815, 0.756, 0.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000473854124662  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.754, 0.719, 0.676\n",
      "Loss  0.000367330573296  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000474783785758  SSIM  0.984, 0.946, 0.899, 0.854, 0.796, 0.75, 0.714, 0.67\n",
      "Loss  0.000367486172659  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000475165619981  SSIM  0.984, 0.946, 0.899, 0.855, 0.798, 0.753, 0.717, 0.675\n",
      "Loss  0.000366802072434  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000474572223728  SSIM  0.984, 0.947, 0.899, 0.854, 0.798, 0.752, 0.716, 0.673\n",
      "Loss  0.000367238558953  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.734\n",
      "Val loss  0.000488671247265  SSIM  0.984, 0.947, 0.9, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000367332871023  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.733\n",
      "Val loss  0.000477221862646  SSIM  0.984, 0.947, 0.9, 0.855, 0.798, 0.752, 0.716, 0.672\n",
      "Loss  0.000366870786578  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.734\n",
      "Val loss  0.000473200373119  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.72, 0.679\n",
      "Loss  0.000367137222206  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.734\n",
      "Val loss  0.000480113461497  SSIM  0.983, 0.946, 0.9, 0.855, 0.799, 0.753, 0.717, 0.674\n",
      "Loss  0.000366673697122  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.756, 0.734\n",
      "Val loss  0.000473745918775  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.753, 0.717, 0.674\n",
      "Loss  0.000366728023595  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.757, 0.734\n",
      "Val loss  0.00047585372458  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.758, 0.722, 0.681\n",
      "Loss  0.000366498682298  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.756, 0.734\n",
      "Val loss  0.000476543669472  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.757, 0.722, 0.681\n",
      "Loss  0.000366847830828  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.756, 0.734\n",
      "Val loss  0.000476469354471  SSIM  0.984, 0.947, 0.9, 0.855, 0.798, 0.75, 0.714, 0.672\n",
      "Loss  0.000366882858164  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.815, 0.756, 0.734\n",
      "Val loss  0.000474247433187  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.72, 0.678\n",
      "Loss  0.00036669149958  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.756, 0.734\n",
      "Val loss  0.000476024483971  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.75, 0.715, 0.673\n",
      "Loss  0.000366775772649  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.757, 0.734\n",
      "Val loss  0.00047599472804  SSIM  0.984, 0.947, 0.9, 0.857, 0.803, 0.758, 0.723, 0.681\n",
      "Loss  0.00036645172811  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.757, 0.734\n",
      "Val loss  0.00047660045157  SSIM  0.984, 0.946, 0.899, 0.854, 0.798, 0.751, 0.714, 0.671\n",
      "Loss  0.000366358740012  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.757, 0.734\n",
      "Val loss  0.000471585592255  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.721, 0.679\n",
      "saving the model  0.000471585592255\n",
      "Loss  0.000366521539644  SSIM  0.984, 0.952, 0.913, 0.872, 0.836, 0.816, 0.757, 0.734\n",
      "Val loss  0.000473378848983  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.72, 0.678\n",
      "Loss  0.000366950540852  SSIM  0.984, 0.952, 0.913, 0.872, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.00047178993409  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.756, 0.721, 0.679\n",
      "Loss  0.000366676077017  SSIM  0.984, 0.952, 0.913, 0.872, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.000473682398675  SSIM  0.984, 0.946, 0.899, 0.856, 0.8, 0.755, 0.719, 0.676\n",
      "Loss  0.000366288006888  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.000475219484302  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.756, 0.721, 0.679\n",
      "Loss  0.000366553153207  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.000474503412086  SSIM  0.984, 0.946, 0.899, 0.855, 0.799, 0.754, 0.718, 0.675\n",
      "Loss  0.000366641913709  SSIM  0.984, 0.952, 0.913, 0.873, 0.836, 0.816, 0.757, 0.734\n",
      "Val loss  0.000473481552501  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.721, 0.68\n",
      "Loss  0.000366138283915  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.735\n",
      "Val loss  0.000476167827845  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.758, 0.723, 0.682\n",
      "Loss  0.000366577058406  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.735\n",
      "Val loss  0.000473763219954  SSIM  0.984, 0.946, 0.899, 0.855, 0.799, 0.752, 0.715, 0.672\n",
      "Loss  0.000366037665262  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.000475734062784  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.721, 0.68\n",
      "Loss  0.000366142626359  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.000474450523849  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.756, 0.72, 0.677\n",
      "Loss  0.000366458587344  SSIM  0.984, 0.952, 0.913, 0.872, 0.837, 0.816, 0.757, 0.734\n",
      "Val loss  0.000478555929149  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.721, 0.678\n",
      "Loss  0.000366133774966  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.735\n",
      "Val loss  0.000474211946654  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.756, 0.721, 0.68\n",
      "Loss  0.000365692620511  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000477259125619  SSIM  0.984, 0.946, 0.899, 0.853, 0.795, 0.748, 0.712, 0.669\n",
      "Loss  0.000366041775982  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.735\n",
      "Val loss  0.000475478392502  SSIM  0.984, 0.946, 0.899, 0.854, 0.797, 0.751, 0.715, 0.673\n",
      "Loss  0.000366504655871  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.757, 0.735\n",
      "Val loss  0.00047696432838  SSIM  0.984, 0.946, 0.9, 0.856, 0.8, 0.756, 0.721, 0.68\n",
      "Loss  0.000365865035638  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.816, 0.757, 0.735\n",
      "Val loss  0.000476543813595  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000366162359932  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000475946267194  SSIM  0.984, 0.946, 0.9, 0.855, 0.799, 0.753, 0.718, 0.676\n",
      "Loss  0.000365827399058  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000475643059006  SSIM  0.984, 0.946, 0.9, 0.857, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000366215020523  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000473196882231  SSIM  0.984, 0.947, 0.9, 0.857, 0.803, 0.758, 0.723, 0.682\n",
      "Loss  0.000365240873991  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.817, 0.758, 0.735\n",
      "Val loss  0.00047374660318  SSIM  0.984, 0.946, 0.899, 0.855, 0.799, 0.753, 0.718, 0.676\n",
      "Loss  0.000366145047051  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000474702178908  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.725, 0.685\n",
      "Loss  0.000365754861866  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000474497963965  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.722, 0.68\n",
      "Loss  0.000365840315901  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.817, 0.758, 0.735\n",
      "Val loss  0.000473420751281  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.756, 0.722, 0.681\n",
      "Loss  0.000365651803726  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.816, 0.758, 0.736\n",
      "Val loss  0.000475630781671  SSIM  0.984, 0.947, 0.9, 0.855, 0.799, 0.753, 0.717, 0.675\n",
      "Loss  0.000365024999211  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.817, 0.758, 0.736\n",
      "Val loss  0.000474558363843  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.757, 0.722, 0.682\n",
      "Loss  0.000365552829993  SSIM  0.984, 0.952, 0.913, 0.873, 0.837, 0.816, 0.758, 0.735\n",
      "Val loss  0.000473787171301  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.757, 0.723, 0.683\n",
      "Loss  0.000365393798869  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.817, 0.758, 0.735\n",
      "Val loss  0.000473193723534  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.755, 0.721, 0.681\n",
      "Loss  0.000365485481931  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.817, 0.758, 0.736\n",
      "Val loss  0.000473341869889  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.755, 0.721, 0.679\n",
      "Loss  0.000365260319916  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.758, 0.736\n",
      "Val loss  0.000482022897981  SSIM  0.984, 0.946, 0.898, 0.854, 0.798, 0.753, 0.718, 0.676\n",
      "Loss  0.000365816230659  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.758, 0.735\n",
      "Val loss  0.000476065533294  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.757, 0.723, 0.682\n",
      "Loss  0.000364811217163  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.758, 0.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000476071554702  SSIM  0.984, 0.947, 0.9, 0.856, 0.799, 0.754, 0.719, 0.676\n",
      "Loss  0.000365600205887  SSIM  0.984, 0.952, 0.914, 0.873, 0.837, 0.817, 0.758, 0.735\n",
      "Val loss  0.000476487729175  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.722, 0.681\n",
      "Loss  0.000365256610354  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.758, 0.736\n",
      "Val loss  0.000473620864912  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.721, 0.68\n",
      "Loss  0.000365054737999  SSIM  0.984, 0.952, 0.913, 0.873, 0.838, 0.817, 0.758, 0.736\n",
      "Val loss  0.000476642818772  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.722, 0.681\n",
      "Loss  0.000365197979788  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.758, 0.736\n",
      "Val loss  0.000474967046059  SSIM  0.984, 0.946, 0.899, 0.855, 0.8, 0.754, 0.718, 0.675\n",
      "Loss  0.000365710697288  SSIM  0.984, 0.952, 0.913, 0.873, 0.838, 0.817, 0.758, 0.736\n",
      "Val loss  0.000474747504748  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.756, 0.722, 0.681\n",
      "Loss  0.000364610852788  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.736\n",
      "Val loss  0.000478542286612  SSIM  0.984, 0.947, 0.9, 0.855, 0.799, 0.752, 0.715, 0.673\n",
      "Loss  0.00036544910747  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.758, 0.736\n",
      "Val loss  0.000474178802804  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.757, 0.723, 0.682\n",
      "Loss  0.000365101362543  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.736\n",
      "Val loss  0.00047738142038  SSIM  0.984, 0.946, 0.899, 0.855, 0.799, 0.754, 0.718, 0.674\n",
      "Loss  0.00036462500599  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.736\n",
      "Val loss  0.000474779543292  SSIM  0.984, 0.947, 0.901, 0.857, 0.801, 0.755, 0.719, 0.677\n",
      "Loss  0.000364946965269  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000477553211618  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.724, 0.683\n",
      "Loss  0.000364932730406  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000473491836572  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.757, 0.722, 0.682\n",
      "Loss  0.000365207167143  SSIM  0.984, 0.952, 0.913, 0.873, 0.838, 0.817, 0.759, 0.736\n",
      "Val loss  0.000475229934091  SSIM  0.984, 0.946, 0.9, 0.856, 0.799, 0.754, 0.718, 0.676\n",
      "Loss  0.00036474591451  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.736\n",
      "Val loss  0.000474206498475  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.758, 0.723, 0.682\n",
      "Loss  0.000364851875722  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000474761451827  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.755, 0.719, 0.677\n",
      "Loss  0.000364665469885  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000472833087551  SSIM  0.984, 0.946, 0.9, 0.856, 0.801, 0.756, 0.721, 0.681\n",
      "Loss  0.000364431235685  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000473260201397  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.72, 0.679\n",
      "Loss  0.000364591239343  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000474035875464  SSIM  0.984, 0.947, 0.901, 0.859, 0.805, 0.76, 0.726, 0.686\n",
      "Loss  0.000364551463816  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000472445150604  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.723, 0.684\n",
      "Loss  0.00036463485194  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000477992219909  SSIM  0.983, 0.946, 0.901, 0.858, 0.804, 0.76, 0.726, 0.687\n",
      "Loss  0.000364222601486  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000473153690982  SSIM  0.984, 0.947, 0.9, 0.856, 0.8, 0.755, 0.72, 0.679\n",
      "Loss  0.000364392089649  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000476893690939  SSIM  0.984, 0.946, 0.899, 0.855, 0.8, 0.755, 0.718, 0.675\n",
      "Loss  0.000364214557967  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000472077952407  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.722, 0.681\n",
      "Loss  0.000364371738438  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000476011289633  SSIM  0.984, 0.946, 0.9, 0.856, 0.801, 0.755, 0.72, 0.679\n",
      "Loss  0.000364364809351  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.759, 0.737\n",
      "Val loss  0.000479638583842  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.758, 0.723, 0.682\n",
      "Loss  0.00036441397912  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.818, 0.759, 0.737\n",
      "Val loss  0.000474187728949  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.76, 0.726, 0.687\n",
      "Loss  0.000364020891531  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.818, 0.76, 0.737\n",
      "Val loss  0.000475247531431  SSIM  0.984, 0.946, 0.899, 0.855, 0.8, 0.754, 0.719, 0.678\n",
      "Loss  0.00036457520869  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.817, 0.76, 0.737\n",
      "Val loss  0.000475605726009  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000364560767286  SSIM  0.984, 0.952, 0.914, 0.873, 0.838, 0.817, 0.76, 0.737\n",
      "Val loss  0.000475814910955  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.756, 0.721, 0.68\n",
      "Loss  0.000364448928277  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.818, 0.76, 0.737\n",
      "Val loss  0.000473908938409  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.723, 0.683\n",
      "Loss  0.00036451896962  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.817, 0.76, 0.737\n",
      "Val loss  0.000475499522989  SSIM  0.984, 0.947, 0.899, 0.855, 0.799, 0.754, 0.719, 0.678\n",
      "Loss  0.000363683621146  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.737\n",
      "Val loss  0.000474598309898  SSIM  0.984, 0.946, 0.9, 0.857, 0.802, 0.757, 0.722, 0.681\n",
      "Loss  0.000364160330681  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.737\n",
      "Val loss  0.000475077260751  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.76, 0.725, 0.685\n",
      "Loss  0.000363634690066  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.818, 0.76, 0.737\n",
      "Val loss  0.000473770433804  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.722, 0.68\n",
      "Loss  0.000364027231439  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.737\n",
      "Val loss  0.00047331180732  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.719, 0.678\n",
      "Loss  0.000364173572002  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.817, 0.76, 0.738\n",
      "Val loss  0.000474766156171  SSIM  0.984, 0.947, 0.902, 0.859, 0.804, 0.76, 0.726, 0.687\n",
      "Loss  0.000364229920085  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.738\n",
      "Val loss  0.000475013345946  SSIM  0.984, 0.946, 0.9, 0.856, 0.8, 0.755, 0.72, 0.679\n",
      "Loss  0.000363609182957  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.738\n",
      "Val loss  0.000475666270708  SSIM  0.983, 0.946, 0.899, 0.856, 0.8, 0.755, 0.72, 0.679\n",
      "Loss  0.000363730875043  SSIM  0.984, 0.952, 0.914, 0.874, 0.838, 0.818, 0.76, 0.738\n",
      "Val loss  0.000474101484055  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.722, 0.682\n",
      "Loss  0.000363896451255  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.738\n",
      "Val loss  0.000475095102738  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.758, 0.723, 0.683\n",
      "Loss  0.000363548690138  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000474194081442  SSIM  0.984, 0.946, 0.9, 0.856, 0.801, 0.756, 0.722, 0.682\n",
      "Loss  0.000364022868193  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.738\n",
      "Val loss  0.000474309667479  SSIM  0.984, 0.947, 0.899, 0.855, 0.798, 0.754, 0.719, 0.679\n",
      "Loss  0.000364018226386  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.738\n",
      "Val loss  0.000474160269951  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.725, 0.685\n",
      "Loss  0.000363375213413  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.76, 0.738\n",
      "Val loss  0.000473910143191  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.756, 0.723, 0.683\n",
      "Loss  0.000363701436542  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.00047332031955  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.722, 0.682\n",
      "Loss  0.00036349711619  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000478055490239  SSIM  0.984, 0.946, 0.899, 0.855, 0.799, 0.754, 0.718, 0.676\n",
      "Loss  0.000363562179233  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000472198879288  SSIM  0.984, 0.947, 0.901, 0.858, 0.805, 0.759, 0.725, 0.685\n",
      "Loss  0.00036337111005  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000474449825007  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.757, 0.722, 0.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000363545282569  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000476042382594  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.722, 0.682\n",
      "Loss  0.000363096782648  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000474577331042  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.725, 0.686\n",
      "Loss  0.000363156099252  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.00047716162703  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.724, 0.684\n",
      "Loss  0.00036371518289  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000477238579711  SSIM  0.984, 0.946, 0.898, 0.853, 0.798, 0.752, 0.717, 0.675\n",
      "Loss  0.000363532850482  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000475146036653  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.756, 0.721, 0.681\n",
      "Loss  0.000363370985932  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000474885873205  SSIM  0.984, 0.947, 0.9, 0.857, 0.804, 0.759, 0.725, 0.685\n",
      "Loss  0.00036354548475  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000475758518616  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.758, 0.723, 0.683\n",
      "Loss  0.000363442271705  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000472913722333  SSIM  0.984, 0.946, 0.9, 0.856, 0.8, 0.755, 0.72, 0.68\n",
      "Loss  0.000363080044278  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000474287764402  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.721, 0.681\n",
      "Loss  0.000363154346819  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000476747540582  SSIM  0.984, 0.946, 0.898, 0.854, 0.798, 0.753, 0.719, 0.679\n",
      "Loss  0.000363534709783  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000474416733079  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.756, 0.722, 0.682\n",
      "Loss  0.000363342822256  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000475319886697  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.724, 0.684\n",
      "Loss  0.000362706217591  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000474270527135  SSIM  0.984, 0.947, 0.901, 0.858, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000362966880629  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000474163322651  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.723, 0.683\n",
      "Loss  0.000362908207861  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000475173086685  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.725, 0.686\n",
      "Loss  0.000363357359343  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.0004739075377  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.756, 0.722, 0.682\n",
      "Loss  0.000363136125907  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000472168242151  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.726, 0.687\n",
      "Loss  0.000362818077979  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000476679465442  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.723, 0.682\n",
      "Loss  0.000362635828248  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.00047344154818  SSIM  0.984, 0.947, 0.899, 0.855, 0.801, 0.756, 0.722, 0.682\n",
      "Loss  0.000362959690392  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.738\n",
      "Val loss  0.000475186909316  SSIM  0.984, 0.947, 0.9, 0.858, 0.804, 0.76, 0.727, 0.687\n",
      "Loss  0.000362352502896  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000474664721871  SSIM  0.984, 0.947, 0.9, 0.857, 0.804, 0.759, 0.724, 0.684\n",
      "Loss  0.000362662017129  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000475610258116  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.758, 0.724, 0.683\n",
      "Loss  0.000362834311598  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000473276988545  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.722, 0.683\n",
      "Loss  0.000362718077794  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000477343153325  SSIM  0.984, 0.947, 0.901, 0.856, 0.801, 0.756, 0.721, 0.681\n",
      "Loss  0.000362924345427  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.00047414267261  SSIM  0.984, 0.947, 0.9, 0.858, 0.804, 0.759, 0.724, 0.683\n",
      "Loss  0.00036266763712  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.761, 0.739\n",
      "Val loss  0.000472760016564  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.758, 0.724, 0.685\n",
      "Loss  0.000362867285246  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000472039737157  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000362787518796  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.761, 0.739\n",
      "Val loss  0.00047670826799  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000362502651518  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.761, 0.739\n",
      "Val loss  0.000474586007651  SSIM  0.984, 0.947, 0.901, 0.859, 0.806, 0.762, 0.728, 0.69\n",
      "Loss  0.000362491275749  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000474966159905  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000362796470115  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000472468259337  SSIM  0.984, 0.947, 0.901, 0.858, 0.805, 0.76, 0.726, 0.687\n",
      "Loss  0.000362492482612  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000489333609759  SSIM  0.984, 0.946, 0.9, 0.856, 0.801, 0.755, 0.719, 0.677\n",
      "Loss  0.000362711450908  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000473885939864  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.757, 0.723, 0.684\n",
      "Loss  0.000361621443456  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000474287809571  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.726, 0.687\n",
      "Loss  0.000362635147536  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.761, 0.739\n",
      "Val loss  0.000480055698019  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000362103700407  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000481924861029  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.761, 0.728, 0.689\n",
      "Loss  0.00036249170744  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.761, 0.739\n",
      "Val loss  0.000473697270849  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.759, 0.726, 0.687\n",
      "Loss  0.000362651293152  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.818, 0.761, 0.739\n",
      "Val loss  0.000472627821437  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.758, 0.725, 0.686\n",
      "Loss  0.000362144282885  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.818, 0.762, 0.739\n",
      "Val loss  0.000475204550894  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.761, 0.727, 0.687\n",
      "Loss  0.000361943414428  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.0004774593162  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.761, 0.727, 0.688\n",
      "Loss  0.000362449280559  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000475109366525  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.76, 0.726, 0.686\n",
      "Loss  0.000362222111809  SSIM  0.984, 0.952, 0.914, 0.874, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000473559985519  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000361609086689  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000473388920887  SSIM  0.984, 0.947, 0.9, 0.857, 0.802, 0.758, 0.724, 0.685\n",
      "Loss  0.000362514295034  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.761, 0.739\n",
      "Val loss  0.000473642223573  SSIM  0.984, 0.947, 0.9, 0.857, 0.801, 0.756, 0.722, 0.682\n",
      "Loss  0.000361962141452  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000473361767072  SSIM  0.984, 0.947, 0.901, 0.858, 0.805, 0.761, 0.726, 0.688\n",
      "Loss  0.000361692637652  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000479845598049  SSIM  0.984, 0.946, 0.899, 0.854, 0.799, 0.753, 0.718, 0.677\n",
      "Loss  0.000361971777195  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.739\n",
      "Val loss  0.000473385338963  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.758, 0.725, 0.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000361680244609  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000472643705085  SSIM  0.984, 0.947, 0.901, 0.856, 0.801, 0.755, 0.72, 0.681\n",
      "Loss  0.000361789341517  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474986413843  SSIM  0.984, 0.946, 0.9, 0.856, 0.801, 0.755, 0.72, 0.679\n",
      "Loss  0.000361927162914  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474574487249  SSIM  0.984, 0.947, 0.9, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000361455751429  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000475886965636  SSIM  0.984, 0.946, 0.9, 0.857, 0.802, 0.758, 0.723, 0.682\n",
      "Loss  0.000361924433334  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474322021124  SSIM  0.984, 0.947, 0.901, 0.856, 0.803, 0.758, 0.723, 0.684\n",
      "Loss  0.000361744412144  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474534769368  SSIM  0.984, 0.946, 0.9, 0.855, 0.8, 0.755, 0.721, 0.681\n",
      "Loss  0.000361610642315  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.739\n",
      "Val loss  0.000474237576127  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.686\n",
      "Loss  0.000362002638325  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.000472065950045  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.76, 0.727, 0.688\n",
      "Loss  0.000361459731343  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.739\n",
      "Val loss  0.00047508825222  SSIM  0.984, 0.946, 0.9, 0.855, 0.8, 0.755, 0.721, 0.681\n",
      "Loss  0.000361441630421  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.739\n",
      "Val loss  0.00047525842092  SSIM  0.984, 0.947, 0.901, 0.856, 0.802, 0.756, 0.723, 0.684\n",
      "Loss  0.000361753539216  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000475122820411  SSIM  0.984, 0.947, 0.9, 0.856, 0.801, 0.755, 0.721, 0.68\n",
      "Loss  0.000361159532135  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000472909731558  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.76, 0.725, 0.685\n",
      "Loss  0.000361585265089  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000483972400136  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.724, 0.684\n",
      "Loss  0.000361646574683  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473158635548  SSIM  0.984, 0.947, 0.901, 0.858, 0.805, 0.76, 0.727, 0.688\n",
      "Loss  0.00036148351962  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000472721894854  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.758, 0.726, 0.687\n",
      "Loss  0.000361165941804  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473871568392  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000361192135436  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474708877329  SSIM  0.984, 0.947, 0.901, 0.857, 0.804, 0.76, 0.726, 0.687\n",
      "Loss  0.000361183693204  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474489112268  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.726, 0.688\n",
      "Loss  0.000361494535004  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473737431108  SSIM  0.984, 0.947, 0.901, 0.858, 0.804, 0.759, 0.725, 0.687\n",
      "Loss  0.00036145965298  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473774750018  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000361359020697  SSIM  0.984, 0.953, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474967557879  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.721, 0.68\n",
      "Loss  0.000361104076193  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000478018263471  SSIM  0.983, 0.947, 0.901, 0.858, 0.805, 0.761, 0.729, 0.69\n",
      "Loss  0.00036138993932  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474242450437  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.726, 0.687\n",
      "Loss  0.000360834788274  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473178995599  SSIM  0.984, 0.947, 0.901, 0.857, 0.804, 0.76, 0.727, 0.689\n",
      "Loss  0.000361229225478  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000475794514641  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000361337585819  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474374532874  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000360917029888  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000472717225726  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.723, 0.685\n",
      "Loss  0.000360917966722  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474445906468  SSIM  0.984, 0.947, 0.901, 0.857, 0.804, 0.76, 0.727, 0.689\n",
      "Loss  0.00036141781507  SSIM  0.984, 0.953, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473462427908  SSIM  0.984, 0.946, 0.9, 0.854, 0.798, 0.753, 0.72, 0.68\n",
      "Loss  0.000360755939633  SSIM  0.984, 0.953, 0.915, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000476870284474  SSIM  0.984, 0.947, 0.902, 0.857, 0.803, 0.758, 0.723, 0.682\n",
      "Loss  0.00036115603135  SSIM  0.984, 0.952, 0.915, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.00047671525256  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.761, 0.727, 0.689\n",
      "Loss  0.0003609770674  SSIM  0.984, 0.953, 0.914, 0.875, 0.84, 0.819, 0.762, 0.741\n",
      "Val loss  0.000474042835122  SSIM  0.984, 0.947, 0.901, 0.855, 0.8, 0.754, 0.721, 0.681\n",
      "Loss  0.000360964261691  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000475978609815  SSIM  0.984, 0.947, 0.901, 0.856, 0.802, 0.757, 0.722, 0.683\n",
      "Loss  0.000360910738248  SSIM  0.984, 0.952, 0.914, 0.875, 0.839, 0.819, 0.762, 0.74\n",
      "Val loss  0.000475600499543  SSIM  0.984, 0.947, 0.903, 0.859, 0.806, 0.76, 0.726, 0.686\n",
      "Loss  0.000360822592524  SSIM  0.984, 0.952, 0.915, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.00047361351084  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.76, 0.726, 0.688\n",
      "Loss  0.000360961437559  SSIM  0.984, 0.953, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000475045571104  SSIM  0.984, 0.947, 0.901, 0.857, 0.804, 0.76, 0.727, 0.688\n",
      "Loss  0.000360219544414  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000474809215637  SSIM  0.984, 0.946, 0.901, 0.855, 0.8, 0.754, 0.718, 0.676\n",
      "Loss  0.000360622802108  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.82, 0.762, 0.74\n",
      "Val loss  0.000476960708795  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.727, 0.688\n",
      "Loss  0.000360560178482  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.819, 0.762, 0.74\n",
      "Val loss  0.000473208054842  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000360833356813  SSIM  0.984, 0.953, 0.914, 0.875, 0.84, 0.82, 0.762, 0.74\n",
      "Val loss  0.00047794287093  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.724, 0.686\n",
      "Loss  0.000360640807047  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000476406111557  SSIM  0.984, 0.946, 0.9, 0.857, 0.804, 0.759, 0.724, 0.684\n",
      "Loss  0.000360863157452  SSIM  0.984, 0.952, 0.915, 0.875, 0.84, 0.819, 0.762, 0.741\n",
      "Val loss  0.000473621535231  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.759, 0.726, 0.688\n",
      "Loss  0.000360648803059  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.82, 0.763, 0.74\n",
      "Val loss  0.000473096572561  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.757, 0.724, 0.685\n",
      "Loss  0.000360364485341  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000472837097244  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.759, 0.726, 0.688\n",
      "Loss  0.000360445646423  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.74\n",
      "Val loss  0.00047347624728  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.76, 0.727, 0.688\n",
      "Loss  0.000360569283992  SSIM  0.984, 0.953, 0.914, 0.875, 0.84, 0.82, 0.763, 0.74\n",
      "Val loss  0.000472721655387  SSIM  0.984, 0.947, 0.901, 0.856, 0.802, 0.757, 0.722, 0.683\n",
      "Loss  0.000360664684664  SSIM  0.984, 0.952, 0.915, 0.875, 0.84, 0.82, 0.763, 0.74\n",
      "Val loss  0.000474576763983  SSIM  0.984, 0.947, 0.901, 0.857, 0.804, 0.759, 0.723, 0.683\n",
      "Loss  0.000360302008642  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000474375668506  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.724, 0.683\n",
      "Loss  0.000360404676785  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.74\n",
      "Val loss  0.000477426349127  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.761, 0.729, 0.692\n",
      "Loss  0.000360620250749  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000477889871225  SSIM  0.984, 0.947, 0.901, 0.857, 0.802, 0.758, 0.725, 0.687\n",
      "Loss  0.000360588864643  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000479502816743  SSIM  0.984, 0.946, 0.9, 0.855, 0.8, 0.755, 0.72, 0.679\n",
      "Loss  0.000360323417876  SSIM  0.984, 0.952, 0.914, 0.875, 0.84, 0.82, 0.763, 0.74\n",
      "Val loss  0.0004756860864  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.724, 0.684\n",
      "Loss  0.000360584380647  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473425478616  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000359796871998  SSIM  0.984, 0.952, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000471922775614  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.684\n",
      "Loss  0.000360371500287  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000471785831032  SSIM  0.984, 0.947, 0.902, 0.857, 0.803, 0.757, 0.722, 0.682\n",
      "Loss  0.000360348796255  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000477075597562  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.761, 0.726, 0.687\n",
      "Loss  0.000360227798117  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000475366548577  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.761, 0.728, 0.69\n",
      "Loss  0.000360164451924  SSIM  0.984, 0.952, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473087537044  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.725, 0.685\n",
      "Loss  0.000360065830735  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000476111497323  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.762, 0.729, 0.691\n",
      "Loss  0.000359728755428  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000472712853632  SSIM  0.984, 0.947, 0.902, 0.857, 0.804, 0.76, 0.726, 0.687\n",
      "Loss  0.000360231912966  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000474246489641  SSIM  0.984, 0.947, 0.903, 0.859, 0.805, 0.761, 0.726, 0.686\n",
      "Loss  0.000359776986126  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000474593327323  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.727, 0.688\n",
      "Loss  0.000359892214071  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473642379977  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.762, 0.728, 0.69\n",
      "Loss  0.000360098799748  SSIM  0.984, 0.953, 0.915, 0.875, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473300896003  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.759, 0.725, 0.685\n",
      "Loss  0.000359735808357  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473171910737  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.759, 0.724, 0.684\n",
      "Loss  0.000360088968787  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473237454076  SSIM  0.984, 0.947, 0.901, 0.857, 0.803, 0.758, 0.724, 0.685\n",
      "Loss  0.000359827341449  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473543960659  SSIM  0.984, 0.947, 0.902, 0.859, 0.807, 0.763, 0.729, 0.69\n",
      "Loss  0.000359799205586  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000477342185448  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.763, 0.728, 0.689\n",
      "Loss  0.00035978643214  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000472141574777  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.761, 0.727, 0.689\n",
      "Loss  0.000360428398852  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000477000863291  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.759, 0.724, 0.685\n",
      "Loss  0.000359552809813  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.821, 0.763, 0.741\n",
      "Val loss  0.000479937725817  SSIM  0.984, 0.947, 0.902, 0.856, 0.802, 0.757, 0.723, 0.683\n",
      "Loss  0.00035944662398  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.742\n",
      "Val loss  0.000476050411176  SSIM  0.984, 0.947, 0.903, 0.86, 0.808, 0.764, 0.73, 0.693\n",
      "Loss  0.000359683027107  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473778705113  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.726, 0.686\n",
      "Loss  0.000359488412422  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000473819316307  SSIM  0.984, 0.947, 0.902, 0.858, 0.804, 0.758, 0.724, 0.685\n",
      "Loss  0.000359917705383  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000472651247401  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.725, 0.685\n",
      "Loss  0.000359479621082  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.741\n",
      "Val loss  0.000472944527981  SSIM  0.984, 0.947, 0.902, 0.858, 0.806, 0.761, 0.727, 0.688\n",
      "Loss  0.00035973611593  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.82, 0.764, 0.741\n",
      "Val loss  0.000473338286451  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.726, 0.687\n",
      "Loss  0.000359463601614  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.764, 0.742\n",
      "Val loss  0.000472781262826  SSIM  0.984, 0.947, 0.903, 0.859, 0.806, 0.761, 0.728, 0.69\n",
      "Loss  0.000359420429333  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.821, 0.763, 0.741\n",
      "Val loss  0.000475436883338  SSIM  0.984, 0.947, 0.902, 0.859, 0.806, 0.761, 0.726, 0.686\n",
      "Loss  0.000360135838454  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.763, 0.742\n",
      "Val loss  0.000473190758727  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.762, 0.727, 0.688\n",
      "Loss  0.000359311830212  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000473767693096  SSIM  0.984, 0.948, 0.903, 0.86, 0.809, 0.765, 0.73, 0.692\n",
      "Loss  0.000359266511812  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000473868078785  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.761, 0.727, 0.687\n",
      "Loss  0.000359539798763  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.821, 0.763, 0.741\n",
      "Val loss  0.000474067647592  SSIM  0.984, 0.948, 0.904, 0.861, 0.81, 0.765, 0.73, 0.692\n",
      "Loss  0.000359561844015  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.82, 0.764, 0.742\n",
      "Val loss  0.000475219415035  SSIM  0.984, 0.948, 0.903, 0.859, 0.806, 0.762, 0.728, 0.69\n",
      "Loss  0.000359330257018  SSIM  0.984, 0.953, 0.915, 0.876, 0.84, 0.82, 0.764, 0.742\n",
      "Val loss  0.000476039208763  SSIM  0.984, 0.947, 0.903, 0.859, 0.806, 0.762, 0.728, 0.689\n",
      "Loss  0.00035984605226  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.82, 0.764, 0.741\n",
      "Val loss  0.00047520172206  SSIM  0.984, 0.947, 0.903, 0.859, 0.807, 0.762, 0.728, 0.69\n",
      "Loss  0.000359423435076  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.82, 0.764, 0.742\n",
      "Val loss  0.000473637737276  SSIM  0.984, 0.948, 0.903, 0.858, 0.806, 0.761, 0.726, 0.686\n",
      "Loss  0.000359525409294  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.741\n",
      "Val loss  0.000476767465356  SSIM  0.984, 0.947, 0.902, 0.857, 0.803, 0.758, 0.722, 0.682\n",
      "Loss  0.000359254957038  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.00047253304784  SSIM  0.984, 0.947, 0.903, 0.859, 0.807, 0.762, 0.727, 0.688\n",
      "Loss  0.000359152160786  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.741\n",
      "Val loss  0.00047480992577  SSIM  0.984, 0.948, 0.903, 0.859, 0.806, 0.761, 0.728, 0.689\n",
      "Loss  0.000359478646496  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000475848227798  SSIM  0.984, 0.948, 0.903, 0.86, 0.808, 0.763, 0.73, 0.692\n",
      "Loss  0.000359195470284  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000478404690453  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.765, 0.732, 0.695\n",
      "Loss  0.000359315753002  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.00047834682645  SSIM  0.984, 0.947, 0.902, 0.857, 0.804, 0.759, 0.725, 0.685\n",
      "Loss  0.000358790888758  SSIM  0.984, 0.953, 0.915, 0.877, 0.841, 0.821, 0.764, 0.743\n",
      "Val loss  0.000474093221535  SSIM  0.984, 0.948, 0.903, 0.86, 0.809, 0.764, 0.73, 0.692\n",
      "Loss  0.000359255101773  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000473195221915  SSIM  0.984, 0.947, 0.903, 0.857, 0.804, 0.759, 0.725, 0.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000359970166859  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000477445518482  SSIM  0.984, 0.948, 0.903, 0.86, 0.808, 0.763, 0.73, 0.692\n",
      "Loss  0.000359120951817  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.764, 0.742\n",
      "Val loss  0.000471800025902  SSIM  0.984, 0.948, 0.903, 0.86, 0.808, 0.764, 0.73, 0.692\n",
      "Loss  0.000358979475561  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.765, 0.743\n",
      "Val loss  0.000475208941207  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.727, 0.689\n",
      "Loss  0.000359354454063  SSIM  0.984, 0.953, 0.915, 0.877, 0.841, 0.821, 0.765, 0.742\n",
      "Val loss  0.000476077596075  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.764, 0.731, 0.693\n",
      "Loss  0.000358723923635  SSIM  0.984, 0.953, 0.915, 0.876, 0.841, 0.821, 0.765, 0.742\n",
      "Val loss  0.000473827067588  SSIM  0.984, 0.948, 0.903, 0.86, 0.808, 0.764, 0.731, 0.693\n",
      "Loss  0.000358575387486  SSIM  0.984, 0.953, 0.915, 0.877, 0.841, 0.821, 0.765, 0.743\n",
      "Val loss  0.000474282966927  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.762, 0.727, 0.688\n",
      "Loss  0.000359032865338  SSIM  0.984, 0.953, 0.915, 0.877, 0.841, 0.822, 0.765, 0.743\n",
      "Val loss  0.000473514377081  SSIM  0.984, 0.948, 0.903, 0.86, 0.809, 0.764, 0.731, 0.692\n",
      "Loss  0.000358937535742  SSIM  0.984, 0.953, 0.915, 0.877, 0.841, 0.821, 0.765, 0.743\n",
      "Val loss  0.00047423689242  SSIM  0.984, 0.948, 0.904, 0.861, 0.809, 0.765, 0.732, 0.694\n",
      "Loss  0.000358931954402  SSIM  0.984, 0.953, 0.915, 0.877, 0.841, 0.821, 0.765, 0.743\n",
      "Val loss  0.000475788691372  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.762, 0.729, 0.69\n",
      "Loss  0.00035853761325  SSIM  0.984, 0.953, 0.916, 0.877, 0.841, 0.821, 0.765, 0.743\n",
      "Val loss  0.000474157726683  SSIM  0.984, 0.948, 0.904, 0.86, 0.808, 0.763, 0.729, 0.69\n",
      "Loss  0.000359064054313  SSIM  0.984, 0.953, 0.916, 0.877, 0.841, 0.822, 0.765, 0.743\n",
      "Val loss  0.000474656942708  SSIM  0.984, 0.947, 0.902, 0.858, 0.805, 0.76, 0.727, 0.689\n",
      "Loss  0.000358699747346  SSIM  0.984, 0.953, 0.916, 0.877, 0.841, 0.822, 0.765, 0.743\n",
      "Val loss  0.000475192085258  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.762, 0.729, 0.69\n",
      "Loss  0.000358924831435  SSIM  0.984, 0.953, 0.916, 0.877, 0.841, 0.822, 0.765, 0.743\n",
      "Val loss  0.000475837989885  SSIM  0.984, 0.948, 0.903, 0.859, 0.807, 0.761, 0.727, 0.686\n",
      "Loss  0.000358688376719  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.765, 0.743\n",
      "Val loss  0.000473466588766  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.765, 0.731, 0.693\n",
      "Loss  0.00035873765527  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.765, 0.743\n",
      "Val loss  0.000473159712157  SSIM  0.984, 0.947, 0.902, 0.858, 0.806, 0.761, 0.727, 0.688\n",
      "Loss  0.000358611338603  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.765, 0.743\n",
      "Val loss  0.000471259200771  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.764, 0.731, 0.692\n",
      "saving the model  0.000471259200771\n",
      "Loss  0.00035892767976  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.766, 0.743\n",
      "Val loss  0.000472282504488  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.765, 0.731, 0.692\n",
      "Loss  0.00035875592611  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.765, 0.743\n",
      "Val loss  0.000473983789678  SSIM  0.984, 0.948, 0.905, 0.861, 0.81, 0.765, 0.731, 0.692\n",
      "Loss  0.000358573020043  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.766, 0.744\n",
      "Val loss  0.000475667522638  SSIM  0.984, 0.947, 0.903, 0.858, 0.806, 0.761, 0.726, 0.685\n",
      "Loss  0.000358351845576  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.766, 0.743\n",
      "Val loss  0.000473384018813  SSIM  0.984, 0.948, 0.903, 0.86, 0.809, 0.764, 0.729, 0.689\n",
      "Loss  0.0003585555449  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.766, 0.743\n",
      "Val loss  0.000475047326006  SSIM  0.984, 0.948, 0.904, 0.861, 0.81, 0.765, 0.731, 0.693\n",
      "Loss  0.000358651077393  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.766, 0.744\n",
      "Val loss  0.000472822698124  SSIM  0.984, 0.948, 0.904, 0.86, 0.81, 0.765, 0.732, 0.693\n",
      "Loss  0.000358368800587  SSIM  0.984, 0.953, 0.916, 0.877, 0.842, 0.822, 0.766, 0.744\n",
      "Val loss  0.0004756510242  SSIM  0.984, 0.948, 0.904, 0.86, 0.808, 0.763, 0.73, 0.692\n",
      "Loss  0.000358744147384  SSIM  0.984, 0.953, 0.916, 0.878, 0.842, 0.822, 0.766, 0.744\n",
      "Val loss  0.000473149394093  SSIM  0.984, 0.948, 0.904, 0.86, 0.81, 0.764, 0.73, 0.691\n",
      "Loss  0.000358376252805  SSIM  0.984, 0.953, 0.916, 0.878, 0.842, 0.822, 0.766, 0.744\n",
      "Val loss  0.000474168543064  SSIM  0.984, 0.948, 0.905, 0.863, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000358205746653  SSIM  0.984, 0.953, 0.916, 0.878, 0.842, 0.823, 0.767, 0.745\n",
      "Val loss  0.00047698077769  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.763, 0.729, 0.688\n",
      "Loss  0.000358544747356  SSIM  0.984, 0.953, 0.916, 0.878, 0.842, 0.823, 0.767, 0.745\n",
      "Val loss  0.000473574546457  SSIM  0.984, 0.948, 0.905, 0.861, 0.81, 0.765, 0.733, 0.694\n",
      "Loss  0.000358415903476  SSIM  0.984, 0.953, 0.916, 0.878, 0.842, 0.823, 0.767, 0.744\n",
      "Val loss  0.000472709502501  SSIM  0.984, 0.948, 0.905, 0.861, 0.811, 0.766, 0.733, 0.693\n",
      "Loss  0.000358303806683  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.767, 0.745\n",
      "Val loss  0.000473651834414  SSIM  0.984, 0.948, 0.905, 0.862, 0.811, 0.766, 0.734, 0.695\n",
      "Loss  0.000358264835501  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.767, 0.745\n",
      "Val loss  0.000473477714171  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.735, 0.697\n",
      "Loss  0.000358019925822  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.745\n",
      "Val loss  0.000472051329096  SSIM  0.984, 0.948, 0.904, 0.861, 0.81, 0.765, 0.733, 0.694\n",
      "Loss  0.000358500923537  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.746\n",
      "Val loss  0.000476422017091  SSIM  0.984, 0.948, 0.904, 0.86, 0.809, 0.764, 0.73, 0.69\n",
      "Loss  0.000357866750379  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.746\n",
      "Val loss  0.000473315853451  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.736, 0.698\n",
      "Loss  0.000358035982188  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.746\n",
      "Val loss  0.000473137181951  SSIM  0.984, 0.947, 0.904, 0.86, 0.811, 0.765, 0.732, 0.692\n",
      "Loss  0.000358263350929  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.745\n",
      "Val loss  0.000472964145942  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.735, 0.696\n",
      "Loss  0.000358206975149  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.746\n",
      "Val loss  0.000481301607913  SSIM  0.984, 0.948, 0.904, 0.86, 0.81, 0.765, 0.732, 0.692\n",
      "Loss  0.000358260053363  SSIM  0.984, 0.953, 0.916, 0.878, 0.843, 0.823, 0.768, 0.746\n",
      "Val loss  0.000473084666766  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.735, 0.696\n",
      "Loss  0.00035784809457  SSIM  0.984, 0.953, 0.917, 0.878, 0.843, 0.823, 0.768, 0.746\n",
      "Val loss  0.00047439230181  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000357885216183  SSIM  0.984, 0.953, 0.916, 0.879, 0.843, 0.824, 0.768, 0.746\n",
      "Val loss  0.000473050352768  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.736, 0.698\n",
      "Loss  0.000358164424657  SSIM  0.984, 0.953, 0.917, 0.879, 0.843, 0.824, 0.769, 0.746\n",
      "Val loss  0.000473319782061  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000358319799215  SSIM  0.984, 0.953, 0.916, 0.879, 0.843, 0.823, 0.769, 0.746\n",
      "Val loss  0.000475295517826  SSIM  0.984, 0.948, 0.904, 0.861, 0.811, 0.766, 0.735, 0.697\n",
      "Loss  0.000358051999419  SSIM  0.984, 0.953, 0.917, 0.879, 0.843, 0.824, 0.769, 0.747\n",
      "Val loss  0.000475416101224  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.735, 0.697\n",
      "Loss  0.000358104012115  SSIM  0.984, 0.953, 0.917, 0.879, 0.843, 0.824, 0.769, 0.746\n",
      "Val loss  0.000472930017568  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000358059851596  SSIM  0.984, 0.953, 0.917, 0.879, 0.843, 0.824, 0.769, 0.747\n",
      "Val loss  0.000473796086852  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.734, 0.695\n",
      "Loss  0.000357597028624  SSIM  0.984, 0.953, 0.917, 0.879, 0.843, 0.824, 0.769, 0.747\n",
      "Val loss  0.000474110201816  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.736, 0.697\n",
      "Loss  0.000357767573311  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000473300793208  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.769, 0.738, 0.701\n",
      "Loss  0.000358363975785  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000472526579048  SSIM  0.984, 0.948, 0.905, 0.861, 0.812, 0.767, 0.733, 0.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000357914031489  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000475587363995  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.771, 0.74, 0.703\n",
      "Loss  0.000357882389952  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000472388846742  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000357759987174  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000475333239301  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000357788693283  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000474440214632  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.696\n",
      "Loss  0.000357852551515  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000472058916814  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000357583345211  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.00047363940865  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.738, 0.7\n",
      "Loss  0.000358353698189  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473611887952  SSIM  0.984, 0.948, 0.906, 0.863, 0.813, 0.768, 0.737, 0.698\n",
      "Loss  0.000357226121821  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000475867356348  SSIM  0.984, 0.948, 0.905, 0.861, 0.811, 0.765, 0.734, 0.694\n",
      "Loss  0.000357705884122  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.769, 0.747\n",
      "Val loss  0.000474207778636  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.697\n",
      "Loss  0.000357846128586  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000475828868744  SSIM  0.984, 0.948, 0.905, 0.861, 0.811, 0.766, 0.733, 0.693\n",
      "Loss  0.000357953374517  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473197683692  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.699\n",
      "Loss  0.000357671539688  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000473110803694  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.7\n",
      "Loss  0.000357394814495  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000471790401323  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.737, 0.699\n",
      "Loss  0.000357819128325  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000475040371297  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.699\n",
      "Loss  0.000357358793108  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000473454504216  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.771, 0.739, 0.701\n",
      "Loss  0.000357468286815  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000472795173817  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.77, 0.738, 0.699\n",
      "Loss  0.000357628047473  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473771272984  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.7\n",
      "Loss  0.000357438100401  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473209455202  SSIM  0.984, 0.948, 0.905, 0.861, 0.812, 0.766, 0.733, 0.694\n",
      "Loss  0.000357526459999  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473665232887  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.701\n",
      "Loss  0.000357532024734  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473629230342  SSIM  0.984, 0.948, 0.905, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000357608278223  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473374328401  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000357157265779  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000474927096278  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000357337384289  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000472846288292  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.77, 0.739, 0.7\n",
      "Loss  0.000357542656949  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.0004772417809  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.000357156603263  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000474855092529  SSIM  0.984, 0.948, 0.904, 0.861, 0.812, 0.766, 0.733, 0.693\n",
      "Loss  0.000357163053221  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000475212464982  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000357687320075  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000478308337217  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.771, 0.741, 0.704\n",
      "Loss  0.000356950731622  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000476545212732  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.698\n",
      "Loss  0.000357601108972  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000476310874335  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.739, 0.701\n",
      "Loss  0.000357308311846  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000475187651231  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.735, 0.696\n",
      "Loss  0.00035723911027  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473857054254  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000357143789968  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.747\n",
      "Val loss  0.000473612728762  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000357062488371  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000471756727668  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.000357247391094  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474484381266  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.7\n",
      "Loss  0.000357304855939  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000484642989875  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.77, 0.738, 0.701\n",
      "Loss  0.000357127448513  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000472290382197  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.736, 0.697\n",
      "Loss  0.000356975155225  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000474399120605  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.699\n",
      "Loss  0.000357435533175  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000473395199399  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000356595085582  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473397660069  SSIM  0.984, 0.948, 0.906, 0.863, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.00035698374157  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000478870171588  SSIM  0.984, 0.948, 0.906, 0.864, 0.817, 0.772, 0.741, 0.704\n",
      "Loss  0.000357217898998  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000474212757486  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000357271096925  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474225155078  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.771, 0.74, 0.702\n",
      "Loss  0.000356710291365  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000475750304118  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.74, 0.703\n",
      "Loss  0.000356718154657  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473404840275  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000356872894812  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000476452277973  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.735, 0.697\n",
      "Loss  0.000357256474487  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000472431925242  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.771, 0.739, 0.701\n",
      "Loss  0.000356532442308  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000473716632114  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000356789595844  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000475875374395  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.77, 0.738, 0.699\n",
      "Loss  0.000357143180148  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000476049438759  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.696\n",
      "Loss  0.000356758247467  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000474071723991  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.000356664725744  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474760926212  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000356664819374  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473288798647  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.77, 0.738, 0.701\n",
      "Loss  0.000356778109424  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474232315435  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000356634663539  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000474600275338  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.77, 0.739, 0.701\n",
      "Loss  0.000356263241401  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000476161171973  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000356636353499  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473939264077  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000356594357801  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000475749765756  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000356695691896  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000472213140165  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000356274755655  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473891658883  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.77, 0.739, 0.702\n",
      "Loss  0.000357190483143  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473852723022  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.737, 0.698\n",
      "Loss  0.000356455487306  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474888668745  SSIM  0.984, 0.948, 0.906, 0.862, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000356350105519  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474648280477  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.771, 0.74, 0.703\n",
      "Loss  0.000356631314938  SSIM  0.984, 0.954, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000472297081375  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000356406290233  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473789591284  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000356586370668  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474388772331  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.7\n",
      "Loss  0.000356601027929  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473951604217  SSIM  0.984, 0.948, 0.905, 0.863, 0.815, 0.77, 0.737, 0.699\n",
      "Loss  0.000356344433708  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473628455366  SSIM  0.984, 0.949, 0.906, 0.863, 0.813, 0.769, 0.737, 0.698\n",
      "Loss  0.000356521047259  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.824, 0.77, 0.748\n",
      "Val loss  0.000475185978808  SSIM  0.984, 0.948, 0.905, 0.861, 0.811, 0.766, 0.734, 0.695\n",
      "Loss  0.000356029294203  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473437057575  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.00035651744837  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.0004760252696  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000356664920269  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000478604886972  SSIM  0.984, 0.948, 0.905, 0.861, 0.813, 0.768, 0.735, 0.696\n",
      "Loss  0.000356079393887  SSIM  0.984, 0.954, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474965301575  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.767, 0.736, 0.699\n",
      "Loss  0.000356519232743  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474417039426  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.738, 0.7\n",
      "Loss  0.000356213542805  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473429089005  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.771, 0.739, 0.7\n",
      "Loss  0.000356132159939  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000475613421004  SSIM  0.984, 0.948, 0.906, 0.863, 0.813, 0.768, 0.736, 0.696\n",
      "Loss  0.000356398483372  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000472915537481  SSIM  0.984, 0.948, 0.906, 0.862, 0.812, 0.767, 0.736, 0.698\n",
      "Loss  0.000355959125006  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473261772131  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.736, 0.698\n",
      "Loss  0.000355933591653  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000473397056281  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.699\n",
      "Loss  0.000356706519352  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.000474580650334  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.772, 0.74, 0.703\n",
      "Loss  0.000356082372902  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473724560987  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000355908757507  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000475962860219  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.772, 0.741, 0.704\n",
      "Loss  0.000356140695041  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474614025152  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000355909196509  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.00047293176956  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.74, 0.702\n",
      "Loss  0.000355760329378  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473722972674  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.771, 0.74, 0.702\n",
      "Loss  0.00035654311751  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.77, 0.748\n",
      "Val loss  0.00047451127047  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000355842790377  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474272214691  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.702\n",
      "Loss  0.000355787384825  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473582098726  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000355688293224  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000475310678303  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000356415781402  SSIM  0.984, 0.953, 0.917, 0.879, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.00047380601702  SSIM  0.984, 0.948, 0.906, 0.862, 0.812, 0.767, 0.735, 0.697\n",
      "Loss  0.000355697292603  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.00047409241792  SSIM  0.984, 0.948, 0.906, 0.862, 0.813, 0.768, 0.737, 0.698\n",
      "Loss  0.000356224521914  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000479040487669  SSIM  0.984, 0.948, 0.905, 0.861, 0.81, 0.765, 0.733, 0.695\n",
      "Loss  0.000355491993814  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475010738708  SSIM  0.984, 0.948, 0.905, 0.861, 0.812, 0.768, 0.736, 0.699\n",
      "Loss  0.000355848789133  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.00047420716699  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000356045615963  SSIM  0.984, 0.954, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000472287420358  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000355855977779  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474443024723  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.771, 0.739, 0.701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000355767985415  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473441450391  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000355903819587  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475185614079  SSIM  0.984, 0.948, 0.904, 0.861, 0.812, 0.767, 0.735, 0.695\n",
      "Loss  0.00035560155802  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474195624061  SSIM  0.984, 0.949, 0.905, 0.862, 0.814, 0.769, 0.736, 0.698\n",
      "Loss  0.000355882249337  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000480281739496  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.7\n",
      "Loss  0.000355979675055  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473788166302  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.739, 0.7\n",
      "Loss  0.000355605506478  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473040046578  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.737, 0.698\n",
      "Loss  0.000355737114968  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000476164508436  SSIM  0.984, 0.948, 0.905, 0.862, 0.812, 0.766, 0.733, 0.693\n",
      "Loss  0.00035561505265  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473805584712  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000355438989143  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000471759656968  SSIM  0.984, 0.949, 0.906, 0.863, 0.813, 0.768, 0.737, 0.699\n",
      "Loss  0.000355318010908  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473758454318  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.697\n",
      "Loss  0.000355460188655  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047623494413  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.699\n",
      "Loss  0.000355725025209  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000472297104832  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.000355166115388  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.0004747285255  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.735, 0.696\n",
      "Loss  0.000355562965119  SSIM  0.984, 0.953, 0.917, 0.88, 0.844, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473083909485  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.000355357231617  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475452380953  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.769, 0.737, 0.699\n",
      "Loss  0.000355854631693  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474728020024  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.699\n",
      "Loss  0.000355399582072  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000475427903293  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000355348268906  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000472967358015  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000355525045318  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000476346409123  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000355251658925  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474708177906  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000355430288712  SSIM  0.984, 0.954, 0.917, 0.88, 0.844, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474670440075  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000355471199681  SSIM  0.984, 0.954, 0.917, 0.88, 0.844, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473264825705  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.77, 0.739, 0.702\n",
      "Loss  0.000355262454532  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473408965627  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.771, 0.739, 0.702\n",
      "Loss  0.000355328651033  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474196795025  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.699\n",
      "Loss  0.000355474407721  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474393499549  SSIM  0.984, 0.948, 0.906, 0.862, 0.812, 0.767, 0.734, 0.695\n",
      "Loss  0.000355454954808  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474946776696  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.771, 0.741, 0.705\n",
      "Loss  0.000355296952419  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000474308988778  SSIM  0.984, 0.948, 0.906, 0.862, 0.813, 0.769, 0.736, 0.697\n",
      "Loss  0.000355196725584  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047224031447  SSIM  0.984, 0.948, 0.906, 0.862, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000355371862726  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473038270546  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000355231780894  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473926331091  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000355221432406  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000477502523689  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.769, 0.737, 0.699\n",
      "Loss  0.000355087122334  SSIM  0.984, 0.954, 0.917, 0.88, 0.844, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047387557372  SSIM  0.984, 0.948, 0.906, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000355215466582  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000476958700514  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.771, 0.74, 0.703\n",
      "Loss  0.000355010480786  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000473272499628  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.7\n",
      "Loss  0.000355206868084  SSIM  0.984, 0.953, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473130924045  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.771, 0.74, 0.703\n",
      "Loss  0.000354824685231  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475419890136  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.771, 0.739, 0.701\n",
      "Loss  0.0003548002691  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473424485594  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.699\n",
      "Loss  0.00035555705718  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.748\n",
      "Val loss  0.000476765131694  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000354892816145  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474509328371  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.701\n",
      "Loss  0.000355327629955  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474294245592  SSIM  0.984, 0.948, 0.906, 0.863, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000355182584258  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475368234678  SSIM  0.984, 0.948, 0.905, 0.861, 0.811, 0.766, 0.735, 0.698\n",
      "Loss  0.000354926602509  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047346014512  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.699\n",
      "Loss  0.00035476363568  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474765814492  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000354765194487  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474164536688  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.768, 0.737, 0.698\n",
      "Loss  0.0003550265015  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473486159346  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.77, 0.737, 0.699\n",
      "Loss  0.00035478347702  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475844597269  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.772, 0.741, 0.704\n",
      "Loss  0.000354648850726  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047955306631  SSIM  0.984, 0.948, 0.906, 0.865, 0.817, 0.772, 0.742, 0.705\n",
      "Loss  0.000354931680943  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000473187959986  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.77, 0.739, 0.702\n",
      "Loss  0.000354908616019  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475156065891  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.697\n",
      "Loss  0.000355069471783  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475839203456  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.771, 0.739, 0.7\n",
      "Loss  0.000354638168352  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047461280023  SSIM  0.984, 0.948, 0.906, 0.862, 0.813, 0.768, 0.737, 0.698\n",
      "Loss  0.000354980127728  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475755449617  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000354539575344  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474995759141  SSIM  0.984, 0.948, 0.905, 0.861, 0.812, 0.767, 0.736, 0.698\n",
      "Loss  0.000354955595897  SSIM  0.984, 0.953, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000476684104244  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.771, 0.74, 0.703\n",
      "Loss  0.000354727654467  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047573068866  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000354551166925  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474499524396  SSIM  0.984, 0.948, 0.906, 0.864, 0.815, 0.771, 0.74, 0.702\n",
      "Loss  0.000354904805793  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473090420419  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.771, 0.739, 0.701\n",
      "Loss  0.000354447581457  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473389698484  SSIM  0.984, 0.948, 0.905, 0.861, 0.812, 0.767, 0.735, 0.696\n",
      "Loss  0.000354657354464  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475670727552  SSIM  0.984, 0.948, 0.906, 0.863, 0.813, 0.768, 0.736, 0.696\n",
      "Loss  0.000354554135907  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474393769342  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000354716928114  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473732715996  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000354393466274  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473636785639  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.771, 0.74, 0.703\n",
      "Loss  0.00035429070367  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473863967054  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000354781131648  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473854146549  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000354709970638  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475495067076  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000354568627516  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474321170535  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000354299224635  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474019215966  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.771, 0.739, 0.701\n",
      "Loss  0.000354366163353  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474747180182  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.741, 0.704\n",
      "Loss  0.0003548065975  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474558151851  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000354327280912  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475727509474  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000354630364051  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000476825393387  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.77, 0.74, 0.703\n",
      "Loss  0.000354563268814  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474336848827  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000354116860172  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047590381169  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000354453086785  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473863755877  SSIM  0.984, 0.948, 0.906, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.00035440525833  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475055827177  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.772, 0.741, 0.704\n",
      "Loss  0.000354160055053  SSIM  0.984, 0.953, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473136358603  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.00035421226684  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474695820536  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.74, 0.702\n",
      "Loss  0.000354692515627  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473746837059  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.77, 0.738, 0.7\n",
      "Loss  0.000354228878578  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.772, 0.749\n",
      "Val loss  0.000479333192518  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.697\n",
      "Loss  0.000354227731975  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475209537544  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.735, 0.695\n",
      "Loss  0.000354485255789  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474530715612  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.769, 0.738, 0.7\n",
      "Loss  0.000354063627236  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047509758122  SSIM  0.984, 0.948, 0.906, 0.862, 0.813, 0.768, 0.737, 0.699\n",
      "Loss  0.00035461893351  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000473598355136  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.769, 0.738, 0.699\n",
      "Loss  0.000354547113997  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473605343956  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.00035384673463  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000476293856278  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.698\n",
      "Loss  0.000354052883241  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000476464165957  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000354139962755  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000473677771748  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.769, 0.739, 0.702\n",
      "Loss  0.0003539142447  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.75\n",
      "Val loss  0.000474200952915  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.772, 0.741, 0.703\n",
      "Loss  0.000353936603361  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474586631637  SSIM  0.984, 0.948, 0.906, 0.863, 0.813, 0.768, 0.737, 0.699\n",
      "Loss  0.000354177069978  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473522508517  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000354176666168  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473887924454  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000354078198708  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047460086568  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000353946063559  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474207230436  SSIM  0.984, 0.948, 0.904, 0.861, 0.811, 0.766, 0.733, 0.694\n",
      "Loss  0.000354217219104  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474222915189  SSIM  0.984, 0.948, 0.905, 0.86, 0.811, 0.765, 0.732, 0.692\n",
      "Loss  0.000353880158972  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473385755322  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0.000354176604524  SSIM  0.984, 0.953, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474747765809  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.735, 0.697\n",
      "Loss  0.000353919218411  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000475679186289  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000354328565885  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000474280814058  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.00035370438053  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000473069260071  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.702\n",
      "Loss  0.000354081981053  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473453654733  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.77, 0.74, 0.704\n",
      "Loss  0.000354357812352  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000472418335499  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.7\n",
      "Loss  0.000353644004334  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000474609296827  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.739, 0.702\n",
      "Loss  0.000353954426528  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475034743315  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000353719928871  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473879595054  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000353829174158  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000474808965111  SSIM  0.984, 0.948, 0.906, 0.863, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000353991008544  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.00047385172511  SSIM  0.984, 0.949, 0.906, 0.862, 0.814, 0.768, 0.736, 0.698\n",
      "Loss  0.000353831032514  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000473637121962  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.738, 0.701\n",
      "Loss  0.000353459924705  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.75\n",
      "Val loss  0.000472692897078  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.769, 0.738, 0.7\n",
      "Loss  0.000354006154574  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475329186011  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000353813099665  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000476160432154  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.7\n",
      "Loss  0.00035369402125  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.749\n",
      "Val loss  0.000475179542089  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.741, 0.704\n",
      "Loss  0.000353718094108  SSIM  0.984, 0.954, 0.917, 0.88, 0.845, 0.825, 0.771, 0.75\n",
      "Val loss  0.000475517023704  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.739, 0.702\n",
      "Loss  0.00035357680864  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474299016059  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000353697436107  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000473642233701  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.739, 0.701\n",
      "Loss  0.000353682498001  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474939957843  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.739, 0.7\n",
      "Loss  0.000353918312526  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.75\n",
      "Val loss  0.000474129400623  SSIM  0.984, 0.948, 0.905, 0.863, 0.815, 0.769, 0.738, 0.7\n",
      "Loss  0.000353887184226  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.75\n",
      "Val loss  0.000473450877646  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000353724582302  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.749\n",
      "Val loss  0.000476156706398  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.737, 0.698\n",
      "Loss  0.000353508423218  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474333765393  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.74, 0.702\n",
      "Loss  0.00035355793928  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474340173882  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000353338477949  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474062948837  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.697\n",
      "Loss  0.000353567591374  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473141703755  SSIM  0.984, 0.949, 0.906, 0.863, 0.816, 0.771, 0.74, 0.702\n",
      "Loss  0.000353154240209  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000472558998095  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.74, 0.702\n",
      "Loss  0.000353750372631  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.772, 0.75\n",
      "Val loss  0.000474347098323  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.737, 0.7\n",
      "Loss  0.000353486774027  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000473947156745  SSIM  0.984, 0.948, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.00035373234011  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000476485599414  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.699\n",
      "Loss  0.00035337167977  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474883642164  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000353593876261  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000475635415001  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000353466948645  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473534676305  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.771, 0.74, 0.702\n",
      "Loss  0.000353301550608  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473546206835  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.738, 0.701\n",
      "Loss  0.000353492288165  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473534872523  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.74, 0.702\n",
      "Loss  0.000353240333191  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473482033063  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.701\n",
      "Loss  0.000353592460251  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474193385686  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.738, 0.699\n",
      "Loss  0.00035307458351  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000475065364968  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.768, 0.738, 0.7\n",
      "Loss  0.000353361501731  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.00047412327514  SSIM  0.984, 0.948, 0.905, 0.863, 0.815, 0.77, 0.738, 0.7\n",
      "Loss  0.000353215475753  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.772, 0.75\n",
      "Val loss  0.000474412289157  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.768, 0.738, 0.699\n",
      "Loss  0.000353327819536  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000476439684455  SSIM  0.984, 0.948, 0.905, 0.861, 0.811, 0.765, 0.732, 0.692\n",
      "Loss  0.000352935037769  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.0004727814332  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.738, 0.701\n",
      "Loss  0.00035337539286  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000476129887917  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.768, 0.737, 0.698\n",
      "Loss  0.000353078145916  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473881995713  SSIM  0.984, 0.949, 0.906, 0.864, 0.815, 0.77, 0.74, 0.703\n",
      "Loss  0.000353794755373  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.749\n",
      "Val loss  0.000475714423286  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.699\n",
      "Loss  0.000353076808846  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000473034806433  SSIM  0.984, 0.949, 0.906, 0.862, 0.813, 0.768, 0.737, 0.699\n",
      "Loss  0.000353519414019  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.771, 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss  0.000474575107219  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.699\n",
      "Loss  0.0003532216504  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474678120809  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.737, 0.698\n",
      "Loss  0.000353202650442  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473634733586  SSIM  0.984, 0.948, 0.906, 0.863, 0.816, 0.77, 0.738, 0.699\n",
      "Loss  0.000353305943718  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473423596937  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000353155975116  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000475358567899  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000353264891128  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.771, 0.75\n",
      "Val loss  0.000474110187148  SSIM  0.984, 0.949, 0.906, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000353001669743  SSIM  0.984, 0.954, 0.918, 0.88, 0.846, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473720170849  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.769, 0.738, 0.701\n",
      "Loss  0.000353234428181  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.825, 0.772, 0.75\n",
      "Val loss  0.000476219531032  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.771, 0.74, 0.704\n",
      "Loss  0.000353514793036  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000475469438941  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.74, 0.703\n",
      "Loss  0.000352714799882  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000475406345329  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.768, 0.736, 0.698\n",
      "Loss  0.000353007124475  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474997696234  SSIM  0.984, 0.949, 0.906, 0.864, 0.816, 0.771, 0.739, 0.702\n",
      "Loss  0.000353128940102  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000475567610003  SSIM  0.984, 0.948, 0.906, 0.863, 0.815, 0.77, 0.739, 0.703\n",
      "Loss  0.000352671386999  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.00047561876697  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.768, 0.738, 0.7\n",
      "Loss  0.000353219785034  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474247083999  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.768, 0.737, 0.699\n",
      "Loss  0.00035270971227  SSIM  0.984, 0.954, 0.918, 0.88, 0.846, 0.826, 0.772, 0.75\n",
      "Val loss  0.000476397670631  SSIM  0.984, 0.948, 0.905, 0.863, 0.814, 0.769, 0.737, 0.699\n",
      "Loss  0.000353350883884  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000475827676768  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.767, 0.735, 0.696\n",
      "Loss  0.000352725052271  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000475326865097  SSIM  0.984, 0.948, 0.905, 0.861, 0.813, 0.767, 0.733, 0.694\n",
      "Loss  0.000353009646799  SSIM  0.984, 0.954, 0.918, 0.88, 0.846, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474334638333  SSIM  0.984, 0.948, 0.906, 0.863, 0.814, 0.769, 0.738, 0.7\n",
      "Loss  0.000353049925762  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473660191929  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.77, 0.739, 0.701\n",
      "Loss  0.000352682041999  SSIM  0.984, 0.954, 0.918, 0.88, 0.845, 0.826, 0.772, 0.75\n",
      "Val loss  0.000474996151752  SSIM  0.984, 0.949, 0.906, 0.863, 0.815, 0.769, 0.738, 0.701\n",
      "Loss  0.000352759043032  SSIM  0.984, 0.954, 0.918, 0.88, 0.846, 0.826, 0.772, 0.75\n",
      "Val loss  0.000473539827857  SSIM  0.984, 0.948, 0.905, 0.862, 0.814, 0.768, 0.737, 0.699\n",
      "Loss  0.000352969205873  SSIM  0.984, 0.954, 0.918, 0.88, 0.846, 0.826, 0.772, 0.75\n",
      "Val loss  0.000472949344141  SSIM  0.984, 0.948, 0.905, 0.862, 0.813, 0.767, 0.735, 0.696\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For training the Pytorch Model for Imitating the result with volume Slice Quadratic Normal\n",
    "\n",
    "import torch.optim as optim\n",
    "from skimage import measure\n",
    "\n",
    "def get_ssim(pred, ground):\n",
    "    ssim_array = []\n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        t1 = np.min(ground[i].flatten())\n",
    "        t2 = np.max(ground[i].flatten())\n",
    "        reference_image = (ground[i, 0]-t1)*255/(t2-t1)\n",
    "        \n",
    "        t1 = np.min(pred[i, 0, :, :].flatten())\n",
    "        t2 = np.max(pred[i, 0, :, :].flatten())\n",
    "        distorted_image = (pred[i, 0]-t1)*255/(t2-t1)\n",
    "        \n",
    "        ssim_temp = measure.compare_ssim(distorted_image, reference_image, data_range=255)\n",
    "        ssim_array.append(ssim_temp)\n",
    "    \n",
    "    return ssim_array\n",
    "\n",
    "def get_ssim_distribution(ssim_input_array, value_array):\n",
    "    ssim_array = {}\n",
    "    ssim_array[0.025] = []\n",
    "    ssim_array[0.050] = []\n",
    "    ssim_array[0.075] = []\n",
    "    ssim_array[0.100] = []\n",
    "    ssim_array[0.125] = []\n",
    "    ssim_array[0.150] = []\n",
    "    ssim_array[0.175] = []\n",
    "    ssim_array[0.200] = []\n",
    "    \n",
    "    for i in range(len(value_array)):\n",
    "        value     = value_array[i]\n",
    "        ssim_temp = ssim_input_array[i]\n",
    "        \n",
    "        #print('value is ', value)\n",
    "        if -value < 0.025:\n",
    "            ssim_array[0.025].append(ssim_temp)\n",
    "            #mae_array[0.1].append(mae_temp)\n",
    "        elif -value < 0.050:\n",
    "            ssim_array[0.050].append(ssim_temp)\n",
    "            #mae_array[0.2].append(mae_temp)    \n",
    "        elif -value < 0.075:\n",
    "            ssim_array[0.075].append(ssim_temp)\n",
    "            #mae_array[0.3].append(mae_temp)    \n",
    "        elif  -value < 0.100:\n",
    "            ssim_array[0.100].append(ssim_temp)\n",
    "            #mae_array[0.4].append(mae_temp)    \n",
    "        elif -value < 0.125:\n",
    "            ssim_array[0.125].append(ssim_temp)\n",
    "            #mae_array[0.5].append(mae_temp)    \n",
    "        elif -value < 0.150:\n",
    "            ssim_array[0.150].append(ssim_temp)\n",
    "        elif -value < 0.175:\n",
    "            ssim_array[0.175].append(ssim_temp)\n",
    "        else:\n",
    "            ssim_array[0.200].append(ssim_temp)\n",
    "            #mae_array[0.6].append(mae_temp)\n",
    "    \n",
    "    mean_ssim_array = []\n",
    "    for k in ssim_array.keys():\n",
    "        mean_ssim_array.append(np.mean(ssim_array[k]))\n",
    "    mean_ssim_array = [str(round(x, 3)) for x in mean_ssim_array]\n",
    "    \n",
    "    return \", \".join(mean_ssim_array)\n",
    "\n",
    "model = MyUnet_half()#_half()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "mse_criterion  = nn.MSELoss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min   = 1000\n",
    "batch_size = 8\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    ssim_array = []\n",
    "    \n",
    "    ssim_z_array = []\n",
    "    value_array  = []\n",
    "    \n",
    "    idx     = np.random.permutation(len(x_array))\n",
    "    x_array = x_array[idx]\n",
    "    y_array = y_array[idx]\n",
    "    z_array = z_array[idx]\n",
    "    v_array = v_array[idx]\n",
    "    \n",
    "    for i in range(len(x_array)//batch_size):\n",
    "        x = x_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        v = v_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        v = torch.tensor(v, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, z)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape)\n",
    "        \n",
    "        loss1  = my_loss(output, y)\n",
    "        #loss2  = mse_criterion(output, y)\n",
    "        \n",
    "        loss   = loss1#+10*loss2\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        y      = y.data.cpu().numpy()\n",
    "        z      = -1*z.data.cpu().numpy()\n",
    "        \n",
    "        ssim_values = get_ssim(output, y)\n",
    "        \n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        for vt in ssim_values:\n",
    "            ssim_array.append(vt)\n",
    "        for vt in z:\n",
    "            value_array.append(vt)\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ssim_string = get_ssim_distribution(ssim_array, value_array)\n",
    "    \n",
    "    print('Loss ', np.mean(loss_array), ' SSIM ', ssim_string)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    ssim_array = []\n",
    "    value_array  = []\n",
    "    \n",
    "    for i in range(len(x_val_array)//batch_size):\n",
    "        x = x_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        v = v_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        v = torch.tensor(v, device=device).float()\n",
    "\n",
    "        output = model(x, z)\n",
    "\n",
    "        loss1 = my_loss(output, y)\n",
    "        #loss2 = mse_criterion(output, y)\n",
    "        loss  = loss1#+10*loss2\n",
    "        \n",
    "        output = output.data.cpu().numpy()\n",
    "        y      = y.data.cpu().numpy()\n",
    "        z      = -1*z.data.cpu().numpy()\n",
    "        \n",
    "        ssim_values = get_ssim(output, y)\n",
    "        \n",
    "        for vt in ssim_values:\n",
    "            ssim_array.append(vt)\n",
    "        for vt in z:\n",
    "            value_array.append(vt)\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "    \n",
    "    \n",
    "    ssim_string = get_ssim_distribution(ssim_array, value_array)\n",
    "        \n",
    "    val_loss = np.mean(loss_array)\n",
    "    print(\"Val loss \", val_loss, ' SSIM ', ssim_string)\n",
    "    \n",
    "    if val_loss < prev_min:\n",
    "        prev_min = val_loss\n",
    "        print('saving the model ', prev_min)\n",
    "        torch.save(model.state_dict(), \"unethalf-quadratic-normal.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19995117 -0.125      -0.0249939  ..., -0.19995117 -0.15002441\n",
      " -0.19995117]\n"
     ]
    }
   ],
   "source": [
    "#plt.plot(z_val_array.flatten())\n",
    "np.random.shuffle(z_val_array)\n",
    "print(z_val_array.flatten(), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unethalf-3.pt\n",
    "#Loss  0.000355252700749  SSIM  0.991, 0.972, 0.944, 0.886, 0.82, 0.789\n",
    "#Val loss  0.000408291269798  SSIM  0.991, 0.973, 0.945, 0.883, 0.805, 0.757\n",
    "#saving the model  0.000408291269798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM 63.5 (unet-nodropout1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     56
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For training the Pytorch Model for Imitating the result\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model = MyUnet()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min   = 1000\n",
    "batch_size = 4\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for i in range(len(x_array)//batch_size):\n",
    "        x = x_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_array[i*batch_size:(i+1)*batch_size, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, z)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape)\n",
    "        \n",
    "        loss = my_loss(output, y)\n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(np.mean(loss_array))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    for i in range(len(x_val_array)//batch_size):\n",
    "        x = x_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        y = y_val_array[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "        z = z_val_array[i*batch_size:(i+1)*batch_size, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "\n",
    "        output = model(x, z)\n",
    "\n",
    "        loss = my_loss(output, y)\n",
    "        loss_array.append(loss.item())\n",
    "    \n",
    "    val_loss = np.mean(loss_array)\n",
    "    print(\"Val loss \", val_loss)\n",
    "    \n",
    "    if val_loss < prev_min:\n",
    "        prev_min = val_loss\n",
    "        print('saving the model ', prev_min)\n",
    "        torch.save(model.state_dict(), \"unet_pytorch_new-3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyUnet      Train: 0.000334 Validation: 0.000413\n",
    "# MyUnet_half Train: 0.00035  Validation: 0.000417\n",
    "# MyUnet_half Train: 0.00035  Validation: 0.000417\n",
    "# MyUnetSlice2 Validation: 0.000410\n",
    "# MyUnetSlice3 Validation: 0.000414\n",
    "# MyUnetSlice4 Validation: 0.0004128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3d002b39e8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = out1.data.cpu().numpy()\n",
    "plt.imshow(np.concatenate([valx[5, 0, :, :], t1[0 , 0, :, :]]).T, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9d55e7d310>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#t1 = out1.data.cpu().numpy()\n",
    "index = random.randint(0, x_val_array.shape[0]-1)\n",
    "plt.imshow(np.concatenate([x_val_array[index, 0, :, :], y_val_array[index , 0, :, :]]).T.astype('float32'), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
