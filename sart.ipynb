{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All Imports\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "from numba import cuda\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import glob\n",
    "from skimage import filters\n",
    "from skimage.filters import unsharp_mask, threshold_local, threshold_minimum\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "\n",
    "\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback, TensorBoard\n",
    "from keras import backend as keras\n",
    "\n",
    "from skimage.measure import label\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#import pylidc as pl\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import pymrt as mrt\n",
    "#import pymrt.geometry\n",
    "import ipyvolume as ipv\n",
    "import copy\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import uuid\n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from ipdb import set_trace as bp\n",
    "\n",
    "\n",
    "\n",
    "#from image_gen import ImageDataGenerator\n",
    "#from load_data import loadDataMontgomery, loadDataJSRT\n",
    "#from build_model import build_UNet2D_4L\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "from keras.layers import Convolution3D, Input, merge, RepeatVector, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import activations, initializers, regularizers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "#from keras.utils.np_utils import conv_output_length\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     6,
     19,
     35,
     45,
     70,
     89,
     287,
     518,
     751,
     975,
     1204,
     1214,
     1225,
     1238,
     1255,
     1269,
     1285,
     1297,
     1421,
     1519,
     1529,
     1536,
     1543,
     1588,
     1627,
     1641,
     1680,
     1719,
     1833,
     1954,
     1981,
     2045,
     2090,
     2115,
     2141,
     2157
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ray Tracing Code\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def x_y_flip(host_prjbuf_temp):\n",
    "    host_prjbuf_temp_gpu  = np.copy(host_prjbuf_temp)\n",
    "    host_prjbuf_1view_gpu = np.copy(host_prjbuf_temp)\n",
    "    \n",
    "    for i in prange(BINSx):\n",
    "        for j in prange(BINSy):\n",
    "            bin_ind_temp = j*BINSx+i\n",
    "            bin_ind      = i*BINSy+j\n",
    "            host_prjbuf_1view_gpu[bin_ind] = host_prjbuf_temp_gpu[bin_ind_temp]\n",
    "    \n",
    "    return host_prjbuf_1view_gpu\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_yry(host_prj_allangle, host_scat_allangle):\n",
    "    all_b_size        =  ANGLES*BINSx*BINSy\n",
    "    host_yry_allangle =  np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    for i in prange(all_b_size):\n",
    "        if (host_prj_allangle[i] == 0):\n",
    "            host_yry_allangle[i] = 0\n",
    "        else:\n",
    "            dif = host_prj_allangle[i] - host_scat_allangle[i]\n",
    "            if (dif <= 0):\n",
    "                dif = host_prj_allangle[i]\n",
    "            host_yry_allangle[i] = (dif*dif)/host_prj_allangle[i]\n",
    "    \n",
    "    return host_yry_allangle\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_gamma_yry(host_yry_allangle, host_gamma_allangle):\n",
    "    all_b_size              = ANGLES*BINSx*BINSy\n",
    "    host_gamma_yry_allangle = np.zeros(all_b_size)\n",
    "    \n",
    "    for i in prange(all_b_size):\n",
    "        host_gamma_yry_allangle[i] = host_yry_allangle[i]*host_gamma_allangle[i]\n",
    "    \n",
    "    return host_gamma_yry_allangle\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_h(host_prj_sub, host_blank_sub, host_line_sub, host_scat_sub):\n",
    "    ANGLES_per_sub  = int(ANGLES/subset_num)\n",
    "    sub_b_size      = int(ANGLES_per_sub*BINSx*BINSy)\n",
    "    \n",
    "    host_sub = np.zeros(sub_b_size)\n",
    "    \n",
    "    for i in prange(sub_b_size):\n",
    "        y_tmp       = host_blank_sub[i]*np.exp(-host_line_sub[i])\n",
    "        host_sub[i] = (host_prj_sub[i]/(y_tmp+host_scat_sub[i])-1)*y_tmp\n",
    "    \n",
    "    return host_sub\n",
    "\n",
    "@njit(parallel=True)\n",
    "def update_est(host_est, host_capL, host_RD, host_d, host_RDD):\n",
    "    f_size    = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "    host_est1 = np.zeros(f_size)\n",
    "    \n",
    "    for i in prange(f_size):\n",
    "        host_est1[i] = host_est[i]-(host_capL[i]+beta*host_RD[i])/(host_d[i]+2*beta*host_RDD[i])\n",
    "        if (host_est1[i] < 0):\n",
    "            host_est1[i] = 0\n",
    "    \n",
    "    return host_est1\n",
    "\n",
    "@njit(parallel=True)\n",
    "def regroup_prj(host_uponregroup_allangle):\n",
    "    all_b_size     = int(ANGLES*BINSx*BINSy)\n",
    "    ANGLES_per_sub = int(ANGLES/subset_num)\n",
    "    b_size         = int(BINSx*BINSy)\n",
    "    \n",
    "    host_allangle_tmp = np.zeros(host_uponregroup_allangle.shape)\n",
    "    flag              = 0\n",
    "    \n",
    "    for i in range(subset_num):\n",
    "        for j in range(ANGLES_per_sub):\n",
    "            for k in range(b_size):\n",
    "                host_allangle_tmp[flag] = host_uponregroup_allangle[int((j*subset_num+i)*b_size+k)]\n",
    "                flag = flag +1\n",
    "    \n",
    "    return host_allangle_tmp\n",
    "\n",
    "import math\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def rayTrace3D_GPU_direct_notexturememory_normprj(d_normprj, x0, y0, z0, x1, y1, z1, status, sum_norm, bin_ind):\n",
    "    # Perform Ray Tracing\n",
    "    sum_norm = 0\n",
    "    dx     = x1-x0\n",
    "    dy     = y1-y0\n",
    "    dz     = z1-z0\n",
    "    Length = math.sqrt( dx*dx+dy*dy+dz*dz )\n",
    "\n",
    "\n",
    "    if (x1 != x0):\n",
    "        min_lx = (x_p0-x0)/dx\n",
    "        max_lx = min_lx+IMGSIZx*Vsize_x/dx\n",
    "\n",
    "        if (min_lx > max_lx):\n",
    "            #SWAP(min_lx, max_lx);\n",
    "            s_temp = min_lx\n",
    "            min_lx = max_lx\n",
    "            max_lx = s_temp\n",
    "    else:\n",
    "        # the line perpendicular to x axis\n",
    "        if (x0 >= IMGSIZx*Vsize_x+x_p0 or x0<=x_p0):\n",
    "            status = -1\n",
    "            return\n",
    "        min_lx = -1e3\n",
    "        max_lx = 1e3\n",
    "    \n",
    "    \n",
    "    if (y0 != y1):\n",
    "        min_ly = (y_p0-y0)/dy\n",
    "        max_ly = min_ly+IMGSIZy*Vsize_y/dy\n",
    "\n",
    "        if (min_ly > max_ly):\n",
    "            #SWAP(min_ly, max_ly);\n",
    "            s_temp = min_ly\n",
    "            min_ly = max_ly\n",
    "            max_ly = s_temp\n",
    "    else:\n",
    "        # the line perpendicular to y axis\n",
    "        if (y0 >= IMGSIZy*Vsize_y+y_p0 or y0 <= y_p0):\n",
    "            status = -1\n",
    "            return\n",
    "        min_ly = -1e3\n",
    "        max_ly = 1e3\n",
    "\n",
    "    \n",
    "    if (z0 != z1):\n",
    "        min_lz = (z_p0-z0)/dz\n",
    "        max_lz = min_lz+IMGSIZz*Vsize_z/dz\n",
    "        if (min_lz > max_lz):\n",
    "            #SWAP(min_lz, max_lz);\n",
    "            s_temp = min_lz\n",
    "            min_lz = max_lz\n",
    "            max_lz = s_temp\n",
    "    else:\n",
    "        # the line perpendicular to z axis\n",
    "        if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "            status = -1\n",
    "            return\n",
    "        min_lz = -1e3\n",
    "        max_lz = 1e3\n",
    "    \n",
    "    \n",
    "    max_l = max_lx\n",
    "    if (max_l > max_ly):\n",
    "        max_l=max_ly\n",
    "    if (max_l > max_lz):\n",
    "        max_l = max_lz\n",
    "\n",
    "    min_l = min_lx\n",
    "    if (min_l < min_ly):\n",
    "        min_l = min_ly\n",
    "    if (min_l < min_lz):\n",
    "        min_l = min_lz\n",
    "\n",
    "    if (min_l >= max_l):\n",
    "        status = -1\n",
    "        return\n",
    "    \n",
    "    if (min_lx != min_l):\n",
    "        prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "\n",
    "        if (x0 < x1):\n",
    "            min_lx= ((prev_x+1)*Vsize_x+x_p0-x0)/ dx\n",
    "        else:\n",
    "            if (x0 == x1):\n",
    "                min_lx = 1e3\n",
    "            else:\n",
    "                min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "    else:\n",
    "        if (x0 < x1):\n",
    "            prev_x = 0\n",
    "            min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "        else:\n",
    "            prev_x = IMGSIZx-1\n",
    "            min_lx = ( prev_x*Vsize_x+x_p0-x0 )/ dx\n",
    "    \n",
    "    if (min_ly != min_l):\n",
    "        prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/Vsize_y ))\n",
    "        if (y0 < y1):\n",
    "            min_ly = ( (prev_y+1)*Vsize_y+y_p0-y0)/ dy\n",
    "        else:\n",
    "            if (y0==y1):\n",
    "                min_ly = 1e3\n",
    "            else:\n",
    "                min_ly = (prev_y*Vsize_y+y_p0-y0)/ dy\n",
    "    else:\n",
    "        if (y0<y1):\n",
    "            prev_y = 0\n",
    "            min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "        else:\n",
    "            prev_y = IMGSIZy-1\n",
    "            min_ly = ( prev_y*Vsize_y+y_p0-y0 )/ dy\n",
    "    \n",
    "    if (min_lz != min_l):\n",
    "        prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/Vsize_z ))\n",
    "        if (z0 < z1):\n",
    "            min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "        else:\n",
    "            if (z0 == z1):\n",
    "                min_lz = 1e3\n",
    "            else:\n",
    "                min_lz = (prev_z*Vsize_z+z_p0-z0)/ dz\n",
    "    else:\n",
    "        if (z0 < z1):\n",
    "            prev_z = 0\n",
    "            min_lz = ( Vsize_z+z_p0-z0 )/ dz\n",
    "        else:\n",
    "            prev_z = (int)(IMGSIZz-1)\n",
    "            min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "    \n",
    "    \n",
    "    min_l_new = min_lx\n",
    "    if (min_l_new > min_ly):\n",
    "        min_l_new = min_ly\n",
    "    if (min_l_new > min_lz):\n",
    "        min_l_new = min_lz\n",
    "    \n",
    "    incx = Vsize_x/dx\n",
    "    incy = Vsize_y/dy\n",
    "    incz = Vsize_z/dz\n",
    "\n",
    "    ind = 0\n",
    "    \n",
    "    while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "        tmp_length = (min_l_new-min_l)*Length; #<-a_ij\n",
    "        if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "            sum_norm = sum_norm + 1*tmp_length\n",
    "        \n",
    "        ind = ind + 1\n",
    "        if (min_l_new == min_lx):\n",
    "            if (x0 < x1):\n",
    "                prev_x = prev_x + 1\n",
    "                min_lx = min_lx + incx; #Vsize_x/dx\n",
    "            else:\n",
    "                prev_x = prev_x - 1\n",
    "                min_lx = min_lx - incx; #Vsize_x/dx;\n",
    "        else:\n",
    "            prev_x = prev_x\n",
    "\n",
    "\n",
    "        if (min_l_new == min_ly):\n",
    "            if (y0 < y1):\n",
    "                prev_y = prev_y + 1\n",
    "                min_ly = min_ly + incy; #Vsize_y / dy;\n",
    "            else:\n",
    "                prev_y = prev_y - 1\n",
    "                min_ly = min_ly- incy; #Vsize_y/dy;\n",
    "        else:\n",
    "            prev_y = prev_y\n",
    "\n",
    "\n",
    "        if (min_l_new == min_lz):\n",
    "            if (z0 < z1):\n",
    "                prev_z = prev_z + 1\n",
    "                min_lz = min_lz + incz #Vsize_z/dz;\n",
    "            else:\n",
    "                prev_z = prev_z - 1\n",
    "                min_lz = min_lz - incz; #Vsize_z/dz\n",
    "        else:\n",
    "            prev_z = prev_z\n",
    "\n",
    "        min_l     = min_l_new\n",
    "        min_l_new = min_lx\n",
    "\n",
    "        if (min_l_new > min_ly):\n",
    "            min_l_new = min_ly\n",
    "\n",
    "        if (min_l_new>min_lz):\n",
    "            min_l_new=min_lz\n",
    "        \n",
    "        \n",
    "        tmp_length = (max_l-min_l)*Length\n",
    "        if ((prev_x>=0) and (prev_x<IMGSIZx) and (prev_y>=0) and (prev_y<IMGSIZy) and (prev_z>=0) and (prev_z<IMGSIZz)):\n",
    "            sum_norm = sum_norm + 1*tmp_length\n",
    "        \n",
    "        d_normprj[bin_ind] = sum_norm\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def rayTrace3D_GPU_direct_notexturememory(d_normprj, d_prjbuf, d_objbuf, x0, y0, z0, x1, y1, z1, status):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    status   = 0\n",
    "    #sum_norm = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "        \n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        fsum_norm = 0.0\n",
    "        fsum      = 0.0\n",
    "        \n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        \n",
    "        d_normprj[bin_ind] = 0\n",
    "        d_prjbuf[bin_ind]  = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "            \n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "            \n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                    fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "                \n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "            status2 = 100\n",
    "        \n",
    "        if status2 == 100:\n",
    "            d_normprj[bin_ind] = fsum_norm\n",
    "            d_prjbuf[bin_ind]  = fsum\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "    \n",
    "@cuda.jit\n",
    "def ray_trace_gpu_manyangles_direct_notexturememory_normprj(d_normprj, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    status   = 0\n",
    "    #sum_norm = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        #print(a)\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "\n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        sum_norm = 0.0\n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        d_normprj[bin_ind] = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "\n",
    "\n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "\n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    sum_norm = sum_norm + 1*tmp_length\n",
    "\n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                sum_norm = sum_norm + 1*tmp_length\n",
    "            status2 = 100\n",
    "        if status2 == 100:\n",
    "            d_normprj[bin_ind] = sum_norm\n",
    "        #else:\n",
    "        #    d_normprj[bin_ind] = sum_norm\n",
    "#         elif status == 10:\n",
    "#             d_normprj[bin_ind] = 100000\n",
    "#         elif status == -1:\n",
    "#             d_normprj[bin_ind] = 50000\n",
    "#         else:\n",
    "#             d_normprj[bin_ind] = 200000\n",
    "#         d_normprj[bin_ind] = Length\n",
    "        cuda.syncthreads()\n",
    "\n",
    "@cuda.jit\n",
    "def ray_trace_gpu_manyangles_direct_notexturememory_OSTR_cos(d_objbuf, d_prjbuf, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    status   = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        #print(a)\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "        \n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        sum_norm = 0.0\n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        #d_prjbuf[bin_ind] = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "\n",
    "\n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "\n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    sum_norm = sum_norm + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "\n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                sum_norm = sum_norm + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "            status2 = 100\n",
    "        \n",
    "        if status2 == 100:\n",
    "            d_prjbuf[bin_ind] = sum_norm*cos_theta\n",
    "        cuda.syncthreads()\n",
    "\n",
    "@cuda.jit\n",
    "def ray_trace_gpu_manyangles_direct_notexturememory_cos(d_objbuf, d_prjbuf, d_normprj, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    status   = 0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        #print(a)\n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        x0        = sourceR*sin_theta\n",
    "        z0        = sourceR*cos_theta\n",
    "        y0        = sourceY\n",
    "        \n",
    "        # calculate bin index\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "\n",
    "        bin_x_pos = (x_d0+(i+0.5)*Bsize_x)\n",
    "        bin_y_pos = (y_d0+(j+0.5)*Bsize_y)\n",
    "\n",
    "        x1 =  bin_x_pos\n",
    "        z1 = -detectorR\n",
    "        y1 =  bin_y_pos\n",
    "\n",
    "        # Iso-centric version\n",
    "        # x1 =  bin_x_pos*cos_theta-detectorR*sin_theta\n",
    "        # z1 = -bin_x_pos*sin_theta-detectorR*cos_theta\n",
    "        # y1 =  bin_y_pos\n",
    "\n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        y0 = sourceY\n",
    "        \n",
    "        # Perform Ray Tracing\n",
    "        fsum_norm = 0.0\n",
    "        fsum      = 0.0\n",
    "        \n",
    "        dx     = x1-x0\n",
    "        dy     = y1-y0\n",
    "        dz     = z1-z0\n",
    "        Length = math.sqrt( dx*dx + dy*dy + dz*dz )\n",
    "        #d_prjbuf[bin_ind] = 0\n",
    "        \n",
    "        if (x1 != x0):\n",
    "            min_lx = (x_p0 - x0)/dx\n",
    "            max_lx = min_lx + (IMGSIZx*Vsize_x)/dx\n",
    "            if (min_lx > max_lx):\n",
    "                #SWAP(min_lx, max_lx);\n",
    "                s_temp = min_lx\n",
    "                min_lx = max_lx\n",
    "                max_lx = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to x axis\n",
    "            if ((x0 >= IMGSIZx*Vsize_x+x_p0) or x0 <= x_p0):\n",
    "                status = -1\n",
    "            min_lx = -1000.0\n",
    "            max_lx =  1000.0\n",
    "        \n",
    "        if (y0 != y1):\n",
    "            min_ly = (y_p0-y0)/dy\n",
    "            max_ly = min_ly + IMGSIZy*Vsize_y/dy\n",
    "            if (min_ly > max_ly):\n",
    "                #SWAP(min_ly, max_ly);\n",
    "                s_temp = min_ly\n",
    "                min_ly = max_ly\n",
    "                max_ly = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to y axis\n",
    "            if (y0 >= IMGSIZy*Vsize_y + y_p0 or y0 <= y_p0):\n",
    "                status = -1\n",
    "            min_ly = -1000.0\n",
    "            max_ly =  1000.0\n",
    "        \n",
    "        if (z0 != z1):\n",
    "            min_lz = (z_p0 - z0)/dz\n",
    "            max_lz = min_lz + IMGSIZz*Vsize_z/dz\n",
    "            if (min_lz > max_lz):\n",
    "                #SWAP(min_lz, max_lz);\n",
    "                s_temp = min_lz\n",
    "                min_lz = max_lz\n",
    "                max_lz = s_temp\n",
    "        else:\n",
    "            # the line perpendicular to z axis\n",
    "            if (z0 >= IMGSIZz*Vsize_z+z_p0 or z0 <= z_p0):\n",
    "                status = -1\n",
    "            min_lz = -1000.0\n",
    "            max_lz =  1000.0\n",
    "        \n",
    "        max_l = max_lx\n",
    "        if (max_l > max_ly):\n",
    "            max_l = max_ly\n",
    "        if (max_l > max_lz):\n",
    "            max_l = max_lz\n",
    "        \n",
    "        min_l = min_lx\n",
    "        if (min_l < min_ly):\n",
    "            min_l = min_ly\n",
    "        if (min_l < min_lz):\n",
    "            min_l = min_lz\n",
    "        \n",
    "        if (min_l >= max_l):\n",
    "            status1 = 10\n",
    "            #d_normprj[bin_ind] = 1\n",
    "        else:\n",
    "            status1 = 0\n",
    "        \n",
    "        if status1 != 10:\n",
    "            if (min_lx != min_l):\n",
    "                prev_x = (int)(math.floor( (min_l* dx + x0 - x_p0) / Vsize_x ))\n",
    "                if (x0 < x1):\n",
    "                    min_lx = ((prev_x+1)*Vsize_x+x_p0 - x0)/ dx\n",
    "                elif (x0 == x1):\n",
    "                    min_lx = 1000\n",
    "                else:\n",
    "                    min_lx = (prev_x*Vsize_x+x_p0-x0) / dx\n",
    "                #d_normprj[bin_ind] = Vsize_x\n",
    "            else:\n",
    "                if (x0 < x1):\n",
    "                    prev_x = 0\n",
    "                    min_lx = ( Vsize_x+x_p0-x0 )/ dx\n",
    "                else:\n",
    "                    prev_x = IMGSIZx-1\n",
    "                    min_lx = ( prev_x*Vsize_x + x_p0 - x0 )/ dx\n",
    "            #d_normprj[bin_ind] = prev_x\n",
    "                \n",
    "            if (min_ly != min_l):\n",
    "                prev_y = (int)(math.floor( (min_l* dy + y0 - y_p0)/ Vsize_y ))\n",
    "                if (y0 < y1):\n",
    "                    min_ly = ( (prev_y+1)*Vsize_y + y_p0 - y0)/ dy\n",
    "                elif (y0 == y1):\n",
    "                    min_ly = 1000\n",
    "                else:\n",
    "                    min_ly = (prev_y*Vsize_y + y_p0 - y0)/ dy\n",
    "            else:\n",
    "                if (y0 < y1):\n",
    "                    prev_y = 0\n",
    "                    min_ly = ( Vsize_y+y_p0-y0 )/ dy\n",
    "                else:\n",
    "                    prev_y = IMGSIZy-1\n",
    "                    min_ly = ( prev_y*Vsize_y + y_p0 - y0 )/ dy\n",
    "                \n",
    "            if (min_lz != min_l):\n",
    "                prev_z = (int)(math.floor( (min_l* dz + z0 - z_p0)/ Vsize_z ))\n",
    "                if (z0 < z1):\n",
    "                    min_lz = ( (prev_z+1)*Vsize_z+z_p0-z0)/ dz\n",
    "                elif (z0 == z1):\n",
    "                    min_lz = 1000\n",
    "                else:\n",
    "                    min_lz = (prev_z*Vsize_z + z_p0 - z0)/ dz\n",
    "            else:\n",
    "                if (z0 < z1):\n",
    "                    prev_z = 0\n",
    "                    min_lz = ( Vsize_z + z_p0 - z0 )/ dz\n",
    "                else:\n",
    "                    prev_z = (int)(IMGSIZz-1)\n",
    "                    min_lz = ( prev_z*Vsize_z+z_p0-z0 )/dz\n",
    "            \n",
    "            min_l_new = min_lx\n",
    "            if (min_l_new > min_ly):\n",
    "                min_l_new = min_ly\n",
    "            if (min_l_new > min_lz):\n",
    "                min_l_new = min_lz\n",
    "\n",
    "\n",
    "            incx = Vsize_x/dx\n",
    "            incy = Vsize_y/dy\n",
    "            incz = Vsize_z/dz\n",
    "\n",
    "            ind = 0\n",
    "            #d_normprj[bin_ind] = max_l\n",
    "            while ( (max_l-min_l_new)/max_l > 0.000001):\n",
    "                tmp_length = (min_l_new - min_l)*Length\n",
    "                if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                    fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                    fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "\n",
    "                ind = ind + 1\n",
    "                if (min_l_new == min_lx):\n",
    "                    if (x0 < x1):\n",
    "                        prev_x = prev_x + 1\n",
    "                        min_lx = min_lx + incx #Vsize_x/dx\n",
    "                    else:\n",
    "                        prev_x = prev_x - 1\n",
    "                        min_lx = min_lx - incx #Vsize_x/dx;\n",
    "                else:\n",
    "                    prev_x = prev_x\n",
    "\n",
    "                if (min_l_new == min_ly):\n",
    "                    if (y0 < y1):\n",
    "                        prev_y = prev_y + 1\n",
    "                        min_ly = min_ly + incy #Vsize_y / dy;\n",
    "                    else:\n",
    "                        prev_y = prev_y - 1\n",
    "                        min_ly = min_ly- incy #Vsize_y/dy;\n",
    "                else:\n",
    "                    prev_y = prev_y\n",
    "\n",
    "                if (min_l_new == min_lz):\n",
    "                    if (z0 < z1):\n",
    "                        prev_z = prev_z + 1\n",
    "                        min_lz = min_lz + incz #Vsize_z/dz;\n",
    "                    else:\n",
    "                        prev_z = prev_z - 1\n",
    "                        min_lz = min_lz - incz; #Vsize_z/dz\n",
    "                else:\n",
    "                    prev_z = prev_z\n",
    "\n",
    "                min_l     = min_l_new\n",
    "                min_l_new = min_lx\n",
    "\n",
    "                if (min_l_new > min_ly):\n",
    "                    min_l_new = min_ly\n",
    "\n",
    "                if (min_l_new > min_lz):\n",
    "                    min_l_new = min_lz\n",
    "            \n",
    "            tmp_length = (max_l - min_l)*Length\n",
    "            if ((prev_x >= 0) and (prev_x < IMGSIZx) and (prev_y >= 0) and (prev_y < IMGSIZy) and (prev_z >= 0) and (prev_z < IMGSIZz)):\n",
    "                fsum_norm      = fsum_norm + 1*tmp_length\n",
    "                fsum           = fsum + d_objbuf[(prev_z*IMGSIZy+prev_y)*IMGSIZx+prev_x]*tmp_length\n",
    "            \n",
    "            status2 = 100\n",
    "        if status2 == 100:\n",
    "            d_normprj[bin_ind] = fsum_norm\n",
    "            d_prjbuf[bin_ind]  = fsum*cos_theta\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "    \n",
    "def fprojectCB_1R_GPU_OSTR_normprj(d_normprj, d_angles, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            ray_trace_gpu_manyangles_direct_notexturememory_normprj[PRJ_GRID, PRJ_THREAD](d_normprj, d_angles, d_index, angleStart, angleEnd, nbBinsX, nbBinsY)\n",
    "            #cuda.synchronize()\n",
    "    return\n",
    "\n",
    "def fprojectCB_1R_GPU_OSTR_cos(estbuf, prj_est, d_angles, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            ray_trace_gpu_manyangles_direct_notexturememory_OSTR_cos[PRJ_GRID, PRJ_THREAD](estbuf, prj_est, d_angles, d_index, \n",
    "                                                                                           angleStart, angleEnd, nbBinsX, nbBinsY)\n",
    "            cuda.synchronize()\n",
    "    return\n",
    "\n",
    "def fprojectCB_1R_GPU_SART_cos(estbuf, prj_est, d_normprj, d_angles, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            ray_trace_gpu_manyangles_direct_notexturememory_cos[PRJ_GRID, PRJ_THREAD](estbuf, prj_est, d_normprj, d_angles, \n",
    "                                                                                      d_index, angleStart, angleEnd, \n",
    "                                                                                      nbBinsX, nbBinsY)\n",
    "            cuda.synchronize()\n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def SART_prj_diff_kernel(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd, nbBinsX, nbBinsY):\n",
    "    ix, iy   = cuda.grid(2)\n",
    "    \n",
    "    # calculate bin index\n",
    "    for a in range(angleStart, angleEnd):\n",
    "        i = nbBinsX*((int)(BINSx/nBatchBINSx)) + ix\n",
    "        j = nbBinsY*((int)(BINSy/nBatchBINSy)) + iy\n",
    "        \n",
    "        bin_ind = ((a-angleStart)*BINSx+i)*BINSy+j\n",
    "        \n",
    "        if normprj[bin_ind] != 0:\n",
    "            diff_line[bin_ind] = prjbuf[bin_ind]#bin_ind#(prjbuf[bin_ind] - prj_est[bin_ind])/normprj[bin_ind]\n",
    "        else:\n",
    "            diff_line[bin_ind] = bin_ind#1\n",
    "    return\n",
    "\n",
    "@njit(parallel=True)\n",
    "def SART_prj_diff(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd):\n",
    "    result_diff_line = np.zeros(prjbuf.shape)\n",
    "    \n",
    "    #for nbBinsX in prange(nBatchBINSx):\n",
    "    #    for nbBinsY in prange(nBatchBINSy):\n",
    "    for bin_ind in prange(prjbuf.shape[0]):\n",
    "        if normprj[bin_ind] != 0:\n",
    "            result_diff_line[bin_ind] = (prjbuf[bin_ind] - prj_est[bin_ind])/normprj[bin_ind]\n",
    "        else:\n",
    "            result_diff_line[bin_ind] = 0.0#prjbuf[bin_ind]#bin_ind\n",
    "    \n",
    "    return result_diff_line\n",
    "\n",
    "#@njit(parallel=True)\n",
    "def SART_prj_diff_old(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd):\n",
    "    PRJ_THREAD = PRJ_ThreX, PRJ_ThreY\n",
    "    PRJ_GRID   = PRJ_GridX, PRJ_GridY\n",
    "    \n",
    "    for nbBinsX in range(nBatchBINSx):\n",
    "        for nbBinsY in range(nBatchBINSy):\n",
    "            SART_prj_diff_kernel[PRJ_GRID, PRJ_THREAD](diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd, nbBinsX, nbBinsY)\n",
    "            cuda.synchronize()\n",
    "    return\n",
    "#SART_prj_diff_kernel<<<PRJ_GRID,PRJ_THREAD>>>(diff_line,prjbuf,prj_est,normprj,d_index,angleStart,angleEnd,nbBinsX,nbBinsY);\n",
    "#CUT_CHECK_ERROR(\"Kernel execution failed\");\n",
    "#cudaThreadSynchronize()\n",
    "\n",
    "#def SART_prj_diff(diff_line, prjbuf, prj_est, normprj, d_index, angleStart, angleEnd):\n",
    "\n",
    "#@cuda.jit\n",
    "def bprojectCB_4B_GPU_R_SART(d_objbuf, d_prjbuf, d_prior, d_index, \n",
    "                                   d_angles, angleStart, angleEnd, lambda_parameter, beta):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    for nbatchIDx in range(nBatchXdim):\n",
    "        backprj_OSSART_gpu_manyviews_R[BACKPRJ_GRID, BACKPRJ_THREAD](d_objbuf, d_prjbuf, d_prior, d_index, \n",
    "                                                                            d_angles, angleStart, angleEnd , nbatchIDx, lambda_parameter, beta)\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def backprj_OSSART_gpu_manyviews_R(d_objbuf, d_prjbuf, d_prior, d_index, d_angles, \n",
    "                                          angleStart, angleEnd, nbatchIDx, lambda_parameter, beta):\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    tid = tx\n",
    "    \n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel = (ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x\n",
    "    \n",
    "    total_sum         = 0.0\n",
    "    total_sensitivity = 0.0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        u_term    = 0.0\n",
    "        \n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        \n",
    "        #(x0,y0,z0) - source position\n",
    "        x0 = sourceR*sin_theta\n",
    "        z0 = sourceR*cos_theta\n",
    "        y0 = sourceY\n",
    "        \n",
    "        #(x1,y1,z1) - center of voxel\n",
    "        x1 = (ind_x+0.5)*Vsize_x + x_p0\n",
    "        y1 = (ind_y+0.5)*Vsize_y + y_p0\n",
    "        z1 = (ind_z+0.5)*Vsize_z + z_p0\n",
    "        \n",
    "        #Check FDK paper for this weight factor. This weight can be set to 1, in a simple case\n",
    "        depth_weight = (x0*x0+y0*y0+z0*z0)/((x0-x1)*(x0-x1) + (y0-y1)*(y0-y1)+(z0-z1)*(z0-z1))\n",
    "        \n",
    "        #Do NOT Rotate (x0,y0,z0)  -theta  around the y-axis\n",
    "        y0r =y0\n",
    "        x0r =x0\n",
    "        z0r =z0\n",
    "        \n",
    "        #Do NOT Rotate (x1,y1,z1)  -theta around the y-axis\n",
    "        y1r = y1\n",
    "        z1r = z1\n",
    "        x1r = x1\n",
    "        \n",
    "        if (z1r != z0r):\n",
    "            t = (-detectorR - z0r) / (z1r - z0r)\n",
    "            x2 = x0r + (x1r - x0r) * t\n",
    "            y2 = y0r + (y1r - y0r) * t\n",
    "            \n",
    "            weight = 1.0\n",
    "            \n",
    "            # BACKPROJECTION USING INTERPOLATION\n",
    "            # Calculate the continuous position (in bin_index coordinate) of the projection of voxel in the detector plane.\n",
    "            imb = ((float)(x2 - x_d0)/Bsize_x)\n",
    "            jmb = ((float)(y2 - y_d0)/Bsize_y)\n",
    "            \n",
    "            ilb = (float)(math.floor(imb))\n",
    "            if (imb < (ilb+0.5)):\n",
    "                ilb = ilb - 1\n",
    "            \n",
    "            jlb = (float)(math.floor(jmb))\n",
    "            if ( jmb < (jlb+0.5)):\n",
    "                jlb = jlb - 1\n",
    "            \n",
    "            fracI = imb - (ilb+0.5)\n",
    "            fracJ = jmb - (jlb+0.5)\n",
    "            \n",
    "            d1 = 0\n",
    "            d2 = 0\n",
    "            d1_sen = 0\n",
    "            d2_sen = 0\n",
    "        \n",
    "            # Interpolation\n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = ilb*BINSy + jlb\n",
    "                d1      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d1_sen  = (1-fracI) \n",
    "\n",
    "            if ((ilb < BINSx-1) and (ilb >= -1) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = (ilb + 1)* BINSy+ jlb\n",
    "                d1      = d1 + fracI * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d1_sen  = d1_sen + fracI \n",
    "\n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy-1) and (jlb >= -1)):\n",
    "                bin_ind = ilb* BINSy + jlb + 1\n",
    "                d2      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d2_sen   =  1-fracI \n",
    "\n",
    "            if ((ilb<BINSx-1) and (ilb>=-1) and (jlb<BINSy-1) and (jlb>=-1)):\n",
    "                bin_ind = (ilb + 1) * BINSy +  jlb + 1\n",
    "                d2 = d2 + fracI  * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "                d2_sen = d2_sen + fracI\n",
    "            \n",
    "            u_term    = (1 - fracJ) * d1 + fracJ * d2\n",
    "            u_term    = u_term*Vsize_z*depth_weight\n",
    "            \n",
    "            u_sensitivity = ((1-fracJ)*d1_sen+fracJ*d2_sen)\n",
    "            u_sensitivity = u_sensitivity *Vsize_z*depth_weight\n",
    "            \n",
    "            total_sum         = total_sum + (u_term*weight)\n",
    "            total_sensitivity = total_sensitivity+(u_sensitivity*weight)\n",
    "    \n",
    "    u_term    = 0\n",
    "    beta_term = 0\n",
    "    \n",
    "    if(total_sensitivity != 0):\n",
    "        u_term    = (total_sum/total_sensitivity)\n",
    "        beta_term = (beta*d_prior[ind_voxel])/total_sensitivity\n",
    "    \n",
    "    d_objbuf[ind_voxel] = d_objbuf[ind_voxel]+lambda_parameter*(u_term+beta_term)\n",
    "    if(d_objbuf[ind_voxel] < 0):\n",
    "        d_objbuf[ind_voxel] = 0\n",
    "    #if(d_objbuf[ind_voxel] > 0.1):\n",
    "    #    d_objbuf[ind_voxel] = 0\n",
    "    \n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def backprj_gpu_manyviews_SBP(d_objbuf, d_prjbuf, d_index, d_angles, angleStart, angleEnd , nbatchIDx):\n",
    "    # Block id in a 1D grid\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    tid = tx\n",
    "    \n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel = (ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x\n",
    "    \n",
    "    total_sum = 0.0\n",
    "    \n",
    "    for a in range(angleStart, angleEnd):\n",
    "        u_term    = 0.0\n",
    "        \n",
    "        s         = d_index[a]\n",
    "        theta     = d_angles[s]\n",
    "        sin_theta = math.sin(theta)\n",
    "        cos_theta = math.cos(theta)\n",
    "        \n",
    "        #(x0,y0,z0) - source position\n",
    "        x0 = sourceR*sin_theta\n",
    "        z0 = sourceR*cos_theta\n",
    "        y0 = sourceY\n",
    "        \n",
    "        #(x1,y1,z1) - center of voxel\n",
    "        x1 = (ind_x+0.5)*Vsize_x + x_p0\n",
    "        y1 = (ind_y+0.5)*Vsize_y + y_p0\n",
    "        z1 = (ind_z+0.5)*Vsize_z + z_p0\n",
    "        \n",
    "        #Check FDK paper for this weight factor. This weight can be set to 1, in a simple case\n",
    "        depth_weight = (x0*x0 + y0*y0 + z0*z0)/((x0-x1)*(x0-x1) + (y0-y1)*(y0-y1)+(z0-z1)*(z0-z1))\n",
    "        \n",
    "        y0r = y0\n",
    "        x0r = x0\n",
    "        z0r = z0\n",
    "        \n",
    "        y1r = y1\n",
    "        z1r = z1\n",
    "        x1r = x1\n",
    "        \n",
    "        if (z1r != z0r):\n",
    "            t = (-detectorR - z0r) / (z1r - z0r)\n",
    "            x2 = x0r + (x1r - x0r) * t\n",
    "            y2 = y0r + (y1r - y0r) * t\n",
    "            \n",
    "            weight = 1.0\n",
    "            \n",
    "            # BACKPROJECTION USING INTERPOLATION\n",
    "            # Calculate the continuous position (in bin_index coordinate) of the projection of voxel in the detector plane.\n",
    "            imb = ((float)(x2 - x_d0)/Bsize_x)\n",
    "            jmb = ((float)(y2 - y_d0)/Bsize_y)\n",
    "            \n",
    "            ilb = (float)(math.floor(imb))\n",
    "            if (imb < (ilb+0.5)):\n",
    "                ilb = ilb - 1\n",
    "            \n",
    "            jlb = (float)(math.floor(jmb))\n",
    "            if ( jmb < (jlb+0.5)):\n",
    "                jlb = jlb - 1\n",
    "\n",
    "            fracI = imb - (ilb+0.5)\n",
    "            fracJ = jmb - (jlb+0.5)\n",
    "            \n",
    "            d1 = 0\n",
    "            d2 = 0\n",
    "            \n",
    "            # Interpolation\n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = ilb*BINSy + jlb\n",
    "                d1      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            if ((ilb < BINSx-1) and (ilb >= -1) and (jlb < BINSy) and (jlb >= 0)):\n",
    "                bin_ind = (ilb + 1)* BINSy+ jlb\n",
    "                d1      = d1 + fracI * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            if ((ilb < BINSx) and (ilb >= 0) and (jlb < BINSy-1) and (jlb >= -1)):\n",
    "                bin_ind = ilb* BINSy + jlb + 1\n",
    "                d2      = (1-fracI) * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            if ((ilb<BINSx-1) and (ilb>=-1) and (jlb<BINSy-1) and (jlb>=-1)):\n",
    "                bin_ind = (ilb + 1) * BINSy +  jlb + 1\n",
    "                d2 = d2 + fracI  * d_prjbuf[int((a-angleStart)*BINSx*BINSy + bin_ind)]\n",
    "            \n",
    "            u_term    = (1 - fracJ) * d1 + fracJ * d2\n",
    "            u_term    = u_term*Vsize_z*depth_weight\n",
    "            total_sum = total_sum + (u_term*weight)\n",
    "        \n",
    "    d_objbuf[ind_voxel] = d_objbuf[ind_voxel]+total_sum        \n",
    "    return\n",
    "\n",
    "\n",
    "def bprojectCB_GPU_SBP(d_objbuf, d_prjbuf, d_index, d_angles, angleStart, angleEnd):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    for nbatchIDx in range(nBatchXdim):\n",
    "        backprj_gpu_manyviews_SBP[BACKPRJ_GRID, BACKPRJ_THREAD](d_objbuf, d_prjbuf, d_index, d_angles, angleStart, angleEnd , nbatchIDx)\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "@njit(parallel=True)\n",
    "def temp_fun1(angleStart, b_size, sub_b_size, host_prj_allangle):\n",
    "    host_prj_sub = np.zeros(sub_b_size)\n",
    "    for i in prange(sub_b_size):\n",
    "        host_prj_sub[i]   = host_prj_allangle[angleStart*b_size+i]\n",
    "    return host_prj_sub\n",
    "\n",
    "@njit(parallel=True)\n",
    "def temp_fun2(subset_num, f_size, host_capL):\n",
    "    temp = np.zeros(f_size)\n",
    "    for i in prange(f_size):\n",
    "        temp[i] = subset_num*host_capL[i]\n",
    "    return temp\n",
    "\n",
    "@cuda.jit\n",
    "def G_Fessler_prior(RDD, RD, estbuf, delta, z_xy_ratio, nbatchIDx):\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    # Thread index\n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    cent = 1\n",
    "    tid  = tx\n",
    "    \n",
    "    # Calculate the index of the voxel being considered\n",
    "    # ind_x = nbatchIDx*((int)(IMGSIZx/h_nBatchXdim))+ tid\n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel=int((ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x)  #(if prj is scanner data, need x_y_flip)\n",
    "    #ind_voxel=(ind_z*IMGSIZx+ind_x)*IMGSIZy+ind_y;\n",
    "    \n",
    "    for ind_nr_z  in range(ind_z-1, ind_z+2):\n",
    "        for ind_nr_y in range(ind_y-1, ind_y+2):\n",
    "            for ind_nr_x in range(ind_x-1, ind_x+2):\n",
    "                distance = math.sqrt(float((ind_nr_x-ind_x)*(ind_nr_x-ind_x)+(ind_nr_y-ind_y)*(ind_nr_y-ind_y)+(ind_nr_z-ind_z)*(ind_nr_z-ind_z)*z_xy_ratio*z_xy_ratio))\n",
    "                \n",
    "                if (distance == 0.0):\n",
    "                    distance = 1.0\n",
    "                    cent     = 0\n",
    "                \n",
    "                if ( ind_nr_x<0  or ind_nr_y<0 or ind_nr_z<0 or ind_nr_x>(IMGSIZx-1) or ind_nr_y>(IMGSIZy-1) or ind_nr_z>(IMGSIZz-1) ):\n",
    "                    ind_nr = int(ind_voxel)\n",
    "                else:\n",
    "                    ind_nr = int(ind_nr_x + ind_nr_y*IMGSIZx + ind_nr_z*IMGSIZx*IMGSIZy)\n",
    "                \n",
    "                diff        = estbuf[ind_voxel]-estbuf[ind_nr]\n",
    "                denominator = 1.0+abs(diff/delta)\n",
    "                RDD_tmp     = cent*(1.0/distance)/denominator\n",
    "                \n",
    "                RDD[ind_voxel] = RDD[ind_voxel] + RDD_tmp\n",
    "                RD[ind_voxel]  = RD[ind_voxel]  + RDD_tmp*diff\n",
    "                \n",
    "                cent = 1 # reset cent\n",
    "    return\n",
    "\n",
    "@cuda.jit\n",
    "def G_Huber_prior_sart(priorbuf, estbuf, delta, nbatchIDx):\n",
    "    bx = cuda.blockIdx.x\n",
    "    by = cuda.blockIdx.y\n",
    "    \n",
    "    # Thread index\n",
    "    tx = cuda.threadIdx.x + (nbatchIDx*cuda.blockDim.x)\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    cent = 1\n",
    "    tid  = tx\n",
    "    \n",
    "    # Calculate the index of the voxel being considered\n",
    "    # ind_x = nbatchIDx*((int)(IMGSIZx/h_nBatchXdim))+ tid\n",
    "    ind_x = tid\n",
    "    ind_y = bx\n",
    "    ind_z = by\n",
    "    \n",
    "    ind_voxel = int((ind_z*IMGSIZy+ind_y)*IMGSIZx+ind_x)  #(if prj is scanner data, need x_y_flip)\n",
    "    #ind_voxel=(ind_z*IMGSIZx+ind_x)*IMGSIZy+ind_y;\n",
    "    \n",
    "    for ind_nr_z  in range(ind_z-1, ind_z+2):\n",
    "        for ind_nr_y in range(ind_y-1, ind_y+2):\n",
    "            for ind_nr_x in range(ind_x-1, ind_x+2):\n",
    "                distance = math.sqrt(float((ind_nr_x-ind_x)*(ind_nr_x-ind_x)+(ind_nr_y-ind_y)*(ind_nr_y-ind_y)+(ind_nr_z-ind_z)*(ind_nr_z-ind_z)))\n",
    "                \n",
    "                if (distance == 0.0):\n",
    "                    distance = 1.0\n",
    "                \n",
    "                if ( ind_nr_x<0  or ind_nr_y<0 or ind_nr_z<0 or ind_nr_x>(IMGSIZx-1) or ind_nr_y>(IMGSIZy-1) or ind_nr_z>(IMGSIZz-1) ):\n",
    "                    ind_nr = int(ind_voxel)\n",
    "                else:\n",
    "                    ind_nr = int(ind_nr_x + ind_nr_y*IMGSIZx + ind_nr_z*IMGSIZx*IMGSIZy)\n",
    "                \n",
    "                diff        = estbuf[ind_voxel]-estbuf[ind_nr]\n",
    "                denominator = math.sqrt(1.0+(diff/delta)*(diff/delta))\n",
    "                \n",
    "                priorbuf[ind_voxel] = priorbuf[ind_voxel] + (1.0/distance)*diff/denominator\n",
    "    return    \n",
    "\n",
    "def prior_GPU_SART(d_prior, d_est, delta):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    if (delta == 0):\n",
    "        print(\"delta cannot be ZERO !!\")\n",
    "        exit(1)\n",
    "    \n",
    "    for nbatchIDx in range(0, nBatchXdim):\n",
    "        G_Huber_prior_sart[BACKPRJ_GRID, BACKPRJ_THREAD](d_prior, d_est, delta, nbatchIDx)\n",
    "        # Check out the content of this kernel in file ConebeamCT_kernel.cu\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "def prior_GPU_OSTR(d_RDD, d_RD, d_est, delta, z_xy_ratio):\n",
    "    BACKPRJ_THREAD = BACKPRJ_ThreX, BACKPRJ_ThreY\n",
    "    BACKPRJ_GRID   = BACKPRJ_GridX, BACKPRJ_GridY\n",
    "    \n",
    "    if (delta == 0):\n",
    "        print(\"delta cannot be ZERO !!\")\n",
    "        exit(1)\n",
    "    \n",
    "    for nbatchIDx in range(0, nBatchXdim):\n",
    "        G_Fessler_prior[BACKPRJ_GRID, BACKPRJ_THREAD](d_RDD, d_RD, d_est, delta, z_xy_ratio, nbatchIDx)\n",
    "        # Check out the content of this kernel in file ConebeamCT_kernel.cu\n",
    "        cuda.synchronize()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This module contains a Python and NumPy implementation of the HaarPSI perceptual similarity index algorithm,\n",
    "as described in \"A Haar Wavelet-Based Perceptual Similarity Index for Image Quality Assessment\" by\n",
    "R. Reisenhofer, S. Bosse, G. Kutyniok and T. Wiegand.\n",
    "\n",
    "Converted by David Neumann from the original MATLAB implementation written by Rafael Reisenhofer.\n",
    "\n",
    "Last updated on 08/01/2018 by David Neumann.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy\n",
    "from scipy import signal\n",
    "\n",
    "try:\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "    import tensorflow as tf\n",
    "    is_tensorflow_available = True\n",
    "except ImportError:\n",
    "    is_tensorflow_available = False\n",
    "\n",
    "def haar_psi(reference_image, distorted_image, preprocess_with_subsampling = True):\n",
    "    \"\"\"\n",
    "    Calculates the HaarPSI perceptual similarity index between the two specified images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        reference_image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The reference image, which can be in RGB or grayscale. The values must be in the range [0, 255].\n",
    "            The image must be a NumPy array or TensorFlow tensor of the shape (width, height, 3) in the case\n",
    "            of RGB, or a NumPy array or TensorFlow tensor in the shape (width, height) for grayscale.\n",
    "        distorted_image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The distorted image, which is to be compared to the reference image. The image can be in RGB or\n",
    "            grayscale. The values must be in the range [0, 255]. The image must be a NumPy array or a\n",
    "            TensorFlow tensor of the shape (width, height, 3) in the case of RGB, or a NumPy array or\n",
    "            TensorFlow tensor in the shape (width, height) for grayscale.\n",
    "        preprocess_with_subsampling: boolean\n",
    "            An optional parameter, which determines whether a preprocessing step is to be performed, which\n",
    "            accommodates for the viewing distance in psychophysical experiments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        (float, numpy.ndarray | tensorflow.Tensor | tensorflow.Variable, numpy.ndarray | tensorflow.Tensor\n",
    "        | tensorflow.Variable): Returns a three-tuple containing the similarity score, the similarity maps\n",
    "        and the weight maps. The similarity score is the Haar wavelet-based perceptual similarity index,\n",
    "        measured in the interval [0,1]. The similarity maps are maps of horizontal and vertical local\n",
    "        similarities. For RGB images, this variable also includes a similarity map with respect to the two\n",
    "        color channels in the YIQ space. The weight maps are maps that measure the importance of the local\n",
    "        similarities in the similarity maps.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(reference_image) and is_numpy(distorted_image):\n",
    "        return haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling)\n",
    "    elif is_tensorflow(reference_image) and is_tensorflow(distorted_image):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        return haar_psi_tensorflow(reference_image, distorted_image, preprocess_with_subsampling)\n",
    "    else:\n",
    "        raise ValueError(\"The reference or the distorted image is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "def haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True):\n",
    "    \"\"\"\n",
    "    Calculates the HaarPSI perceptual similarity index between the two specified images. This implementation uses NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        reference_image: numpy.ndarray\n",
    "            The reference image, which can be in RGB or grayscale. The values must be in the range [0, 255].\n",
    "            The image must be a NumPy array of the shape (width, height, 3) in the case of RGB or a NumPy\n",
    "            array in the shape (width, height) for grayscale.\n",
    "        distorted_image: numpy.ndarray\n",
    "            The distorted image, which is to be compared to the reference image. The image can be in RGB or\n",
    "            grayscale. The values must be in the range [0, 255]. The image must be a NumPy array of the\n",
    "            shape (width, height, 3) in the case of RGB or a NumPy array in the shape (width, height) for\n",
    "            grayscale.\n",
    "        preprocess_with_subsampling: boolean\n",
    "            An optional parameter, which determines whether a preprocessing step is to be performed, which\n",
    "            accommodates for the viewing distance in psychophysical experiments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        (float, numpy.ndarray, numpy.ndarray): Returns a three-tuple containing the similarity score, the\n",
    "        similarity maps and the weight maps. The similarity score is the Haar wavelet-based perceptual\n",
    "        similarity index, measured in the interval [0,1]. The similarity maps are maps of horizontal and\n",
    "        vertical local similarities. For RGB images, this variable also includes a similarity map with\n",
    "        respect to the two color channels in the YIQ space. The weight maps are maps that measure the\n",
    "        importance of the local similarities in the similarity maps.\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if the image is a grayscale or an RGB image\n",
    "    if reference_image.shape != distorted_image.shape:\n",
    "        raise ValueError(\"The shapes of the reference image and the distorted image do not match.\")\n",
    "    if len(reference_image.shape) == 2:\n",
    "        is_color_image = False\n",
    "    elif reference_image.shape[2] == 1:\n",
    "        is_color_image = False\n",
    "    else:\n",
    "        is_color_image = True\n",
    "\n",
    "    # Converts the image values to double precision floating point numbers\n",
    "    reference_image = reference_image.astype(numpy.float64)\n",
    "    distorted_image = distorted_image.astype(numpy.float64)\n",
    "\n",
    "    # The HaarPSI algorithm requires two constants, C and alpha, that have been experimentally determined\n",
    "    # to be C = 30 and alpha = 4.2\n",
    "    C     = 30.0\n",
    "    alpha = 4.2\n",
    "\n",
    "    # If the images are in RGB, then they are transformed to the YIQ color space\n",
    "    if is_color_image:\n",
    "        reference_image_y = 0.299 * reference_image[:, :, 0] + 0.587 * reference_image[:, :, 1] + 0.114 * reference_image[:, :, 2]\n",
    "        distorted_image_y = 0.299 * distorted_image[:, :, 0] + 0.587 * distorted_image[:, :, 1] + 0.114 * distorted_image[:, :, 2]\n",
    "        reference_image_i = 0.596 * reference_image[:, :, 0] - 0.274 * reference_image[:, :, 1] - 0.322 * reference_image[:, :, 2]\n",
    "        distorted_image_i = 0.596 * distorted_image[:, :, 0] - 0.274 * distorted_image[:, :, 1] - 0.322 * distorted_image[:, :, 2]\n",
    "        reference_image_q = 0.211 * reference_image[:, :, 0] - 0.523 * reference_image[:, :, 1] + 0.312 * reference_image[:, :, 2]\n",
    "        distorted_image_q = 0.211 * distorted_image[:, :, 0] - 0.523 * distorted_image[:, :, 1] + 0.312 * distorted_image[:, :, 2]\n",
    "    else:\n",
    "        reference_image_y = reference_image\n",
    "        distorted_image_y = distorted_image\n",
    "\n",
    "    # Subsamples the images, which simulates the typical distance between an image and its viewer\n",
    "    if preprocess_with_subsampling:\n",
    "        reference_image_y = subsample(reference_image_y)\n",
    "        distorted_image_y = subsample(distorted_image_y)\n",
    "        if is_color_image:\n",
    "            reference_image_i = subsample(reference_image_i)\n",
    "            distorted_image_i = subsample(distorted_image_i)\n",
    "            reference_image_q = subsample(reference_image_q)\n",
    "            distorted_image_q = subsample(distorted_image_q)\n",
    "\n",
    "    # Performs the Haar wavelet decomposition\n",
    "    number_of_scales = 3\n",
    "    coefficients_reference_image_y = haar_wavelet_decompose(reference_image_y, number_of_scales)\n",
    "    coefficients_distorted_image_y = haar_wavelet_decompose(distorted_image_y, number_of_scales)\n",
    "    if is_color_image:\n",
    "        coefficients_reference_image_i = numpy.abs(convolve2d(reference_image_i, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_i = numpy.abs(convolve2d(distorted_image_i, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_reference_image_q = numpy.abs(convolve2d(reference_image_q, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_q = numpy.abs(convolve2d(distorted_image_q, numpy.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "\n",
    "    # Pre-allocates the variables for the local similarities and the weights\n",
    "    if is_color_image:\n",
    "        local_similarities = numpy.zeros(sum([reference_image_y.shape, (3, )], ()))\n",
    "        weights = numpy.zeros(sum([reference_image_y.shape, (3, )], ()))\n",
    "    else:\n",
    "        local_similarities = numpy.zeros(sum([reference_image_y.shape, (2, )], ()))\n",
    "        weights = numpy.zeros(sum([reference_image_y.shape, (2, )], ()))\n",
    "\n",
    "    # Computes the weights and similarities for each orientation\n",
    "    for orientation in range(2):\n",
    "        weights[:, :, orientation] = numpy.maximum(\n",
    "            numpy.abs(coefficients_reference_image_y[:, :, 2 + orientation * number_of_scales]),\n",
    "            numpy.abs(coefficients_distorted_image_y[:, :, 2 + orientation * number_of_scales])\n",
    "        )\n",
    "        coefficients_reference_image_y_magnitude = numpy.abs(coefficients_reference_image_y[:, :, (orientation * number_of_scales, 1 + orientation * number_of_scales)])\n",
    "        coefficients_distorted_image_y_magnitude = numpy.abs(coefficients_distorted_image_y[:, :, (orientation * number_of_scales, 1 + orientation * number_of_scales)])\n",
    "        local_similarities[:, :, orientation] = numpy.sum(\n",
    "            (2 * coefficients_reference_image_y_magnitude * coefficients_distorted_image_y_magnitude + C) / (coefficients_reference_image_y_magnitude**2 + coefficients_distorted_image_y_magnitude**2 + C),\n",
    "            axis = 2\n",
    "        ) / 2\n",
    "\n",
    "    # Computes the similarities for color channels\n",
    "    if is_color_image:\n",
    "        similarity_i = (2 * coefficients_reference_image_i * coefficients_distorted_image_i + C) / (coefficients_reference_image_i**2 + coefficients_distorted_image_i**2 + C)\n",
    "        similarity_q = (2 * coefficients_reference_image_q * coefficients_distorted_image_q + C) / (coefficients_reference_image_q**2 + coefficients_distorted_image_q**2 + C)\n",
    "        local_similarities[:, :, 2] = (similarity_i + similarity_q) / 2\n",
    "        weights[:, :, 2] = (weights[:, :, 0] + weights[:, :, 1]) / 2\n",
    "\n",
    "    # Calculates the final score\n",
    "    similarity = logit(numpy.sum(sigmoid(local_similarities[:], alpha) * weights[:]) / numpy.sum(weights[:]), alpha)**2\n",
    "\n",
    "    # Returns the result\n",
    "    return similarity, local_similarities, weights\n",
    "\n",
    "def haar_psi_tensorflow(reference_image, distorted_image, preprocess_with_subsampling = True):\n",
    "    \"\"\"\n",
    "    Calculates the HaarPSI perceptual similarity index between the two specified images. This implementation uses TensorFlow.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        reference_image: tensorflow.Tensor | tensorflow.Variable\n",
    "            The reference image, which can be in RGB or grayscale. The values must be in the range [0, 255].\n",
    "            The image must be a TensorFlow Tensor of the shape (width, height, 3) in the case of RGB or a\n",
    "            TensorFlow tensor in the shape (width, height) for grayscale.\n",
    "        distorted_image: tensorflow.Tensor | tensorflow.Variable\n",
    "            The distorted image, which is to be compared to the reference image. The image can be in RGB or\n",
    "            grayscale. The values must be in the range [0, 255]. The image must be a TensorFlow tensor of\n",
    "            the shape (width, height, 3) in the case of RGB or a TensorFlow tensor in the shape\n",
    "            (width, height) for grayscale.\n",
    "        preprocess_with_subsampling: boolean\n",
    "            An optional parameter, which determines whether a preprocessing step is to be performed, which\n",
    "            accommodates for the viewing distance in psychophysical experiments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        (float, tensorflow.Tensor, tensorflow.Tensor): Returns a three-tuple containing the similarity score,\n",
    "        the similarity maps and the weight maps. The similarity score is the Haar wavelet-based perceptual\n",
    "        similarity index, measured in the interval [0,1]. The similarity maps are maps of horizontal and\n",
    "        vertical local similarities. For RGB images, this variable also includes a similarity map with\n",
    "        respect to the two color channels in the YIQ space. The weight maps are maps that measure the\n",
    "        importance of the local similarities in the similarity maps.\n",
    "    \"\"\"\n",
    "\n",
    "    if not is_tensorflow_available:\n",
    "        raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "    # Checks if the images are both single precision floats\n",
    "    if reference_image.dtype != tf.float32:\n",
    "        raise ValueError(\"The reference image has to be single precision float.\")\n",
    "    if distorted_image.dtype != tf.float32:\n",
    "        raise ValueError(\"The distorted image has to be single precision float.\")\n",
    "\n",
    "    # Checks if the image is a grayscale or an RGB image\n",
    "    if reference_image.get_shape().as_list() != distorted_image.get_shape().as_list():\n",
    "        raise ValueError(\"The shapes of the reference image and the distorted image do not match.\")\n",
    "    if len(reference_image.get_shape().as_list()) == 2:\n",
    "        is_color_image = False\n",
    "    elif reference_image.get_shape().as_list()[2] == 1:\n",
    "        is_color_image = False\n",
    "    else:\n",
    "        is_color_image = True\n",
    "\n",
    "    # The HaarPSI algorithm requires two constants, C and alpha, that have been experimentally determined\n",
    "    # to be C = 30 and alpha = 4.2\n",
    "    C = tf.constant(30.0, dtype = tf.float32)\n",
    "    alpha = tf.constant(4.2, dtype = tf.float32)\n",
    "\n",
    "    # If the images are in RGB, then they are transformed to the YIQ color space\n",
    "    if is_color_image:\n",
    "        reference_image_y = 0.299 * reference_image[:, :, 0] + 0.587 * reference_image[:, :, 1] + 0.114 * reference_image[:, :, 2]\n",
    "        distorted_image_y = 0.299 * distorted_image[:, :, 0] + 0.587 * distorted_image[:, :, 1] + 0.114 * distorted_image[:, :, 2]\n",
    "        reference_image_i = 0.596 * reference_image[:, :, 0] - 0.274 * reference_image[:, :, 1] - 0.322 * reference_image[:, :, 2]\n",
    "        distorted_image_i = 0.596 * distorted_image[:, :, 0] - 0.274 * distorted_image[:, :, 1] - 0.322 * distorted_image[:, :, 2]\n",
    "        reference_image_q = 0.211 * reference_image[:, :, 0] - 0.523 * reference_image[:, :, 1] + 0.312 * reference_image[:, :, 2]\n",
    "        distorted_image_q = 0.211 * distorted_image[:, :, 0] - 0.523 * distorted_image[:, :, 1] + 0.312 * distorted_image[:, :, 2]\n",
    "    else:\n",
    "        reference_image_y = reference_image\n",
    "        distorted_image_y = distorted_image\n",
    "\n",
    "    # Subsamples the images, which simulates the typical distance between an image and its viewer\n",
    "    if preprocess_with_subsampling:\n",
    "        reference_image_y = subsample(reference_image_y)\n",
    "        distorted_image_y = subsample(distorted_image_y)\n",
    "        if is_color_image:\n",
    "            reference_image_i = subsample(reference_image_i)\n",
    "            distorted_image_i = subsample(distorted_image_i)\n",
    "            reference_image_q = subsample(reference_image_q)\n",
    "            distorted_image_q = subsample(distorted_image_q)\n",
    "\n",
    "    # Performs the Haar wavelet decomposition\n",
    "    number_of_scales = 3\n",
    "    coefficients_reference_image_y = haar_wavelet_decompose(reference_image_y, number_of_scales)\n",
    "    coefficients_distorted_image_y = haar_wavelet_decompose(distorted_image_y, number_of_scales)\n",
    "    if is_color_image:\n",
    "        coefficients_reference_image_i = tf.abs(convolve2d(reference_image_i, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_i = tf.abs(convolve2d(distorted_image_i, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_reference_image_q = tf.abs(convolve2d(reference_image_q, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "        coefficients_distorted_image_q = tf.abs(convolve2d(distorted_image_q, tf.ones((2, 2)) / 4.0, mode = \"same\"))\n",
    "\n",
    "    # Pre-allocates the variables for the local similarities and the weights\n",
    "    if is_color_image:\n",
    "        local_similarities = [tf.zeros_like(reference_image_y)] * 3\n",
    "        weights = [tf.zeros_like(reference_image_y)] * 3\n",
    "    else:\n",
    "        local_similarities = [tf.zeros_like(reference_image_y)] * 2\n",
    "        weights = [tf.zeros_like(reference_image_y)] * 2\n",
    "\n",
    "    # Computes the weights and similarities for each orientation\n",
    "    for orientation in range(2):\n",
    "        weights[orientation] = tf.maximum(\n",
    "            tf.abs(coefficients_reference_image_y[:, :, 2 + orientation * number_of_scales]),\n",
    "            tf.abs(coefficients_distorted_image_y[:, :, 2 + orientation * number_of_scales])\n",
    "        )\n",
    "        coefficients_reference_image_y_magnitude = tf.abs(coefficients_reference_image_y[:, :, orientation * number_of_scales:2 + orientation * number_of_scales])\n",
    "        coefficients_distorted_image_y_magnitude = tf.abs(coefficients_distorted_image_y[:, :, orientation * number_of_scales:2 + orientation * number_of_scales])\n",
    "        local_similarities[orientation] = tf.reduce_sum(\n",
    "            (2 * coefficients_reference_image_y_magnitude * coefficients_distorted_image_y_magnitude + C) / (coefficients_reference_image_y_magnitude**2 + coefficients_distorted_image_y_magnitude**2 + C),\n",
    "            axis = 2\n",
    "        ) / 2\n",
    "    weights = tf.stack(weights, axis = -1)\n",
    "    local_similarities = tf.stack(local_similarities, axis = -1)\n",
    "\n",
    "    # Computes the similarities for color channels\n",
    "    if is_color_image:\n",
    "        similarity_i = (2 * coefficients_reference_image_i * coefficients_distorted_image_i + C) / (coefficients_reference_image_i**2 + coefficients_distorted_image_i**2 + C)\n",
    "        similarity_q = (2 * coefficients_reference_image_q * coefficients_distorted_image_q + C) / (coefficients_reference_image_q**2 + coefficients_distorted_image_q**2 + C)\n",
    "        local_similarities = tf.concat([local_similarities[:, :, slice(0, 2)], tf.expand_dims((similarity_i + similarity_q) / 2, axis = 2)], axis = 2)\n",
    "        weights = tf.concat([weights[:, :, slice(0, 2)], tf.expand_dims((weights[:, :, 0] + weights[:, :, 1]) / 2, axis = 2)], axis = 2)\n",
    "\n",
    "    # Calculates the final score\n",
    "    similarity = logit(tf.reduce_sum(sigmoid(local_similarities[:], alpha) * weights[:]) / tf.reduce_sum(weights[:]), alpha)**2\n",
    "\n",
    "    # Returns the result\n",
    "    return similarity, local_similarities, weights\n",
    "\n",
    "def subsample(image):\n",
    "    \"\"\"\n",
    "    Convolves the specified image with a 2x2 mean filter and performs a dyadic subsampling step. This\n",
    "    simulates the typical distance between an image and its viewer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The image that is to be subsampled.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.ndarray | tensorflow.Tensor: Returns the subsampled image.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(image):\n",
    "        subsampled_image = convolve2d(image, numpy.ones((2, 2)) / 4.0, mode = \"same\")\n",
    "    elif is_tensorflow(image):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        subsampled_image = convolve2d(image, tf.ones((2, 2)) / 4.0, mode = \"same\")\n",
    "    else:\n",
    "        raise ValueError(\"The image is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "    subsampled_image = subsampled_image[::2, ::2]\n",
    "    return subsampled_image\n",
    "\n",
    "def convolve2d(data, kernel, mode = \"same\"):\n",
    "    \"\"\"\n",
    "    Convolves the first input array with the second one in the same way MATLAB does. Due to an\n",
    "    implementation detail, the SciPy and MATLAB implementations yield different results. This method\n",
    "    rectifies this shortcoming of the SciPy implementation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        data: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The first input array.\n",
    "        kernel: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The second input array with which the fist input array is being convolved.\n",
    "        mode: str\n",
    "            A string indicating the size of the output.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.ndarray | tensorflow.Tensor: Returns a 2-dimensional array containing a subset of the discrete\n",
    "        linear convolution of the first input array with the second input array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks if the NumPy or the TensorFlow implementation is to be used\n",
    "    if is_numpy(data) and is_numpy(kernel):\n",
    "\n",
    "        # Due to an implementation detail of MATLAB, the input arrays have to be rotated by 90 degrees to\n",
    "        # retrieve a similar result as compared to MATLAB\n",
    "        rotated_data = numpy.rot90(data, 2)\n",
    "        rotated_kernel = numpy.rot90(kernel, 2)\n",
    "\n",
    "        # The convolution result has to be rotated again by 90 degrees to get the same result as in MATLAB\n",
    "        result = signal.convolve2d(\n",
    "            rotated_data,\n",
    "            rotated_kernel,\n",
    "            mode = mode\n",
    "        )\n",
    "        result = numpy.rot90(result, 2)\n",
    "\n",
    "    elif is_tensorflow(data) and is_tensorflow(kernel):\n",
    "\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "        # TensorFlow requires a 4D Tensor for convolution, the data has to be shaped [batch_size, width, height, number_of_channels]\n",
    "        # and the kernel has to be shaped [width, height, number_of_channels_in, number_of_channels_out]\n",
    "        data_shape = data.get_shape().as_list()\n",
    "        data = tf.reshape(data, [1, data_shape[0], data_shape[1], 1])\n",
    "        kernel_shape = kernel.get_shape().as_list()\n",
    "        kernel = tf.reshape(kernel, [kernel_shape[0], kernel_shape[1], 1, 1])\n",
    "\n",
    "        # Calculates the convolution, for some reason that I do not fully understand, the result has to be negated\n",
    "        result = tf.nn.conv2d(\n",
    "            data,\n",
    "            kernel,\n",
    "            padding = mode.upper(),\n",
    "            strides = [1, 1, 1, 1]\n",
    "        )\n",
    "        result = tf.negative(tf.squeeze(result))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either the data or the kernel is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "    # Returns the result of the convolution\n",
    "    return result\n",
    "\n",
    "def haar_wavelet_decompose(image, number_of_scales):\n",
    "    \"\"\"\n",
    "    Performs the Haar wavelet decomposition.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        image: numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The image that is to be decomposed.\n",
    "        number_of_scales: int\n",
    "            The number different filter scales that is to be used.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.ndarray | tensorflow.Tensor: Returns the coefficients that were determined by the Haar wavelet\n",
    "        decomposition.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(image):\n",
    "\n",
    "        coefficients = numpy.zeros(sum([image.shape, (2 * number_of_scales, )], ()))\n",
    "        for scale in range(1, number_of_scales + 1):\n",
    "            haar_filter = 2**(-scale) * numpy.ones((2**scale, 2**scale))\n",
    "            haar_filter[:haar_filter.shape[0] // 2, :] = -haar_filter[:haar_filter.shape[0] // 2, :]\n",
    "            coefficients[:, :, scale - 1] = convolve2d(image, haar_filter, mode = \"same\")\n",
    "            coefficients[:, :, scale + number_of_scales - 1] = convolve2d(image, numpy.transpose(haar_filter), mode = \"same\")\n",
    "\n",
    "    elif is_tensorflow(image):\n",
    "\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "        coefficients = [None] * (2 * number_of_scales)\n",
    "        for scale in range(1, number_of_scales + 1):\n",
    "            upper_part = -2**(-scale) * tf.ones((2**scale // 2, 2**scale))\n",
    "            lower_part = 2**(-scale) * tf.ones((2**scale // 2, 2**scale))\n",
    "            haar_filter = tf.concat([upper_part, lower_part], axis = 0)\n",
    "            coefficients[scale - 1] = convolve2d(image, haar_filter, mode = \"same\")\n",
    "            coefficients[scale + number_of_scales - 1] = convolve2d(image, tf.transpose(haar_filter), mode = \"same\")\n",
    "        coefficients = tf.stack(coefficients, axis = -1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"The image is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "    return coefficients\n",
    "\n",
    "def sigmoid(value, alpha):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid (logistic) function to the specified value.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value: int | float | numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The value to which the sigmoid function is to be applied.\n",
    "        alpha: float\n",
    "            The steepness of the \"S\"-shaped curve produced by the sigmoid function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        int | float | numpy.ndarray | tensorflow.Tensor: Returns the result of the sigmoid function.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(value):\n",
    "        return 1.0 / (1.0 + numpy.exp(-alpha * value))\n",
    "    elif is_tensorflow(value):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        return 1.0 / (1.0 + tf.exp(-alpha * value))\n",
    "    else:\n",
    "        raise ValueError(\"The value is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "def logit(value, alpha):\n",
    "    \"\"\"\n",
    "    Applies the logit function to the specified value, which is the reverse of the sigmoid\n",
    "    (logistic) function.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value: int | float | numpy.ndarray | tensorflow.Tensor | tensorflow.Variable\n",
    "            The value to which the logit function is to be applied.\n",
    "        alpha: float\n",
    "            The steepness of the \"S\"-shaped curve produced by the logit function.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        int | float | tensorflow.Tensor: Returns the result of the logit function.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_numpy(value):\n",
    "        return numpy.log(value / (1 - value)) / alpha\n",
    "    elif is_tensorflow(value):\n",
    "        if not is_tensorflow_available:\n",
    "            raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "        return tf.log(value / (1 - value)) / alpha\n",
    "    else:\n",
    "        raise ValueError(\"The value is neither a NumPy array, nor a TensorFlow tensor or variable. There are only NumPy and TensorFlow implementations available.\")\n",
    "\n",
    "def is_numpy(value):\n",
    "    \"\"\"\n",
    "    Determines whether the specified value is a NumPy value, i.e. an numpy.ndarray or a NumPy scalar, etc.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value:\n",
    "            The value for which is to be determined if it is a NumPy value or not.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        boolean: Returns True if the value is a NumPy value and False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    return type(value).__module__.split(\".\")[0] == \"numpy\"\n",
    "\n",
    "def is_tensorflow(value):\n",
    "    \"\"\"\n",
    "    Determines whether the specified value is a TensorFlow value, i.e. an tensorflow.Variable or a\n",
    "    tensorflow.Tensor, etc.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        value:\n",
    "            The value for which is to be determined if it is a TensorFlow value or not.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        boolean: Returns True if the value is a TensorFlow value and False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    if not is_tensorflow_available:\n",
    "        raise ValueError(\"TensorFlow is not installed. If you have TensorFlow installed, please check your installation.\")\n",
    "\n",
    "    return type(value).__module__.split(\".\")[0] == \"tensorflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     2,
     32,
     91,
     138,
     143,
     172
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# File Reading Code\n",
    "\n",
    "def get_duke_proj(index, lesion):\n",
    "    if lesion:\n",
    "        a       = sio.loadmat(\"/media/dril/My Passport/CHO-DATA/WITH-LESION-MAT/LE/\"+str(index)+\".mat\")[\"head\"]\n",
    "    else:\n",
    "        a       = sio.loadmat(\"/media/dril/My Passport/CHO-DATA/NO-LESION-MAT/LE/\"+str(index)+\".mat\")[\"head\"]\n",
    "    testvol = np.rollaxis(a, 2, 0)\n",
    "    testvol = np.moveaxis(testvol, [0, 1, 2], [0, 2, 1])\n",
    "    \n",
    "    testvol[testvol == 0.80] = 0.81\n",
    "    print(np.unique(testvol.flatten()))\n",
    "    \n",
    "    testvol = testvol/65\n",
    "    proj_arr         = W*testvol\n",
    "    \n",
    "    # All Flags\n",
    "    insert_noise     = 1\n",
    "    if insert_noise:\n",
    "        I0        = 1000\n",
    "        proj      = I0*np.exp(-proj_arr)\n",
    "        proj_noi  = np.random.poisson(proj)\n",
    "        proj_noi[proj_noi == 0] = 1\n",
    "        g_noi                   = np.log(I0) - np.log(proj_noi) # convert back to line integrals \n",
    "        g_noi[g_noi < 0]        = 0\n",
    "        proj_arr = g_noi\n",
    "    \n",
    "    temp_proj = np.reshape(proj_arr, [detCols, num_angles, detRows])\n",
    "    temp_proj = np.rollaxis(temp_proj, 0, 2)\n",
    "    #print(temp_proj.shape)\n",
    "    return temp_proj\n",
    "\n",
    "def load_prj_raw(breast_type):\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    print(BINSx*BINSy, ANGLES, prj_allangle.shape)\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    start_angle = -21.30\n",
    "    \n",
    "    proj_paths = glob.glob(\"/media/dril/Windows/mcgpu1/projections_without_fsm\"+projection_name+\"/*.raw\")\n",
    "    proj_paths.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "    \n",
    "    for p in proj_paths:\n",
    "        print(p)\n",
    "        \n",
    "        if '.0000.' in p:\n",
    "            continue\n",
    "        \n",
    "        a    = np.fromfile(p, dtype='float32')#pydicom.dcmread(p)\n",
    "        a    = np.reshape(a, [2, 1504, 3000])\n",
    "        temp = a[0, :, :]#.pixel_array.T\n",
    "        temp = np.log(10000000)-np.log(temp)\n",
    "        \n",
    "        if(0):\n",
    "            # Sharpening filter\n",
    "            temp = unsharp_mask(temp, radius=3, amount=1, preserve_range=True)\n",
    "            thresh_min      = threshold_minimum(temp)\n",
    "            binary_adaptive = temp > thresh_min\n",
    "            temp = np.multiply(temp, binary_adaptive)\n",
    "            \n",
    "        if breast_type == \"right\":\n",
    "            temp = np.fliplr(temp)\n",
    "            temp = temp[-BINSy:]\n",
    "        else:\n",
    "            temp = temp[:BINSy]\n",
    "            temp = np.flipud(temp)\n",
    "            print(temp.shape)\n",
    "        \n",
    "        temp = temp.flatten()\n",
    "        temp = x_y_flip(temp)\n",
    "        \n",
    "        x.append(temp)\n",
    "        y.append(start_angle)\n",
    "        start_angle = start_angle + 1.92\n",
    "    \n",
    "    y = np.array(y)*np.pi/180\n",
    "    \n",
    "    print(\"length x \", len(x), \" \", len(y))\n",
    "    y, x = zip(*sorted(zip(y, x)))\n",
    "    for j in range(len(x)):\n",
    "        print(\"Proj \", j)\n",
    "        flag2 = j\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = x[j][i]\n",
    "    \n",
    "    return prj_allangle, y\n",
    "\n",
    "def load_prj_ima(breast_type):\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    print(BINSx*BINSy, ANGLES, prj_allangle.shape)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    proj_paths = glob.glob(\"/media/dril/ubuntudata/DBT_recon_data/\"+projection_name+\"/CE*.IMA\")\n",
    "    for p in proj_paths:\n",
    "        if '.0000.' in p:\n",
    "            continue\n",
    "        \n",
    "        a    = pydicom.dcmread(p)\n",
    "        temp = a.pixel_array.T\n",
    "        temp = np.log(10000)-np.log(temp)\n",
    "        # Sharpening filter\n",
    "        temp = unsharp_mask(temp, radius=3, amount=1, preserve_range=True)\n",
    "        thresh_min      = threshold_minimum(temp)\n",
    "        binary_adaptive = temp > thresh_min\n",
    "        temp = np.multiply(temp, binary_adaptive)\n",
    "            \n",
    "        if breast_type == \"right\":\n",
    "            temp = np.fliplr(temp)\n",
    "            temp = temp[-BINSy:]\n",
    "        else:\n",
    "            temp = temp[:BINSy]\n",
    "            temp = np.flipud(temp)\n",
    "        \n",
    "        temp = temp.flatten()\n",
    "        temp = x_y_flip(temp)\n",
    "        \n",
    "        x.append(temp)\n",
    "        y.append(float(a[0x00181530].value))\n",
    "    y = np.array(y)*np.pi/180\n",
    "    \n",
    "    print(\"length x \", len(x), \" \", len(y))\n",
    "    y, x = zip(*sorted(zip(y, x)))\n",
    "    for j in range(len(x)):\n",
    "        print(\"Proj \", j)\n",
    "        flag2 = j\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = x[j][i]\n",
    "    \n",
    "    return prj_allangle, y\n",
    "\n",
    "def import_param():\n",
    "    for i in range(ANGLES):\n",
    "        index[i] = i\n",
    "    return index\n",
    "\n",
    "def load_prj():\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    \n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    scat_allangle = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    for viewangle in range(ANGLES):\n",
    "        s        = viewangle + 1\n",
    "        filename = basepath + filepath+str(s).zfill(4)#+'.raw'\n",
    "        \n",
    "        with open(filename, 'rb') as f:\n",
    "            primary_plus_scatter  = np.fromfile(f, dtype=np.float32)\n",
    "            host_prj_temp1        = primary_plus_scatter[:b_size]\n",
    "            host_prj_temp2        = primary_plus_scatter[b_size:]\n",
    "        \n",
    "        host_prj_1view_temp = x_y_flip(host_prj_temp1)\n",
    "        host_sct_1view_temp = x_y_flip(host_prj_temp2)\n",
    "        \n",
    "        print(host_prj_1view_temp.shape)\n",
    "        \n",
    "        # all angle together\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = host_prj_1view_temp[i]\n",
    "            scat_allangle[flag2*BINSx*BINSy + i] = host_sct_1view_temp[i]\n",
    "        \n",
    "        flag2 = flag2+1\n",
    "    return prj_allangle, scat_allangle\n",
    "    \n",
    "def load_prj_std(data_type):\n",
    "    b_size = BINSx*BINSy\n",
    "    flag2  = 0\n",
    "    \n",
    "    prj_allangle  = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    #scat_allangle = np.zeros(BINSx*BINSy*ANGLES)\n",
    "    \n",
    "    for viewangle in range(ANGLES):\n",
    "        s        = viewangle + 1\n",
    "        \n",
    "        if data_type   == 0:\n",
    "            #filename = basepath + 'OSTR_prelog/'+projection_name+str(s).zfill(4)#+\".raw\"\n",
    "            filename = basepath + 'Projections_Renamed_Seg/'+projection_name+str(s).zfill(4)#+\".raw\"\n",
    "        elif data_type == 1:\n",
    "            filename = basepath + 'OSTR_scatter/'+scatter_name+str(s).zfill(4)#+\".raw\"\n",
    "        else:\n",
    "            filename = basepath + 'OSTR_blank/'+blank_name+str(s).zfill(4)#+\".raw\"\n",
    "        \n",
    "        #print(filename)\n",
    "        with open(filename, 'rb') as f:\n",
    "            #data  = np.load(f)\n",
    "            data  = np.fromfile(f, dtype=np.float32)\n",
    "            # If doign SART\n",
    "            #data  = np.log(10000) - np.log(data)\n",
    "            \n",
    "            #print(data.shape)\n",
    "            #data  = np.reshape(data, (1400, 3584))\n",
    "            #data  = data[:1400, :]\n",
    "            #data  = np.flip(data, 0)\n",
    "            #data  = data.flatten()\n",
    "            #print(data.shape)\n",
    "                #data  = np.fromfile(f, dtype=np.float32)\n",
    "        #np.save(filename+'.npy', data)\n",
    "        proj = x_y_flip(data)\n",
    "        \n",
    "        # all angle together\n",
    "        for i in range(0, BINSx*BINSy):\n",
    "            prj_allangle[flag2*BINSx*BINSy + i]  = proj[i]\n",
    "        \n",
    "        flag2 = flag2+1\n",
    "    \n",
    "    return prj_allangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All settings\n",
    "# CE18 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE05 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE08 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE11 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE24 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE07 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE14 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE25 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE28 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE03 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE06 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE20 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE12 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE22 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings Hash\n",
    "\n",
    "train_list = ['CE18', 'CE05', 'CE28', 'CE25', 'CE14', 'CE24', 'CE11',  'CE20', 'CE12', 'CE22']\n",
    "x_p0_list  = [-116.25, -116.25, ]\n",
    "\n",
    "# CE18 right\n",
    "# x_p0    = \n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE05 right\n",
    "# x_p0    = \n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE08 right\n",
    "# x_p0    = -116.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE11 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE24 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE07 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE14 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE25 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE28 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE03 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE06 left\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE20 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE12 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0\n",
    "# CE22 right\n",
    "# x_p0    = -126.25\n",
    "# y_p0    = -115.1\n",
    "# z_p0    = -30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings Part for Monte Carlo Data\n",
    "\n",
    "projection_name = \"1\"#\"CE26.3584x1000.\"#\"OSTR_LE.3584x1400.\"\n",
    "\n",
    "IMGSIZx = 2600\n",
    "IMGSIZy = 1200\n",
    "IMGSIZz = 48\n",
    "f_size  = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "\n",
    "BINSx   = 3000#3584\n",
    "#BINSy   = 2816\n",
    "BINSy   = 1500#1600\n",
    "\n",
    "Vsize_x = 0.085\n",
    "Vsize_y = 0.085\n",
    "Vsize_z = 1\n",
    "\n",
    "x_p0    = -IMGSIZx*Vsize_x*0.5#-116.25\n",
    "y_p0    = -IMGSIZy*Vsize_y\n",
    "z_p0    = -30\n",
    "\n",
    "x_d0    = -BINSx*0.085*0.5\n",
    "y_d0    = -BINSy*0.085\n",
    "\n",
    "Bsize_x = 0.085\n",
    "Bsize_y = 0.085\n",
    "b_size  = BINSx*BINSy\n",
    "\n",
    "ANGLES  = 25\n",
    "index   = []\n",
    "angles  = []\n",
    "\n",
    "\n",
    "detectorR = 47.0\n",
    "sourceR   = 608.5\n",
    "sourceY   = 0.0\n",
    "\n",
    "# Tuning Parameters\n",
    "beta  = 1000\n",
    "delta = 0.03\n",
    "#####################\n",
    "\n",
    "iter_num   = 5\n",
    "subset_num = 5\n",
    "\n",
    "IO_Iter = 0\n",
    "method  = 0\n",
    "\n",
    "\n",
    "BACKPRJ_ThreX = 390\n",
    "BACKPRJ_ThreY = 1\n",
    "BACKPRJ_GridX = 1000\n",
    "BACKPRJ_GridY = 48\n",
    "nBatchXdim    = 8\n",
    "\n",
    "nBatchBINSx = 1\n",
    "nBatchBINSy = 1\n",
    "\n",
    "PRJ_ThreX = 15\n",
    "PRJ_ThreY = 15\n",
    "PRJ_GridX = 200\n",
    "PRJ_GridY = 100\n",
    "\n",
    "\n",
    "f_size     = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "all_b_size = ANGLES*BINSx*BINSy\n",
    "sub_b_size = BINSx*BINSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Settings Part for Real Data\n",
    "\n",
    "projection_name = \"CE18\"#\"CE26.3584x1000.\"#\"OSTR_LE.3584x1400.\"\n",
    "\n",
    "IMGSIZx = 2600\n",
    "IMGSIZy = 1200\n",
    "IMGSIZz = 48\n",
    "f_size  = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "\n",
    "BINSx   = 3584\n",
    "#BINSy   = 2816\n",
    "BINSy   = 1600\n",
    "\n",
    "Vsize_x = 0.085\n",
    "Vsize_y = 0.085\n",
    "Vsize_z = 1\n",
    "\n",
    "x_p0    = -116.25\n",
    "y_p0    = -115.1\n",
    "z_p0    = -30.0\n",
    "\n",
    "x_d0    = -152.32\n",
    "y_d0    = -137.7\n",
    "\n",
    "Bsize_x = 0.085\n",
    "Bsize_y = 0.085\n",
    "b_size  = BINSx*BINSy\n",
    "\n",
    "ANGLES  = 25\n",
    "index   = []\n",
    "angles  = []\n",
    "\n",
    "\n",
    "detectorR = 47.0\n",
    "sourceR   = 608.5\n",
    "sourceY   = 0.0\n",
    "\n",
    "# Tuning Parameters\n",
    "beta  = 1000\n",
    "delta = 0.03\n",
    "#####################\n",
    "\n",
    "iter_num   = 5\n",
    "subset_num = 5\n",
    "\n",
    "IO_Iter = 0\n",
    "method  = 0\n",
    "\n",
    "\n",
    "BACKPRJ_ThreX = 390\n",
    "BACKPRJ_ThreY = 1\n",
    "BACKPRJ_GridX = 1000\n",
    "BACKPRJ_GridY = 48\n",
    "nBatchXdim    = 8\n",
    "\n",
    "nBatchBINSx = 1\n",
    "nBatchBINSy = 1\n",
    "\n",
    "PRJ_ThreX = 16\n",
    "PRJ_ThreY = 16\n",
    "PRJ_GridX = 224\n",
    "PRJ_GridY = 100\n",
    "\n",
    "\n",
    "f_size     = IMGSIZx*IMGSIZy*IMGSIZz\n",
    "all_b_size = ANGLES*BINSx*BINSy\n",
    "sub_b_size = BINSx*BINSy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code for doing SART Recon\n",
    "#h_angles\n",
    "#host_prj_allangle_backup, h_angles   = load_prj_ima(\"right\")\n",
    "projection_name = \"1\"\n",
    "host_prj_allangle_backup, h_angles   = load_prj_raw(\"left\")\n",
    "h_angles = list(h_angles)\n",
    "\n",
    "h_index   = np.array(list(range(0, 25)))\n",
    "\n",
    "d_angles = cuda.to_device(h_angles)\n",
    "d_index  = cuda.to_device(h_index)\n",
    "\n",
    "angleStart = 0\n",
    "angleEnd   = 25\n",
    "\n",
    "\n",
    "host_prj_allangle   = copy.deepcopy(host_prj_allangle_backup) #load_prj_std(0) # Load prelog  data\n",
    "\n",
    "host_prj_allangle   = regroup_prj(host_prj_allangle)\n",
    "\n",
    "index_tmp = np.zeros(ANGLES)\n",
    "for i in range(0, ANGLES):\n",
    "    index_tmp[i] = h_index[i]\n",
    "\n",
    "flag           = 0\n",
    "ANGLES_per_sub = int(ANGLES/subset_num)\n",
    "h_index        = np.zeros(ANGLES, dtype=int)\n",
    "\n",
    "for i in range(0, subset_num):\n",
    "    for j in range(0, ANGLES_per_sub):\n",
    "        h_index[flag] = index_tmp[j*subset_num+i]\n",
    "        flag          = flag + 1\n",
    "        \n",
    "\n",
    "\n",
    "sub_b_size     = ANGLES_per_sub*b_size\n",
    "\n",
    "print('sub_b_size is ', sub_b_size)\n",
    "print('delta is ',      delta)\n",
    "print(\"Indexes are \",   h_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     42
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recon Loop\n",
    "\n",
    "delta_array      = [0.0005]#[0.0001, 0.0002, 0.0003, 0.0005, 0.0006, 0.0007, 0.001]\n",
    "beta_array       = []\n",
    "beta_array.append(0)\n",
    "# for i in range(6):\n",
    "#     beta_array.append(np.random.uniform(0.11, 0.69))\n",
    "beta_array       = -1*np.around(beta_array, decimals=3)\n",
    "print(\"BETA array\")\n",
    "print(beta_array)\n",
    "\n",
    "#0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0]#[-0.7, -0.5, -0.3, -0.1, 0]\n",
    "lambda_parameter = 0.9\n",
    "\n",
    "for delta in delta_array:\n",
    "    for beta in beta_array:\n",
    "        print(\"Reconstructing \", beta, delta)\n",
    "        \n",
    "        d_line_sub     = cuda.device_array(int(sub_b_size))\n",
    "        d_normprj      = cuda.device_array(int(sub_b_size))\n",
    "\n",
    "        d_index        = cuda.to_device(h_index)\n",
    "\n",
    "        host_est      = np.zeros(f_size, np.float32)\n",
    "        d_est         = cuda.to_device(host_est)\n",
    "\n",
    "        host_prj_est  = np.zeros(f_size, np.float32)\n",
    "        prj_est       = cuda.to_device(host_prj_est)\n",
    "\n",
    "        host_prj_est  = np.zeros(f_size, np.float32)\n",
    "        prj_est       = cuda.to_device(host_prj_est)\n",
    "\n",
    "        d_prior       = np.zeros(f_size, np.float32)\n",
    "        d_prior       = cuda.to_device(d_prior)\n",
    "\n",
    "        d_diff_line_sub = cuda.device_array(int(sub_b_size))\n",
    "        d_normprj_sub   = cuda.device_array(int(sub_b_size))\n",
    "        d_prj_est_sub   = cuda.device_array(int(sub_b_size))\n",
    "        #d_prj_buf_sub   = cuda.device_array(int(sub_b_size))\n",
    "\n",
    "        for i in range(0, 5):\n",
    "            #print(\"Iteration \", i)\n",
    "            for a in range(0, 5):\n",
    "                angleStart = a*ANGLES_per_sub\n",
    "                angleEnd   = (a+1)*ANGLES_per_sub\n",
    "\n",
    "                host_prj_sub  = temp_fun1(angleStart, b_size, sub_b_size, host_prj_allangle)\n",
    "                d_prj_buf_sub = cuda.to_device(host_prj_sub)\n",
    "\n",
    "                d_prior       = np.zeros(f_size, np.float32)\n",
    "                d_prior       = cuda.to_device(d_prior)\n",
    "\n",
    "                prior_GPU_SART(d_prior, d_est, delta)\n",
    "\n",
    "                fprojectCB_1R_GPU_SART_cos(\n",
    "                    d_est,\n",
    "                    d_prj_est_sub,\n",
    "                    d_normprj_sub,\n",
    "                    d_angles,\n",
    "                    d_index,\n",
    "                    angleStart,\n",
    "                    angleEnd)\n",
    "\n",
    "                #d_normprj_sub\n",
    "                h_diff_line_sub  = d_diff_line_sub.copy_to_host()\n",
    "                h_normprj_sub    = d_normprj_sub.copy_to_host()\n",
    "                h_prj_est_sub    = d_prj_est_sub.copy_to_host()\n",
    "\n",
    "                #h_normprj_sub[h_normprj_sub  < 0.5] = 10000\n",
    "\n",
    "                result_diff = SART_prj_diff(h_diff_line_sub,\n",
    "                    host_prj_sub,\n",
    "                    h_prj_est_sub,\n",
    "                    h_normprj_sub,\n",
    "                    h_index,\n",
    "                    angleStart,\n",
    "                    angleEnd)\n",
    "\n",
    "                #result_diff[result_diff > 0.5] = 0\n",
    "                #result_diff[result_diff > 100] = 0\n",
    "                #result_diff = np.nan_to_num(np.divide(host_prj_sub - h_prj_est_sub, h_normprj_sub))\n",
    "\n",
    "                d_diff_line_sub = cuda.to_device(result_diff)\n",
    "\n",
    "                bprojectCB_4B_GPU_R_SART (d_est, d_diff_line_sub, d_prior,\n",
    "                                          d_index,\n",
    "                                          d_angles,\n",
    "                                          angleStart,\n",
    "                                          angleEnd,\n",
    "                                          lambda_parameter, beta)\n",
    "\n",
    "                d_prj_est_sub = np.zeros(d_prj_est_sub.shape)\n",
    "                d_prj_est_sub = cuda.to_device(d_prj_est_sub)\n",
    "\n",
    "                d_normprj_sub = np.zeros(d_normprj_sub.shape)\n",
    "                d_normprj_sub = cuda.to_device(d_normprj_sub)\n",
    "\n",
    "                d_prj_buf_sub = np.zeros(d_prj_buf_sub.shape)\n",
    "                d_prj_buf_sub = cuda.to_device(d_prj_buf_sub)\n",
    "                \n",
    "        host_est = d_est.copy_to_host()\n",
    "        host_est.astype('float32').tofile('/media/dril/My Passport/'+projection_name+'_'+str(IMGSIZx)+'x'+str(IMGSIZy)+'x'+str(IMGSIZz)+'.'+str(i)+'_'+str(delta)+'_'+str(beta)+'.raw')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     55,
     161,
     261,
     371,
     479,
     584,
     686,
     727,
     754
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CNN Models\n",
    "\n",
    "def rating_cnn(input_size = (256, 256, 1)):\n",
    "    filter1 = 4\n",
    "    filter2 = 4\n",
    "    filter3 = 4\n",
    "    filter4 = 4\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same',kernel_initializer = 'glorot_normal')(input1)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #conv1 = Dropout(0.2)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #conv2 = Dropout(0.2)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filter3, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #conv3 = Dropout(0.2)(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(filter4, 3, padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    out1 = Flatten()(conv4)\n",
    "    #out1 = Dropout(0.3)(out1)\n",
    "    \n",
    "    #out2 = Dense(64, kernel_initializer = 'glorot_normal')(out1)\n",
    "    #out2 = LeakyReLU()(out2)\n",
    "    #out2 = Dropout(0.3)(out2)\n",
    "    \n",
    "    #out3 = Dense(32,  kernel_initializer = 'glorot_normal')(out2)\n",
    "    #out3 = LeakyReLU()(out3)\n",
    "    \n",
    "    out3 = Dense(1, activation=\"sigmoid\")(out1)\n",
    "    \n",
    "    model  = Model(input = input1, output = out3)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def unet_double(pretrained_weights = None, input_size = (128, 128, 5), ):\n",
    "    filter1 = 64\n",
    "    filter2 = 128\n",
    "    filter3 = 256\n",
    "    filter4 = 512\n",
    "    filter5 = 1024\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    input3 = Input((1, ))\n",
    "    \n",
    "    hash_val1 = Dense(128, activation='relu')(input2)\n",
    "    hash_val1 = Dense(1, activation='relu')(hash_val1)\n",
    "    \n",
    "    hash_val2 = Dense(128, activation='relu')(input3)\n",
    "    hash_val2 = Dense(1, activation='relu')(hash_val2)\n",
    "    \n",
    "    hash_val = Multiply()([hash_val1, hash_val2])\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(hash_val)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2, input3], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_vanilla(pretrained_weights = None, input_size = (128, 128, 1), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    #input2 = Input((1, ))\n",
    "    \n",
    "    #hash_val = Dense(128, activation='relu')(input2)\n",
    "    #hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    #hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    #input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    #conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    #conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    #conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.1)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    #pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.1)(conv5)\n",
    "    #drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    #conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    #conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    #conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = input1, output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_two(pretrained_weights = None, input_size = (128, 128, 1), ):\n",
    "    filter1 = 64\n",
    "    filter2 = 128\n",
    "    filter3 = 256\n",
    "    filter4 = 512\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(input2)\n",
    "    hash_val = Dropout(0.3)(hash_val)\n",
    "    hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    hash_val1 = Dense(128, activation='relu')(input2)\n",
    "    hash_val1 = Dropout(0.3)(hash_val1)\n",
    "    hash_val1 = Dense(32, activation='relu')(hash_val1)\n",
    "    hash_val1 = Dense(1, activation='relu')(hash_val1)\n",
    "    \n",
    "    input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Dropout(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val1, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Dropout(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val1, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Dropout(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val1, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet(pretrained_weights = None, input_size = (256, 256, 1), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(input2)\n",
    "    hash_val = Dropout(0.3)(hash_val)\n",
    "    hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4, up6], axis = 3)\n",
    "    \n",
    "    \n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Dropout(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Dropout(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Dropout(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_no_dense(pretrained_weights = None, input_size = (256, 256, 1), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input((1, ))\n",
    "    \n",
    "    #hash_val = Dense(128, activation='relu')(input2)\n",
    "    #hash_val = Dropout(0.3)(hash_val)\n",
    "    #hash_val = Dense(32, activation='relu')(hash_val)\n",
    "    hash_val = input2#Dense(1, activation='relu')(hash_val)\n",
    "    \n",
    "    input_mul = Multiply()([hash_val, input1])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Dropout(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Dropout(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Dropout(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, :, :, 4])(input1)\n",
    "    input_last  = input1#Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    conv10 = Subtract()([input_last, conv9])\n",
    "    model  = Model(input = [input1, input2], output = conv10)\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def unet_lstm(pretrained_weights = None, input_size = (128, 128, 2), ):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    single_input = Input(input_size)\n",
    "    \n",
    "    input1 = Lambda(lambda x: x[:, :, :, 0])(single_input)\n",
    "    input1 = Reshape([128, 128, 1])(input1)\n",
    "    \n",
    "    input2 = Lambda(lambda x: x[:, :, :, 1])(single_input)\n",
    "    input2 = Flatten()(input2)\n",
    "    input2 = Reshape([1, 128*128])(input2) \n",
    "    input2 = Lambda(lambda x: x[:, :, 0])(input2)\n",
    "    \n",
    "    hash_val = Dense(128, activation='relu')(input2)\n",
    "    hash_val = Dense(1, activation='relu')(hash_val)\n",
    "        \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(input1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = LeakyReLU(0.2)(conv2)\n",
    "    conv2 = Multiply()([hash_val, conv2])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = LeakyReLU(0.2)(conv3)\n",
    "    conv3 = Multiply()([hash_val, conv3])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    conv4 = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = LeakyReLU(0.2)(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    pool4 = Multiply()([hash_val, pool4])\n",
    "    \n",
    "    conv5 = Conv2D(filter5, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = LeakyReLU(0.2)(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    drop5 = Multiply()([hash_val, drop5])\n",
    "    \n",
    "    up6    = Conv2D(filter4, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6    = LeakyReLU(0.2)(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Conv2D(filter4, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6  = LeakyReLU(0.2)(conv6)\n",
    "    conv6  = Multiply()([hash_val, conv6])\n",
    "        \n",
    "    up7    = Conv2D(filter3, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7    = LeakyReLU(0.2)(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7  = LeakyReLU(0.2)(conv7)\n",
    "    conv7  = Multiply()([hash_val, conv7])\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8    = LeakyReLU(0.2)(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8  = LeakyReLU(0.2)(conv8)\n",
    "    conv8  = Multiply()([hash_val, conv8])\n",
    "    \n",
    "    up9    = Conv2D(filter1, 2,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9    = LeakyReLU(0.2)(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    conv9  = Conv2D(1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9  = LeakyReLU(0.2)(conv9)\n",
    "    \n",
    "    #conv10 = Subtract()([input1, conv9])\n",
    "    \n",
    "    model  = Model(input = single_input, output = conv9)\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def lstm_model():\n",
    "    input_size = (5, 128, 128, 1)\n",
    "    \n",
    "    input1     = Input(input_size)\n",
    "    input2     = Input((1, ))\n",
    "    \n",
    "    cnn_model  = unet()\n",
    "    \n",
    "    #time2       = TimeDistributed(cnn_model)(input1)\n",
    "    \n",
    "    lstm_out1   = ConvLSTM2D(filters=32, kernel_size=(3, 3), input_shape=(5, 128, 128, 1),\n",
    "                             padding='same', activation=LeakyReLU(alpha=0.2), return_sequences=True)(input1)\n",
    "    \n",
    "    lstm_out2   = ConvLSTM2D(filters=1, kernel_size=(3, 3), padding='same', activation=LeakyReLU(alpha=0.2),\n",
    "                            return_sequences=False)(lstm_out1)\n",
    "    \n",
    "    input_one = Lambda(lambda x: x[:, 4, :, :, :])(input1)\n",
    "    input_one = Reshape([128, 128, 1])(input_one)\n",
    "    \n",
    "    cnn_out1   = cnn_model([lstm_out2, input2])\n",
    "    \n",
    "    final_out = Subtract()([input_one, cnn_out1])\n",
    "    #lstm_out1   = ConvLSTM2D(filters=40, kernel_size=(3, 3), input_shape=(5, 128, 128, 1),\n",
    "    #                         padding='same', activation=LeakyReLU(alpha=0.2), return_sequences=True)(lstm_out1)\n",
    "    #lstm_out1   = ConvLSTM2D(filters=40, kernel_size=(3, 3), input_shape=(5, 128, 128, 1),\n",
    "    #                         padding='same', activation=LeakyReLU(alpha=0.2), return_sequences=True)(lstm_out1)\n",
    "    #lstm_out2   = ConvLSTM2D(filters=1, kernel_size=(3, 3), padding='same', activation=LeakyReLU(alpha=0.2),\n",
    "    #                         return_sequences=False)(lstm_out1)\n",
    "    \n",
    "    #input_last  = Lambda(lambda x: x[:, 4, :, :, 0])(input1)\n",
    "    #input_last  = Reshape([128, 128, 1])(input_last)\n",
    "    \n",
    "    #conv10      = Subtract()([input1, lstm_out2])\n",
    "    \n",
    "    time_model  = Model(input = [input1, input2], output = final_out)\n",
    "    time_model.compile(optimizer = Adam(lr = 1e-4), \n",
    "                  loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    \n",
    "    return time_model\n",
    "\n",
    "def conv_lstm_model():\n",
    "    seq = Sequential()\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                       input_shape=(5, 128, 128, 1),\n",
    "                       padding='same', return_sequences=True))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=True))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=True))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=1, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=False))\n",
    "    #seq.add(BatchNormalization())\n",
    "\n",
    "    #seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "    #               activation='sigmoid',\n",
    "    #               padding='same', data_format='channels_last'))\n",
    "    \n",
    "    seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def unet_combined(pretrained_weights = None, input_size = (128, 128, 1)):\n",
    "    base_model  = unet()\n",
    "    base_model.load_weights(\"all-data-0-to-7-0.0005-5.h5\")\n",
    "\n",
    "    filter1 = 32\n",
    "    filter2 = 32\n",
    "    filter3 = 32\n",
    "    \n",
    "    input1 = Input(input_size)\n",
    "    input2 = Input(input_size)\n",
    "    \n",
    "    input1_1 = Input((1, ))\n",
    "    input1_2 = Input((1, ))\n",
    "    input1_3 = Input((1, ))\n",
    "    input1_4 = Input((1, ))\n",
    "    input1_5 = Input((1, ))\n",
    "    input1_6 = Input((1, ))\n",
    "    input1_7 = Input((1, ))\n",
    "    \n",
    "    for t in base_model.layers:\n",
    "        t.trainable = False\n",
    "    \n",
    "    w1    = Concatenate()([input1, input2])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(w1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter2, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter3, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    \n",
    "    layer_output = base_model.layers[-4].output\n",
    "    \n",
    "    new_model    = Model(base_model.input, layer_output)\n",
    "    \n",
    "    r1 = new_model([input1, input1_1])\n",
    "    r2 = new_model([input1, input1_2])\n",
    "    r3 = new_model([input1, input1_3])\n",
    "    r4 = new_model([input1, input1_4])\n",
    "    r5 = new_model([input1, input1_5])\n",
    "    r6 = new_model([input1, input1_6])\n",
    "    r7 = new_model([input1, input1_7])\n",
    "    \n",
    "#     c1 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 0])(conv1))\n",
    "#     c2 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 1])(conv1))\n",
    "#     c3 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 2])(conv1))\n",
    "#     c4 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 3])(conv1))\n",
    "#     c5 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 4])(conv1))\n",
    "#     c6 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 5])(conv1))\n",
    "#     c7 = Reshape([128, 128, 1])(Lambda(lambda x: x[:, :, :, 6])(conv1))\n",
    "    \n",
    "    \n",
    "#     q1 = Multiply()([conv1, r1])\n",
    "#     q2 = Multiply()([conv1, r2])\n",
    "#     q3 = Multiply()([conv1, r3])\n",
    "#     q4 = Multiply()([conv1, r4])\n",
    "#     q5 = Multiply()([conv1, r5])\n",
    "#     q6 = Multiply()([conv1, r6])\n",
    "#     q7 = Multiply()([conv1, r7])\n",
    "    \n",
    "    #ut   = Add()([q1, q2, q3, q4, q5, q6, q7])\n",
    "    #ut   = Add()([c1, c2, c3, c4, c5, c6, c7])\n",
    "    out   = Add()([r1, r2, r3, r4, r5, r6, r7])\n",
    "    out   = Multiply()([conv1, out])\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = LeakyReLU(0.2)(conv1)\n",
    "    conv1 = Conv2D(1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    out   = LeakyReLU(0.2)(conv1)\n",
    "    \n",
    "    #conv1 = Multiply()([hash_val, conv1])\n",
    "    \n",
    "    model1  = Model(input = [input1, input2, input1_1, input1_2, input1_3, input1_4, input1_5, input1_6, input1_7], output = out)\n",
    "    \n",
    "    model1.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    return model1\n",
    "\n",
    "m = rating_cnn()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to check the files created after the Reconstruction\n",
    "\n",
    "train_list = ['CE18', 'CE28', 'CE14', 'CE25', 'CE24', 'CE11', 'CE05', 'CE20', 'CE12', 'CE22'] # Add this later: 'CE25'\n",
    "test_list  = ['CE03', 'CE07' 'CE18', 'CE27', 'CE17']\n",
    "\n",
    "x_array = []\n",
    "y_array = []\n",
    "z_array = []\n",
    "\n",
    "sample_per_volume = 100\n",
    "valid_vals        = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for name in train_list[:-3]:\n",
    "    p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR-RANDOM/\"+name+\"*.4_\"+str(0.0005)+\"*.raw\")\n",
    "    p.sort()\n",
    "    print(\"*****************************************\")\n",
    "    print(name)\n",
    "    for t in p:\n",
    "        val = float(t.split('-')[-1][:-4])\n",
    "        if val not in valid_vals:\n",
    "            print(t, val)\n",
    "        #print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading the Training Data for Baseline U-Net Model with Multiple Volumes\n",
    "\n",
    "train_list = ['CE18', 'CE28', 'CE14', 'CE25', 'CE24', 'CE11', 'CE05', 'CE20', 'CE12', 'CE22'] # Add this later: 'CE25'\n",
    "test_list  = ['CE03', 'CE07' 'CE18', 'CE27', 'CE17']\n",
    "\n",
    "\n",
    "valid_vals        = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "sample_per_volume = 20\n",
    "\n",
    "\n",
    "\n",
    "for name in train_list:#train_list[-3:]:\n",
    "    p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR-RANDOM/\"+name+\"*.4_\"+str(0.0005)+\"*.raw\")\n",
    "    p.sort()\n",
    "    \n",
    "    x1_array = []\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    z_array = []\n",
    "\n",
    "    y_vol_array = np.zeros([len(p)-1, 48, 1200, 2600], dtype='float16')\n",
    "    \n",
    "    print(\"NAME \", name, len(p))\n",
    "    print(\"*****************************************\")\n",
    "    #print(name)\n",
    "    for t in p:\n",
    "        print(t)\n",
    "    \n",
    "    x = np.fromfile(p[0], dtype='float32')\n",
    "    x = np.reshape(x, [48, 1200, 2600])\n",
    "    x = x.astype('float16')\n",
    "    \n",
    "    print(p[0])\n",
    "    print(p[0].replace(\".4_\", \".0_\"),)\n",
    "    \n",
    "    x1 = np.fromfile(p[0].replace(\".4_\", \".0_\"), dtype='float32')\n",
    "    x1 = np.reshape(x1, [48, 1200, 2600])\n",
    "    x1 = x1.astype('float16')\n",
    "    \n",
    "    val_list    = []\n",
    "    \n",
    "    count = 0\n",
    "    for t in p[1:]:\n",
    "        val = float(t.split('-')[-1][:-4])\n",
    "        if val < 0.5:#val not in valid_vals:\n",
    "            y = np.fromfile(t, dtype='float32')\n",
    "            y = np.reshape(y, [48, 1200, 2600])\n",
    "            y = y.astype('float16')\n",
    "            y_vol_array[count, :, :, :] = y\n",
    "            val_list.append(float(t.split('-')[-1][:-4]))\n",
    "            count = count+1\n",
    "            print(t, float(t.split('-')[-1][:-4]))\n",
    "    \n",
    "    count = 0\n",
    "    while(True):\n",
    "        ix = np.random.randint(128, 1200-128)\n",
    "        iy = np.random.randint(128, 1200-128)\n",
    "        iz = np.random.randint(0, 48)\n",
    "        \n",
    "        tempx = x[iz, ix:ix+128, iy:iy+128]\n",
    "        \n",
    "        if np.count_nonzero(tempx.flatten())*1.0/(128*128) < 0.9:\n",
    "            continue\n",
    "        \n",
    "        #val_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        \n",
    "        for j in range(len(val_list)):\n",
    "            x_array.append(tempx)\n",
    "            tempy = y_vol_array[j, iz, ix:ix+128, iy:iy+128]\n",
    "            y_array.append(tempy)\n",
    "            z_array.append(val_list[j])\n",
    "        \n",
    "        count = count+1\n",
    "        if count == sample_per_volume:\n",
    "            break\n",
    "\n",
    "    x_array = np.expand_dims(x_array, axis=-1)\n",
    "    y_array = np.expand_dims(y_array, axis=-1)\n",
    "    z_array = np.expand_dims(z_array, axis=-1)\n",
    "    \n",
    "    print(x_array.shape, y_array.shape, z_array.shape)\n",
    "    \n",
    "    np.save('x_array_random-'+name+'-2-one-iter.npy', x_array)\n",
    "    np.save('y_array_random-'+name+'-2-one-iter.npy', y_array)\n",
    "    np.save('z_array_random-'+name+'-2-one-iter.npy', z_array)\n",
    "\n",
    "#     np.save('x_array_random-'+name+'-valid.npy', x_array)\n",
    "#     np.save('y_array_random-'+name+'-valid.npy', y_array)\n",
    "#     np.save('z_array_random-'+name+'-valid.npy', z_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading data from numpy array\n",
    "\n",
    "train_list = ['CE18', 'CE28', 'CE14', 'CE25', 'CE24', 'CE11', 'CE05', 'CE20', 'CE12', 'CE22'] # Add this later: 'CE25'\n",
    "test_list  = ['CE03', 'CE07' 'CE18', 'CE27', 'CE17']\n",
    "\n",
    "x_array = np.zeros([14560, 128, 128, 1], dtype='float16')\n",
    "y_array = np.zeros([14560, 128, 128, 1], dtype='float16')\n",
    "z_array = np.zeros([14560, 1], dtype='float16')\n",
    "\n",
    "x_val_array = np.zeros([7000, 128, 128, 1], dtype='float16')\n",
    "y_val_array = np.zeros([7000, 128, 128, 1], dtype='float16')\n",
    "z_val_array = np.zeros([7000, 1], dtype='float16')\n",
    "\n",
    "# x_array = np.zeros([6750, 128, 128, 1], dtype='float16')\n",
    "# y_array = np.zeros([6750, 128, 128, 1], dtype='float16')\n",
    "# z_array = np.zeros([6750, 1], dtype='float16')\n",
    "\n",
    "# x_val_array = np.zeros([3875, 128, 128, 1], dtype='float16')\n",
    "# y_val_array = np.zeros([3875, 128, 128, 1], dtype='float16')\n",
    "# z_val_array = np.zeros([3875, 1], dtype='float16')\n",
    "\n",
    "# x_array = np.zeros([175*7, 128, 128, 1], dtype='float16')\n",
    "# y_array = np.zeros([175*7, 128, 128, 1], dtype='float16')\n",
    "# z_array = np.zeros([175*7, 1], dtype='float16')\n",
    "\n",
    "# x_val_array = np.zeros([175*3, 128, 128, 1], dtype='float16')\n",
    "# y_val_array = np.zeros([175*3, 128, 128, 1], dtype='float16')\n",
    "# z_val_array = np.zeros([175*3, 1], dtype='float16')\n",
    "\n",
    "\n",
    "total_count = 0\n",
    "for name in train_list[:-3]:\n",
    "    a = np.load('x_array_random-'+name+'-2.npy')\n",
    "    x_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('y_array_random-'+name+'-2.npy')\n",
    "    y_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('z_array_random-'+name+'-2.npy')\n",
    "    z_array[total_count:total_count+a.shape[0],  :]     = a\n",
    "    \n",
    "    total_count = total_count + a.shape[0]\n",
    "print(total_count)\n",
    "\n",
    "total_count = 0\n",
    "for name in train_list[-3:]:\n",
    "    a = np.load('x_array_random-'+name+'-2.npy')\n",
    "    x_val_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('y_array_random-'+name+'-2.npy')\n",
    "    y_val_array[total_count:total_count+a.shape[0], :, :, :] = a\n",
    "    \n",
    "    a = np.load('z_array_random-'+name+'-2.npy')\n",
    "    z_val_array[total_count:total_count+a.shape[0],  :]     = a\n",
    "    \n",
    "    total_count = total_count + a.shape[0]\n",
    "\n",
    "\n",
    "x_array1 = np.zeros([9720, 128, 128, 1], dtype='float16')\n",
    "y_array1 = np.zeros([9720, 128, 128, 1], dtype='float16')\n",
    "z_array1 = np.zeros([9720, 1], dtype='float16')\n",
    "\n",
    "x_val_array1 = np.zeros([4380, 128, 128, 1], dtype='float16')\n",
    "y_val_array1 = np.zeros([4380, 128, 128, 1], dtype='float16')\n",
    "z_val_array1 = np.zeros([4380, 1], dtype='float16')\n",
    "\n",
    "\n",
    "xi = 0\n",
    "for i in range(len(x_array)):\n",
    "    if z_array[i] <= 0.5:\n",
    "        x_array1[xi, :, :, 0] = x_array[i, :, :, 0]\n",
    "        y_array1[xi, :, :, 0] = y_array[i, :, :, 0]\n",
    "        z_array1[xi,  0]      = z_array[i, 0]\n",
    "        xi = xi+1\n",
    "\n",
    "xi = 0\n",
    "for i in range(len(x_val_array)):\n",
    "    if z_val_array[i] <= 0.5:\n",
    "        x_val_array1[xi, :, :, 0] = x_val_array[i, :, :, 0]\n",
    "        y_val_array1[xi, :, :, 0] = y_val_array[i, :, :, 0]\n",
    "        z_val_array1[xi,  0]      = z_val_array[i,  0]\n",
    "        xi = xi+1\n",
    "\n",
    "x_array = x_array1\n",
    "y_array = y_array1\n",
    "z_array = z_array1\n",
    "\n",
    "x_val_array = x_val_array1\n",
    "y_val_array = y_val_array1\n",
    "z_val_array = z_val_array1\n",
    "\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Astra Projection Code\n",
    "\n",
    "import astra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import time\n",
    "import pydicom\n",
    "import glob\n",
    "from numba import jit\n",
    "from skimage import filters\n",
    "import copy\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "\n",
    "scaling_factor = 1\n",
    "voxel_size = 0.02\n",
    "SOD       = 65/(voxel_size*scaling_factor)\n",
    "ODD       = 4.5/(voxel_size*scaling_factor)\n",
    "detWidth  = 0.0085/(voxel_size/scaling_factor)   # size of each detector pixel\n",
    "detHeight = detWidth                             # size of each detector pixel\n",
    "detRows   = 3000\n",
    "detCols   = 1504\n",
    "num_angles = 25\n",
    "\n",
    "a       = sio.loadmat(\"/media/dril/My Passport/CHO-DATA/NO-LESION-MAT/LE/\"+str(1)+\".mat\")[\"head\"]\n",
    "testvol = np.rollaxis(a, 2, 0)\n",
    "testvol = np.moveaxis(testvol, [0, 1, 2], [0, 2, 1])\n",
    "\n",
    "vol_geom = astra.create_vol_geom(int(testvol.shape[1]), int(testvol.shape[2]), int(testvol.shape[0]))\n",
    "proj_arr = np.zeros((num_angles, detCols, detRows), dtype='float16')\n",
    "testones = np.ones([int(testvol.shape[0]), int(testvol.shape[1]), int(testvol.shape[2])],  dtype='uint8')\n",
    "estimate = np.zeros([int(testvol.shape[0]), int(testvol.shape[1]), int(testvol.shape[2])], dtype='float16')\n",
    "\n",
    "# Get simulation angles\n",
    "start_angle = -21\n",
    "theta       = []\n",
    "for i in range(num_angles):\n",
    "    theta.append(start_angle*np.pi/180.0)\n",
    "    start_angle = start_angle+1.98\n",
    "\n",
    "vectors = np.zeros((len(theta), 12))\n",
    "\n",
    "# For reconstructing real data\n",
    "vectors[:, 0:3]  = np.transpose(np.array([np.sin(theta), np.zeros(len(theta)), np.cos(theta)])) * SOD        # S source to object\n",
    "vectors[:,3:6]   = np.transpose(np.array([np.zeros(len(theta)), np.zeros(len(theta)),  -np.ones(len(theta))*ODD]))             # D object to detector\n",
    "vectors[:,6:9]   = np.transpose(np.array([np.ones(len(theta))*detWidth, np.zeros(len(theta)), np.zeros(len(theta))]))         # U\n",
    "vectors[:,9:12]  = np.transpose(np.array([np.zeros(len(theta)), np.ones(len(theta))*detWidth, np.zeros(len(theta))]))        # V\n",
    "# Creating the projection matrix\n",
    "proj_geom        = astra.create_proj_geom('cone_vec', detCols, detRows, vectors)\n",
    "proj_id          = astra.create_projector('cuda3d',   proj_geom, vol_geom)\n",
    "W                = astra.OpTomo(proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     17,
     50
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert lesion loop\n",
    "\n",
    "#train_lesions = np.load(\"/home/pranjal/VICTRE/victre_breastmass/breastMass/train_lesions.npy\")\n",
    "#train_lesions_array = []\n",
    "\n",
    "# for name in train_lesions:\n",
    "#     temp = np.fromfile(name, dtype='uint8')\n",
    "#     t    = int(name.split(\"_\")[-1].split(\".\")[0])\n",
    "#     temp = np.reshape(temp, [t, t, t])\n",
    "#     train_lesions_array.append(temp)\n",
    "train_lesions_array = []\n",
    "train_lesions_array.append(mask)\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/My Passport/CHO-DATA/NO-LESION-MAT/LE/*.mat\")\n",
    "print(len(allfiles))\n",
    "allfiles.sort()\n",
    "\n",
    "def insert_lesion(image, z_slice, index):\n",
    "    coord = []\n",
    "    count = 0\n",
    "    #index = random.randint(0, len(train_lesions)-1)\n",
    "    \n",
    "    while(count < 4):\n",
    "        k     = count\n",
    "        temp  = train_lesions_array[index]\n",
    "        \n",
    "        tx    = int(temp.shape[0]/2)\n",
    "        temp1 = image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 100-tx:100+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx]\n",
    "        \n",
    "        temp1[temp == 1] = 0.80\n",
    "        image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 100-tx:100+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx] = temp1\n",
    "        \n",
    "        count = count+1\n",
    "    \n",
    "    count = 0\n",
    "    while(count < 4):\n",
    "        k     = count\n",
    "        temp  = train_lesions_array[index]\n",
    "        \n",
    "        tx    = int(temp.shape[0]/2)\n",
    "        temp1 = image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 220-tx:220+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx]\n",
    "        \n",
    "        temp1[temp == 1] = 0.80\n",
    "        image[250+k*100-tx:250+k*100+temp.shape[0]-tx, 220-tx:220+temp.shape[0]-tx, z_slice-tx:z_slice+temp.shape[0]-tx] = temp1\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "    return image\n",
    "\n",
    "index = 0\n",
    "for f in allfiles:\n",
    "    data    = sio.loadmat(f)[\"head\"]\n",
    "    print(data.shape, f)\n",
    "    #tx = int(f.split(\"/\")[-1].split(\"_\")[1].split(\"x\")[0])\n",
    "    #ty = int(f.split(\"/\")[-1].split(\"_\")[1].split(\"x\")[1])\n",
    "    #tz = int(f.split(\"/\")[-1].split(\"_\")[1].split(\"x\")[2].split(\".\")[0])\n",
    "    \n",
    "    name = f.split(\"/\")[-1]\n",
    "    \n",
    "    image = data#.reshape([tz, ty, tx])\n",
    "#     index = int(name.split(\"-\")[1].split(\"_\")[0])\n",
    "    #index = index%len(train_lesions)\n",
    "    \n",
    "#     #print(name, index)\n",
    "    \n",
    "#     #if image.shape[0] < 280:\n",
    "#     #    image = insert_lesion(image, 130, index)\n",
    "#     #else:\n",
    "#     image = data\n",
    "    image = insert_lesion(image, 160, index)\n",
    "    #print(image.shape)\n",
    "    #break\n",
    "    \n",
    "    temp = {}\n",
    "    temp[\"head\"] = np.single(image)\n",
    "    sio.savemat(\"/media/dril/My Passport/CHO-DATA/WITH-LESION-MAT/LE/\"+name, temp, do_compression=True)\n",
    "# #     image.tofile(\"/media/pranjal/BackupPlus/CEDBT/CHO-DATA/WITH-LESION-MAT/\"+name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the combined Model\n",
    "\n",
    "\n",
    "model       = unet_two()\n",
    "checkpoints = ModelCheckpoint('all-data-0-to-7-combined-0.0005-1.h5', \n",
    "                                             monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                                             save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "z_array1     = np.ones(x_array.shape)\n",
    "z_val_array1 = np.ones(x_val_array.shape)\n",
    "\n",
    "for i in range(len(z_array1)):\n",
    "    z_array1[i, :, :, :] = z_array1[i, :, :, :]*z_array[i]\n",
    "for i in range(len(z_val_array1)):\n",
    "    z_val_array1[i, :, :, :] = z_val_array1[i, :, :, :]*z_val_array[i]\n",
    "\n",
    "model.fit([x_array, z_array1, np.ones(z_array.shape)*0.1, np.ones(z_array.shape)*0.2, np.ones(z_array.shape)*0.3, np.ones(z_array.shape)*0.4, np.ones(z_array.shape)*0.5, np.ones(z_array.shape)*0.6, np.ones(z_array.shape)*0.7], y_array,\n",
    "          validation_data=([x_val_array, z_val_array1, np.ones(z_val_array.shape)*0.1, np.ones(z_val_array.shape)*0.2, np.ones(z_val_array.shape)*0.3, np.ones(z_val_array.shape)*0.4, np.ones(z_val_array.shape)*0.5, np.ones(z_val_array.shape)*0.6, np.ones(z_val_array.shape)*0.7], y_val_array), \n",
    "          batch_size=8, \n",
    "          epochs=10000, \n",
    "          callbacks=[checkpoints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For drawing the Pictures of all samples together\n",
    "\n",
    "index      = 0\n",
    "total_size = 500\n",
    "\n",
    "z_arr  = []\n",
    "drawit = []\n",
    "for i in range(259, 262):#range(index*total_size, total_size*(index+1)):\n",
    "    print(z_val_array[i, 0])\n",
    "    if True:#z_val_array[i, 0] < 0.35 and z_val_array[i, 0] > 0.25:\n",
    "        #print(\"Adding Image\")\n",
    "        drawit.append(np.concatenate([x_val_array[i, :, :, 0], y_val_array[i, :, :, 0]], axis=-1))\n",
    "        z_arr.append(z_val_array[i, 0])\n",
    "\n",
    "drawit = np.array(drawit)\n",
    "drawit = np.reshape(drawit, [-1, 256])\n",
    "print(drawit.shape)\n",
    "\n",
    "plt.figure(figsize=(12800/2000, 256))\n",
    "plt.imshow(drawit.astype('float32'), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128, 1) (1000, 128, 128, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Some garbage code for reading the data\n",
    "\n",
    "x_array = np.load('/media/dril/My Passport/TRAINING-DATA/x_array.npy')\n",
    "y_array = np.load('/media/dril/My Passport/TRAINING-DATA/y_array.npy')\n",
    "z_array = np.load('/media/dril/My Passport/TRAINING-DATA/z_array.npy')\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "z1 = []\n",
    "\n",
    "for i in range(7000):\n",
    "    #if z_array[i, 0] == 0.2 or z_array[i, 0] == 0.4 or z_array[i, 0] == 0.6:#(i+1) % 6 == 0 or i % 6 == 0:\n",
    "    #    continue\n",
    "    if z_array[i, 0] != 0.3:\n",
    "        continue\n",
    "    else:\n",
    "        x1.append(x_array[i, :, :, :])\n",
    "        y1.append(y_array[i, :, :, :])\n",
    "        z1.append(z_array[i, :])\n",
    "\n",
    "x1 = np.array(x1)\n",
    "y1 = np.array(y1)\n",
    "z1 = np.array(z1)\n",
    "\n",
    "print(x1.shape, y1.shape, z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_array = np.load('/media/dril/My Passport/TRAINING-DATA/x_array_random2.npy')\n",
    "# y_array = np.load('/media/dril/My Passport/TRAINING-DATA/y_array_random2.npy')\n",
    "# z_array = np.load('/media/dril/My Passport/TRAINING-DATA/z_array_random2.npy')\n",
    "\n",
    "# x_val_array = np.load('/media/dril/My Passport/TRAINING-DATA/x_val_array_random2.npy')\n",
    "# y_val_array = np.load('/media/dril/My Passport/TRAINING-DATA/y_val_array_random2.npy')\n",
    "# z_val_array = np.load('/media/dril/My Passport/TRAINING-DATA/z_val_array_random2.npy')\n",
    "\n",
    "\n",
    "model = unet()\n",
    "#model.load_weights('all-data-random-0-to-7-0.0005-2.h5')\n",
    "checkpoints = ModelCheckpoint('all-data-0-to-7-0.0005-5.h5', \n",
    "                                              monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                                              save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "model.fit([x_array, z_array], y_array, \n",
    "          validation_data=([x_val_array, z_val_array], y_val_array), \n",
    "          batch_size=8, \n",
    "          epochs=10000, \n",
    "          callbacks=[checkpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss 0.00031360463\n",
      "Test Loss 0.00057295326\n",
      "**********************************\n"
     ]
    }
   ],
   "source": [
    "# Check the loss values\n",
    "\n",
    "check_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "r2 = []\n",
    "y2 = []\n",
    "for i in range(int(len(x1)*0.7)):\n",
    "    r2.append(result_train[i])\n",
    "    y2.append(y1[i])\n",
    "train_loss = np.mean(np.abs(np.array(r2)-np.array(y2)))\n",
    "\n",
    "r2= []\n",
    "y2 = []\n",
    "for i in range(int(len(x1)*0.7), len(x1)):\n",
    "    r2.append(result_train[i])\n",
    "    y2.append(y1[i])\n",
    "test_loss = np.mean(np.abs(np.array(r2)-np.array(y2)))\n",
    "    \n",
    "print(\"Train Loss\", train_loss)\n",
    "print(\"Test Loss\", test_loss)\n",
    "print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the loss values\n",
    "\n",
    "\n",
    "check_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for k in range(7):\n",
    "    check_val = check_values[k]\n",
    "\n",
    "    r1 = []\n",
    "    y1 = []\n",
    "    for i in range(int(len(x_array)*0.7)):\n",
    "        if z_array[i, 0] == check_val:\n",
    "            r1.append(result_train[i])\n",
    "            y1.append(y_array[i])\n",
    "    train_loss = np.mean(np.abs(np.array(r1)-np.array(y1)))\n",
    "\n",
    "    r1 = []\n",
    "    y1 = []\n",
    "    for i in range(int(len(x_array)*0.7), len(x_array)):\n",
    "        if z_array[i, 0] == check_val:\n",
    "            r1.append(result_train[i])\n",
    "            y1.append(y_array[i])\n",
    "    test_loss = np.mean(np.abs(np.array(r1)-np.array(y1)))\n",
    "    \n",
    "    print(\"Check value \", check_values[k])\n",
    "    print(\"Train Loss\", train_loss)\n",
    "    print(\"Test Loss\", test_loss)\n",
    "    print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some signal calculation Code\n",
    "\n",
    ".randint(int(len(x1)*0.1), int(len(x1)*0.4))\n",
    "print(index)\n",
    "print(z_array[index])\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "#print(np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])), np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])))\n",
    "#print(np.mean(np.abs(result_train1[index, :, :, 0]-result_train[index, :, :, 0])), np.mean(np.abs(result_train1[index, :, :, 0]-y1[index, :, :, 0])), np.mean(np.abs(y1[index, :, :, 0]-result_train[index, :, :, 0])))\n",
    "\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()),  ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "y1 = y_val_array\n",
    "x1 = x_val_array\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "index = 261#index = random.randint(int(len(x_array)*0.8), len(x_array)-1)\n",
    "index = random.randint(0, len(x_val_array)-1)\n",
    "#index = random.randint(int(len(x1)*0.1), int(len(x1)*0.4))\n",
    "print(index)\n",
    "print(z_array[index])\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "#print(np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])), np.mean(np.abs(result_train[index, :, :, 0], y_array[index, :, :, 0])))\n",
    "#print(np.mean(np.abs(result_train1[index, :, :, 0]-result_train[index, :, :, 0])), np.mean(np.abs(result_train1[index, :, :, 0]-y1[index, :, :, 0])), np.mean(np.abs(y1[index, :, :, 0]-result_train[index, :, :, 0])))\n",
    "\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()),  ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "y1 = y_val_array\n",
    "x1 = x_val_array\n",
    "\n",
    "#print(ssim(result_train[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "\n",
    "#index = 253\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a  = np.asanyarray(a)\n",
    "    m  = np.mean(a)#a.mean(axis)\n",
    "    sd = np.std(a) #a.std(axis=axis, ddof=ddof)\n",
    "    return m/sd#np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "print(ssim(x1[index, :, :, 0], y1[index, :, :, 0], dynamic_range=y1[index, :, :, 0].max() - y1[index, :, :, 0].min()))\n",
    "print(signaltonoise(result_train[index, :, :, 0]), signaltonoise(x1[index, :, :, 0]), signaltonoise(y1[index, :, :, 0]))\n",
    "print(haar_psi(result_train[index, :, :, 0], y1[index, :, :, 0], preprocess_with_subsampling = True)[0], haar_psi(x1[index, :, :, 0], y1[index, :, :, 0], preprocess_with_subsampling = True)[0])\n",
    "print(np.mean(np.abs(result_train[index, :, :, 0] - y1[index, :, :, 0])), np.mean(np.abs(x1[index, :, :, 0] - y1[index, :, :, 0])))\n",
    "\n",
    "print(np.mean(np.abs(result_train[index, :, :, 0] - y_val_array[index, :, :, 0])), np.mean(np.abs(x_val_array[index, :, :, 0] - y_val_array[index, :, :, 0])))\n",
    "\n",
    "#plt.imshow(np.concatenate([x1[index, :, :, 0], result_train[index, :, :, 0], result_train1[index, :, :, 0], y1[index, :, :, 0]], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([x_array[index, :, :, 0], result_train[index, :, :, 0], y_array[index, :, :, 0]], axis=-1), cmap='gray')\n",
    "plt.imshow(np.concatenate([x_val_array[index, :, :, 0].astype('float32'),  result_train[index, :, :, 0], y_val_array[index, :, :, 0].astype('float32')], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([x_val_array[index, :, :, 0].astype('float32'), result_train[index, :, :, 0].astype('float32'), y_val_array[index, :, :, 0].astype('float32')], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some Garbage Reading Code\n",
    "\n",
    "s = 7800\n",
    "\n",
    "\n",
    "x_array = []\n",
    "y_array = []\n",
    "z_array = []\n",
    "\n",
    "print(\"Reading Done\")\n",
    "\n",
    "while(True):\n",
    "    ix = np.random.randint(128, 1200-128)\n",
    "    iy = np.random.randint(128, 1200-128)\n",
    "    iz = np.random.randint(25, 48)\n",
    "    \n",
    "    tempx = x[iz, ix:ix+128, iy:iy+128]\n",
    "    \n",
    "    if np.count_nonzero(tempx.flatten())*1.0/(128*128) < 0.9:\n",
    "        continue\n",
    "    \n",
    "    for j in range(6):\n",
    "        x_array.append(tempx)\n",
    "    \n",
    "    tempy = y1[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y2[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y3[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y4[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y5[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    tempy = y6[iz, ix:ix+128, iy:iy+128]\n",
    "    y_array.append(tempy)\n",
    "    #tempy = y7[iz, ix:ix+128, iy:iy+128]\n",
    "    #y_array.append(tempy)\n",
    "    \n",
    "    z_array.append(0.1)\n",
    "    z_array.append(0.2)\n",
    "    z_array.append(0.3)\n",
    "    z_array.append(0.4)\n",
    "    z_array.append(0.5)\n",
    "    z_array.append(0.7)\n",
    "    \n",
    "    if len(x_array) == s:\n",
    "        break\n",
    "\n",
    "# perm    = np.random.permutation(len(x_array))\n",
    "# x_array = np.array(x_array)[perm]\n",
    "# y_array = np.array(y_array)[perm]\n",
    "# z_array = np.array(z_array)[perm]\n",
    "\n",
    "x_array = np.expand_dims(x_array, axis=-1)\n",
    "y_array = np.expand_dims(y_array, axis=-1)\n",
    "z_array = np.expand_dims(z_array, axis=-1)\n",
    "\n",
    "\n",
    "print(x_array.shape, y_array.shape, z_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For reading the Data\n",
    "\n",
    "input_p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE18*\"+str(0.0005)+\"*_0.raw\")#+str(0.1)+\"'\".raw')\n",
    "for t in input_p:\n",
    "    print(t)\n",
    "print(\"*********************\")\n",
    "output_p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE18*4_\"+str(0.0005)+\"*.raw\")\n",
    "#output_p = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE18*4_*.raw\")\n",
    "output_p.sort()\n",
    "output_p_new = []\n",
    "counter      = 0\n",
    "for t in output_p:\n",
    "    if '_0.raw' not in t:\n",
    "        print(counter, t)\n",
    "        output_p_new.append(t)\n",
    "        counter = counter+1\n",
    "\n",
    "output_p = output_p_new\n",
    "print(\"Length of output_p is \", len(output_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For creating signal present and absent training data pairs\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/My Passport/CHO-VOL-LESION/*.raw\")\n",
    "allfiles.sort()\n",
    "\n",
    "print(len(allfiles))\n",
    "\n",
    "todo = [7, 8, 9, 10, 15, 16, 19, 20, 27, 29, 31, 35]\n",
    "\n",
    "def extract_2d_patches(a):\n",
    "    patches = []\n",
    "    sx = 789\n",
    "    sy = 1453\n",
    "    ts = 128\n",
    "    \n",
    "    for i in range(4):\n",
    "        temp = a[28, sx-ts:sx+ts, sy-ts:sy+ts]\n",
    "        sy   = sy-235\n",
    "        #print(temp.shape)\n",
    "        patches.append(temp)\n",
    "    \n",
    "    sx = 503\n",
    "    sy = 1453\n",
    "    for i in range(4):\n",
    "        temp = a[25, sx-ts:sx+ts, sy-ts:sy+ts]\n",
    "        sy   = sy-235\n",
    "        #print(temp.shape)\n",
    "        patches.append(temp)\n",
    "    \n",
    "    return np.array(patches)\n",
    "\n",
    "# all_patches = []\n",
    "\n",
    "# for f in allfiles:\n",
    "#     if int(f.split(\"/\")[-1].split(\"_\")[0]) not in todo:\n",
    "#         continue\n",
    "#     print(f.split(\"/\")[-1])\n",
    "    \n",
    "#     a = np.fromfile(f, dtype='float32')\n",
    "#     #a = np.load(f)\n",
    "#     a = np.reshape(a, [48, 1200, 2200])\n",
    "#     #np.save(f, a.astype('float16'))\n",
    "#     patches = extract_2d_patches(a)\n",
    "#     for k in range(8):\n",
    "#         all_patches.append(patches[k])\n",
    "#     #break\n",
    "# all_patches1 = np.array(all_patches)\n",
    "\n",
    "# #np.save('all_patches_lesion.npy', all_patches)\n",
    "# print(all_patches1.shape)\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/My Passport/CHO-VOL/*.raw\")\n",
    "allfiles.sort()\n",
    "\n",
    "all_patches = []\n",
    "for f in allfiles:\n",
    "    if int(f.split(\"/\")[-1].split(\"_\")[0]) not in todo:\n",
    "        continue\n",
    "    \n",
    "    print(f.split(\"/\")[-1])\n",
    "    #a = np.load(f)\n",
    "    a = np.fromfile(f, dtype='float32')\n",
    "    a = np.reshape(a, [48, 1200, 2200])\n",
    "    #np.save(f, a.astype('float16'))\n",
    "    patches = extract_2d_patches(a)\n",
    "    for k in range(8):\n",
    "        all_patches.append(patches[k])\n",
    "    #all_patches.append(patches)\n",
    "all_patches = np.array(all_patches)\n",
    "\n",
    "#np.save('all_patches_without_lesion.npy', all_patches)\n",
    "print(all_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Output image patches\n",
    "\n",
    "y_raw_array = []\n",
    "output_p    = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE27*4_*.raw\")\n",
    "output_p.sort()\n",
    "output_p_new = []\n",
    "counter      = 0\n",
    "for t in output_p:\n",
    "    if '_0.raw' not in t and '.0003' not in t and '.0001' not in t and '.0006' not in t and '0.2' not in t and '0.4' not in t:\n",
    "        print(counter, t)\n",
    "        output_p_new.append(t)\n",
    "        counter = counter+1\n",
    "output_p = output_p_new\n",
    "\n",
    "for p in output_p:\n",
    "    #print(p)\n",
    "    temp_y = np.fromfile(p, dtype='float32')\n",
    "    temp_y = temp_y.astype('float16')\n",
    "    temp_y = np.reshape(temp_y, [48, 1200, 2600])\n",
    "    y_raw_array.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Image patches\n",
    "\n",
    "arr1 = [0.0002, 0.0005, 0.0007, 0.001]\n",
    "arr2 = [0.1,  0.3,  0.5, 0.7]\n",
    "\n",
    "output_p_new1 = []\n",
    "\n",
    "for a1 in arr1:\n",
    "    for a2 in arr2:\n",
    "        y_raw_array = []\n",
    "        output_p    = glob.glob(\"/media/dril/My Passport/DBT-HUBER-VOL-DEBLUR/CE27*\"+str(a1)+\"*\"+str(a2)+\".raw\")\n",
    "        output_p.sort()\n",
    "        counter      = 0\n",
    "        for f in output_p:\n",
    "            #print(f)\n",
    "            output_p_new1.append(f)\n",
    "        print(\"*************************\")\n",
    "\n",
    "output_p_new = []\n",
    "counter      = 0\n",
    "for t in output_p_new1:\n",
    "    if '_0.raw' not in t and '.0003' not in t and '.0001' not in t and '.0006' not in t and '0.2' not in t and '0.4' not in t:\n",
    "        print(counter, t)\n",
    "        output_p_new.append(t)\n",
    "        counter = counter+1\n",
    "output_p = output_p_new\n",
    "\n",
    "for p in output_p_new:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lesion Location Information Array\n",
    "1  1692, 1034, 34\n",
    "3  2043, 280,  18\n",
    "3  2124, 1146, 17\n",
    "3  1272, 236,  32\n",
    "6  1293, 440,  16\n",
    "7  1708, 496,  44\n",
    "7  941, 1100,  13\n",
    "10 874, 1018,  28\n",
    "10 1922, 734,  33 \n",
    "10 1957, 413,  38\n",
    "10 2018, 556,  37\n",
    "10 1961, 470,  7\n",
    "11 1298, 661,  22\n",
    "13 1628, 348,  34\n",
    "13 1797, 854,  34\n",
    "13 1622, 349,  34\n",
    "13 1596, 510,  31\n",
    "13 1550, 669,  37\n",
    "19 686, 1125, 20\n",
    "21 732, 464,  9\n",
    "25 1985, 576,  64\n",
    "25 1440, 256,  57\n",
    "25 1864, 1040, 36\n",
    "27 1429. 925,  64\n",
    "27 1278, 829,  64\n",
    "29 1246, 977,  21\n",
    "29 1380, 905,  19\n",
    "33 1104, 666,  24\n",
    "35 1670, 725,  17\n",
    "37 1128, 877,  56\n",
    "41 1084, 934,  42\n",
    "44 1480, 970,  19\n",
    "45 1638, 610,  47\n",
    "47 1062, 646,  23\n",
    "47 1301, 564,  23\n",
    "47 1870, 625,  23\n",
    "54 706, 1162,  27\n",
    "59 841, 1038,  32\n",
    "60 554, 553,   28\n",
    "60 468, 830,   22\n",
    "64 1948, 854,  22\n",
    "65 1820, 600,  25\n",
    "66 1510, 328,  40\n",
    "66 1328, 1001, 20\n",
    "66 1950, 630,  46\n",
    "66 1544, 529,  37\n",
    "67 1672, 542,  42\n",
    "67 2138, 612,  36\n",
    "67 1797, 694,  35\n",
    "67 1164, 737,  33\n",
    "70 1341, 762, 10\n",
    "71 1433, 769, 14 \n",
    "74 2302, 457, 28 \n",
    "75 2107, 777, 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lesion Location information Array hash Creation\n",
    "\n",
    "h = {}\n",
    "s = open(\"/home/dril/lesion_array\", \"r\").read()\n",
    "s = s.split(\"\\n\")\n",
    "s = s[:-1]\n",
    "count = 0\n",
    "for t in s:\n",
    "    #print(t, \"p\")\n",
    "    a = t.strip().split()\n",
    "    #print(a[0], \" p \", a[1], a[2], a[3])\n",
    "    i = int(a[0])\n",
    "    x = int(a[1].replace(\",\", \"\"))\n",
    "    y = int(a[2].replace(\",\", \"\"))\n",
    "    z = int(a[3].replace(\",\", \"\"))\n",
    "    #print(i, x, y, z)\n",
    "    h[count] = [i, x, y, z]\n",
    "    count = count+1\n",
    "np.save('lesion_array_hash.npy', h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "for k in h:\n",
    "    print(k)\n",
    "    if k < 18:\n",
    "        continue\n",
    "    \n",
    "    if h[k][0] == 27:\n",
    "        continue\n",
    "    \n",
    "    patches = []\n",
    "    values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "    vol  = np.fromfile(path, dtype=\"float32\")\n",
    "    vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    patches.append(vol[h[k][3]-2:h[k][3]+2, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128])\n",
    "    values.append(0)\n",
    "    \n",
    "    allpaths  = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw.npy\")\n",
    "    for t in allpaths:\n",
    "        s = float(t.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        values.append(s)\n",
    "        print(t, s)\n",
    "        \n",
    "        vol  = np.load(t)\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        temp = vol[h[k][3]-2:h[k][3]+2, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "        print(temp.shape, h[k][2])\n",
    "        patches.append(temp)\n",
    "    \n",
    "    #print()\n",
    "    a = np.array(patches)\n",
    "    b = np.array(values)\n",
    "    print(\"Length is \", len(values), a.shape)\n",
    "    np.save(\"dbt_real_patches_\"+str(k)+\".npy\",       a)\n",
    "    np.save(\"dbt_real_patches_values_\"+str(k)+\".npy\", b)\n",
    "    #for \n",
    "    #break\n",
    "    #print(vol.shape)\n",
    "    #print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion for training the calibaration CNN with No lesions\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    #print(f, index)\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "\n",
    "x      = []\n",
    "values = []\n",
    "\n",
    "for k in allindex:\n",
    "    if h[k][0] in test_list:\n",
    "        continue\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     z = []\n",
    "    \n",
    "#     patches = []\n",
    "#     values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "#     vol  = np.fromfile(path, dtype=\"float32\")\n",
    "#     vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    \n",
    "#     dx_array = [-5, 5]#, -10, 10]\n",
    "#     dy_array = [-5, 5]#, -10, 10]\n",
    "    \n",
    "#     temp_count = 0\n",
    "#     while(temp_count < 5):\n",
    "#         ix = np.random.randint(256, 1200-256)\n",
    "#         iy = np.random.randint(256, 3000-256)\n",
    "#         iz = np.random.randint(10, 54)\n",
    "\n",
    "# #         #if locations_flag:\n",
    "# #         ix = locations_array[temp_count][0]\n",
    "# #         iy = locations_array[temp_count][1]\n",
    "# #         iz = locations_array[temp_count][2]\n",
    "\n",
    "#         tempx = vol[iz, ix:ix+256, iy:iy+256]\n",
    "\n",
    "#         if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "#             continue\n",
    "        \n",
    "#         if tempx.shape[0] == 256 and tempx.shape[1] == 256:\n",
    "#             x.append(tempx)\n",
    "#             temp_count = temp_count + 1\n",
    "# #         if locations_flag == 0:\n",
    "# #             locations_array.append([ix, iy, iz])\n",
    "        \n",
    "            \n",
    "#     for tp in range(-2, 2):\n",
    "#         temp = vol[h[k][3]+tp, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "#         if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#             x.append(temp)\n",
    "    \n",
    "#     for dx in dx_array:\n",
    "#         for dy in dy_array:\n",
    "#             for tp in range(-2, 2):\n",
    "#                 temp = vol[h[k][3]+tp, h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy]\n",
    "#                 if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#                     x.append(temp)\n",
    "    \n",
    "#     values_stored  = list(np.load(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/reorder-b-\"+str(k)+\".npy\"))\n",
    "#     ratings_stored = list(np.load(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/values-b-\"+str(k)+\".npy\"))\n",
    "    \n",
    "#     print(values_stored)\n",
    "#     print(ratings_stored)\n",
    "    \n",
    "    locations_array = []\n",
    "    locations_flag  = 0\n",
    "    \n",
    "    allpaths  = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw.npy\")\n",
    "    for t in allpaths:\n",
    "        print(t)\n",
    "        s = float(t.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        values.append(s)\n",
    "        #current_rating = ratings_stored[values_stored.index(s)]\n",
    "        \n",
    "#         if current_rating < 1 or current_rating == 3:\n",
    "#             continue\n",
    "        \n",
    "#         print(\"Some values \", s, values_stored.index(s))\n",
    "        \n",
    "        vol  = np.load(t)\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        \n",
    "#         if current_rating  < 3:\n",
    "#             max_size = 10\n",
    "#         else:\n",
    "#             max_size = 10\n",
    "        \n",
    "        temp_count      = 0\n",
    "        \n",
    "#         for tp in range(-2, 2):\n",
    "#             temp = vol[h[k][3]+tp, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "#             #print(temp.shape)\n",
    "#             if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#                 x.append(temp)\n",
    "        \n",
    "#         for tp in range(-2, 2):\n",
    "#             for dx in dx_array:\n",
    "#                 for dy in dy_array:\n",
    "#                     temp = vol[h[k][3]+tp, h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy]\n",
    "#                     #print(temp.shape)\n",
    "#                     if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "#                         x.append(temp)\n",
    "\n",
    "        # Get all Locations\n",
    "        while(temp_count < 20):\n",
    "            ix = np.random.randint(256, 1200-256)\n",
    "            iy = np.random.randint(256, 3000-256)\n",
    "            iz = np.random.randint(10, 54)\n",
    "            \n",
    "#             if locations_flag:\n",
    "#                 ix = locations_array[temp_count][0]\n",
    "#                 iy = locations_array[temp_count][1]\n",
    "#                 iz = locations_array[temp_count][2]\n",
    "            \n",
    "            tempx = vol[iz, ix:ix+256, iy:iy+256]\n",
    "            \n",
    "            if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "                continue\n",
    "            \n",
    "            if tempx.shape[0] == 256 and tempx.shape[1] == 256:\n",
    "                x.append(tempx)\n",
    "                temp_count = temp_count + 1\n",
    "        print(\"Length are \", len(x), len(values))\n",
    "            #if locations_flag == 0:\n",
    "            #    locations_array.append([ix, iy, iz])\n",
    "            \n",
    "#             if current_rating == 5:\n",
    "#                 x.append(tempx)\n",
    "#                 y.append(1)\n",
    "#                 z.append(s)\n",
    "#             #elif current_rating < 3:\n",
    "#             #    y.append(0)\n",
    "#             #    z.append(s)\n",
    "            \n",
    "#             temp_count = temp_count+1\n",
    "#         locations_flag = 1\n",
    "        #x.append(vol[h[k][3], h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128])\n",
    "        #y.append(current_rating)\n",
    "        \n",
    "        #for dx in dx_array:\n",
    "        #     for dy in dy_array:\n",
    "        #         x.append(vol[h[k][3], h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy])\n",
    "        #        y.append(current_rating)\n",
    "        \n",
    "        #print(len(x), len(y), current_rating, h[k][0])\n",
    "        \n",
    "    #x = np.array(x).astype('float16')\n",
    "    #y = np.array(y)\n",
    "    #z = np.array(z)\n",
    "    \n",
    "    #print(x.shape, y.shape, z.shape)\n",
    "    #print(x.shape)\n",
    "    \n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/no_x_\"+str(k)+\".npy\", x)\n",
    "    \n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/x_\"+str(k)+\".npy\", x)\n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/y_\"+str(k)+\".npy\", y)\n",
    "    #np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/z_\"+str(k)+\".npy\", z)\n",
    "    \n",
    "        #temp = vol[h[k][3]-2:h[k][3]+2, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "        #print(temp.shape, h[k][2])\n",
    "        #patches.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     24,
     175,
     187
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] Getting patches for each lesion for training the calibaration CNN with lesions\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "#print(val_list)\n",
    "\n",
    "\n",
    "for img_counter in range(1, 20):\n",
    "    counter = 0\n",
    "    for k in allindex:\n",
    "        #print(h[k][0], h[k], test_list)\n",
    "\n",
    "        if h[k][0] not in test_list:\n",
    "            continue\n",
    "\n",
    "        counter = counter+1\n",
    "        if counter < img_counter:\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        all_outputs = []\n",
    "        all_ssim = []\n",
    "        all_haar = []\n",
    "\n",
    "        patches = []\n",
    "        values  = []\n",
    "\n",
    "        path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "        vol  = np.fromfile(path, dtype=\"float32\")\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        \n",
    "        px = random.randint(500, 800)\n",
    "        rx = random.randint(1500, 2000)\n",
    "        tx = random.randint(25, 35)\n",
    "        \n",
    "        for tp in range(1, 2):\n",
    "            #tx = 0\n",
    "            #rx = 0\n",
    "            temp = vol[tx, -128+px:128+px, -128+rx:128+rx]\n",
    "            #temp = vol[h[k][3]+tp+tx, h[k][2]-128+rx:h[k][2]+128+rx, h[k][1]-128+rx:h[k][1]+128+rx]\n",
    "            #print(temp.shape)\n",
    "            if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "                x.append(temp)\n",
    "                values.append(0)\n",
    "\n",
    "        locations_array = []\n",
    "        locations_flag  = 0\n",
    "\n",
    "        allpaths  = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw.npy\")\n",
    "        allpaths.sort()\n",
    "\n",
    "        print(allpaths[0])\n",
    "\n",
    "        for t in allpaths:\n",
    "            #print(t)\n",
    "            s = float(t.split(\"/\")[-1].split(\"-\")[-1].split(\"_\")[0])\n",
    "\n",
    "            vol  = np.load(t)\n",
    "            vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "\n",
    "            temp_count      = 0\n",
    "\n",
    "            for tp in range(1, 2):\n",
    "                #for dx in dx_array:\n",
    "                    #for dy in dy_array:\n",
    "                #rx = 0\n",
    "                #tx = 0\n",
    "                temp = vol[tx, -128+px:128+px, -128+rx:128+rx]\n",
    "                #temp = vol[h[k][3]+tp+tx, h[k][2]-128+rx:h[k][2]+128+rx, h[k][1]-128+rx:h[k][1]+128+rx]\n",
    "                #print(temp.shape)\n",
    "                #temp = vol[h[k][3]+tp, h[k][2]-128+dx:h[k][2]+128+dx, h[k][1]-128+dy:h[k][1]+128+dy]\n",
    "                #print(temp.shape)\n",
    "                if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "                    x.append(temp)\n",
    "                    values.append(s)\n",
    "\n",
    "                    #print(s)\n",
    "                    pp1 = np.expand_dims(x[0], 0)\n",
    "                    pp1 = np.expand_dims(pp1,  0)\n",
    "                    pv1 = np.expand_dims(-1*s, 0)\n",
    "                    #print(pp1.shape, pv1.shape)\n",
    "\n",
    "                    pp1 = torch.tensor(pp1, device=device).float()\n",
    "                    pv1 = torch.tensor(pv1, device=device).float()\n",
    "\n",
    "                    result = unet_model.forward(pp1, pv1).data.cpu().numpy()\n",
    "                    all_outputs.append(result)\n",
    "                    #ssim_temp = measure.compare_ssim(result[0, 0, :, :].astype('float32'), temp.astype('float32'), data_range=temp.max() - temp.min())\n",
    "                    t1 = np.min(result[0, 0, :, :].flatten())\n",
    "                    t2 = np.max(result[0, 0, :, :].flatten())\n",
    "                    distorted_image  = (result[0, 0, :, :]-t1)*255/(t2-t1)\n",
    "\n",
    "                    t1 = np.min(temp.flatten())\n",
    "                    t2 = np.max(temp.flatten())\n",
    "                    reference_image = (temp-t1)*255/(t2-t1)\n",
    "\n",
    "                    ssim_temp = measure.compare_ssim(reference_image.astype('float32'), distorted_image.astype('float32'), 255)\n",
    "                    #print(temp.max(), temp.min(), temp.max() - temp.min())\n",
    "\n",
    "                    ssim_temp1 = haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True)[0]\n",
    "                    all_haar.append(ssim_temp1)\n",
    "                    all_ssim.append(ssim_temp)\n",
    "                    #print(temp.shape, result.shape, ssim_temp, ssim_temp1)\n",
    "\n",
    "        x      = np.array(x)\n",
    "        values = np.array(values)\n",
    "        all_outputs = np.array(all_outputs)\n",
    "        all_outputs = all_outputs[:, 0, 0, :, :]\n",
    "\n",
    "        #print(x.shape, values.shape, all_outputs.shape)\n",
    "        break\n",
    "\n",
    "    #plt.figure(figsize=(40,20))\n",
    "    #plt.axis('off')\n",
    "    tp1 = [x[1], x[3], x[4], x[5], x[6], x[7]]\n",
    "    tv1 = np.array([values[1], values[3], values[4], values[5], values[6], values[7]])\n",
    "    tv1[tv1 > 0.6] = 0.6\n",
    "\n",
    "    ssim_arr = [all_ssim[1-1], all_ssim[3-1], all_ssim[4-1], all_ssim[5-1], all_ssim[6-1], all_ssim[7-1]]\n",
    "    haar_arr = [all_haar[1-1], all_haar[3-1], all_haar[4-1], all_haar[5-1], all_haar[6-1], all_haar[7-1]]\n",
    "\n",
    "    #plt.imshow(np.concatenate(tp1, axis=0).T, cmap='gray')\n",
    "\n",
    "    print(values)\n",
    "    print(tv1)\n",
    "    print(ssim_arr)\n",
    "    print(haar_arr)\n",
    "\n",
    "    tp2 = [all_outputs[1-1], all_outputs[3-1], all_outputs[4-1], all_outputs[5-1], all_outputs[6-1], all_outputs[7-1]]\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "    #gs1 = gridspec.GridSpec(1, 8)\n",
    "    #gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "    top_title = \"\"\n",
    "    for i in range(1, len(tp2)+1):\n",
    "        if i == 1:\n",
    "            top_title = top_title+r'$\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "        else:\n",
    "            top_title = top_title+r'               $\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "\n",
    "\n",
    "    bottom_title = \"\"\n",
    "    for i in range(1, len(tp2)+1):\n",
    "        if i == 1:\n",
    "            bottom_title = bottom_title+\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "        else:\n",
    "            bottom_title = bottom_title+\"   SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        #if i == 1:\n",
    "        axs[0].set_ylabel(\"Ground Truth\")\n",
    "        axs[0].imshow(np.concatenate(tp1).T, cmap='gray')\n",
    "        axs[0].set_title(top_title, y=0.95, fontsize=10)\n",
    "        axs[0].set_xticks([], [])\n",
    "        axs[0].set_yticks([], [])\n",
    "        axs[0].spines['top'].set_visible(False)\n",
    "        axs[0].spines['bottom'].set_visible(False)\n",
    "        axs[0].spines['left'].set_visible(False)\n",
    "        axs[0].spines['right'].set_visible(False)\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        #if i == 1:\n",
    "        axs[1].set_ylabel(\"U-Net Output\")\n",
    "        axs[1].imshow(np.concatenate(tp2).T, cmap='gray')\n",
    "        axs[1].set_title(bottom_title, y=-0.15, fontsize=6)\n",
    "        axs[1].set_xticks([], [])\n",
    "        axs[1].set_yticks([], [])\n",
    "        axs[1].spines['top'].set_visible(False)\n",
    "        axs[1].spines['bottom'].set_visible(False)\n",
    "        axs[1].spines['left'].set_visible(False)\n",
    "        axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        left=False,\n",
    "        right=False,\n",
    "        labelbottom=False)\n",
    "    plt.tick_params(\n",
    "        axis='y',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left=False,\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        right=False,\n",
    "        labelbottom=False)\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    f.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "    plt.savefig('compare_supp_random4_'+str(img_counter)+'.png', dpi=300, bbox_inches = 'tight',\n",
    "        pad_inches = 0.1)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.show(block=True)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40,20))\n",
    "# print(values)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(np.concatenate(x[:-2], axis=0).T, cmap='gray')\n",
    "# print(x.shape, values.shape)\n",
    "#np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/x_\"+str(k)+\".npy\", x)\n",
    "#np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/y_\"+str(k)+\".npy\", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# For plotting the images\n",
    "\n",
    "#plt.figure(figsize=(40,20))\n",
    "#plt.axis('off')\n",
    "tp1 = [x[1], x[3], x[4], x[5], x[6], x[7]]\n",
    "tv1 = np.array([values[1], values[3], values[4], values[5], values[6], values[7]])\n",
    "tv1[tv1 > 0.6] = 0.6\n",
    "\n",
    "ssim_arr = [all_ssim[1-1], all_ssim[3-1], all_ssim[4-1], all_ssim[5-1], all_ssim[6-1], all_ssim[7-1]]\n",
    "haar_arr = [all_haar[1-1], all_haar[3-1], all_haar[4-1], all_haar[5-1], all_haar[6-1], all_haar[7-1]]\n",
    "\n",
    "#plt.imshow(np.concatenate(tp1, axis=0).T, cmap='gray')\n",
    "\n",
    "print(values)\n",
    "print(tv1)\n",
    "print(ssim_arr)\n",
    "print(haar_arr)\n",
    "\n",
    "tp2 = [all_outputs[1-1], all_outputs[3-1], all_outputs[4-1], all_outputs[5-1], all_outputs[6-1], all_outputs[7-1]]\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "#gs1 = gridspec.GridSpec(1, 8)\n",
    "#gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "top_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        top_title = top_title+r'$\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "    else:\n",
    "        top_title = top_title+r'               $\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "\n",
    "\n",
    "bottom_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        bottom_title = bottom_title+\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "    else:\n",
    "        bottom_title = bottom_title+\"   SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "\n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[0].set_ylabel(\"Ground Truth\")\n",
    "    axs[0].imshow(np.concatenate(tp1).T, cmap='gray')\n",
    "    axs[0].set_title(top_title, y=0.95, fontsize=10)\n",
    "    axs[0].set_xticks([], [])\n",
    "    axs[0].set_yticks([], [])\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    \n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[1].set_ylabel(\"U-Net Output\")\n",
    "    axs[1].imshow(np.concatenate(tp2).T, cmap='gray')\n",
    "    axs[1].set_title(bottom_title, y=-0.15, fontsize=6)\n",
    "    axs[1].set_xticks([], [])\n",
    "    axs[1].set_yticks([], [])\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.savefig('compare_supp'+str(img_counter)+'.png', dpi=300, bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp2 = [all_outputs[1-1], all_outputs[3-1], all_outputs[4-1], all_outputs[5-1], all_outputs[6-1], all_outputs[7-1]]\n",
    "# plt.figure(figsize=(40,20))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(np.concatenate(tp2, axis=0).T, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Old Matplotlib Code\n",
    "# f = plt.figure()\n",
    "# plt.rcParams[\"figure.figsize\"] = [9, 6]\n",
    "\n",
    "# #gs1 = gridspec.GridSpec(1, 8)\n",
    "# #gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# for i in range(1, 7):\n",
    "#     f.add_subplot(2, 7, i)\n",
    "#     plt.imshow(tp1[i-1], cmap='gray')\n",
    "#     plt.title(r'$\\beta$='+str(np.round(tv1[i-1], 3)), y=0.95, fontsize=12)\n",
    "#     plt.axis('off')\n",
    "    \n",
    "# for i in range(1, 7):\n",
    "#     f.add_subplot(1, 7, i)\n",
    "#     plt.imshow(tp2[i-1], cmap='gray')\n",
    "#     plt.title(\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3)), y=-0.15, fontsize=6)\n",
    "#     plt.axis('off')\n",
    "    \n",
    "# f.tight_layout()\n",
    "# plt.subplots_adjust(wspace=0.02, hspace=0.0001, bottom=0.16)\n",
    "# plt.savefig('compare_supp10.png', dpi=300, bbox_inches = 'tight',\n",
    "#     pad_inches = 0)\n",
    "# plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Experimenting Something with individual figures\n",
    "\n",
    "# f = plt.figure()\n",
    "# plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "# #gs1 = gridspec.GridSpec(1, 8)\n",
    "# #gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# fig, axs = plt.subplots(2, 6, constrained_layout=True)\n",
    "# #print(axs)\n",
    "# for i in range(1, 7):\n",
    "#     if i == 1:\n",
    "#         axs[0, i-1].set_ylabel(\"Ground Truth\")\n",
    "#     axs[0, i-1].imshow(tp1[i-1], cmap='gray')\n",
    "#     axs[0, i-1].set_title(r'$\\beta$='+str(np.round(tv1[i-1], 3)), y=0.95, fontsize=10)\n",
    "#     axs[0, i-1].set_xticks([], [])\n",
    "#     axs[0, i-1].set_yticks([], [])\n",
    "#     axs[0, i-1].spines['top'].set_visible(False)\n",
    "#     axs[0, i-1].spines['bottom'].set_visible(False)\n",
    "#     axs[0, i-1].spines['left'].set_visible(False)\n",
    "#     axs[0, i-1].spines['right'].set_visible(False)\n",
    "    \n",
    "# for i in range(1, 7):\n",
    "#     if i == 1:\n",
    "#         axs[1, i-1].set_ylabel(\"U-Net Output\")\n",
    "#     axs[1, i-1].imshow(tp2[i-1], cmap='gray')\n",
    "#     axs[1, i-1].set_title(\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3)), y=-0.15, fontsize=6)\n",
    "#     axs[1, i-1].set_xticks([], [])\n",
    "#     axs[1, i-1].set_yticks([], [])\n",
    "#     axs[1, i-1].spines['top'].set_visible(False)\n",
    "#     axs[1, i-1].spines['bottom'].set_visible(False)\n",
    "#     axs[1, i-1].spines['left'].set_visible(False)\n",
    "#     axs[1, i-1].spines['right'].set_visible(False)\n",
    "\n",
    "# plt.tick_params(\n",
    "#     axis='x',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     bottom=False,      # ticks along the bottom edge are off\n",
    "#     top=False,         # ticks along the top edge are off\n",
    "#     left=False,\n",
    "#     right=False,\n",
    "#     labelbottom=False)\n",
    "# plt.tick_params(\n",
    "#     axis='y',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     left=False,\n",
    "#     bottom=False,      # ticks along the bottom edge are off\n",
    "#     top=False,         # ticks along the top edge are off\n",
    "#     right=False,\n",
    "#     labelbottom=False)\n",
    "# plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "# f.tight_layout()\n",
    "# plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "# plt.savefig('compare_supp1.png', dpi=300, bbox_inches = 'tight',\n",
    "#     pad_inches = 0)\n",
    "# plt.gca().axes.get_yaxis().set_visible(False)\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Experimenting Something 1\n",
    "\n",
    "f = plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = [9.6, 3.4]\n",
    "\n",
    "#gs1 = gridspec.GridSpec(1, 8)\n",
    "#gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "top_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        top_title = top_title+r'$\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "    else:\n",
    "        top_title = top_title+r'               $\\beta$='+str(np.round(tv1[i-1], 3))\n",
    "\n",
    "\n",
    "bottom_title = \"\"\n",
    "for i in range(1, len(tp2)+1):\n",
    "    if i == 1:\n",
    "        bottom_title = bottom_title+\"SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "    else:\n",
    "        bottom_title = bottom_title+\"   SSIM=\"+str(np.round(ssim_arr[i-1], 3))+\",HaarPSI=\"+str(np.round(haar_arr[i-1], 3))\n",
    "\n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[0].set_ylabel(\"Ground Truth\")\n",
    "    axs[0].imshow(np.concatenate(tp1).T, cmap='gray')\n",
    "    axs[0].set_title(top_title, y=0.95, fontsize=10)\n",
    "    axs[0].set_xticks([], [])\n",
    "    axs[0].set_yticks([], [])\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['bottom'].set_visible(False)\n",
    "    axs[0].spines['left'].set_visible(False)\n",
    "    axs[0].spines['right'].set_visible(False)\n",
    "    \n",
    "for i in range(1, 2):\n",
    "    #if i == 1:\n",
    "    axs[1].set_ylabel(\"U-Net Output\")\n",
    "    axs[1].imshow(np.concatenate(tp2).T, cmap='gray')\n",
    "    axs[1].set_title(bottom_title, y=-0.15, fontsize=6)\n",
    "    axs[1].set_xticks([], [])\n",
    "    axs[1].set_yticks([], [])\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['bottom'].set_visible(False)\n",
    "    axs[1].spines['left'].set_visible(False)\n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    right=False,\n",
    "    labelbottom=False)\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "plt.savefig('compare_supp5.png', dpi=300, bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     33,
     37
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For optimizing the Tuning parameter using the PyTorch Model in a Loop\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "#unet_model.eval()\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.Adam([input_img.requires_grad_()], lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "opt_counter = 0\n",
    "for img_counter in range(1, 20):\n",
    "    counter = 0\n",
    "    for k in allindex:\n",
    "        #print(h[k][0], h[k], test_list)\n",
    "\n",
    "        if h[k][0] not in test_list:\n",
    "            continue\n",
    "\n",
    "        counter = counter+1\n",
    "        if counter < img_counter:\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        all_outputs = []\n",
    "        all_ssim    = []\n",
    "        all_haar    = []\n",
    "\n",
    "        patches = []\n",
    "        values  = []\n",
    "\n",
    "        path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "        vol  = np.fromfile(path, dtype=\"float32\")\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        print(path)\n",
    "        \n",
    "        px = random.randint(800, 1000)\n",
    "        rx = random.randint(2000, 2500)\n",
    "        tx = random.randint(15, 25)\n",
    "        \n",
    "        for tp in range(1, 2):\n",
    "            tx = 0\n",
    "            rx = 0\n",
    "            #temp = vol[tx, -128+px:128+px, -128+rx:128+rx]\n",
    "            temp = vol[h[k][3]+tp+tx, h[k][2]-128+rx:h[k][2]+128+rx, h[k][1]-128+rx:h[k][1]+128+rx]\n",
    "            #print(temp.shape)\n",
    "            if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "                x.append(temp)\n",
    "                values.append(0)\n",
    "        x = np.array(x)\n",
    "        \n",
    "        device  = torch.device(\"cuda:0\")\n",
    "\n",
    "        targets = torch.tensor(np.ones([1, 1]), device=device).float()\n",
    "\n",
    "        in1 = x[0, :, :]#np.ones([1, 1, 256, 256]) #np.ones([256, 256])\n",
    "        in1 = np.expand_dims(in1, axis=0)\n",
    "        in1 = np.expand_dims(in1, axis=1)\n",
    "        in1 = torch.tensor(in1, device=device).float()\n",
    "\n",
    "        in2 = Variable(torch.tensor(-0.2*np.ones([1, 1], dtype='float32')).cuda(), requires_grad=True)\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        optimizer = get_input_optimizer(in2)\n",
    "\n",
    "        first_image = 0\n",
    "        best_image  = 0\n",
    "        best = 1000\n",
    "        print('Optimizing..')\n",
    "        run = [0]\n",
    "\n",
    "        s1 = time.time()\n",
    "        while run[0] <= 100:\n",
    "            optimizer.zero_grad()\n",
    "            out1 = unet_model(in1, in2)\n",
    "            out2 = rating_cnn(out1)\n",
    "\n",
    "            if run[0] == 0:\n",
    "                first_image = out1.data.cpu().numpy()\n",
    "\n",
    "            loss = criterion(out2, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            #if run[0] % 10 == 0:\n",
    "                #print(np.mean(out1.data.cpu().numpy().flatten()))\n",
    "            if loss.item() < best:\n",
    "                best       = loss.item()\n",
    "                best_image = out1.data.cpu().numpy()\n",
    "                #print(\"Loss is \", loss.item(), \" variable \", in2.item(), \" out2 \", out2.item())#, \"out1 \", out1.item())#np.mean(out1.item().flatten()))\n",
    "            optimizer.step()\n",
    "        s2 = time.time()\n",
    "        #print(s2-s1)\n",
    "        \n",
    "        #\n",
    "        font = {'family': 'times new roman',  'weight': 'normal', 'size': 16}\n",
    "        plt.axis('off')\n",
    "        u1 = r'    $\\beta$='+str(0)\n",
    "        u2 = r'                                    $\\beta_{man}$='+str(0.2)\n",
    "        u3 = r'                                    $\\beta_{opt}$='+str(np.round(-1*in2.data.cpu().numpy()[0][0], 3))\n",
    "        plt.title(u1+u2+u3) #   $\\beta$='+str(np.round(in2.data.cpu().numpy()[0][0], 3)))\n",
    "        #plt.title(r'    $\\beta$='+str(0) +'  $\\beta$=0.2') #   $\\beta$='+str(np.round(in2.data.cpu().numpy()[0][0], 3)))\n",
    "        #plt.title(\"testing \", fontdict=font)\n",
    "        plt.imshow(np.concatenate([x[0, :, :], first_image[0, 0, :, :], best_image[0, 0, :, :]], axis=-1), cmap='gray')\n",
    "        print(opt_counter, in2.data.cpu().numpy())\n",
    "        plt.savefig('optimization_'+str(opt_counter)+'.png', dpi=300, bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        opt_counter = opt_counter+1\n",
    "        break\n",
    "    \n",
    "        #print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [STAR] For optimizing the Tuning parameter using the PyTorch Model\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "rating_cnn = RatingModel()\n",
    "rating_cnn.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "rating_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/rating_pytorch.pt')\n",
    "rating_cnn.load_state_dict(rating_weights)\n",
    "\n",
    "\n",
    "#unet_model.eval()\n",
    "#rating_cnn.eval()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device  = torch.device(\"cuda:0\")\n",
    "\n",
    "targets = torch.tensor(np.ones([1, 1]), device=device).float()\n",
    "\n",
    "in1 = x[0, :, :]#np.ones([1, 1, 256, 256]) #np.ones([256, 256])\n",
    "in1 = np.expand_dims(in1, axis=0)\n",
    "in1 = np.expand_dims(in1, axis=1)\n",
    "in1 = torch.tensor(in1, device=device).float()\n",
    "\n",
    "in2 = Variable(torch.tensor(-0.2*np.ones([1, 1], dtype='float32')).cuda(), requires_grad=True)\n",
    "\n",
    "\n",
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.Adam([input_img.requires_grad_()], lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = get_input_optimizer(in2)\n",
    "\n",
    "first_image = 0\n",
    "best_image  = 0\n",
    "best = 1000\n",
    "print('Optimizing..')\n",
    "run = [0]\n",
    "\n",
    "s1 = time.time()\n",
    "while run[0] <= 100:\n",
    "    optimizer.zero_grad()\n",
    "    out1 = unet_model(in1, in2)\n",
    "    out2 = rating_cnn(out1)\n",
    "    \n",
    "    if run[0] == 0:\n",
    "        first_image = out1.data.cpu().numpy()\n",
    "        \n",
    "    loss = criterion(out2, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    run[0] += 1\n",
    "    #if run[0] % 10 == 0:\n",
    "        #print(np.mean(out1.data.cpu().numpy().flatten()))\n",
    "    if loss.item() < best:\n",
    "        best       = loss.item()\n",
    "        best_image = out1.data.cpu().numpy()\n",
    "        #print(\"Loss is \", loss.item(), \" variable \", in2.item(), \" out2 \", out2.item())#, \"out1 \", out1.item())#np.mean(out1.item().flatten()))\n",
    "    optimizer.step()\n",
    "s2 = time.time()\n",
    "print(s2-s1)\n",
    "\n",
    "# Good counters = 11, 12 (16 is best)\n",
    "plt.axis('off')\n",
    "plt.imshow(np.concatenate([x[0, :, :], first_image[0, 0, :, :], best_image[0, 0, :, :]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/MC-16-LE-L-CC_3000x1200x64.4_0.0005_0_10.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/MC-16-LE-L-CC_3000x1200x64.4_0.0005_0_10.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/CE-10-LE-R-CC_3000x1200x64.4_0.0005_0_44.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-09-LE-R-MLO_3000x1200x64.4_0.0005_0_74.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-09-LE-R-CC_3000x1200x64.4_0.0005_0_75.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/MC-16-LE-L-CC_3000x1200x64.4_0.0005_0_10.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/MC-16-LE-L-CC_3000x1200x64.4_0.0005_0_10.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/MC-16-LE-L-CC_3000x1200x64.4_0.0005_0_10.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/CE-08-LE-R-CC_3000x1200x64.4_0.0005_0_45.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/CE-05-LE-R-CC_3000x1200x64.4_0.0005_0_47.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/CE-05-LE-R-CC_3000x1200x64.4_0.0005_0_47.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/CE-05-LE-R-CC_3000x1200x64.4_0.0005_0_47.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-29-LE-L-CC_3000x1200x64.4_0.0005_0_59.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-29-LE-L-MLO_3000x1200x64.4_0.0005_0_60.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-29-LE-L-MLO_3000x1200x64.4_0.0005_0_60.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-22-LE-L-MLO_3000x1200x64.4_0.0005_0_66.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-22-LE-L-MLO_3000x1200x64.4_0.0005_0_66.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-22-LE-L-MLO_3000x1200x64.4_0.0005_0_66.raw\n",
      "(1200, 3000)\n",
      "/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/AR-22-LE-L-MLO_3000x1200x64.4_0.0005_0_66.raw\n",
      "(1200, 3000)\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For filtering the entire slice using PyTorch Model\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.Adam([input_img.requires_grad_()], lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "opt_counter = 0\n",
    "for img_counter in range(1, 20):\n",
    "    counter = 0\n",
    "    for k in allindex:\n",
    "        #print(h[k][0], h[k], test_list)\n",
    "\n",
    "        if h[k][0] not in test_list:\n",
    "            continue\n",
    "\n",
    "        counter = counter+1\n",
    "        if counter < img_counter:\n",
    "            continue\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        all_outputs = []\n",
    "        all_ssim    = []\n",
    "        all_haar    = []\n",
    "\n",
    "        patches = []\n",
    "        values  = []\n",
    "\n",
    "        path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "        vol  = np.fromfile(path, dtype=\"float32\")\n",
    "        vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "        print(path)\n",
    "        \n",
    "        for tp in range(1, 2):\n",
    "            temp = vol[h[k][3]+tp, :, :]\n",
    "            #print(temp.shape)\n",
    "        \n",
    "        #1280, 3072\n",
    "        image_slice = np.pad(temp, ((40, 40), (36, 36)), 'constant', constant_values=(0, 0))\n",
    "        #print(image_slice.shape)\n",
    "        \n",
    "        temp_all = []\n",
    "        for tk in range(5):\n",
    "            temp_row = []\n",
    "            for tj in range(12):\n",
    "                img = image_slice[tk*256:(tk+1)*256, tj*256:(tj+1)*256]\n",
    "                \n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                t1  = np.expand_dims(img, axis=1)\n",
    "                \n",
    "                t2 = np.expand_dims(-1*np.ones([1, 1])*0.125, axis=-1)\n",
    "                \n",
    "                x1      = torch.tensor(t1, device=device).float()\n",
    "                values1 = torch.tensor(t2, device=device).float()\n",
    "                \n",
    "                output = unet_model.forward(x1, values1)\n",
    "                output = output.data.cpu().numpy()\n",
    "                output = output[0, 0, :, :]\n",
    "                temp_row.append(output)\n",
    "            temp_row = np.concatenate(temp_row, axis=1)\n",
    "            temp_all.append(temp_row)\n",
    "        temp_all1 = np.concatenate(temp_all, axis=0)\n",
    "        \n",
    "        temp_all = []\n",
    "        for tk in range(5):\n",
    "            temp_row = []\n",
    "            for tj in range(12):\n",
    "                img = image_slice[tk*256:(tk+1)*256, tj*256:(tj+1)*256]\n",
    "                \n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                t1  = np.expand_dims(img, axis=1)\n",
    "                \n",
    "                t2 = np.expand_dims(-1*np.ones([1, 1])*0.2, axis=-1)\n",
    "                \n",
    "                x1      = torch.tensor(t1, device=device).float()\n",
    "                values1 = torch.tensor(t2, device=device).float()\n",
    "                \n",
    "                output = unet_model.forward(x1, values1)\n",
    "                output = output.data.cpu().numpy()\n",
    "                output = output[0, 0, :, :]\n",
    "                temp_row.append(output)\n",
    "            temp_row = np.concatenate(temp_row, axis=1)\n",
    "            temp_all.append(temp_row)\n",
    "        temp_all2 = np.concatenate(temp_all, axis=0)\n",
    "        \n",
    "        temp_all2   = temp_all2[40:-40, 36:-36]\n",
    "        temp_all1   = temp_all1[40:-40, 36:-36]\n",
    "        image_slice = image_slice[40:-40, 36:-36]\n",
    "        \n",
    "        image_slice.astype('float32').tofile('image_slice'+str(img_counter)+'_3000x1200.raw')\n",
    "        temp_all1.astype('float32').tofile('result_slice'+str(img_counter)+'_3000x1200.raw')\n",
    "        temp_all2.astype('float32').tofile('result_2slice'+str(img_counter)+'_3000x1200.raw')\n",
    "        \n",
    "        print(temp_all1.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 600\n",
    "iy = 1500\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "#plt.imshow(np.concatenate([temp_all1[ix:ix+256, iy:iy+256], image_slice[ix:ix+256, iy:iy+256]]), cmap='gray')\n",
    "plt.imshow(np.concatenate([temp_all1, image_slice]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     172
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] PyTorch Model Imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# in1 = np.ones([10, 1, 256, 256])\n",
    "# in2 = np.ones([10, 1])\n",
    "\n",
    "# in1 = torch.tensor(in1, device=device).float()\n",
    "# in2 = torch.tensor(in2, device=device).float()\n",
    "\n",
    "\n",
    "# Define model\n",
    "class MyUnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "    \n",
    "        self.dense_block = nn.Sequential(nn.Linear(1, 128),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(128, 32),\n",
    "                                         nn.LeakyReLU(),\n",
    "                                         nn.Linear(32, 1),\n",
    "                                         nn.LeakyReLU()\n",
    "                                        )\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter5, filter5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.upsample1   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample2   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample3   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.upsample4   = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        self.conv_block_merge1 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge2 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge3 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block_merge4 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        \n",
    "        self.conv_block6 = nn.Sequential(\n",
    "            nn.Conv2d(filter5, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter4, filter4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block7 = nn.Sequential(\n",
    "            nn.Conv2d(filter4, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter3, filter3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block8 = nn.Sequential(\n",
    "            nn.Conv2d(filter3, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter2, filter2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block9 = nn.Sequential(\n",
    "            nn.Conv2d(filter2, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(filter1, filter1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        self.conv_block10 = nn.Sequential(\n",
    "            nn.Conv2d(filter1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        hash_val = self.dense_block(y)\n",
    "        hash_val = hash_val.view(-1, 1, 1, 1)\n",
    "        \n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = torch.mul(x1, hash_val)\n",
    "        p1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(p1)\n",
    "        x2 = torch.mul(x2, hash_val)\n",
    "        p2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(p2)\n",
    "        x3 = torch.mul(x3, hash_val)\n",
    "        p3 = self.pool3(x3)\n",
    "        p3 = self.d1(p3)\n",
    "        \n",
    "        x4 = self.conv_block4(p3)\n",
    "        x4 = torch.mul(x4, hash_val)\n",
    "        p4 = self.pool4(x4)\n",
    "        p4 = self.d2(p4)\n",
    "        \n",
    "        x5 = self.conv_block5(p4)\n",
    "        x5 = torch.mul(x5, hash_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        u1 = self.upsample1(x5)\n",
    "        m6 = self.conv_block_merge1(u1)\n",
    "        m6 = torch.cat((x4, m6), 1)\n",
    "        x6 = self.conv_block6(m6)\n",
    "        x6 = torch.mul(x6, hash_val)\n",
    "        \n",
    "        u2 = self.upsample2(x6)\n",
    "        m7 = self.conv_block_merge2(u2)\n",
    "        m7 = torch.cat((x3, m7), 1)\n",
    "        x7 = self.conv_block7(m7)\n",
    "        x7 = torch.mul(x7, hash_val)\n",
    "        \n",
    "        u3 = self.upsample3(x7)\n",
    "        m8 = self.conv_block_merge3(u3)\n",
    "        m8 = torch.cat((x2, m8), 1)\n",
    "        x8 = self.conv_block8(m8)\n",
    "        x8 = torch.mul(x8, hash_val)\n",
    "        \n",
    "        u4 = self.upsample4(x8)\n",
    "        m9 = self.conv_block_merge4(u4)\n",
    "        m9 = torch.cat((x1, m9), 1)\n",
    "        x9 = self.conv_block9(m9)\n",
    "        x9 = self.conv_block10(x9)\n",
    "        \n",
    "        out = torch.sub(x, x9)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class RatingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            #nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(2, stride=2))\n",
    "        \n",
    "        self.out = nn.Sequential(nn.Linear(256, 1),\n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        \n",
    "        x = x.view(-1, 256)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "#model = MyUnet()\n",
    "#model.cuda()\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if type(m) == nn.Linear:\n",
    "        #nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "#model.apply(init_normal)\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "# rating_cnn = RatingModel()\n",
    "# rating_cnn.cuda()\n",
    "\n",
    "#rating_cnn.apply(init_normal)\n",
    "summary(unet_model, [(1, 256, 256), (1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [STAR] For predicting the result PyTorch Model\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "rating_cnn = RatingModel()\n",
    "rating_cnn.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "rating_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/rating_pytorch.pt')\n",
    "rating_cnn.load_state_dict(rating_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.831712484359741\n",
      "(218, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# [STAR] For predicting the result PyTorch Model for Time calculation\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "unet_model = MyUnet()\n",
    "unet_model.cuda()\n",
    "\n",
    "rating_cnn = RatingModel()\n",
    "rating_cnn.cuda()\n",
    "\n",
    "unet_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/unet_pytorch.pt')\n",
    "unet_model.load_state_dict(unet_weights)\n",
    "\n",
    "rating_weights = torch.load('/media/dril/Windows/newrecon2/newrecon/rating_pytorch.pt')\n",
    "rating_cnn.load_state_dict(rating_weights)\n",
    "\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "#all_outputs.append(x[0, :, :])\n",
    "import time\n",
    "\n",
    "x = np.random.rand(3515, 256, 256)\n",
    "s1 = time.time()\n",
    "for i in range(1, 219):\n",
    "    t1 = np.expand_dims(x[i*16:(i+1)*16, :, :], axis=1)\n",
    "    #1 = [x[i*8:(i+1)*8, :, :]]\n",
    "    t2 = np.expand_dims(-1*np.ones([16, 1])*0.2, axis=-1)\n",
    "    #t2 = np.expand_dims(-1*np.array([values[i]]), axis=-1)\n",
    "    #print(values[i])\n",
    "    \n",
    "    x1      = torch.tensor(t1, device=device).float()\n",
    "    values1 = torch.tensor(t2, device=device).float()\n",
    "    \n",
    "    output = unet_model.forward(x1, values1)\n",
    "    output = output.data.cpu().numpy()\n",
    "    \n",
    "    all_outputs.append(output[0, 0, :, :])\n",
    "all_outputs = np.array(all_outputs)\n",
    "\n",
    "s2 = time.time()\n",
    "\n",
    "print(s2-s1)\n",
    "print(all_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import caffe\n",
    "from pytorch_caffe import prototxt\n",
    "from pytorch_caffe.caffenet import CaffeNet\n",
    "from skimage.transform import resize\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "#from prototxt import *\n",
    "import load_hed_snapshot_share as l\n",
    "\n",
    "net = l.load_hed_net('/media/dril/Windows/newrecon2/newrecon/deploy.prototxt', '/media/dril/Windows/newrecon2/newrecon/pytorch_models/fold0/pytorch_phnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 194)\n",
      "create conv1_1              (   3 x  400 x  400) -> (  64 x  468 x  468)\n",
      "create relu1_1              (  64 x  468 x  468) -> (  64 x  468 x  468)\n",
      "create conv1_2              (  64 x  468 x  468) -> (  64 x  468 x  468)\n",
      "create relu1_2              (  64 x  468 x  468) -> (  64 x  468 x  468)\n",
      "create batch-norm1          (  64 x  468 x  468) -> (  64 x  468 x  468)\n",
      "create pool1                (  64 x  468 x  468) -> (  64 x  234 x  234)\n",
      "create conv2_1              (  64 x  234 x  234) -> ( 128 x  234 x  234)\n",
      "create relu2_1              ( 128 x  234 x  234) -> ( 128 x  234 x  234)\n",
      "create conv2_2              ( 128 x  234 x  234) -> ( 128 x  234 x  234)\n",
      "create relu2_2              ( 128 x  234 x  234) -> ( 128 x  234 x  234)\n",
      "create batch-norm2          ( 128 x  234 x  234) -> ( 128 x  234 x  234)\n",
      "create pool2                ( 128 x  234 x  234) -> ( 128 x  117 x  117)\n",
      "create conv3_1              ( 128 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create relu3_1              ( 256 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create conv3_2              ( 256 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create relu3_2              ( 256 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create conv3_3              ( 256 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create relu3_3              ( 256 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create batch-norm3          ( 256 x  117 x  117) -> ( 256 x  117 x  117)\n",
      "create pool3                ( 256 x  117 x  117) -> ( 256 x   59 x   59)\n",
      "create conv4_1              ( 256 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create relu4_1              ( 512 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create conv4_2              ( 512 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create relu4_2              ( 512 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create conv4_3              ( 512 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create relu4_3              ( 512 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create batch-norm4          ( 512 x   59 x   59) -> ( 512 x   59 x   59)\n",
      "create pool4                ( 512 x   59 x   59) -> ( 512 x   30 x   30)\n",
      "create conv5_1              ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create relu5_1              ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create conv5_2              ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create relu5_2              ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create conv5_3              ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create relu5_3              ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create batch-norm5          ( 512 x   30 x   30) -> ( 512 x   30 x   30)\n",
      "create score-dsn1           (  64 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create crop                 (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create score-dsn2           ( 128 x  234 x  234) -> (   1 x  234 x  234)\n",
      "create upsample_2           (   1 x  234 x  234) -> (   1 x  468 x  468)\n",
      "create crop                 (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create weighted_fuse        (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create score-dsn3           ( 256 x  117 x  117) -> (   1 x  117 x  117)\n",
      "create upsample_4           (   1 x  117 x  117) -> (   1 x  234 x  234)\n",
      "create crop                 (   1 x  234 x  234) -> (   1 x  234 x  234)\n",
      "create weighted_fuse        (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create score-dsn4           ( 512 x   59 x   59) -> (   1 x   59 x   59)\n",
      "create upsample_8           (   1 x   59 x   59) -> (   1 x  118 x  118)\n",
      "create crop                 (   1 x  118 x  118) -> (   1 x  118 x  118)\n",
      "create weighted_fuse        (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create score-dsn5           ( 512 x   30 x   30) -> (   1 x   30 x   30)\n",
      "create upsample_16          (   1 x   30 x   30) -> (   1 x   60 x   60)\n",
      "create crop                 (   1 x   60 x   60) -> (   1 x   60 x   60)\n",
      "create weighted_fuse        (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create sigmoid-dsn1         (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create sigmoid-dsn2         (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create sigmoid-dsn3         (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create sigmoid-dsn4         (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create sigmoid-dsn5         (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "create sigmoid-fuse         (   1 x  468 x  468) -> (   1 x  468 x  468)\n",
      "(512, 512, 194)\n",
      "Segmenting 194 slices with batch size of 2\n",
      "Slice 0\n",
      "Slice 1\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 2\n",
      "Slice 3\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 4\n",
      "Slice 5\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 6\n",
      "Slice 7\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 9\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 10\n",
      "Slice 11\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 12\n",
      "Slice 13\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 14\n",
      "Slice 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 16\n",
      "Slice 17\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 19\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 20\n",
      "Slice 21\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 22\n",
      "Slice 23\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 25\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 26\n",
      "Slice 27\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 28\n",
      "Slice 29\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 31\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 32\n",
      "Slice 33\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 34\n",
      "Slice 35\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 36\n",
      "Slice 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 38\n",
      "Slice 39\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 41\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 42\n",
      "Slice 43\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 44\n",
      "Slice 45\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 47\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 48\n",
      "Slice 49\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 50\n",
      "Slice 51\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 52\n",
      "Slice 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 54\n",
      "Slice 55\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 57\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 58\n",
      "Slice 59\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 60\n",
      "Slice 61\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 62\n",
      "Slice 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 64\n",
      "Slice 65\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 67\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 68\n",
      "Slice 69\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 70\n",
      "Slice 71\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 72\n",
      "Slice 73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 74\n",
      "Slice 75\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 77\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 78\n",
      "Slice 79\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 80\n",
      "Slice 81\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 83\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 84\n",
      "Slice 85\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 86\n",
      "Slice 87\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 89\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 90\n",
      "Slice 91\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 92\n",
      "Slice 93\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 94\n",
      "Slice 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 96\n",
      "Slice 97\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 98\n",
      "Slice 99\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 100\n",
      "Slice 101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 102\n",
      "Slice 103\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 105\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 106\n",
      "Slice 107\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 108\n",
      "Slice 109\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 111\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 112\n",
      "Slice 113\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 114\n",
      "Slice 115\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 117\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 118\n",
      "Slice 119\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 120\n",
      "Slice 121\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 123\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 124\n",
      "Slice 125\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 126\n",
      "Slice 127\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 129\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 130\n",
      "Slice 131\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 132\n",
      "Slice 133\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 134\n",
      "Slice 135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 136\n",
      "Slice 137\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 139\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 140\n",
      "Slice 141\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 142\n",
      "Slice 143\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 145\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 146\n",
      "Slice 147\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 148\n",
      "Slice 149\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 151\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 152\n",
      "Slice 153\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 154\n",
      "Slice 155\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 157\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 158\n",
      "Slice 159\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 160\n",
      "Slice 161\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 163\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 164\n",
      "Slice 165\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 166\n",
      "Slice 167\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 168\n",
      "Slice 169\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 170\n",
      "Slice 171\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 172\n",
      "Slice 173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 174\n",
      "Slice 175\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 177\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 178\n",
      "Slice 179\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 180\n",
      "Slice 181\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 183\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 184\n",
      "Slice 185\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 186\n",
      "Slice 187\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 188\n",
      "Slice 189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 190\n",
      "Slice 191\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "Slice 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 193\n",
      "forward conv1_1                        [2, 3, 400, 400] -> [2, 64, 468, 468]\n",
      "forward relu1_1                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward conv1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward relu1_2                        [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward batch-norm1                    [2, 64, 468, 468] -> [2, 64, 468, 468]\n",
      "forward pool1                          [2, 64, 468, 468] -> [2, 64, 234, 234]\n",
      "forward conv2_1                        [2, 64, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_1                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward conv2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward relu2_2                        [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward batch-norm2                    [2, 128, 234, 234] -> [2, 128, 234, 234]\n",
      "forward pool2                          [2, 128, 234, 234] -> [2, 128, 117, 117]\n",
      "forward conv3_1                        [2, 128, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_1                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_2                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward conv3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward relu3_3                        [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward batch-norm3                    [2, 256, 117, 117] -> [2, 256, 117, 117]\n",
      "forward pool3                          [2, 256, 117, 117] -> [2, 256, 59, 59]\n",
      "forward conv4_1                        [2, 256, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_1                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_2                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward conv4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward relu4_3                        [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward batch-norm4                    [2, 512, 59, 59] -> [2, 512, 59, 59]\n",
      "forward pool4                          [2, 512, 59, 59] -> [2, 512, 30, 30]\n",
      "forward conv5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_1                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_2                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward conv5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward relu5_3                        [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward batch-norm5                    [2, 512, 30, 30] -> [2, 512, 30, 30]\n",
      "forward score-dsn1                     [2, 64, 468, 468] -> [2, 1, 468, 468]\n",
      "forward crop                           [2, 1, 468, 468] -> [2, 1, 400, 400]\n",
      "forward score-dsn2                     [2, 128, 234, 234] -> [2, 1, 234, 234]\n",
      "forward upsample_2                     [2, 1, 234, 234] -> [2, 1, 470, 470]\n",
      "forward crop                           [2, 1, 470, 470] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn3                     [2, 256, 117, 117] -> [2, 1, 117, 117]\n",
      "forward upsample_4                     [2, 1, 117, 117] -> [2, 1, 472, 472]\n",
      "forward crop                           [2, 1, 472, 472] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn4                     [2, 512, 59, 59] -> [2, 1, 59, 59]\n",
      "forward upsample_8                     [2, 1, 59, 59] -> [2, 1, 480, 480]\n",
      "forward crop                           [2, 1, 480, 480] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward score-dsn5                     [2, 512, 30, 30] -> [2, 1, 30, 30]\n",
      "forward upsample_16                    [2, 1, 30, 30] -> [2, 1, 496, 496]\n",
      "forward crop                           [2, 1, 496, 496] -> [2, 1, 400, 400]\n",
      "forward weighted_fuse                  [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn1                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn2                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn3                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn4                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-dsn5                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n",
      "forward sigmoid-fuse                   [2, 1, 400, 400] -> [2, 1, 400, 400]\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "ct_windows = np.array([[600, 1200], [1040, 400], [225, 450]])\n",
    "\n",
    "file_in = '/media/dril/New Volume/LUNA/ORIG-NII/1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222365663678666836860.nii.gz'\n",
    "volume = nib.load(file_in)\n",
    "v_data = np.squeeze(volume.get_fdata())\n",
    "print(v_data.shape)\n",
    "\n",
    "mean_file = '/media/dril/Windows/p-hnn-master/caffe_model/train_colour_slice_list_0.lst_mean_image.npy'\n",
    "#mean_image = np.load(mean_file)\n",
    "#print(mean_image.shape)\n",
    "\n",
    "def run_lung_segmentation(file_in, file_out, mean_file, offset, batch_size, model_weights, model_spec):\n",
    "\n",
    "    ct_windows = np.array([[600, 1200], [1040, 400], [225, 450]])\n",
    "    net = l.load_hed_net(model_spec, model_weights)\n",
    "\n",
    "    volume = nib.load(file_in)\n",
    "    v_data = np.squeeze(volume.get_fdata())\n",
    "    mean_image = np.load(mean_file)\n",
    "\n",
    "    result_data = l.run_volume_hed(\n",
    "        net, v_data, mean_image, ct_windows, offset, batch_size)\n",
    "\n",
    "    result = nib.Nifti1Image(\n",
    "        result_data, volume.affine, volume.header)\n",
    "    nib.save(result, file_out)\n",
    "\n",
    "\n",
    "run_lung_segmentation(file_in, '/media/dril/New Volume/phnn-out.nii.gz', mean_file,\n",
    "                          1024, 2, '/home/dril/Downloads/pytorch_phnn.pth', '/media/dril/Windows/newrecon2/newrecon/deploy.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "'/home/dril/Downloads/pytorch_phnn.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2212075710296631 0.013774563985952545\n"
     ]
    }
   ],
   "source": [
    "a = [0.24677252769470215, 0.2077016830444336, 0.2233893871307373, 0.21227669715881348, 0.2158975601196289]\n",
    "print(np.mean(a), np.std(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.523446750640868 0.10497122145263522\n"
     ]
    }
   ],
   "source": [
    "b = [13.407370567321777, 13.721302509307861, 13.491996765136719, 13.50873589515686, 13.487828016281128]\n",
    "print(np.mean(b), np.std(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For plotting the results\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "o1 = np.concatenate(all_outputs[:7, :, :], axis=0).T\n",
    "print(o1.shape)\n",
    "\n",
    "o2 = np.concatenate(x[1:8, :, :]).T\n",
    "print(o2.shape)\n",
    "\n",
    "#print(o1.shape, o2.shape)\n",
    "\n",
    "together = np.concatenate([o1, o2], axis=0)\n",
    "#print(o1.shape, o2.shape, together.shape)\n",
    "print(values[1:])\n",
    "plt.imshow(together, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "code_folding": [
     0,
     17
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [STAR] Comparing the Noise Power Spectrum\n",
    "\n",
    "from scipy import fftpack\n",
    "import pyfits\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import radialProfile\n",
    "\n",
    "index  = 2\n",
    "image1 = o1[:, index*256:(index+1)*256]\n",
    "image2 = o2[:, index*256:(index+1)*256]\n",
    "\n",
    "index  = 5\n",
    "image3 = o1[:, index*256:(index+1)*256]\n",
    "image4 = o2[:, index*256:(index+1)*256]\n",
    "\n",
    "\n",
    "def get_power_spectrum(image):    \n",
    "    # Take the fourier transform of the image.\n",
    "    F1 = fftpack.fft2(image)\n",
    "    F2 = fftpack.fftshift(F1)\n",
    "    \n",
    "    # Calculate a 2D power spectrum\n",
    "    psf2D = np.abs( F2 )**2\n",
    "    \n",
    "    # Calculate the azimuthally averaged 1D power spectrum\n",
    "    psf1D = radialProfile.azimuthalAverage(psf2D)\n",
    "    return psf1D\n",
    "\n",
    "t1 = get_power_spectrum(image1)\n",
    "t2 = get_power_spectrum(image2)\n",
    "\n",
    "t3 = get_power_spectrum(image3)\n",
    "t4 = get_power_spectrum(image4)\n",
    "\n",
    "\n",
    "py.figure(3)\n",
    "py.clf()\n",
    "\n",
    "py.semilogy( t1, 'r--', label=r'U-Net             $\\beta = 0.154$')\n",
    "py.semilogy( t3, 'b--', label=r'U-Net             $\\beta = 0.454$')\n",
    "\n",
    "py.semilogy( t2, label=r'Ground Truth $\\beta = 0.154$')\n",
    "py.semilogy( t4, label=r'Ground Truth $\\beta = 0.454$')\n",
    "\n",
    "\n",
    "py.xlabel(\"Spatial Frequency\", fontsize=24)\n",
    "py.ylabel(\"Power Spectrum\",fontsize=24)\n",
    "py.legend(fontsize=20)\n",
    "py.xticks(fontsize=16)\n",
    "py.yticks(fontsize=16)\n",
    "py.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [STAR] For getting the SSIM metric\n",
    "\n",
    "#from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "#from skimage import structural_similarity as ssim\n",
    "from skimage import measure\n",
    "import glob\n",
    "\n",
    "import importlib\n",
    "importlib.reload(haarPsi)\n",
    "\n",
    "#import \n",
    "from haarPsi import haar_psi_numpy\n",
    "\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "ssim_array = {}\n",
    "ssim_array[0.1] = []\n",
    "ssim_array[0.2] = []\n",
    "ssim_array[0.3] = []\n",
    "ssim_array[0.4] = []\n",
    "ssim_array[0.5] = []\n",
    "ssim_array[0.6] = []\n",
    "\n",
    "\n",
    "mae_array = {}\n",
    "mae_array[0.1] = []\n",
    "mae_array[0.2] = []\n",
    "mae_array[0.3] = []\n",
    "mae_array[0.4] = []\n",
    "mae_array[0.5] = []\n",
    "mae_array[0.6] = []\n",
    "\n",
    "def my_mae(x, y):\n",
    "    return np.mean(np.abs(x-y))\n",
    "\n",
    "unet_model.eval()\n",
    "\n",
    "checkit = []\n",
    "\n",
    "flag = False\n",
    "\n",
    "for t in test_list:\n",
    "    a        = np.load(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_0.npy\")\n",
    "    allfiles = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_-*.npy\")\n",
    "    \n",
    "    for f in allfiles:\n",
    "        value = -1*float(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "        b     = np.load(f)\n",
    "        print(f, value)\n",
    "        \n",
    "        for index in range(50):\n",
    "            b1    = b[index, :, :, 0]\n",
    "            \n",
    "            t1    = a[index, :, :, 0]\n",
    "            t1    = np.expand_dims(t1, 0)\n",
    "            t1    = np.expand_dims(t1, 1)\n",
    "            \n",
    "            values  = -1*value*np.ones([1, 1])\n",
    "            \n",
    "            x1      = torch.tensor(t1, device=device).float()\n",
    "            values  = torch.tensor(values, device=device).float()\n",
    "        \n",
    "            output = unet_model.forward(x1, values)\n",
    "            pred   = output.data.cpu().numpy()\n",
    "            \n",
    "            t1 = np.min(b1.flatten())\n",
    "            t2 = np.max(b1.flatten())\n",
    "            reference_image = (b1-t1)*255/(t2-t1)\n",
    "            \n",
    "            t1 = np.min(pred[0, 0, :, :].flatten())\n",
    "            t2 = np.max(pred[0, 0, :, :].flatten())\n",
    "            distorted_image = (pred[0, 0, :, :]-t1)*255/(t2-t1)\n",
    "            #print(np.min(distorted_image), np.max(distorted_image), np.max(reference_image), np.min(reference_image))\n",
    "            \n",
    "            ssim_temp = measure.compare_ssim(distorted_image, reference_image, data_range=255)\n",
    "            #ssim_temp = measure.compare_ssim(pred[0, 0, :, :].astype('float16'), b1.astype('float16'))\n",
    "            #ssim_temp = measure.compare_ssim(pred[0, 0, :, :].astype('float32'), b1.astype('float32'), data_range=b1.max() - b1.min())\n",
    "            #ssim_temp = measure.compare_ssim(pred[0, 0, :, :].astype('float32'), b1.astype('float32'), data_range=pred[0, 0, :, :].max() - pred[0, 0, :, :].min())\n",
    "            \n",
    "            #ssim_temp = haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True)[0]\n",
    "            if ssim_temp < 0.6 and value < 0.6:\n",
    "                import random\n",
    "                lp = random.randint(0, 100)\n",
    "                if lp > 90:\n",
    "                    flag       = True\n",
    "                    ssim_temp1 = haar_psi_numpy(reference_image.astype('float32'), distorted_image.astype('float32'),  preprocess_with_subsampling = True)[0]\n",
    "                    print(ssim_temp, value, ssim_temp1)\n",
    "                    checkit.append([reference_image, distorted_image])\n",
    "                    break\n",
    "            #print(ssim_temp[0], ssim_temp[1].shape)\n",
    "            \n",
    "            mae_temp  = my_mae(pred[0, 0, :, :], b1)\n",
    "                \n",
    "            if value < 0.1:\n",
    "                ssim_array[0.1].append(ssim_temp)\n",
    "                mae_array[0.1].append(mae_temp)\n",
    "            elif value < 0.2:\n",
    "                ssim_array[0.2].append(ssim_temp)\n",
    "                mae_array[0.2].append(mae_temp)    \n",
    "            elif  value < 0.3:\n",
    "                ssim_array[0.3].append(ssim_temp)\n",
    "                mae_array[0.3].append(mae_temp)    \n",
    "            elif  value < 0.4:\n",
    "                ssim_array[0.4].append(ssim_temp)\n",
    "                mae_array[0.4].append(mae_temp)    \n",
    "            elif value < 0.5:\n",
    "                ssim_array[0.5].append(ssim_temp)\n",
    "                mae_array[0.5].append(mae_temp)    \n",
    "            elif value < 0.6:\n",
    "                ssim_array[0.6].append(ssim_temp)\n",
    "                mae_array[0.6].append(mae_temp)\n",
    "        if flag:\n",
    "            break\n",
    "    if flag:\n",
    "        break\n",
    "\n",
    "values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "for t in values:\n",
    "    print(t, np.mean(ssim_array[t]), np.mean(mae_array[t]), np.std(ssim_array[t]), np.std(mae_array[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM results\n",
    "0.1 0.9914873887960779 0.00018285964 0.0061945855375389125 4.591579e-05\n",
    "0.2 0.9469701962447921 0.0002514394 0.02808622002535202 4.0652736e-05\n",
    "0.3 0.8693526790506381 0.00026405914 0.07103994994361851 6.837431e-05\n",
    "0.4 0.7924587842729388 0.00028266825 0.109039188851624 9.9856086e-05\n",
    "0.5 0.7234613368989369 0.0002761438 0.1480347905261776 7.468571e-05\n",
    "0.6 0.6754057684000083 0.00030263996 0.1760634203245287 0.00011321019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625813677591749\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 691.2x244.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.concatenate([reference_image, distorted_image]).T, cmap='gray')\n",
    "ssim_temp = haar_psi_numpy(reference_image, distorted_image, preprocess_with_subsampling = True)[0]\n",
    "print(ssim_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3850\n"
     ]
    }
   ],
   "source": [
    "print(700+500+850+750+550+500)\n",
    "# 700+500+850+750+550+500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98, 0.  , 0.02])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around([0.9781404488519797, 0.00018285964, 0.01689025516708194], decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HaarPSI metric Results\n",
    "\n",
    "C = 200\n",
    "0.1 0.9858204980953706 0.00018285964 0.011030629237313055 4.591579e-05\n",
    "0.2 0.9441371588055242 0.0002514394 0.029445817913910526 4.0652736e-05\n",
    "0.3 0.8953782020430879 0.00026405914 0.0610303481328526 6.837431e-05\n",
    "0.4 0.8582752275967497 0.00028266825 0.08258155017354446 9.9856086e-05\n",
    "0.5 0.8333061976821139 0.0002761438 0.10266725558456456 7.468571e-05\n",
    "0.6 0.8278191186427702 0.00030263996 0.10160239220458343 0.00011321019\n",
    "\n",
    "C = 100\n",
    "0.1 0.9781404488519797 0.00018285964 0.01689025516708194 4.591579e-05\n",
    "0.2 0.9161082165669477 0.0002514394 0.04262870928171611 4.0652736e-05\n",
    "0.3 0.8528422052051116 0.00026405914 0.08093317170347102 6.837431e-05\n",
    "0.4 0.8089372698393853 0.00028266825 0.10316644268939193 9.9856086e-05\n",
    "0.5 0.7805865981601848 0.0002761438 0.12404749575544136 7.468571e-05\n",
    "0.6 0.772734007012864 0.00030263996 0.1221296098897257 0.00011321019\n",
    "\n",
    "C = 30\n",
    "0.1 0.9578447597119935 0.00018285964 0.03167215278443286 4.591579e-05\n",
    "0.2 0.8526258075981621 0.0002514394 0.06833211279899469 4.0652736e-05\n",
    "0.3 0.7715300871905484 0.00026405914 0.11194060661440992 6.837431e-05\n",
    "0.4 0.7223023686087682 0.00028266825 0.12983286520123713 9.9856086e-05\n",
    "0.5 0.69266904946197 0.0002761438 0.14962337437161627 7.468571e-05\n",
    "0.6 0.6805525969198479 0.00030263996 0.14551783795880077 0.00011321019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion for training the calibaration CNN with lesions only Noisy patches\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "for k in allindex:\n",
    "    #if h[k][0] not in allindex:\n",
    "    #    continue\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    patches = []\n",
    "    values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "    vol  = np.fromfile(path, dtype=\"float32\")\n",
    "    vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    \n",
    "    temp_count = 0\n",
    "    \n",
    "    for tp in range(-2, 2):\n",
    "        temp = vol[h[k][3]+tp, h[k][2]-128:h[k][2]+128, h[k][1]-128:h[k][1]+128]\n",
    "        if temp.shape[0] == 256 and temp.shape[1] == 256:\n",
    "            x.append(temp)\n",
    "    \n",
    "    x      = np.array(x)\n",
    "    \n",
    "    print(path, x.shape, k)\n",
    "    \n",
    "    np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_x_\"+str(k)+\".npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting patches for each lesion for training the calibaration CNN with No lesions only Noisy patches\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_annotation/index-b-*.npy\")\n",
    "allindex = []\n",
    "for f in allfiles:\n",
    "    index = int(f.split(\"/\")[-1].split(\"-\")[-1][:-4])\n",
    "    #print(f, index)\n",
    "    allindex.append(index)\n",
    "\n",
    "patches = {}\n",
    "values  = {}\n",
    "\n",
    "\n",
    "\n",
    "for k in allindex:\n",
    "    #if h[k][0] not in allindex:\n",
    "    #    continue\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    patches = []\n",
    "    values  = []\n",
    "    \n",
    "    path = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(h[k][0])+\".raw\")[0]\n",
    "    vol  = np.fromfile(path, dtype=\"float32\")\n",
    "    vol  = np.reshape(vol, [64, 1200, 3000])\n",
    "    \n",
    "    dx_array = [-5, 5]#, -10, 10]\n",
    "    dy_array = [-5, 5]#, -10, 10]\n",
    "    \n",
    "    temp_count = 0\n",
    "    while(temp_count < 50):\n",
    "        ix = np.random.randint(256, 1200-256)\n",
    "        iy = np.random.randint(256, 3000-256)\n",
    "        iz = np.random.randint(10, 54)\n",
    "\n",
    "        tempx = vol[iz, ix:ix+256, iy:iy+256]\n",
    "\n",
    "        if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "            continue\n",
    "        \n",
    "        if tempx.shape[0] == 256 and tempx.shape[1] == 256:\n",
    "            x.append(tempx)\n",
    "            temp_count = temp_count + 1\n",
    "#         \n",
    "        \n",
    "    x = np.array(x).astype('float16')\n",
    "    #y = np.array(y)\n",
    "    #z = np.array(z)\n",
    "    \n",
    "    #print(x.shape, y.shape, z.shape)\n",
    "    print(x.shape, k)\n",
    "    \n",
    "    np.save(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_no_x_\"+str(k)+\".npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For plotting Power Spectrum\n",
    "\n",
    "from scipy import fftpack\n",
    "import pyfits\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import radialProfile\n",
    "\n",
    "image = #pyfits.getdata(myimage.fits)\n",
    "\n",
    "# Take the fourier transform of the image.\n",
    "F1 = fftpack.fft2(image)\n",
    "F2 = fftpack.fftshift( F1 )from scipy import fftpack\n",
    "import pyfits\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import radialProfile\n",
    "\n",
    "image = #pyfits.getdata(myimage.fits)\n",
    "\n",
    "# Take the fourier transform of the image.\n",
    "F1 = fftpack.fft2(image)\n",
    "F2 = fftpack.fftshift( F1 )\n",
    "\n",
    "# Calculate a 2D power spectrum\n",
    "psd2D = np.abs( F2 )**2\n",
    "\n",
    "# Calculate the azimuthally averaged 1D power spectrum\n",
    "psd1D = radialProfile.azimuthalAverage(psd2D)\n",
    "\n",
    "# Now plot up both\n",
    "py.figure(1)\n",
    "py.clf()\n",
    "py.imshow( np.log10( image ), cmap=py.cm.Greys)\n",
    "\n",
    "py.figure(2)\n",
    "py.clf()\n",
    "py.imshow( np.log10( psf2D ))\n",
    "\n",
    "py.figure(3)\n",
    "py.clf()\n",
    "py.semilogy( psf1D )\n",
    "py.xlabel(Spatial Frequency)\n",
    "py.ylabel(Power Spectrum)\n",
    "\n",
    "py.show()\n",
    "\n",
    "# Calculate a 2D power spectrum\n",
    "psd2D = np.abs( F2 )**2\n",
    "\n",
    "# Calculate the azimuthally averaged 1D power spectrum\n",
    "psd1D = radialProfile.azimuthalAverage(psd2D)\n",
    "\n",
    "# Now plot up both\n",
    "py.figure(1)\n",
    "py.clf()\n",
    "py.imshow( np.log10( image ), cmap=py.cm.Greys)\n",
    "\n",
    "py.figure(2)\n",
    "py.clf()\n",
    "py.imshow( np.log10( psf2D ))\n",
    "\n",
    "py.figure(3)\n",
    "py.clf()\n",
    "py.semilogy( psf1D )\n",
    "py.xlabel(Spatial Frequency)\n",
    "py.ylabel(Power Spectrum)\n",
    "\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     26
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN using Real DBT slices Data\n",
    "\n",
    "#10336 4148\n",
    "#6920 2770\n",
    "\n",
    "#2160 864\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "#trainx = np.zeros([153, 1, 256, 256])\n",
    "#trainy = np.zeros([153, 1])\n",
    "#trainv = np.zeros([153, 1])\n",
    "\n",
    "valx   = np.zeros([63, 1, 256, 256])\n",
    "valy   = np.zeros([63, 1])\n",
    "valv   = np.zeros([63, 1])\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "traincount = 0\n",
    "valcount   = 0\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_x_*.npy\")\n",
    "for f in allfiles:\n",
    "    print(f)\n",
    "    x1 = np.load(f)\n",
    "    y1 = -1*np.load(f.replace(\"noisy_x_\", \"y_\"))\n",
    "    #print(y1)\n",
    "    \n",
    "    #print(f.split(\"/\")[-1].split(\"_\"))\n",
    "    k = int(f.split(\"/\")[-1].split(\"_\")[2][:-4])\n",
    "    #print(k, h[k])\n",
    "    \n",
    "    x1 = np.expand_dims(x1, axis=-1)\n",
    "    #y1 = np.expand_dims(y1, axis=-1)\n",
    "    \n",
    "    #print(x1.shape, y1.shape)\n",
    "    \n",
    "    if h[k][0] in train_list:\n",
    "        #print(x1.shape, y1.shape, \"Train\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        #trainx[traincount:traincount+x1.shape[0], 0, :, :] = x1[:, :, :, 0]\n",
    "        #trainy[traincount:traincount+x1.shape[0], 0] = 1\n",
    "        #trainv[traincount:traincount+x1.shape[0], 0] = y1\n",
    "        \n",
    "        #trainx.append(x1)\n",
    "        #trainy.append(y1)\n",
    "        traincount = traincount+x1.shape[0]\n",
    "    elif h[k][0] in val_list:\n",
    "        #print(x1.shape, y1.shape, \"Val\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        valx[valcount:valcount+x1.shape[0], 0, :, :] = x1[:, :, :, 0]\n",
    "        valy[valcount:valcount+x1.shape[0], 0] = 1\n",
    "        #valv[valcount:valcount+x1.shape[0], 0] = y1\n",
    "        \n",
    "        #valx.append(x1)\n",
    "        #valy.append(y1)\n",
    "        valcount = valcount+x1.shape[0]\n",
    "\n",
    "print(traincount, valcount)\n",
    "\n",
    "# # trainx_lesion = copy.deepcopy(trainx)\n",
    "# # trainy_lesion = copy.deepcopy(trainy)\n",
    "\n",
    "# share = 10\n",
    "# allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_cho_data/noisy_no_x_*.npy\")\n",
    "# for f in allfiles:\n",
    "#     #print(f)\n",
    "#     x1 = np.load(f)\n",
    "#     #y1 = -1*np.load(f.replace(\"x_\", \"v_\"))\n",
    "    \n",
    "#     #print(f.split(\"/\")[-1].split(\"_\"))\n",
    "#     k = int(f.split(\"/\")[-1].split(\"_\")[3][:-4])\n",
    "#     #print(k, h[k])\n",
    "    \n",
    "#     x1 = np.expand_dims(x1, axis=-1)\n",
    "#     #y1 = np.expand_dims(y1, axis=-1)\n",
    "    \n",
    "#     #print(x1.shape, y1.shape, k)\n",
    "    \n",
    "    \n",
    "#     if h[k][0] in train_list:\n",
    "#         #print(x1.shape, y1.shape, \"Train\")\n",
    "#         if x1.shape[0] == 0:\n",
    "#             continue\n",
    "        \n",
    "#         #trainx[traincount:traincount+int(x1.shape[0]/share), 0, :, :] = x1[:int(x1.shape[0]/share), :, :, 0]\n",
    "#         #trainy[traincount:traincount+int(x1.shape[0]/share), 0] = 0\n",
    "#         #trainv[traincount:traincount+x1.shape[0], 0] = y1\n",
    "        \n",
    "#         #trainx.append(x1)\n",
    "#         #trainy.append(y1)\n",
    "#         traincount = traincount+int(x1.shape[0]/share)\n",
    "#         #print(traincount, \" traincount\")\n",
    "#     elif h[k][0] in val_list:\n",
    "#         #print(x1.shape, y1.shape, \"Val\")\n",
    "#         if x1.shape[0] == 0:\n",
    "#             continue\n",
    "        \n",
    "#         valx[valcount:valcount+int(x1.shape[0]/share), 0, :, :] = x1[:int(x1.shape[0]/share), :, :, 0]\n",
    "#         valy[valcount:valcount+int(x1.shape[0]/share), 0] = 0\n",
    "#         #valv[valcount:valcount+x1.shape[0], 0] = y1\n",
    "#         #valx.append(x1)\n",
    "#         #valy.append(y1)\n",
    "#         valcount = valcount+int(x1.shape[0]/share)\n",
    "# #     elif h[k][0] in test_list:\n",
    "# #         print(\"Found in test \", k)\n",
    "# #     else:\n",
    "# #         print(\"Not found \")\n",
    "\n",
    "\n",
    "\n",
    "print(traincount, valcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN in Keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "aug_train = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "tempx = []\n",
    "tempy = []\n",
    "#\n",
    "#whileaug_train.flow(trainx, trainy, batch_size=32)\n",
    "\n",
    "for i, (x, y) in enumerate(aug_train.flow(trainx, trainy, batch_size=32)):\n",
    "    for k in range(len(x)):\n",
    "        tempx.append(x[k])\n",
    "    for k in range(len(y)):\n",
    "        tempy.append(y[k])\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    if len(tempx) >= 30000:\n",
    "        break\n",
    "\n",
    "tempx = np.array(tempx)\n",
    "tempy = np.array(tempy)\n",
    "\n",
    "print(tempx.shape, tempy.shape)\n",
    "\n",
    "#tempx = np.reshape(tempx, [len(tempx)*32, 1, 256, 256])\n",
    "#tempy = np.reshape(tempy, [len(tempy)*32, 1])\n",
    "\n",
    "print(tempx.shape, tempy.shape)\n",
    "\n",
    "np.save(\"trainx_rating.npy\", tempx)\n",
    "np.save(\"trainy_rating.npy\", tempy)\n",
    "#print(i, x.shape, y.shape)\n",
    "#print(aug_train.flow(trainx, trainy, batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     29
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN in Pytorch\n",
    "\n",
    "trainx = np.zeros([160, 256, 256, 1])\n",
    "trainy = np.zeros([160, 1])\n",
    "valx   = np.zeros([230, 256, 256, 1])\n",
    "valy   = np.zeros([230, 1])\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "traincount = 0\n",
    "valcount   = 0\n",
    "\n",
    "allfiles = glob.glob(\"/media/dril/Windows/newrecon2/newrecon/dbt_real_ratings/x_*.npy\")\n",
    "for f in allfiles:\n",
    "    #print(f)\n",
    "    \n",
    "    x1 = np.load(f)\n",
    "    y1 = -1*np.load(f.replace(\"x_\", \"z_\"))\n",
    "    \n",
    "    k = int(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "    #print(k, h[k])\n",
    "    \n",
    "    x1 = np.expand_dims(x1, axis=-1)\n",
    "    y1 = np.expand_dims(y1, axis=-1)\n",
    "    \n",
    "    #print(x1.shape, y1.shape)\n",
    "    \n",
    "    if h[k][0] in train_list:\n",
    "        #print(x1.shape, y1.shape, \"Train\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        trainx[traincount:traincount+x1.shape[0], :, :, :] = x1\n",
    "        trainy[traincount:traincount+x1.shape[0], :] = y1\n",
    "        #trainx.append(x1)\n",
    "        #trainy.append(y1)\n",
    "        traincount = traincount+x1.shape[0]\n",
    "    elif h[k][0] in test_list:\n",
    "        print(f)\n",
    "        #print(x1.shape, y1.shape, \"Val\")\n",
    "        if x1.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        #valx[valcount:valcount+x1.shape[0], :, :, :] = x1\n",
    "        #valy[valcount:valcount+x1.shape[0], :] = y1\n",
    "        #valx.append(x1)\n",
    "        #valy.append(y1)\n",
    "        valcount = valcount+x1.shape[0]\n",
    "\n",
    "print(traincount, valcount)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the CNN in Keras\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# new_input = Input(shape=(256, 256, 3))\n",
    "# #model = VGG16(include_top=False, input_tensor=new_input)\n",
    "\n",
    "# base_model = VGG16(weights='imagenet', include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "# x=base_model.output\n",
    "# x=GlobalAveragePooling2D()(x)\n",
    "# # x = Dropout(0.5)(x)\n",
    "# x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "# x=Dense(512,activation='relu')(x)\n",
    "# x=Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "# #x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "# # x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "# # preds=Dense(1,activation='relu')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input,outputs=x)\n",
    "# model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = rating_cnn()\n",
    "#model.load_weights(\"rate-6-ddsm.h5\")\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "#out1 = model.outputrating_c\n",
    "#newmodel = Model()\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "#print(model.summary())\n",
    "checkpoints = ModelCheckpoint('rate-10.h5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                                        save_weights_only=False, mode='auto', period=1)\n",
    "# trainy1 = trainy-1\n",
    "# valy1   = valy-1\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "aug_train = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "model.fit_generator(aug_train.flow(trainx, trainy, batch_size=32),\n",
    "                    validation_data=(valx, valy),\n",
    "                    steps_per_epoch=len(trainx) // 32,\n",
    "                    epochs=10000,\n",
    "                   callbacks=[checkpoints])\n",
    "\n",
    "#model.fit(trainx, trainy, validation_data=(valx, valy), batch_size=32, epochs=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bad index -> 2, 6, 23, 18, 20, 36, 54\n",
    "# For paper -> 10, 16, 33 (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lesion Location information\n",
    "\n",
    "1  1692, 1034, 34\n",
    "3  2043, 280,  18\n",
    "3  2124, 1146, 17\n",
    "3  1272, 236,  32\n",
    "6  1293, 440,  16\n",
    "7  1708, 496,  44\n",
    "7  941, 1100,  13\n",
    "10 874, 1018,  28\n",
    "10 1922, 734,  33 \n",
    "10 1957, 413,  38\n",
    "10 2018, 556,  37\n",
    "10 1961, 470,  7\n",
    "11 1298, 661,  22\n",
    "12 \n",
    "13 1628, 348,  34\n",
    "13 1797, 854,  34\n",
    "13 1622, 349,  34\n",
    "13 1596, 510,  31\n",
    "13 1550, 669,  37\n",
    "16 \n",
    "17  \n",
    "19 686, 1125, 20\n",
    "21 732, 464,  9\n",
    "23 \n",
    "25 1985, 576,  64\n",
    "25 1440, 256,  57\n",
    "25 1864, 1040, 36\n",
    "27 1429. 925,  64\n",
    "27 1278, 829,  64\n",
    "29 1246, 977,  21\n",
    "29 1380, 905,  19\n",
    "31\n",
    "33 1104, 666,  24\n",
    "35 1670, 725,  17\n",
    "37 1128, 877,  56\n",
    "39 \n",
    "41 1084, 934,  42\n",
    "43 \n",
    "44 1480, 970,  19\n",
    "45 1638, 610,  47\n",
    "47 1062, 646,  23\n",
    "47 1301, 564,  23\n",
    "47 1870, 625,  23\n",
    "50 \n",
    "52 \n",
    "54 706, 1162,  27\n",
    "55 \n",
    "56 (bad)\n",
    "57 (bad)\n",
    "58 \n",
    "59 841, 1038,  32\n",
    "60 554, 553,   28\n",
    "60 468, 830,   22\n",
    "61 \n",
    "62 \n",
    "64 1948, 854,  22\n",
    "65 1820, 600,  25\n",
    "66 1510, 328,  40\n",
    "66 1328, 1001, 20\n",
    "66 1950, 630,  46 (test)\n",
    "66 1544, 529,  37\n",
    "67 1672, 542,  42\n",
    "67 2138, 612,  36\n",
    "67 1797, 694,  35\n",
    "67 1164, 737,  33 (test)\n",
    "68                (train) \n",
    "69                (train)\n",
    "70 1341, 762, 10\n",
    "71 1433, 769, 14  (train)\n",
    "72                (train)\n",
    "73                (train)\n",
    "74 2302, 457, 28  (test)\n",
    "75 2107, 777, 40  (test)\n",
    "76                (train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code to get the patches\n",
    "\n",
    "#todo = [15, 16, 19, 20, 27, 29, 31, 35]\n",
    "\n",
    "for i in range(1, 77):\n",
    "    if i not in test_list:\n",
    "        continue\n",
    "    \n",
    "    #todo = [15, 16, 19, 20, 27, 29, 31, 35]\n",
    "    allfiles = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(i)+\".raw.npy\")\n",
    "    if len(allfiles) == 0:\n",
    "        continue\n",
    "    \n",
    "    mainfile = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/RECONS/*_\"+str(i)+\".raw\")[0]\n",
    "    \n",
    "    all_vols   = np.zeros([len(allfiles)+1, 64, 1200, 3000], dtype='float16')\n",
    "    all_index  = []\n",
    "    all_values = []\n",
    "    \n",
    "    temp = np.fromfile(mainfile, dtype='float32')\n",
    "    temp = np.reshape(temp, [64, 1200, 3000])\n",
    "    all_vols[0, :, :, :] = temp\n",
    "    all_index.append(i)\n",
    "    all_values.append(-0)\n",
    "    \n",
    "    counter = 1\n",
    "    for f in allfiles:\n",
    "        #a = np.fromfile(f, dtype='float32')\n",
    "        a     = np.load(f)\n",
    "        a     = np.reshape(a, [64, 1200, 3000])\n",
    "        all_vols[counter, :, :, :] = a\n",
    "        \n",
    "        index = int(f.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "        value = float(f.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        \n",
    "        all_index.append(index)\n",
    "        all_values.append(value)\n",
    "        print(index, value, a.shape, f)\n",
    "        counter = counter+1\n",
    "    \n",
    "    total_count   = 50\n",
    "    all_locations = []\n",
    "    \n",
    "    # Get all Locations\n",
    "    while(True):\n",
    "        ix = np.random.randint(256, 1200-256)\n",
    "        iy = np.random.randint(256, 3000-256)\n",
    "        iz = np.random.randint(10, 54)\n",
    "        \n",
    "        tempx = all_vols[0][iz, ix:ix+256, iy:iy+256]\n",
    "        \n",
    "        if np.count_nonzero(tempx.flatten())*1.0/(256*256) < 0.9:\n",
    "            continue\n",
    "        \n",
    "        all_locations.append([ix, iy, iz])\n",
    "        if len(all_locations) == total_count:\n",
    "            break\n",
    "    \n",
    "    # Get patches\n",
    "    for k in range(len(all_vols)):\n",
    "        y_array = np.zeros([total_count, 256, 256, 1], dtype='float16')\n",
    "        counter = 0\n",
    "        \n",
    "        for p in all_locations:\n",
    "            iz = p[2]\n",
    "            ix = p[0]\n",
    "            iy = p[1]\n",
    "            \n",
    "            tempy   = all_vols[k][iz, ix:ix+256, iy:iy+256]\n",
    "            y_array[counter, :, :, 0] = tempy\n",
    "            counter = counter+1\n",
    "        np.save(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(all_index[k])+'_'+str(all_values[k])+'.npy', y_array)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10250, 1, 256, 256) (10250, 1, 256, 256) (10250, 1) 10250\n",
      "(3950, 1, 256, 256) (3950, 1, 256, 256) (3950, 1) 3950\n"
     ]
    }
   ],
   "source": [
    "# For reading the training data\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "train_list = [1, 3, 6, 7, 11, 12, 13, 16, 17, 31, 33, 35, 37, 39, 41, 43, 50, 52, 55,  68, 69, 70, 71, 72, 73, 76]\n",
    "val_list   = [19, 21, 23, 25, 27, 29, 61, 62, 64, 65]\n",
    "test_list  = [10, 44, 45, 47, 54, 58, 59, 60, 66, 67, 74, 75]\n",
    "\n",
    "# 10650, 3950\n",
    "# 8200, 3160\n",
    "\n",
    "x_array = np.zeros([10250, 1, 256, 256], dtype='float16')\n",
    "z_array = np.zeros([10250, 1], dtype='float16')\n",
    "y_array = np.zeros([10250, 1, 256, 256], dtype='float16')\n",
    "\n",
    "\n",
    "x_val_array = np.zeros([3950, 1, 256, 256], dtype='float16')\n",
    "z_val_array = np.zeros([3950, 1], dtype='float16')\n",
    "y_val_array = np.zeros([3950, 1, 256, 256], dtype='float16')\n",
    "\n",
    "count = 0\n",
    "for t in train_list:\n",
    "    #print(t)\n",
    "    maintemp = np.load(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_0.npy\")\n",
    "    #maintemp = np.load(mainfile)\n",
    "    \n",
    "    allfiles = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_*-*.npy\")\n",
    "    for f in allfiles:\n",
    "        temp = np.load(f)\n",
    "        #print(temp.shape)\n",
    "        #print(f, temp.shape, float(f.split(\"/\")[-1].split(\"_\")[1][:-4]))\n",
    "        y_array[count: count+50, 0, :, :] = temp[:, :, :, 0]\n",
    "        x_array[count: count+50, 0, :, :] = maintemp[:, :, :, 0]\n",
    "        z_array[count: count+50, :]       = np.ones([50, 1])*float(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "        count = count+50\n",
    "\n",
    "print(x_array.shape, y_array.shape, z_array.shape, count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for t in val_list:\n",
    "    #print(t)\n",
    "    maintemp = np.load(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_0.npy\")\n",
    "    #maintemp = np.load(mainfile)\n",
    "    \n",
    "    allfiles = glob.glob(\"/media/dril/My Passport/REAL-DBT-PROJECTIONS/PATCHES/\"+str(t)+\"_*-*.npy\")\n",
    "    for f in allfiles:\n",
    "        temp = np.load(f)\n",
    "        \n",
    "        #print(f, temp.shape, float(f.split(\"/\")[-1].split(\"_\")[1][:-4]))\n",
    "        y_val_array[count: count+50, 0, :, :] = temp[:50, :, :, 0]\n",
    "        x_val_array[count: count+50, 0, :, :] = maintemp[:50, :, :, 0]\n",
    "        z_val_array[count: count+50, :]       = np.ones([50, 1])*float(f.split(\"/\")[-1].split(\"_\")[1][:-4])\n",
    "        count = count+50\n",
    "        \n",
    "print(x_val_array.shape, y_val_array.shape, z_val_array.shape, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30020, 1, 256, 256) (30020, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "trainx = np.load(\"trainx_rating.npy\")\n",
    "trainy = np.load(\"trainy_rating.npy\")\n",
    "\n",
    "print(trainx.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For training the Rating CNN pytorch\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(rating_cnn.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min = 1000\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    rating_cnn.train()\n",
    "    loss_array = []\n",
    "    \n",
    "    for i in range(len(trainx)//32):\n",
    "        x = trainx[i*32:(i+1)*32, :, :, :]\n",
    "        y = trainy[i*32:(i+1)*32, :]\n",
    "        #z = z_array[i*8:(i+1)*8, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        #z = torch.tensor(z, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = rating_cnn(x)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape, y.data.shape)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i %100 == 0:\n",
    "            rating_cnn.eval()\n",
    "            loss_array_val = []\n",
    "            for ik in range(len(valx)//8):\n",
    "                x = valx[ik*8:(ik+1)*8, :, :, :]\n",
    "                y = valy[ik*8:(ik+1)*8, :]\n",
    "                #z = z_val_array[i*8:(i+1)*8, :]\n",
    "\n",
    "                x = torch.tensor(x, device=device).float()\n",
    "                y = torch.tensor(y, device=device).float()\n",
    "                #z = torch.tensor(z, device=device).float()\n",
    "\n",
    "                output = rating_cnn(x)\n",
    "\n",
    "                loss = criterion(output, y)\n",
    "                loss_array_val.append(loss.item())\n",
    "\n",
    "            val_loss = np.mean(loss_array_val)\n",
    "            print(\"Val loss \", val_loss)\n",
    "\n",
    "            if val_loss < prev_min:\n",
    "                prev_min = val_loss\n",
    "                torch.save(rating_cnn.state_dict(), \"rating_pytorch.pt\")\n",
    "            rating_cnn.train()\n",
    "    print(np.mean(loss_array))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_cnn.eval()\n",
    "total_outputs = []\n",
    "total_ground  = []\n",
    "\n",
    "loss_array_val = []\n",
    "for ik in range(len(valx)//8):\n",
    "    x = valx[ik*8:(ik+1)*8, :, :, :]\n",
    "    y = valy[ik*8:(ik+1)*8, :]\n",
    "    #z = z_val_array[i*8:(i+1)*8, :]\n",
    "\n",
    "    x = torch.tensor(x, device=device).float()\n",
    "    y = torch.tensor(y, device=device).float()\n",
    "    #z = torch.tensor(z, device=device).float()\n",
    "\n",
    "    output = rating_cnn(x)\n",
    "    \n",
    "    temp = y.data.cpu().flatten()\n",
    "    for p in temp:\n",
    "        total_ground.append(p)\n",
    "    temp = output.data.cpu().flatten()\n",
    "    for p in temp:\n",
    "        total_outputs.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13,
     16
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device    = torch.device(\"cuda:0\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "def my_loss(output, target):\n",
    "    loss = torch.mean(torch.abs((output - target)))\n",
    "    return loss\n",
    "\n",
    "prev_min = 1000\n",
    "\n",
    "#model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for i in range(len(x_array)//8):\n",
    "        x = x_array[i*8:(i+1)*8, :, :, :]\n",
    "        y = y_array[i*8:(i+1)*8, :, :, :]\n",
    "        z = z_array[i*8:(i+1)*8, :]\n",
    "        \n",
    "        #print(x.shape, y.shape, z.shape)\n",
    "        \n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, z)\n",
    "        #print(output.shape)\n",
    "        #break\n",
    "        #print(x.data.shape, output.data.shape)\n",
    "        \n",
    "        loss = my_loss(output, y)\n",
    "        #if i % 100 == 0:\n",
    "        #    print(i, loss.data.shape, loss.item())\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        \n",
    "        #print(loss.item())\n",
    "        #optim.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(np.mean(loss_array))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    for i in range(len(x_val_array)//8):\n",
    "        x = x_val_array[i*8:(i+1)*8, :, :, :]\n",
    "        y = y_val_array[i*8:(i+1)*8, :, :, :]\n",
    "        z = z_val_array[i*8:(i+1)*8, :]\n",
    "\n",
    "        x = torch.tensor(x, device=device).float()\n",
    "        y = torch.tensor(y, device=device).float()\n",
    "        z = torch.tensor(z, device=device).float()\n",
    "\n",
    "        output = model(x, z)\n",
    "\n",
    "        loss = my_loss(output, y)\n",
    "        loss_array.append(loss.item())\n",
    "    \n",
    "    val_loss = np.mean(loss_array)\n",
    "    print(\"Val loss \", val_loss)\n",
    "    if val_loss < prev_min:\n",
    "        prev_min = val_loss\n",
    "        torch.save(model.state_dict(), \"unet_pytorch.pt\")\n",
    "    \n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3d002b39e8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = out1.data.cpu().numpy()\n",
    "plt.imshow(np.concatenate([valx[5, 0, :, :], t1[0 , 0, :, :]]).T, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"/media/dril/Windows/newrecon2/newrecon/pytorch1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
