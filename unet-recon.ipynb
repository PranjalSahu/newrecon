{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback, TensorBoard\n",
    "from keras import backend as keras\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wavelet_type = 'db3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 36, 28)\n",
      "(26, 54, 34)\n",
      "(26, 54, 34)\n",
      "(350, 804, 480)\n"
     ]
    }
   ],
   "source": [
    "# Do reconstruction after doing the wavelet replacement\n",
    "\n",
    "ypred = model.predict(xtest)\n",
    "ypred = np.reshape(ypred[0, :, :, :, 0], [60, 36, 28])\n",
    "ypred = ypred*100.0\n",
    "print(ypred.shape)\n",
    "\n",
    "ccpred    = ytest[0]\n",
    "temp      = ypred[3:-3, 1:-1, 1:-1]\n",
    "temp      = np.moveaxis(temp, [2, 0, 1], [0, 1, 2])\n",
    "print(temp.shape)\n",
    "ccpred[0] = temp\n",
    "\n",
    "print(ccpred[0].shape)\n",
    "\n",
    "newvol    = pywt.waverecn(ccpred, wavelet_type)\n",
    "print(newvol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doing it in loop for all the dataset\n",
    "\n",
    "path1 = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/duke_phantom/25_proj_wave_full_resolution_6_iterations/'\n",
    "path2 = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/duke_phantom/25_proj_pred_full_resolution/'\n",
    "\n",
    "wavelet_type = 'db3'\n",
    "\n",
    "for i in range(1, 177):\n",
    "    print(i)\n",
    "    \n",
    "    xtest        = []\n",
    "    ytest        = []\n",
    "    \n",
    "    path = path1+str(i)+'.mat'\n",
    "    a    = hdf5storage.loadmat(path)\n",
    "    a    = a['recSART_all']\n",
    "    \n",
    "    vol          = np.reshape(a[5, :, :, :], [350, 804, 480])\n",
    "    cc25         = pywt.wavedecn(vol, wavelet_type, mode='symmetric', level=4)\n",
    "    ytest.append(cc25)\n",
    "\n",
    "    vol         = np.moveaxis(cc25[0], [0, 1, 2], [2, 0, 1])\n",
    "\n",
    "    xtest.append(vol)\n",
    "    xtest = np.array(xtest)\n",
    "\n",
    "    xtest = (xtest-20)/20.0\n",
    "    #xtest = xtest/100.0\n",
    "    xtest = np.expand_dims(xtest, axis=4)\n",
    "    xtest = np.pad(xtest, ((0,0), (3, 3), (1, 1), (1, 1), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "    \n",
    "    ypred = model.predict(xtest)\n",
    "    ypred = np.reshape(ypred[0, :, :, :, 0], [60, 36, 28])\n",
    "    #ypred = ypred*100.0\n",
    "    ypred = ypred*30+30\n",
    "\n",
    "    ccpred    = ytest[0]\n",
    "    temp      = ypred[3:-3, 1:-1, 1:-1]\n",
    "    temp      = np.moveaxis(temp, [2, 0, 1], [0, 1, 2])\n",
    "    ccpred[0] = temp\n",
    "    \n",
    "    newvol    = pywt.waverecn(ccpred, wavelet_type)\n",
    "    \n",
    "    savepath  = path2+str(i)+'.npy'\n",
    "    np.save(savepath, newvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For testing the result images\n",
    "\n",
    "index  = 120\n",
    "t1 = np.reshape(newvol[index, :, :], [804, 480])\n",
    "t2 = np.reshape(vol65[index, :, :], [804, 480])\n",
    "t3 = np.reshape(vol25[index, :, :], [804, 480])\n",
    "t4 = np.reshape(vol_replace[index, :, :], [804, 480])\n",
    "\n",
    "#image = np.concatenate((t1, t2, t3), axis=1)\n",
    "image = np.concatenate((t3, t1, t4, t2), axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 80))\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "#db3 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For testing the result iamge\n",
    "index  = 540\n",
    "t1 = np.reshape(newvol[:, index, :], [350, 480])\n",
    "t2 = np.reshape(vol65[:, index, :], [350, 480])\n",
    "t3 = np.reshape(vol25[:, index, :], [350, 480])\n",
    "t4 = np.reshape(vol_replace[:, index, :], [350, 480])\n",
    "\n",
    "#image = np.concatenate((t1, t2, t3), axis=1)\n",
    "image = np.concatenate((t3, t1, t4, t2), axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 80))\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "#db3 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savepath = '/media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3d U-net model\n",
    "\n",
    "def unet_3d_prelu_cond(input_size = (60, 36, 28, 1)):\n",
    "    filter0 = 16\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    \n",
    "    inputs   = Input(input_size)\n",
    "    \n",
    "    #class_variable  = Input(shape=(1,)) \n",
    "    #class_v1 = Embedding(3, 128)(class_v)\n",
    "    #class_v1 = Flatten()(class_v1)\n",
    "    #class_variable = Dense(1, input_shape=(128, ), activation='relu')(class_v1)\n",
    "    \n",
    "    conv0 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    #conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    #conv0_ones = Lambda(lambda x: K.ones_like(x, dtype='float32'))(conv0)\n",
    "    #conv0_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(conv0_ones)\n",
    "    #conv0_cond = concatenate([conv0, conv0_cond])\n",
    "    \n",
    "    conv0 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    #conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    #conv0_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(conv0)\n",
    "    #conv0_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(conv0_ones)\n",
    "    #conv0_cond = concatenate([conv0, conv0_cond])\n",
    "        \n",
    "    conv1 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    #conv1 = Dropout(0.1)(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    \n",
    "    #pool1_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(pool1)\n",
    "    #pool1_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(pool1_ones)\n",
    "    #pool1_cond = concatenate([pool1, pool1_cond])\n",
    "    \n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    #conv2 = Dropout(0.1)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    \n",
    "    #pool2_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(pool2)\n",
    "    #pool2_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(pool2_ones)\n",
    "    \n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    #conv3 = Dropout(0.1)(conv3)\n",
    "        \n",
    "    up6 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv3))\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    up6 = ReLU()(up6)\n",
    "    #up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    #up6_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(up6)\n",
    "    #up6_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(up6_ones)\n",
    "    \n",
    "    merge6   = Add()([up6,conv2]) #concatenate([, up6_cond])\n",
    "    \n",
    "    conv6 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    up7 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv6))\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    up7 = ReLU()(up7)\n",
    "    #up7 = Dropout(0.1)(up7)\n",
    "    \n",
    "    #up7_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(up7)\n",
    "    #up7_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(up7_ones)\n",
    "    \n",
    "    merge7   = Add()([up7, conv1])#concatenate([, up7_cond])\n",
    "    \n",
    "    conv6 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "\n",
    "    #conv6_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(conv6)\n",
    "    #conv6_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(conv6_ones)\n",
    "    \n",
    "    conv6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    #conv6_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(conv6)\n",
    "    #conv6_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(conv6_ones)\n",
    "                                                                                    \n",
    "    conv6 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = PReLU()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    #conv6_ones = Lambda(lambda x: tf.ones_like(x, dtype='float32'))(conv6)\n",
    "    #conv6_cond = Lambda(lambda x: tf.multiply(class_variable[:, None, None ,None], x))(conv6_ones)\n",
    "                                                                                   \n",
    "    conv6 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    #conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = PReLU()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv9 = PReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'mean_absolute_error', metrics = ['mae'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    #if(pretrained_weights):\n",
    "    #    model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu(input_size = (60, 36, 28, 1)):\n",
    "    filter0 = 32\n",
    "    filter1 = 64\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv0 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    conv0 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    \n",
    "    #conv1 = Conv3D(32, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    #conv1 = BatchNormalization()(conv1)\n",
    "    #conv1 = ReLU()(conv1)\n",
    "    #conv1 = Dropout(0.25)(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    \n",
    "    \n",
    "#     conv2 = Conv3D(64, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "#     conv2 = ReLU()(conv2)\n",
    "#     conv2 = Dropout(0.25)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.1)(conv3)\n",
    "    \n",
    "#     conv3 = Conv3D(256, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "#     conv3 = BatchNormalization()(conv3)\n",
    "#     conv3 = ReLU()(conv3)\n",
    "#     conv3 = Dropout(0.25)(conv3)\n",
    "    \n",
    "    up6 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv3))\n",
    "    up6 = ReLU()(up6)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    merge6 = concatenate([up6, conv2])\n",
    "    \n",
    "    conv6 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    up7 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv6))\n",
    "    up7 = ReLU()(up7)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    up7 = Dropout(0.1)(up7)\n",
    "    \n",
    "    merge7 = concatenate([up7, conv1])\n",
    "    \n",
    "    conv6 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "\n",
    "    conv6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv6 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv6 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    #if(pretrained_weights):\n",
    "    #    model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the Training Data\n",
    "\n",
    "startnum = 0;\n",
    "\n",
    "xpath         = '/home/dril/dbt_recon/WAVEDEC4_VOLUMES/50_proj_wave_4/'\n",
    "y_100_path    = '/home/dril/dbt_recon/WAVEDEC4_VOLUMES/100_proj_wave_4/'\n",
    "y_130_path    = '/home/dril/dbt_recon/WAVEDEC4_VOLUMES/130_proj_wave_4/'\n",
    "y_180_path    = '/home/dril/dbt_recon/WAVEDEC4_VOLUMES/180_proj_wave_4/'\n",
    "\n",
    "samples          = 176\n",
    "validate_samples = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#t    = np.array(range(samples))\n",
    "#perm = np.random.permutation(len(t))\n",
    "#np.save('perm.npy', perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perm = np.load('perm.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 60, 36, 28, 1)\n",
      "(352, 60, 36, 28, 1)\n",
      "(352, 60, 36, 28, 1)\n",
      "(352, 60, 36, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# For reading the training data and doing some preproscessing\n",
    "\n",
    "xtrain       = []\n",
    "x_cond_train = []\n",
    "\n",
    "y_100_train = []\n",
    "y_130_train = []\n",
    "y_180_train = []\n",
    "\n",
    "tmax1_a = []\n",
    "tmax2_a = []\n",
    "\n",
    "# Reading the data in loop\n",
    "for k in range(samples):\n",
    "    i = perm[k]+1\n",
    "    \n",
    "    x = loadmat(xpath+str(startnum+i)+'.mat')\n",
    "    x = x['recSART_all']\n",
    "    for j in range(10, 12): # only considering after the first 10 iterations\n",
    "        xt = x[j, :, :, :]\n",
    "        xt = np.moveaxis(xt, [0, 1, 2], [2, 0, 1])\n",
    "        tmax1 = np.max(xt)\n",
    "        xt   = (xt-10)/20.0\n",
    "        tmax1_a.append(tmax1)\n",
    "        xtrain.append(xt)\n",
    "    \n",
    "    x = loadmat(y_180_path+str(startnum+i)+'.mat')\n",
    "    x = x['img']\n",
    "    x = np.moveaxis(x, [0, 1, 2], [2, 0, 1])\n",
    "    x = (x-15)/30.0\n",
    "    for j in range(2):\n",
    "        y_180_train.append(x)\n",
    "    \n",
    "    x = loadmat(y_130_path+str(startnum+i)+'.mat')\n",
    "    x = x['recSART_all']\n",
    "    x = np.moveaxis(x, [0, 1, 2], [2, 0, 1])\n",
    "    x = (x-15)/30.0\n",
    "    for j in range(2):\n",
    "        y_130_train.append(x)\n",
    "    \n",
    "    x = loadmat(y_100_path+str(startnum+i)+'.mat')\n",
    "    x = x['recSART_all']\n",
    "    x = np.moveaxis(x, [0, 1, 2], [2, 0, 1])\n",
    "    x = (x-15)/30.0\n",
    "    for j in range(2):\n",
    "        y_100_train.append(x)\n",
    "    \n",
    "\n",
    "xtrain      = np.array(xtrain)\n",
    "y_100_train = np.array(y_100_train)\n",
    "y_130_train = np.array(y_130_train)\n",
    "y_180_train = np.array(y_180_train)\n",
    "\n",
    "xtrain      = np.expand_dims(xtrain, axis=4)\n",
    "y_100_train = np.expand_dims(y_100_train, axis=4)\n",
    "y_130_train = np.expand_dims(y_130_train, axis=4)\n",
    "y_180_train = np.expand_dims(y_180_train, axis=4)\n",
    "\n",
    "xtrain       = np.pad(xtrain,      ((0,0), (3, 3), (1, 1), (1, 1), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "y_100_train  = np.pad(y_100_train, ((0,0), (3, 3), (1, 1), (1, 1), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "y_130_train  = np.pad(y_130_train, ((0,0), (3, 3), (1, 1), (1, 1), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "y_180_train  = np.pad(y_180_train, ((0,0), (3, 3), (1, 1), (1, 1), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "#print(xtrain.shape)\n",
    "#xtrain_v      = xtrain[-70:, :, :, :, :]\n",
    "#y_100_train_v = y_100_train[-70:, :, :, :, :] \n",
    "#y_130_train_v = y_130_train[-70:, :, :, :, :]\n",
    "#y_180_train_v = y_180_train[-70:, :, :, :, :]\n",
    "\n",
    "#xtrain      = xtrain[:-70, :, :, :, :]\n",
    "#y_100_train = y_100_train[:-70, :, :, :, :]\n",
    "#y_130_train = y_130_train[:-70, :, :, :, :]\n",
    "#y_180_train = y_180_train[:-70, :, :, :, :]\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(y_100_train.shape)\n",
    "print(y_130_train.shape)\n",
    "print(y_180_train.shape)\n",
    "\n",
    "#print(xtrain_v.shape)\n",
    "#print(y_100_train_v.shape)\n",
    "#print(y_130_train_v.shape)\n",
    "#print(y_180_train_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846,)\n",
      "(846, 60, 36, 28, 1)\n",
      "(846, 60, 36, 28, 1)\n",
      "(210,)\n",
      "(210, 60, 36, 28, 1)\n",
      "(210, 60, 36, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# For generating the conditioning variables\n",
    "\n",
    "x_cond_train = np.concatenate((np.ones(len(xtrain))*0.25, np.ones(len(xtrain))*0.5, np.ones(len(xtrain))*1), axis=0)\n",
    "xtrain       = np.concatenate((xtrain, xtrain, xtrain), axis=0)\n",
    "ytrain       = np.concatenate((y_100_train, y_130_train, y_180_train), axis=0)\n",
    "\n",
    "x_cond_train_v = np.concatenate((np.ones(len(xtrain_v))*0.25, np.ones(len(xtrain_v))*0.5, np.ones(len(xtrain_v))*1), axis=0)\n",
    "xtrain_v       = np.concatenate((xtrain_v, xtrain_v, xtrain_v), axis=0)\n",
    "ytrain_v       = np.concatenate((y_100_train_v, y_130_train_v, y_180_train_v), axis=0)\n",
    "\n",
    "\n",
    "print(x_cond_train.shape)\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "print(x_cond_train_v.shape)\n",
    "print(xtrain_v.shape)\n",
    "print(ytrain_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     6
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For storing the results\n",
    "\n",
    "image_indexes_result      = []\n",
    "temp_image_indexes_result = []\n",
    "slice_indexes_result      = []\n",
    "\n",
    "def store_results(epoch, x, y, model, saveseed=5):\n",
    "    global image_indexes_result\n",
    "    global slice_indexes_result\n",
    "    global temp_image_indexes_result\n",
    "    \n",
    "    imgshape = 200\n",
    "    \n",
    "    r, c = 6, 6\n",
    "    \n",
    "    #random.seed(saveseed)\n",
    "    \n",
    "    #plt.subplots_adjust(top=0.92, bottom=0.38, left=0.40, right=0.75)\n",
    "    #plt.tight_layout()\n",
    "    fig, axs = plt.subplots(r, c, figsize=(90,30))\n",
    "    cnt      = 0\n",
    "    \n",
    "    cleanimg = model.predict(x, batch_size=4)\n",
    "    \n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if len(image_indexes_result) == 0:\n",
    "                imgindex   = random.randint(1, 68)\n",
    "                sliceindex = random.randint(30, 40)\n",
    "                \n",
    "                temp_image_indexes_result.append(imgindex)\n",
    "                slice_indexes_result.append(sliceindex)\n",
    "            else:\n",
    "                imgindex   = image_indexes_result[cnt]\n",
    "                sliceindex = slice_indexes_result[cnt]\n",
    "            \n",
    "            combined = np.array([x[imgindex, sliceindex, :, :, 0], cleanimg[imgindex, sliceindex, :, :, 0], y[imgindex, sliceindex, :, :, 0]])\n",
    "            combined = np.hstack(combined.reshape(3, 36, 28))\n",
    "            \n",
    "            axs[i,j].imshow(combined, cmap='gray')\n",
    "            axs[i, j].set_xticklabels([])\n",
    "            axs[i, j].set_yticklabels([])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    \n",
    "    if len(image_indexes_result) == 0:\n",
    "        image_indexes_result = temp_image_indexes_result\n",
    "    \n",
    "    #print(temp_image_indexes_result)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    \n",
    "    print('saving image ', savepath)\n",
    "    fig.savefig(savepath+\"clean_%d.png\" % epoch, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Callback for storing results\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        if epoch%10 == 0:\n",
    "            store_results(epoch, x, y, self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dril/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"p_...)`\n"
     ]
    }
   ],
   "source": [
    "model = unet_3d_prelu_cond()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow time  1561178567.360167\n"
     ]
    }
   ],
   "source": [
    "# For checkpoint\n",
    "\n",
    "checkpoint  = ModelCheckpoint(monitor='val_loss', verbose=1, filepath='/home/dril/SummerWork/new_norm_test1.h5', period=10)\n",
    "reduce_lr   = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5, min_lr=0.000001)\n",
    "t = time.time()\n",
    "print('Tensorflow time ', t)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(t))\n",
    "#tensorboard = TensorBoard(log_dir=\"logs/1551025594.89692\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('cond_model_small_prelu_l1_1561092785.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 281 samples, validate on 71 samples\n",
      "Epoch 1/10000\n",
      "281/281 [==============================] - 14s 50ms/step - loss: 0.3970 - mean_absolute_error: 0.3970 - val_loss: 0.3465 - val_mean_absolute_error: 0.3465\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 2/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.3168 - mean_absolute_error: 0.3168 - val_loss: 0.3096 - val_mean_absolute_error: 0.3096\n",
      "Epoch 3/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.3029 - val_mean_absolute_error: 0.3029\n",
      "Epoch 4/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.3038 - mean_absolute_error: 0.3038 - val_loss: 0.3002 - val_mean_absolute_error: 0.3002\n",
      "Epoch 5/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.2954 - mean_absolute_error: 0.2954 - val_loss: 0.2965 - val_mean_absolute_error: 0.2965\n",
      "Epoch 6/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.2771 - mean_absolute_error: 0.2771 - val_loss: 0.2635 - val_mean_absolute_error: 0.2635\n",
      "Epoch 7/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.2358 - mean_absolute_error: 0.2358 - val_loss: 0.1935 - val_mean_absolute_error: 0.1935\n",
      "Epoch 8/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.1404 - mean_absolute_error: 0.1404 - val_loss: 0.1640 - val_mean_absolute_error: 0.1640\n",
      "\n",
      "Epoch 00008: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 9/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.1432 - val_mean_absolute_error: 0.1432\n",
      "Epoch 10/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0562 - mean_absolute_error: 0.0562 - val_loss: 0.1232 - val_mean_absolute_error: 0.1232\n",
      "Epoch 11/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0508 - mean_absolute_error: 0.0508 - val_loss: 0.0948 - val_mean_absolute_error: 0.0948\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 12/10000\n",
      "281/281 [==============================] - 13s 47ms/step - loss: 0.0473 - mean_absolute_error: 0.0473 - val_loss: 0.0825 - val_mean_absolute_error: 0.0825\n",
      "Epoch 13/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0444 - mean_absolute_error: 0.0444 - val_loss: 0.0643 - val_mean_absolute_error: 0.0643\n",
      "Epoch 14/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0412 - mean_absolute_error: 0.0412 - val_loss: 0.0588 - val_mean_absolute_error: 0.0588\n",
      "Epoch 15/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0396 - mean_absolute_error: 0.0396 - val_loss: 0.0522 - val_mean_absolute_error: 0.0522\n",
      "Epoch 16/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0382 - mean_absolute_error: 0.0382 - val_loss: 0.0481 - val_mean_absolute_error: 0.0481\n",
      "Epoch 17/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0376 - mean_absolute_error: 0.0376 - val_loss: 0.0422 - val_mean_absolute_error: 0.0422\n",
      "Epoch 18/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0368 - mean_absolute_error: 0.0368 - val_loss: 0.0436 - val_mean_absolute_error: 0.0436\n",
      "\n",
      "Epoch 00018: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 19/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0349 - mean_absolute_error: 0.0349 - val_loss: 0.0447 - val_mean_absolute_error: 0.0447\n",
      "Epoch 20/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0343 - mean_absolute_error: 0.0343 - val_loss: 0.0444 - val_mean_absolute_error: 0.0444\n",
      "Epoch 21/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0412 - val_mean_absolute_error: 0.0412\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 22/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0381 - val_mean_absolute_error: 0.0381\n",
      "Epoch 23/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
      "Epoch 24/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0337 - val_mean_absolute_error: 0.0337\n",
      "Epoch 25/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0343 - val_mean_absolute_error: 0.0343\n",
      "Epoch 26/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0298 - mean_absolute_error: 0.0298 - val_loss: 0.0350 - val_mean_absolute_error: 0.0350\n",
      "Epoch 27/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0294 - mean_absolute_error: 0.0294 - val_loss: 0.0358 - val_mean_absolute_error: 0.0358\n",
      "Epoch 28/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0296 - mean_absolute_error: 0.0296 - val_loss: 0.0350 - val_mean_absolute_error: 0.0350\n",
      "\n",
      "Epoch 00028: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 29/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0297 - mean_absolute_error: 0.0297 - val_loss: 0.0335 - val_mean_absolute_error: 0.0335\n",
      "Epoch 30/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0276 - mean_absolute_error: 0.0276 - val_loss: 0.0324 - val_mean_absolute_error: 0.0324\n",
      "Epoch 31/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0276 - mean_absolute_error: 0.0276 - val_loss: 0.0333 - val_mean_absolute_error: 0.0333\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 32/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0271 - mean_absolute_error: 0.0271 - val_loss: 0.0317 - val_mean_absolute_error: 0.0317\n",
      "Epoch 33/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0268 - mean_absolute_error: 0.0268 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 34/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0271 - mean_absolute_error: 0.0271 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
      "Epoch 35/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0269 - mean_absolute_error: 0.0269 - val_loss: 0.0323 - val_mean_absolute_error: 0.0323\n",
      "Epoch 36/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0259 - mean_absolute_error: 0.0259 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 37/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0265 - mean_absolute_error: 0.0265 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 38/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0253 - mean_absolute_error: 0.0253 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "\n",
      "Epoch 00038: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 39/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0254 - mean_absolute_error: 0.0254 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 40/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0250 - mean_absolute_error: 0.0250 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 41/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0251 - mean_absolute_error: 0.0251 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 42/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0243 - mean_absolute_error: 0.0243 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
      "Epoch 43/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0240 - mean_absolute_error: 0.0240 - val_loss: 0.0286 - val_mean_absolute_error: 0.0286\n",
      "Epoch 44/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0238 - mean_absolute_error: 0.0238 - val_loss: 0.0278 - val_mean_absolute_error: 0.0278\n",
      "Epoch 45/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0241 - mean_absolute_error: 0.0241 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
      "Epoch 46/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0237 - mean_absolute_error: 0.0237 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
      "Epoch 47/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0237 - mean_absolute_error: 0.0237 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
      "Epoch 48/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0233 - mean_absolute_error: 0.0233 - val_loss: 0.0266 - val_mean_absolute_error: 0.0266\n",
      "\n",
      "Epoch 00048: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 49/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0230 - mean_absolute_error: 0.0230 - val_loss: 0.0279 - val_mean_absolute_error: 0.0279\n",
      "Epoch 50/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0232 - mean_absolute_error: 0.0232 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
      "Epoch 51/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0233 - mean_absolute_error: 0.0233 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 52/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0228 - mean_absolute_error: 0.0228 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
      "Epoch 53/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0226 - mean_absolute_error: 0.0226 - val_loss: 0.0279 - val_mean_absolute_error: 0.0279\n",
      "Epoch 54/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0221 - mean_absolute_error: 0.0221 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 55/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0220 - mean_absolute_error: 0.0220 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
      "Epoch 56/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0222 - mean_absolute_error: 0.0222 - val_loss: 0.0252 - val_mean_absolute_error: 0.0252\n",
      "Epoch 57/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0221 - mean_absolute_error: 0.0221 - val_loss: 0.0265 - val_mean_absolute_error: 0.0265\n",
      "Epoch 58/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0215 - mean_absolute_error: 0.0215 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
      "\n",
      "Epoch 00058: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 59/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0215 - mean_absolute_error: 0.0215 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 60/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0223 - mean_absolute_error: 0.0223 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
      "Epoch 61/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0218 - mean_absolute_error: 0.0218 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 62/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0218 - mean_absolute_error: 0.0218 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
      "Epoch 63/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
      "Epoch 64/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 65/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0210 - mean_absolute_error: 0.0210 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
      "Epoch 66/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0214 - mean_absolute_error: 0.0214 - val_loss: 0.0254 - val_mean_absolute_error: 0.0254\n",
      "Epoch 67/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0248 - val_mean_absolute_error: 0.0248\n",
      "Epoch 68/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0208 - mean_absolute_error: 0.0208 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "\n",
      "Epoch 00068: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 69/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 70/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0252 - val_mean_absolute_error: 0.0252\n",
      "Epoch 71/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 72/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0252 - val_mean_absolute_error: 0.0252\n",
      "Epoch 73/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0240 - val_mean_absolute_error: 0.0240\n",
      "Epoch 74/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "Epoch 75/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 76/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
      "Epoch 77/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0241 - val_mean_absolute_error: 0.0241\n",
      "Epoch 78/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
      "\n",
      "Epoch 00078: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 79/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233\n",
      "Epoch 80/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0242 - val_mean_absolute_error: 0.0242\n",
      "Epoch 81/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0196 - mean_absolute_error: 0.0196 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 82/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
      "Epoch 83/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 84/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0242 - val_mean_absolute_error: 0.0242\n",
      "Epoch 85/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 86/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
      "Epoch 87/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 88/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0241 - val_mean_absolute_error: 0.0241\n",
      "\n",
      "Epoch 00088: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 89/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0234 - val_mean_absolute_error: 0.0234\n",
      "Epoch 90/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
      "Epoch 91/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0230 - val_mean_absolute_error: 0.0230\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 92/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0238 - val_mean_absolute_error: 0.0238\n",
      "Epoch 93/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 94/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 95/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0243 - val_mean_absolute_error: 0.0243\n",
      "Epoch 96/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 97/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
      "Epoch 98/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0248 - val_mean_absolute_error: 0.0248\n",
      "\n",
      "Epoch 00098: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 99/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0238 - val_mean_absolute_error: 0.0238\n",
      "Epoch 100/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0230 - val_mean_absolute_error: 0.0230\n",
      "Epoch 101/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 102/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0242 - val_mean_absolute_error: 0.0242\n",
      "Epoch 103/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 104/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 105/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 106/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 107/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0234 - val_mean_absolute_error: 0.0234\n",
      "Epoch 108/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0239 - val_mean_absolute_error: 0.0239\n",
      "\n",
      "Epoch 00108: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 109/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0171 - mean_absolute_error: 0.0171 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 110/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "Epoch 111/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 112/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0172 - mean_absolute_error: 0.0172 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 113/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0234 - val_mean_absolute_error: 0.0234\n",
      "Epoch 114/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 115/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 116/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
      "Epoch 117/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 118/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0172 - mean_absolute_error: 0.0172 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "\n",
      "Epoch 00118: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 119/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 120/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "Epoch 121/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 122/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 123/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 124/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 125/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 126/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 127/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 128/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00128: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 129/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 130/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 131/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 132/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0167 - mean_absolute_error: 0.0167 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "Epoch 133/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 134/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 135/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 136/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
      "Epoch 137/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 138/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "\n",
      "Epoch 00138: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 139/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 140/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 141/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 142/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 143/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 144/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 145/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 146/10000\n",
      "281/281 [==============================] - 13s 47ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 147/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 148/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "\n",
      "Epoch 00148: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 149/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 150/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0155 - mean_absolute_error: 0.0155 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 151/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 152/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 153/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 154/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 155/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0153 - mean_absolute_error: 0.0153 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 156/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 157/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0155 - mean_absolute_error: 0.0155 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 158/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "\n",
      "Epoch 00158: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 159/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0153 - mean_absolute_error: 0.0153 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 160/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "Epoch 161/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 162/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 163/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 164/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 165/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "Epoch 166/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 167/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0153 - mean_absolute_error: 0.0153 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 168/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "\n",
      "Epoch 00168: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 169/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0149 - mean_absolute_error: 0.0149 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 170/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "Epoch 171/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 172/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 173/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 174/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 175/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 176/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 177/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 178/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0149 - mean_absolute_error: 0.0149 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "\n",
      "Epoch 00178: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 179/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 180/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 181/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0148 - mean_absolute_error: 0.0148 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 182/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 183/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 184/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 185/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 186/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 187/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233\n",
      "Epoch 188/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00188: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 189/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "Epoch 190/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 191/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 192/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0152 - mean_absolute_error: 0.0152 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 193/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 194/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 195/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 196/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 197/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 198/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00198: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 199/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 200/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 201/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 202/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 203/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 204/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 205/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 206/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 207/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 208/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "\n",
      "Epoch 00208: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 209/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 210/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 211/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 212/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 213/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 214/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0137 - mean_absolute_error: 0.0137 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 215/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0137 - mean_absolute_error: 0.0137 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 216/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 217/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 218/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00218: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 219/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 220/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 221/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 222/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 223/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 224/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 225/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 226/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 227/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 228/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "\n",
      "Epoch 00228: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 229/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 230/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 231/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 232/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 233/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 234/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 235/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 236/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0131 - mean_absolute_error: 0.0131 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 237/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0137 - mean_absolute_error: 0.0137 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 238/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "\n",
      "Epoch 00238: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 239/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 240/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 241/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 242/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 243/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 244/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0131 - mean_absolute_error: 0.0131 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 245/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0131 - mean_absolute_error: 0.0131 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 246/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 247/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 248/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00248: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 249/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 250/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 251/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 252/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 253/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 254/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 255/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 256/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 257/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 258/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "\n",
      "Epoch 00258: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 259/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 260/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 261/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 262/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 263/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 264/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 265/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 266/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 267/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 268/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "\n",
      "Epoch 00268: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 269/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 270/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 271/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 272/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 273/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 274/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 275/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 276/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 277/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 278/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00278: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 279/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 280/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 281/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 282/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 283/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 284/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 285/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 286/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 287/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 288/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "\n",
      "Epoch 00288: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 289/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 290/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 291/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 292/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 293/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 294/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 295/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 296/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 297/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 298/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00298: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 299/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 300/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 301/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 302/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 303/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 304/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 305/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 307/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 308/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "\n",
      "Epoch 00308: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 309/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 310/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 311/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 312/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 313/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 314/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 315/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 316/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 317/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 318/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "\n",
      "Epoch 00318: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 319/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 320/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 321/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 322/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 323/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 324/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 325/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 326/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 327/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 328/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00328: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 329/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 330/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 331/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 332/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 333/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "Epoch 334/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "Epoch 335/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 336/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 337/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 338/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "\n",
      "Epoch 00338: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 339/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 340/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 341/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 342/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 343/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 344/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 345/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 346/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 347/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 348/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00348: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 349/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 350/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 351/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 352/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 353/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 354/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 355/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 356/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 357/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 358/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00358: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 359/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 360/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 361/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 362/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 363/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 364/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 365/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 366/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 367/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 368/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00368: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 369/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 370/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 371/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 372/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 373/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 374/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 375/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "Epoch 376/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 377/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 378/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00378: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 379/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 380/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 381/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 382/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 383/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 384/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 385/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 386/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 387/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 388/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "\n",
      "Epoch 00388: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 389/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 390/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 391/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 392/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 393/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 394/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "Epoch 395/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 396/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 397/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 398/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "\n",
      "Epoch 00398: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 399/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 400/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 401/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 402/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 403/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 404/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 405/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 406/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 407/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 408/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00408: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 409/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 410/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 411/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 412/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 413/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 414/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 415/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 416/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 417/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 418/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00418: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 419/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 420/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 421/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 422/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 423/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 424/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 425/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 426/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 427/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 428/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00428: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 429/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 430/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 431/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 432/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 433/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 434/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 435/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 436/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 437/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 438/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00438: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 439/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 440/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 441/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 442/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 443/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 444/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 445/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 446/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 447/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 448/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "\n",
      "Epoch 00448: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 449/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 450/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 451/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 452/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 453/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 454/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "Epoch 455/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 456/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 457/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 458/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "\n",
      "Epoch 00458: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 459/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 460/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0236 - val_mean_absolute_error: 0.0236\n",
      "Epoch 461/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 462/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 463/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 464/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 465/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 466/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 467/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 468/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00468: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 469/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 470/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 471/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 472/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 473/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 474/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 475/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 476/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 477/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 478/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00478: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 479/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 480/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 481/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 482/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 483/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 484/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 485/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 486/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 487/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 488/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "\n",
      "Epoch 00488: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 489/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 490/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 491/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 492/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 493/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 494/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 495/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 496/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 497/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 498/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00498: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 499/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 500/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 501/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 502/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 503/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 504/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 505/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 506/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 507/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 508/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00508: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 509/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 510/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 511/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 512/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 513/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 514/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 515/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 516/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 517/10000\n",
      "281/281 [==============================] - 13s 48ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 518/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00518: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 519/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 520/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 521/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 522/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 523/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 524/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 525/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 526/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 527/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 528/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00528: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 529/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 530/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 531/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 532/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 533/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 534/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 535/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 536/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 537/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 538/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00538: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 539/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 540/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 541/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 542/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 543/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 544/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 545/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 546/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 547/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 548/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "\n",
      "Epoch 00548: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 549/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 550/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 551/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 552/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 553/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 554/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 555/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 556/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 557/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 558/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00558: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 559/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 560/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 561/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 562/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 563/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 564/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 565/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 566/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 567/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 568/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "\n",
      "Epoch 00568: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 569/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 570/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 571/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 572/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 573/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 574/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 575/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 576/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 577/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 578/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00578: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 579/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 580/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 581/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 582/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 583/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 584/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 585/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 586/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 587/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 588/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00588: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 589/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 590/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 591/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 592/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 593/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 594/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 595/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 596/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 597/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 598/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00598: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 599/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 600/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 601/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 602/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 603/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 604/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 605/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 606/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 607/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 608/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00608: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 609/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 610/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 611/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 612/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 613/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 614/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 615/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 616/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 617/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 618/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00618: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 619/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 620/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 621/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 622/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 623/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 624/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 625/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 626/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 627/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 628/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "\n",
      "Epoch 00628: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 629/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "Epoch 630/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 631/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 632/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 633/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 634/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 635/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 636/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 637/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 638/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00638: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 639/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 640/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 641/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 642/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 643/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 644/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 645/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 646/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 647/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 648/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00648: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 649/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 650/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 651/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 652/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 653/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 654/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 655/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 656/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 657/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 658/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "\n",
      "Epoch 00658: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 659/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 660/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 661/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 662/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 663/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 664/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 665/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 666/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 667/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 668/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "\n",
      "Epoch 00668: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 669/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 670/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 671/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 672/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 673/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 674/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 675/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 676/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 677/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 678/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00678: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 679/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 680/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 681/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 682/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 683/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 684/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 685/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 686/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 687/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 688/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "\n",
      "Epoch 00688: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 689/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 690/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 691/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 692/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 693/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 694/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 695/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 696/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 697/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 698/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00698: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 699/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 700/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 701/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 702/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 703/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 704/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 705/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 706/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 707/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 708/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00708: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 709/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 710/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 711/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 712/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 713/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 714/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 715/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 716/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 717/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 718/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00718: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 719/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 720/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 721/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 722/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 723/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 724/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 725/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 726/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 727/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 728/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00728: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 729/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 730/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 731/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 732/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 733/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 734/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 735/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 736/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 737/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 738/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "\n",
      "Epoch 00738: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 739/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 740/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 741/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 742/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 743/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 744/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 745/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 746/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 747/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 748/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "\n",
      "Epoch 00748: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 749/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 750/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "Epoch 751/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 752/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 753/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 754/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 755/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 756/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 757/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 758/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00758: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 759/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 760/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 761/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 762/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 763/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 764/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 765/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 766/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 767/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 768/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00768: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 769/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 770/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 771/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 772/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 773/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 774/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 775/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 776/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 777/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 778/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00778: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 779/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 780/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 781/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 782/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 783/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 784/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 785/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 786/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 787/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 788/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00788: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 789/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 790/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 791/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 792/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 793/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 794/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 795/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 796/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 797/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 798/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "\n",
      "Epoch 00798: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 799/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 800/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 801/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 802/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 803/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 804/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 805/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 806/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 807/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 808/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "\n",
      "Epoch 00808: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 809/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 810/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 811/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 812/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 813/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 814/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 815/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 816/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 817/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244\n",
      "Epoch 818/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00818: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 819/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 820/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 821/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 822/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 823/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 824/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 825/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 826/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 827/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 828/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "\n",
      "Epoch 00828: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 829/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 830/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 831/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 832/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 833/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 834/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 835/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 836/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 837/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 838/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00838: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 839/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 840/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 841/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 842/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 843/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 844/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 845/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 846/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 847/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 848/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "\n",
      "Epoch 00848: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 849/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 850/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 851/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 852/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 853/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 854/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 855/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 856/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 857/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 858/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "\n",
      "Epoch 00858: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 859/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 860/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 861/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 862/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 863/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 864/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 865/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 866/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 867/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 868/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "\n",
      "Epoch 00868: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 869/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 870/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 871/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 872/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 873/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 874/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 875/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 876/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 877/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 878/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "\n",
      "Epoch 00878: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 879/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 880/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 881/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 882/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 883/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 884/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 885/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 886/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 887/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 888/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00888: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 889/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 890/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 891/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 892/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 893/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 894/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 895/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 896/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 897/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 898/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "\n",
      "Epoch 00898: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 899/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 900/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 901/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 902/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 903/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 904/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 905/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 906/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 907/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 908/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "\n",
      "Epoch 00908: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 909/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 910/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 911/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 912/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 913/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 914/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 915/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 916/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 917/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 918/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "\n",
      "Epoch 00918: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 919/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 920/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 921/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 922/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 923/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 924/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 925/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 926/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 927/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 928/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00928: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 929/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 930/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 931/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 932/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 933/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 934/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 935/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 936/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 937/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 938/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00938: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 939/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 940/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 941/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 942/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 943/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 944/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 945/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 946/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 947/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 948/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "\n",
      "Epoch 00948: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 949/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 950/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 951/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 952/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 953/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 954/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 955/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 956/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 957/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 958/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00958: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 959/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 960/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 961/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 962/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 963/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 964/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 965/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 966/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 967/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 968/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "\n",
      "Epoch 00968: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 969/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 970/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 971/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 972/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 973/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 974/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 975/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 976/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 977/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 978/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00978: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 979/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 980/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 981/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 982/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 983/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 984/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 985/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 986/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 987/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 988/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00988: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 989/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 990/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 991/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 992/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 993/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 994/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 995/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 996/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 997/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 998/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
      "\n",
      "Epoch 00998: saving model to /home/dril/SummerWork/cascade1.h5\n",
      "Epoch 999/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 1000/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 1001/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "saving image  /media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/new_norm_test1/\n",
      "Epoch 1002/10000\n",
      "281/281 [==============================] - 13s 45ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 1003/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 1004/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 1005/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 1006/10000\n",
      "281/281 [==============================] - 13s 46ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 1007/10000\n",
      " 30/281 [==>...........................] - ETA: 10s - loss: 0.0081 - mean_absolute_error: 0.0081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4cb965c120a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#model.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/models_small3/duke_model_small3.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_180_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "\n",
    "#from np.random import permutation\n",
    "\n",
    "#perm = np.random.permutation(len(xtrain))\n",
    "#np.save('perm.npy', perm)\n",
    "\n",
    "\n",
    "#xtrain = xtrain[perm]\n",
    "#ytrain = ytrain[perm]\n",
    "ytrain = y_180_train\n",
    "\n",
    "#model.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/models_small3/duke_model_small3.h5')\n",
    "model.fit(xtrain, y_180_train, batch_size=5, epochs=10000, validation_split=0.2,  callbacks=[checkpoint, tensorboard, TestCallback((xtrain[-70:-1, :, :, :, :], ytrain[-70:-1, :, :, :, :]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/media/dril/72fd13fc-2566-4738-946e-a92bad2acf3d/dril/duke_phantom/SART/db3/models_small3/1560897401.8170357_only_relu_less_conditoning_l1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For second stage training\n",
    "\n",
    "perm       = np.load('perm.npy')\n",
    "batch_size = 12\n",
    "\n",
    "train_input_data_path = '/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/stage_two_data/train/input/'\n",
    "train_pred_data_path  = '/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/stage_two_data/train/pred/'\n",
    "\n",
    "valid_input_data_path = '/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/stage_two_data/train/input/'\n",
    "valid_pred_data_path  = '/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/stage_two_data/train/pred/'\n",
    "\n",
    "test_data_path  = '/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/stage_two_data/train/output/'\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    while True:\n",
    "        index_list  = random.sample(range(1, 140), batch_size)\n",
    "        sample_list = random.sample(range(1, 69),  batch_size)\n",
    "        \n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        \n",
    "        for k in range(len(index_list)):\n",
    "            # Read from the training set used for training the 3D CNN\n",
    "            i = perm[index_list[k]]+1\n",
    "            \n",
    "            in_data   = np.load(train_input_data_path+str(i)+'_'+str(sample_list[k])+'.npy')\n",
    "            pred_data = np.load(train_pred_data_path+str(i)+'_'+str(sample_list[k])+'.npy')\n",
    "            out_data  = np.load(test_data_path+str(i)+'_'+str(sample_list[k])+'.npy')\n",
    "            \n",
    "            a = np.concatenate((in_data, pred_data), axis=-1)\n",
    "            b = out_data\n",
    "            \n",
    "            alldata_x.append(a)\n",
    "            alldata_y.append(b)\n",
    "        \n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        #print(alldata_x.shape, alldata_y.shape)\n",
    "        yield alldata_x, alldata_y\n",
    "\n",
    "def validation_generator():\n",
    "    while True:\n",
    "        index_list  = random.sample(range(141, 175), batch_size)\n",
    "        sample_list = random.sample(range(1, 69),  batch_size)\n",
    "        \n",
    "        alldata_x = []\n",
    "        alldata_y = []\n",
    "        \n",
    "        for k in range(len(index_list)):\n",
    "            # Read from the training set used for training the 3D CNN\n",
    "            i = perm[index_list[k]]+1\n",
    "            \n",
    "            in_data   = np.load(valid_input_data_path+str(i)+'_'+str(sample_list[k])+'.npy')\n",
    "            pred_data = np.load(valid_pred_data_path+str(i)+'_'+str(sample_list[k])+'.npy')\n",
    "            out_data  = np.load(test_data_path+str(i)+'_'+str(sample_list[k])+'.npy')\n",
    "            \n",
    "            a = np.concatenate((in_data, pred_data), axis=-1)\n",
    "            b = out_data\n",
    "            \n",
    "            alldata_x.append(a)\n",
    "            alldata_y.append(b)\n",
    "        \n",
    "        alldata_x = np.array(alldata_x)\n",
    "        alldata_y = np.array(alldata_y)\n",
    "        #print(alldata_x.shape, alldata_y.shape)\n",
    "        yield alldata_x, alldata_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet_2d_prelu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow time  1551328985.776317\n"
     ]
    }
   ],
   "source": [
    "# Second stage training of model\n",
    "checkpoint  = ModelCheckpoint(filepath='/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/duke_phantom/SART/db3/models_small3/duke_model_small3_0001_second_stage.h5', monitor='val_loss', period=5, verbose=1, save_best_only=True, mode='min')\n",
    "t           = time.time()\n",
    "print('Tensorflow time ', t)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Second stage training loop\n",
    "\n",
    "model.fit_generator(train_generator(),\n",
    "                    use_multiprocessing=True,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=10000,\n",
    "                    validation_data=validation_generator(),\n",
    "                    validation_steps=20,\n",
    "                    callbacks=[checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "\n",
    "counter         = 0\n",
    "phantom_counter = 0\n",
    "\n",
    "for phantom_counter in range(220, 250):\n",
    "    print(phantom_counter)\n",
    "    for counter in range(5, 26):\n",
    "        if counter%5 == 0:\n",
    "            fname     = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/DBT_data/network-infer-volume-partial-5/'+str(phantom_counter)+'_'+str(counter)+'.mat'\n",
    "            net_fname = '/media/pranjal/2d33dff3-95f7-4dc0-9842-a9b18bcf1bf9/pranjal/DBT_data/network-infer-volume-partial-5/'+str(phantom_counter)+'_net_'+str(counter)+'.mat'\n",
    "\n",
    "            while(True):\n",
    "                if os.path.isfile(fname):\n",
    "                    try:\n",
    "                        temp = []\n",
    "                        a = sio.loadmat(fname)\n",
    "                        a = np.moveaxis(a['res_temp'], [0, 1, 2], [2, 0, 1])\n",
    "                        temp.append(a)\n",
    "                        temp = np.array(temp)\n",
    "                        temp = np.expand_dims(temp, axis=4)\n",
    "                        temp = model.predict(temp)\n",
    "                        temp = temp[0, :, :, :, 0]\n",
    "                        img = np.moveaxis(temp,  [2, 0, 1], [0, 1, 2])\n",
    "                        sio.savemat(net_fname, {'img':img})\n",
    "                        print('File created ', time.time())\n",
    "                        break\n",
    "                    except:\n",
    "                        print('File not ready yet trying again')\n",
    "                        time.sleep(5)\n",
    "                else:\n",
    "                    #print('Going to sleep')\n",
    "                    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 120, 48)\n",
      "(120, 48, 32)\n",
      "(120, 48, 32)\n",
      "(32, 120, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4341e98048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = sio.loadmat('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/DBT_recon_data/network-infer-volume/1_1.mat')\n",
    "temp = a['res_temp']\n",
    "print(temp.shape)\n",
    "temp = np.moveaxis(temp, [0, 1, 2], [2, 0, 1])\n",
    "print(temp.shape)\n",
    "tp1 = []\n",
    "tp1.append(temp)\n",
    "tp1 = np.array(tp1)\n",
    "tp1 = np.expand_dims(tp1, axis=4)\n",
    "temp = tp1[0, :, :, :, 0]\n",
    "print(temp.shape)\n",
    "temp = np.moveaxis(temp,  [2, 0, 1], [0, 1, 2])\n",
    "print(temp.shape)\n",
    "plt.imshow(temp[:, :, 24]*2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "HOST = 'localhost' \n",
    "PORT = 50007\n",
    "s    = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "s.bind((HOST, PORT))\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    s.listen(4)\n",
    "    print(\"waiting for response from client at port \",PORT)\n",
    "    (conn, (ip, port)) = s.accept()\n",
    "    \n",
    "    print('Connected by', ip)\n",
    "    print('hello')\n",
    "    \n",
    "    newthread         = ClientThread(ip, port, conn)\n",
    "    newthread.start()\n",
    "conn.close()\n",
    "\n",
    "#     data = conn.recv(1024)\n",
    "    \n",
    "#     print(data)\n",
    "    \n",
    "#     clientdata = \"hello client\".encode()\n",
    "#     conn.sendall(clientdata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import socket \n",
    "from threading import Thread \n",
    "\n",
    "# Multithreaded Python server : TCP Server Socket Thread Pool\n",
    "class ClientThread(Thread): \n",
    " \n",
    "    def __init__(self, ip, port, conn): \n",
    "        Thread.__init__(self) \n",
    "        self.ip   = ip \n",
    "        self.port = port \n",
    "        self.conn = conn\n",
    "        print(\"[+] New server socket thread started for \" + ip + \":\" + str(port))\n",
    " \n",
    "    def run(self):\n",
    "        data = self.conn.recv(2048) \n",
    "        print(\"Server received data:\", data)\n",
    "        self.conn.send(\"Message recieved\".encode())\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0,
     83
    ]
   },
   "outputs": [],
   "source": [
    "def unet_3d_ReLU_pancreas(input_size = (40, 80, 40, 1)):\n",
    "    filter0 = 64\n",
    "    filter1 = 128\n",
    "    filter2 = 256\n",
    "    filter3 = 512\n",
    "    \n",
    "    inputs          = Input(input_size)\n",
    "    #pca_mean_tensor = Input((81920,))\n",
    "    \n",
    "    conv0 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    conv1 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "        \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.1)(conv3)\n",
    "        \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "        \n",
    "    up5 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv4))\n",
    "    up5 = ReLU()(up5)\n",
    "    up5 = BatchNormalization()(up5)\n",
    "    up5 = Dropout(0.1)(up5)\n",
    "    \n",
    "    merge5 = concatenate([up5, conv3])\n",
    "    \n",
    "    up6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(merge5))\n",
    "    up6 = ReLU()(up6)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    merge6 = concatenate([up6, conv2])\n",
    "    \n",
    "    up7 = Conv3D(filter0, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(merge6))\n",
    "    up7 = ReLU()(up7)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    up7 = Dropout(0.1)(up7)\n",
    "    \n",
    "    merge7 = concatenate([up7, conv1])\n",
    "    \n",
    "    conv6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "\n",
    "    conv6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv6 = Conv3D(filter0, 3, padding = 'same',  kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', activation='sigmoid', kernel_initializer = 'he_normal')(conv6)\n",
    "    output_node      = conv9\n",
    "    model            = Model(input = inputs, output = output_node)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.01), loss = [dice_coefficient_loss], loss_weights=[1], metrics = [dice_coefficient])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def unet_3d_ReLU_pancreas_multi(input_size = (80, 160, 80, 1)):\n",
    "    filter0 = 8\n",
    "    filter1 = 16\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    \n",
    "    inputs          = Input(input_size)\n",
    "    #pca_mean_tensor = Input((81920,))\n",
    "    \n",
    "    conv0 = Conv3D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    #conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    #conv1 = Dropout(0.1)(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    #conv2 = Dropout(0.1)(conv2)\n",
    "        \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    #conv3 = Dropout(0.1)(conv3)\n",
    "        \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "        \n",
    "    up5 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv4))\n",
    "    up5 = ReLU()(up5)\n",
    "    up5 = BatchNormalization()(up5)\n",
    "    #up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    merge5 = concatenate([up5, conv3])\n",
    "    \n",
    "    up6 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(merge5))\n",
    "    up6 = ReLU()(up6)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    #up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    merge6 = concatenate([up6, conv2])\n",
    "    \n",
    "    up7 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(merge6))\n",
    "    up7 = ReLU()(up7)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    #up7 = Dropout(0.1)(up7)\n",
    "    \n",
    "    merge7 = concatenate([up7, conv1])\n",
    "    \n",
    "    conv6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "\n",
    "    conv6 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv9 = Conv3D(filter0, 3, padding = 'same',  kernel_initializer = 'he_normal')(conv6)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    #conv9 = BatchNormalization()(conv9)\n",
    "    output_node = Conv3D(1, 1, padding='same', activation='sigmoid', kernel_initializer = 'he_normal')(conv9)\n",
    "    \n",
    "    conv8 = Conv3D(8, 3, padding = 'same',  kernel_initializer = 'he_normal')(output_node)\n",
    "    conv8 = ReLU()(conv8)\n",
    "    output_dist = Conv3D(1, 3, padding='same', activation='relu', kernel_initializer = 'he_normal')(conv8)\n",
    "    \n",
    "    model       = Model(input = inputs, output = [output_node, output_dist])\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.01), loss = [dice_coefficient_loss, 'mean_absolute_error'], loss_weights=[1, 10], metrics = [dice_coefficient])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     6,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coefficient_numpy(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def unet_2d_ReLU_pancreas(input_size = (160, 80, 1)):\n",
    "    filter0 = 8\n",
    "    filter1 = 16\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    \n",
    "    inputs          = Input(input_size)\n",
    "    #pca_mean_tensor = Input((81920,))\n",
    "    \n",
    "    conv0 = Conv2D(filter0, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv0 = ReLU()(conv0)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    #conv0 = Dropout(0.1)(conv0)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, padding = 'same', kernel_initializer = 'he_normal')(conv0)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    #conv1 = Dropout(0.1)(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    #conv2 = Dropout(0.1)(conv2)\n",
    "        \n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    #conv3 = Dropout(0.1)(conv3)\n",
    "        \n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "        \n",
    "    up5 = Conv2D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv4))\n",
    "    up5 = ReLU()(up5)\n",
    "    up5 = BatchNormalization()(up5)\n",
    "    #up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    merge5 = concatenate([up5, conv3])\n",
    "    \n",
    "    up6 = Conv2D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(merge5))\n",
    "    up6 = ReLU()(up6)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    #up6 = Dropout(0.1)(up6)\n",
    "    \n",
    "    merge6 = concatenate([up6, conv2])\n",
    "    \n",
    "    up7 = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(merge6))\n",
    "    up7 = ReLU()(up7)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    #up7 = Dropout(0.1)(up7)\n",
    "    \n",
    "    merge7 = concatenate([up7, conv1])\n",
    "    \n",
    "    conv6 = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "\n",
    "    conv6 = Conv2D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv6 = Conv2D(filter0, 3, padding = 'same',  kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = ReLU()(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    #conv6 = Dropout(0.1)(conv6)\n",
    "    \n",
    "    conv9 = Conv2D(1, 1, padding='same', activation='sigmoid', kernel_initializer = 'he_normal')(conv6)\n",
    "    output_node      = conv9\n",
    "    model            = Model(input = inputs, output = output_node)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.01), loss = [dice_coefficient_loss], loss_weights=[1], metrics = [dice_coefficient])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 80, 160, 80, 1)\n",
      "(82, 40, 80, 40, 1)\n",
      "(82, 40, 80, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(1, 83):\n",
    "    name  = str(i).zfill(4)\n",
    "    temp  = np.load('/media/dril/ubuntudata/PANCREAS/labels_reshaped1/'+name+'.npy')\n",
    "    temp1 = np.load('/media/dril/ubuntudata/PANCREAS/volumes_reshaped1/'+name+'.npy')\n",
    "    \n",
    "    temp  = ndimage.zoom(temp, 0.5)\n",
    "    temp1 = ndimage.zoom(temp1, 0.5)\n",
    "\n",
    "    y.append(temp)\n",
    "    x.append(temp1)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x = np.expand_dims(x, -1)\n",
    "y = np.expand_dims(y, -1)\n",
    "\n",
    "x[x<-100] = -100\n",
    "x[x>200] = 200\n",
    "\n",
    "x = x/200\n",
    "y[y<0.5] = 0\n",
    "y[y>0.5] = 1\n",
    "\n",
    "\n",
    "xmorph = np.load('xmorph.npy')\n",
    "xmorph = np.expand_dims(xmorph, -1)\n",
    "\n",
    "print(xmorph.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet_2d_ReLU_pancreas()\n",
    "c1    = ModelCheckpoint('./model_2d_4_'+str(count)+'.h5', monitor='val_loss', \n",
    "                         verbose=0, save_best_only=True, \n",
    "                         save_weights_only=False, mode='auto', period=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=0.001)\n",
    "model.fit(x, y, batch_size=8, validation_split=0.25, \n",
    "              callbacks=[c1,reduce_lr], epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: (61,) TEST: (21,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dril/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61 samples, validate on 21 samples\n",
      "Epoch 1/250\n",
      "61/61 [==============================] - 38s 621ms/step - loss: 0.7507 - dice_coefficient: 0.2493 - val_loss: 0.8944 - val_dice_coefficient: 0.1056\n",
      "Epoch 2/250\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.4301 - dice_coefficient: 0.5699 - val_loss: 0.8305 - val_dice_coefficient: 0.1695\n",
      "Epoch 3/250\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.3361 - dice_coefficient: 0.6639 - val_loss: 0.6100 - val_dice_coefficient: 0.3900\n",
      "Epoch 4/250\n",
      "61/61 [==============================] - 14s 226ms/step - loss: 0.2901 - dice_coefficient: 0.7099 - val_loss: 0.6083 - val_dice_coefficient: 0.3917\n",
      "Epoch 5/250\n",
      "61/61 [==============================] - 14s 226ms/step - loss: 0.2648 - dice_coefficient: 0.7352 - val_loss: 0.4417 - val_dice_coefficient: 0.5583\n",
      "Epoch 6/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.2355 - dice_coefficient: 0.7645 - val_loss: 0.2833 - val_dice_coefficient: 0.7167\n",
      "Epoch 7/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.2279 - dice_coefficient: 0.7721 - val_loss: 0.2501 - val_dice_coefficient: 0.7499\n",
      "Epoch 8/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1924 - dice_coefficient: 0.8076 - val_loss: 0.2752 - val_dice_coefficient: 0.7248\n",
      "Epoch 9/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1814 - dice_coefficient: 0.8186 - val_loss: 0.3360 - val_dice_coefficient: 0.6640\n",
      "Epoch 10/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1780 - dice_coefficient: 0.8220 - val_loss: 0.4837 - val_dice_coefficient: 0.5163\n",
      "Epoch 11/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1743 - dice_coefficient: 0.8257 - val_loss: 0.2507 - val_dice_coefficient: 0.7493\n",
      "Epoch 12/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1621 - dice_coefficient: 0.8379 - val_loss: 0.3367 - val_dice_coefficient: 0.6633\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 13/250\n",
      "61/61 [==============================] - 14s 226ms/step - loss: 0.1605 - dice_coefficient: 0.8395 - val_loss: 0.4222 - val_dice_coefficient: 0.5778\n",
      "Epoch 14/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.1514 - dice_coefficient: 0.8486 - val_loss: 0.2849 - val_dice_coefficient: 0.7151\n",
      "Epoch 15/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.1448 - dice_coefficient: 0.8552 - val_loss: 0.2637 - val_dice_coefficient: 0.7363\n",
      "Epoch 16/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.1379 - dice_coefficient: 0.8621 - val_loss: 0.3772 - val_dice_coefficient: 0.6228\n",
      "Epoch 17/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1387 - dice_coefficient: 0.8613 - val_loss: 0.3248 - val_dice_coefficient: 0.6752\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 18/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.1330 - dice_coefficient: 0.8670 - val_loss: 0.3589 - val_dice_coefficient: 0.6411\n",
      "Epoch 19/250\n",
      "61/61 [==============================] - 14s 236ms/step - loss: 0.1327 - dice_coefficient: 0.8673 - val_loss: 0.2911 - val_dice_coefficient: 0.7089\n",
      "Epoch 20/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1309 - dice_coefficient: 0.8691 - val_loss: 0.2754 - val_dice_coefficient: 0.7246\n",
      "Epoch 21/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1281 - dice_coefficient: 0.8719 - val_loss: 0.2799 - val_dice_coefficient: 0.7201\n",
      "Epoch 22/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1272 - dice_coefficient: 0.8728 - val_loss: 0.2617 - val_dice_coefficient: 0.7383\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 23/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1249 - dice_coefficient: 0.8751 - val_loss: 0.2644 - val_dice_coefficient: 0.7356\n",
      "Epoch 24/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1239 - dice_coefficient: 0.8761 - val_loss: 0.2621 - val_dice_coefficient: 0.7379\n",
      "Epoch 25/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1208 - dice_coefficient: 0.8792 - val_loss: 0.2568 - val_dice_coefficient: 0.7432\n",
      "Epoch 26/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1207 - dice_coefficient: 0.8793 - val_loss: 0.2612 - val_dice_coefficient: 0.7388\n",
      "Epoch 27/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1193 - dice_coefficient: 0.8807 - val_loss: 0.2416 - val_dice_coefficient: 0.7584\n",
      "Epoch 28/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1190 - dice_coefficient: 0.8810 - val_loss: 0.2926 - val_dice_coefficient: 0.7074\n",
      "Epoch 29/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1201 - dice_coefficient: 0.8799 - val_loss: 0.2294 - val_dice_coefficient: 0.7706\n",
      "Epoch 30/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1174 - dice_coefficient: 0.8826 - val_loss: 0.2439 - val_dice_coefficient: 0.7561\n",
      "Epoch 31/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1172 - dice_coefficient: 0.8828 - val_loss: 0.2325 - val_dice_coefficient: 0.7675\n",
      "Epoch 32/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1180 - dice_coefficient: 0.8820 - val_loss: 0.2301 - val_dice_coefficient: 0.7699\n",
      "Epoch 33/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1162 - dice_coefficient: 0.8838 - val_loss: 0.2320 - val_dice_coefficient: 0.7680\n",
      "Epoch 34/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1154 - dice_coefficient: 0.8846 - val_loss: 0.2634 - val_dice_coefficient: 0.7366\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 35/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1140 - dice_coefficient: 0.8860 - val_loss: 0.2549 - val_dice_coefficient: 0.7451\n",
      "Epoch 36/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1125 - dice_coefficient: 0.8875 - val_loss: 0.2554 - val_dice_coefficient: 0.7446\n",
      "Epoch 37/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1113 - dice_coefficient: 0.8887 - val_loss: 0.2214 - val_dice_coefficient: 0.7786\n",
      "Epoch 38/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1118 - dice_coefficient: 0.8882 - val_loss: 0.2589 - val_dice_coefficient: 0.7411\n",
      "Epoch 39/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1110 - dice_coefficient: 0.8890 - val_loss: 0.2709 - val_dice_coefficient: 0.7291\n",
      "Epoch 40/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1099 - dice_coefficient: 0.8901 - val_loss: 0.2548 - val_dice_coefficient: 0.7452\n",
      "Epoch 41/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1098 - dice_coefficient: 0.8902 - val_loss: 0.2712 - val_dice_coefficient: 0.7288\n",
      "Epoch 42/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1090 - dice_coefficient: 0.8910 - val_loss: 0.2281 - val_dice_coefficient: 0.7719\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 43/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1101 - dice_coefficient: 0.8899 - val_loss: 0.2579 - val_dice_coefficient: 0.7421\n",
      "Epoch 44/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1094 - dice_coefficient: 0.8906 - val_loss: 0.2186 - val_dice_coefficient: 0.7814\n",
      "Epoch 45/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1081 - dice_coefficient: 0.8919 - val_loss: 0.3323 - val_dice_coefficient: 0.6677\n",
      "Epoch 46/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1073 - dice_coefficient: 0.8927 - val_loss: 0.2518 - val_dice_coefficient: 0.7482\n",
      "Epoch 47/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1074 - dice_coefficient: 0.8926 - val_loss: 0.2605 - val_dice_coefficient: 0.7395\n",
      "Epoch 48/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1070 - dice_coefficient: 0.8930 - val_loss: 0.3108 - val_dice_coefficient: 0.6892\n",
      "Epoch 49/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1067 - dice_coefficient: 0.8933 - val_loss: 0.2266 - val_dice_coefficient: 0.7734\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 50/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1068 - dice_coefficient: 0.8932 - val_loss: 0.2103 - val_dice_coefficient: 0.7897\n",
      "Epoch 51/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1056 - dice_coefficient: 0.8944 - val_loss: 0.2595 - val_dice_coefficient: 0.7405\n",
      "Epoch 52/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1051 - dice_coefficient: 0.8949 - val_loss: 0.2379 - val_dice_coefficient: 0.7621\n",
      "Epoch 53/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1039 - dice_coefficient: 0.8961 - val_loss: 0.2332 - val_dice_coefficient: 0.7668\n",
      "Epoch 54/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1035 - dice_coefficient: 0.8965 - val_loss: 0.2243 - val_dice_coefficient: 0.7757\n",
      "Epoch 55/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1034 - dice_coefficient: 0.8966 - val_loss: 0.2266 - val_dice_coefficient: 0.7734\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 56/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1035 - dice_coefficient: 0.8965 - val_loss: 0.2961 - val_dice_coefficient: 0.7039\n",
      "Epoch 57/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1041 - dice_coefficient: 0.8959 - val_loss: 0.2383 - val_dice_coefficient: 0.7617\n",
      "Epoch 58/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1063 - dice_coefficient: 0.8937 - val_loss: 0.2364 - val_dice_coefficient: 0.7636\n",
      "Epoch 59/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1033 - dice_coefficient: 0.8967 - val_loss: 0.2742 - val_dice_coefficient: 0.7258\n",
      "Epoch 60/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1028 - dice_coefficient: 0.8972 - val_loss: 0.2533 - val_dice_coefficient: 0.7467\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 61/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1013 - dice_coefficient: 0.8987 - val_loss: 0.2457 - val_dice_coefficient: 0.7543\n",
      "Epoch 62/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1008 - dice_coefficient: 0.8992 - val_loss: 0.2110 - val_dice_coefficient: 0.7890\n",
      "Epoch 63/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1014 - dice_coefficient: 0.8986 - val_loss: 0.2568 - val_dice_coefficient: 0.7432\n",
      "Epoch 64/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1001 - dice_coefficient: 0.8999 - val_loss: 0.2455 - val_dice_coefficient: 0.7545\n",
      "Epoch 65/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0999 - dice_coefficient: 0.9001 - val_loss: 0.2155 - val_dice_coefficient: 0.7845\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 66/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.1001 - dice_coefficient: 0.8999 - val_loss: 0.2088 - val_dice_coefficient: 0.7912\n",
      "Epoch 67/250\n",
      "61/61 [==============================] - 15s 238ms/step - loss: 0.1002 - dice_coefficient: 0.8998 - val_loss: 0.2189 - val_dice_coefficient: 0.7811\n",
      "Epoch 68/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.1007 - dice_coefficient: 0.8993 - val_loss: 0.2209 - val_dice_coefficient: 0.7791\n",
      "Epoch 69/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1001 - dice_coefficient: 0.8999 - val_loss: 0.2380 - val_dice_coefficient: 0.7620\n",
      "Epoch 70/250\n",
      "61/61 [==============================] - 14s 235ms/step - loss: 0.0990 - dice_coefficient: 0.9010 - val_loss: 0.2751 - val_dice_coefficient: 0.7249\n",
      "Epoch 71/250\n",
      "61/61 [==============================] - 15s 241ms/step - loss: 0.0980 - dice_coefficient: 0.9020 - val_loss: 0.2445 - val_dice_coefficient: 0.7555\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 72/250\n",
      "61/61 [==============================] - 15s 247ms/step - loss: 0.0980 - dice_coefficient: 0.9020 - val_loss: 0.2478 - val_dice_coefficient: 0.7522\n",
      "Epoch 73/250\n",
      "61/61 [==============================] - 15s 241ms/step - loss: 0.0973 - dice_coefficient: 0.9027 - val_loss: 0.2318 - val_dice_coefficient: 0.7682\n",
      "Epoch 74/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0962 - dice_coefficient: 0.9038 - val_loss: 0.2873 - val_dice_coefficient: 0.7127\n",
      "Epoch 75/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0967 - dice_coefficient: 0.9033 - val_loss: 0.2308 - val_dice_coefficient: 0.7692\n",
      "Epoch 76/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0962 - dice_coefficient: 0.9038 - val_loss: 0.2179 - val_dice_coefficient: 0.7821\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 77/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0958 - dice_coefficient: 0.9042 - val_loss: 0.2408 - val_dice_coefficient: 0.7592\n",
      "Epoch 78/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.0989 - dice_coefficient: 0.9011 - val_loss: 0.2110 - val_dice_coefficient: 0.7890\n",
      "Epoch 79/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0978 - dice_coefficient: 0.9022 - val_loss: 0.1940 - val_dice_coefficient: 0.8060\n",
      "Epoch 80/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0969 - dice_coefficient: 0.9031 - val_loss: 0.2096 - val_dice_coefficient: 0.7904\n",
      "Epoch 81/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0960 - dice_coefficient: 0.9040 - val_loss: 0.2089 - val_dice_coefficient: 0.7911\n",
      "Epoch 82/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.0956 - dice_coefficient: 0.9044 - val_loss: 0.1969 - val_dice_coefficient: 0.8031\n",
      "Epoch 83/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0944 - dice_coefficient: 0.9056 - val_loss: 0.2275 - val_dice_coefficient: 0.7725\n",
      "Epoch 84/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0947 - dice_coefficient: 0.9053 - val_loss: 0.2048 - val_dice_coefficient: 0.7952\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 85/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0941 - dice_coefficient: 0.9059 - val_loss: 0.2202 - val_dice_coefficient: 0.7798\n",
      "Epoch 86/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0941 - dice_coefficient: 0.9059 - val_loss: 0.2622 - val_dice_coefficient: 0.7378\n",
      "Epoch 87/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0952 - dice_coefficient: 0.9048 - val_loss: 0.2168 - val_dice_coefficient: 0.7832\n",
      "Epoch 88/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0939 - dice_coefficient: 0.9061 - val_loss: 0.2304 - val_dice_coefficient: 0.7696\n",
      "Epoch 89/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0931 - dice_coefficient: 0.9069 - val_loss: 0.2092 - val_dice_coefficient: 0.7908\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 90/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0924 - dice_coefficient: 0.9076 - val_loss: 0.1905 - val_dice_coefficient: 0.8095\n",
      "Epoch 91/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0933 - dice_coefficient: 0.9067 - val_loss: 0.2194 - val_dice_coefficient: 0.7806\n",
      "Epoch 92/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0938 - dice_coefficient: 0.9062 - val_loss: 0.1999 - val_dice_coefficient: 0.8001\n",
      "Epoch 93/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0928 - dice_coefficient: 0.9072 - val_loss: 0.2147 - val_dice_coefficient: 0.7853\n",
      "Epoch 94/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0920 - dice_coefficient: 0.9080 - val_loss: 0.2230 - val_dice_coefficient: 0.7770\n",
      "Epoch 95/250\n",
      "61/61 [==============================] - 14s 235ms/step - loss: 0.0910 - dice_coefficient: 0.9090 - val_loss: 0.2041 - val_dice_coefficient: 0.7959\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 235ms/step - loss: 0.0922 - dice_coefficient: 0.9078 - val_loss: 0.1969 - val_dice_coefficient: 0.8031\n",
      "Epoch 97/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0916 - dice_coefficient: 0.9084 - val_loss: 0.2049 - val_dice_coefficient: 0.7951\n",
      "Epoch 98/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0913 - dice_coefficient: 0.9087 - val_loss: 0.2033 - val_dice_coefficient: 0.7967\n",
      "Epoch 99/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0920 - dice_coefficient: 0.9080 - val_loss: 0.2079 - val_dice_coefficient: 0.7921\n",
      "Epoch 100/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0915 - dice_coefficient: 0.9085 - val_loss: 0.2399 - val_dice_coefficient: 0.7601\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 101/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0927 - dice_coefficient: 0.9073 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "Epoch 102/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0903 - dice_coefficient: 0.9097 - val_loss: 0.2040 - val_dice_coefficient: 0.7960\n",
      "Epoch 103/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0895 - dice_coefficient: 0.9105 - val_loss: 0.2061 - val_dice_coefficient: 0.7939\n",
      "Epoch 104/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0894 - dice_coefficient: 0.9106 - val_loss: 0.2060 - val_dice_coefficient: 0.7940\n",
      "Epoch 105/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0893 - dice_coefficient: 0.9107 - val_loss: 0.1999 - val_dice_coefficient: 0.8001\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 106/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0893 - dice_coefficient: 0.9107 - val_loss: 0.2390 - val_dice_coefficient: 0.7610\n",
      "Epoch 107/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0885 - dice_coefficient: 0.9115 - val_loss: 0.2071 - val_dice_coefficient: 0.7929\n",
      "Epoch 108/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0890 - dice_coefficient: 0.9110 - val_loss: 0.2373 - val_dice_coefficient: 0.7627\n",
      "Epoch 109/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0882 - dice_coefficient: 0.9118 - val_loss: 0.2010 - val_dice_coefficient: 0.7990\n",
      "Epoch 110/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0884 - dice_coefficient: 0.9116 - val_loss: 0.2147 - val_dice_coefficient: 0.7853\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 111/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0874 - dice_coefficient: 0.9126 - val_loss: 0.2416 - val_dice_coefficient: 0.7584\n",
      "Epoch 112/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0866 - dice_coefficient: 0.9134 - val_loss: 0.2085 - val_dice_coefficient: 0.7915\n",
      "Epoch 113/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0873 - dice_coefficient: 0.9127 - val_loss: 0.1881 - val_dice_coefficient: 0.8119\n",
      "Epoch 114/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0869 - dice_coefficient: 0.9131 - val_loss: 0.2168 - val_dice_coefficient: 0.7832\n",
      "Epoch 115/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0871 - dice_coefficient: 0.9129 - val_loss: 0.1961 - val_dice_coefficient: 0.8039\n",
      "Epoch 116/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0870 - dice_coefficient: 0.9130 - val_loss: 0.2031 - val_dice_coefficient: 0.7969\n",
      "Epoch 117/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0869 - dice_coefficient: 0.9131 - val_loss: 0.1976 - val_dice_coefficient: 0.8024\n",
      "Epoch 118/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0867 - dice_coefficient: 0.9133 - val_loss: 0.2142 - val_dice_coefficient: 0.7858\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 119/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0850 - dice_coefficient: 0.9150 - val_loss: 0.1885 - val_dice_coefficient: 0.8115\n",
      "Epoch 120/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0860 - dice_coefficient: 0.9140 - val_loss: 0.2398 - val_dice_coefficient: 0.7602\n",
      "Epoch 121/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0853 - dice_coefficient: 0.9147 - val_loss: 0.2577 - val_dice_coefficient: 0.7423\n",
      "Epoch 122/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0854 - dice_coefficient: 0.9146 - val_loss: 0.2275 - val_dice_coefficient: 0.7725\n",
      "Epoch 123/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0851 - dice_coefficient: 0.9149 - val_loss: 0.2195 - val_dice_coefficient: 0.7805\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 124/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0838 - dice_coefficient: 0.9162 - val_loss: 0.2175 - val_dice_coefficient: 0.7825\n",
      "Epoch 125/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0835 - dice_coefficient: 0.9165 - val_loss: 0.2146 - val_dice_coefficient: 0.7854\n",
      "Epoch 126/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0843 - dice_coefficient: 0.9157 - val_loss: 0.2207 - val_dice_coefficient: 0.7793\n",
      "Epoch 127/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0843 - dice_coefficient: 0.9157 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "Epoch 128/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0841 - dice_coefficient: 0.9159 - val_loss: 0.2455 - val_dice_coefficient: 0.7545\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 129/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0852 - dice_coefficient: 0.9148 - val_loss: 0.2285 - val_dice_coefficient: 0.7715\n",
      "Epoch 130/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0845 - dice_coefficient: 0.9155 - val_loss: 0.2116 - val_dice_coefficient: 0.7884\n",
      "Epoch 131/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0835 - dice_coefficient: 0.9165 - val_loss: 0.2205 - val_dice_coefficient: 0.7795\n",
      "Epoch 132/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0821 - dice_coefficient: 0.9179 - val_loss: 0.2018 - val_dice_coefficient: 0.7982\n",
      "Epoch 133/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0828 - dice_coefficient: 0.9172 - val_loss: 0.2376 - val_dice_coefficient: 0.7624\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 134/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0841 - dice_coefficient: 0.9159 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "Epoch 135/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0835 - dice_coefficient: 0.9165 - val_loss: 0.2333 - val_dice_coefficient: 0.7667\n",
      "Epoch 136/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0824 - dice_coefficient: 0.9176 - val_loss: 0.1927 - val_dice_coefficient: 0.8073\n",
      "Epoch 137/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0827 - dice_coefficient: 0.9173 - val_loss: 0.2037 - val_dice_coefficient: 0.7963\n",
      "Epoch 138/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0827 - dice_coefficient: 0.9173 - val_loss: 0.2030 - val_dice_coefficient: 0.7970\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 139/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0820 - dice_coefficient: 0.9180 - val_loss: 0.2000 - val_dice_coefficient: 0.8000\n",
      "Epoch 140/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0816 - dice_coefficient: 0.9184 - val_loss: 0.2150 - val_dice_coefficient: 0.7850\n",
      "Epoch 141/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0816 - dice_coefficient: 0.9184 - val_loss: 0.2040 - val_dice_coefficient: 0.7960\n",
      "Epoch 142/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0810 - dice_coefficient: 0.9190 - val_loss: 0.2132 - val_dice_coefficient: 0.7868\n",
      "Epoch 143/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0803 - dice_coefficient: 0.9197 - val_loss: 0.1970 - val_dice_coefficient: 0.8030\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 144/250\n",
      "61/61 [==============================] - 14s 234ms/step - loss: 0.0802 - dice_coefficient: 0.9198 - val_loss: 0.1952 - val_dice_coefficient: 0.8048\n",
      "Epoch 145/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0801 - dice_coefficient: 0.9199 - val_loss: 0.1990 - val_dice_coefficient: 0.8010\n",
      "Epoch 146/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0805 - dice_coefficient: 0.9195 - val_loss: 0.1854 - val_dice_coefficient: 0.8146\n",
      "Epoch 147/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0793 - dice_coefficient: 0.9207 - val_loss: 0.1920 - val_dice_coefficient: 0.8080\n",
      "Epoch 148/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.0798 - dice_coefficient: 0.9202 - val_loss: 0.2228 - val_dice_coefficient: 0.7772\n",
      "Epoch 149/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0792 - dice_coefficient: 0.9208 - val_loss: 0.1922 - val_dice_coefficient: 0.8078\n",
      "Epoch 150/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.0794 - dice_coefficient: 0.9206 - val_loss: 0.2066 - val_dice_coefficient: 0.7934\n",
      "Epoch 151/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0787 - dice_coefficient: 0.9213 - val_loss: 0.1956 - val_dice_coefficient: 0.8044\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 152/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0789 - dice_coefficient: 0.9211 - val_loss: 0.1954 - val_dice_coefficient: 0.8046\n",
      "Epoch 153/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1934 - val_dice_coefficient: 0.8066\n",
      "Epoch 154/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0783 - dice_coefficient: 0.9217 - val_loss: 0.1928 - val_dice_coefficient: 0.8072\n",
      "Epoch 155/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1911 - val_dice_coefficient: 0.8089\n",
      "Epoch 156/250\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0786 - dice_coefficient: 0.9214 - val_loss: 0.2439 - val_dice_coefficient: 0.7561\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 157/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0785 - dice_coefficient: 0.9215 - val_loss: 0.1937 - val_dice_coefficient: 0.8063\n",
      "Epoch 158/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0778 - dice_coefficient: 0.9222 - val_loss: 0.2028 - val_dice_coefficient: 0.7972\n",
      "Epoch 159/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0772 - dice_coefficient: 0.9228 - val_loss: 0.1993 - val_dice_coefficient: 0.8007\n",
      "Epoch 160/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0772 - dice_coefficient: 0.9228 - val_loss: 0.1934 - val_dice_coefficient: 0.8066\n",
      "Epoch 161/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0763 - dice_coefficient: 0.9237 - val_loss: 0.2189 - val_dice_coefficient: 0.7811\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 162/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0768 - dice_coefficient: 0.9232 - val_loss: 0.2154 - val_dice_coefficient: 0.7846\n",
      "Epoch 163/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0764 - dice_coefficient: 0.9236 - val_loss: 0.1945 - val_dice_coefficient: 0.8055\n",
      "Epoch 164/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0759 - dice_coefficient: 0.9241 - val_loss: 0.1965 - val_dice_coefficient: 0.8035\n",
      "Epoch 165/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0775 - dice_coefficient: 0.9225 - val_loss: 0.2076 - val_dice_coefficient: 0.7924\n",
      "Epoch 166/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0767 - dice_coefficient: 0.9233 - val_loss: 0.2018 - val_dice_coefficient: 0.7982\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 167/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0775 - dice_coefficient: 0.9225 - val_loss: 0.1897 - val_dice_coefficient: 0.8103\n",
      "Epoch 168/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0770 - dice_coefficient: 0.9230 - val_loss: 0.2085 - val_dice_coefficient: 0.7915\n",
      "Epoch 169/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0763 - dice_coefficient: 0.9237 - val_loss: 0.1899 - val_dice_coefficient: 0.8101\n",
      "Epoch 170/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0760 - dice_coefficient: 0.9240 - val_loss: 0.2137 - val_dice_coefficient: 0.7863\n",
      "Epoch 171/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0752 - dice_coefficient: 0.9248 - val_loss: 0.1922 - val_dice_coefficient: 0.8078\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 172/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0754 - dice_coefficient: 0.9246 - val_loss: 0.1947 - val_dice_coefficient: 0.8053\n",
      "Epoch 173/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0745 - dice_coefficient: 0.9255 - val_loss: 0.2112 - val_dice_coefficient: 0.7888\n",
      "Epoch 174/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0744 - dice_coefficient: 0.9256 - val_loss: 0.1965 - val_dice_coefficient: 0.8035\n",
      "Epoch 175/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0756 - dice_coefficient: 0.9244 - val_loss: 0.2165 - val_dice_coefficient: 0.7835\n",
      "Epoch 176/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0749 - dice_coefficient: 0.9251 - val_loss: 0.1935 - val_dice_coefficient: 0.8065\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 177/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0743 - dice_coefficient: 0.9257 - val_loss: 0.2101 - val_dice_coefficient: 0.7899\n",
      "Epoch 178/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0736 - dice_coefficient: 0.9264 - val_loss: 0.2016 - val_dice_coefficient: 0.7984\n",
      "Epoch 179/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0742 - dice_coefficient: 0.9258 - val_loss: 0.1893 - val_dice_coefficient: 0.8107\n",
      "Epoch 180/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0735 - dice_coefficient: 0.9265 - val_loss: 0.1892 - val_dice_coefficient: 0.8108\n",
      "Epoch 181/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0735 - dice_coefficient: 0.9265 - val_loss: 0.2023 - val_dice_coefficient: 0.7977\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 182/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0733 - dice_coefficient: 0.9267 - val_loss: 0.2041 - val_dice_coefficient: 0.7959\n",
      "Epoch 183/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0734 - dice_coefficient: 0.9266 - val_loss: 0.2089 - val_dice_coefficient: 0.7911\n",
      "Epoch 184/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0740 - dice_coefficient: 0.9260 - val_loss: 0.1987 - val_dice_coefficient: 0.8013\n",
      "Epoch 185/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0745 - dice_coefficient: 0.9255 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "Epoch 186/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0731 - dice_coefficient: 0.9269 - val_loss: 0.2163 - val_dice_coefficient: 0.7837\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 187/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0728 - dice_coefficient: 0.9272 - val_loss: 0.1887 - val_dice_coefficient: 0.8113\n",
      "Epoch 188/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0719 - dice_coefficient: 0.9281 - val_loss: 0.1870 - val_dice_coefficient: 0.8130\n",
      "Epoch 189/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0724 - dice_coefficient: 0.9276 - val_loss: 0.2018 - val_dice_coefficient: 0.7982\n",
      "Epoch 190/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0722 - dice_coefficient: 0.9278 - val_loss: 0.2120 - val_dice_coefficient: 0.7880\n",
      "Epoch 191/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0714 - dice_coefficient: 0.9286 - val_loss: 0.2073 - val_dice_coefficient: 0.7927\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 192/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1882 - val_dice_coefficient: 0.8118\n",
      "Epoch 193/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0723 - dice_coefficient: 0.9277 - val_loss: 0.1971 - val_dice_coefficient: 0.8029\n",
      "Epoch 194/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0719 - dice_coefficient: 0.9281 - val_loss: 0.2052 - val_dice_coefficient: 0.7948\n",
      "Epoch 195/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0718 - dice_coefficient: 0.9282 - val_loss: 0.1879 - val_dice_coefficient: 0.8121\n",
      "Epoch 196/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0713 - dice_coefficient: 0.9287 - val_loss: 0.2049 - val_dice_coefficient: 0.7951\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 197/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0717 - dice_coefficient: 0.9283 - val_loss: 0.1895 - val_dice_coefficient: 0.8105\n",
      "Epoch 198/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0709 - dice_coefficient: 0.9291 - val_loss: 0.1923 - val_dice_coefficient: 0.8077\n",
      "Epoch 199/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0706 - dice_coefficient: 0.9294 - val_loss: 0.1866 - val_dice_coefficient: 0.8134\n",
      "Epoch 200/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0696 - dice_coefficient: 0.9304 - val_loss: 0.2041 - val_dice_coefficient: 0.7959\n",
      "Epoch 201/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0695 - dice_coefficient: 0.9305 - val_loss: 0.1956 - val_dice_coefficient: 0.8044\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 202/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0704 - dice_coefficient: 0.9296 - val_loss: 0.1896 - val_dice_coefficient: 0.8104\n",
      "Epoch 203/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0703 - dice_coefficient: 0.9297 - val_loss: 0.1904 - val_dice_coefficient: 0.8096\n",
      "Epoch 204/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0715 - dice_coefficient: 0.9285 - val_loss: 0.2009 - val_dice_coefficient: 0.7991\n",
      "Epoch 205/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0694 - dice_coefficient: 0.9306 - val_loss: 0.2033 - val_dice_coefficient: 0.7967\n",
      "Epoch 206/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0693 - dice_coefficient: 0.9307 - val_loss: 0.1897 - val_dice_coefficient: 0.8103\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 207/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0696 - dice_coefficient: 0.9304 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "Epoch 208/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0695 - dice_coefficient: 0.9305 - val_loss: 0.1876 - val_dice_coefficient: 0.8124\n",
      "Epoch 209/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0683 - dice_coefficient: 0.9317 - val_loss: 0.2186 - val_dice_coefficient: 0.7814\n",
      "Epoch 210/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0681 - dice_coefficient: 0.9319 - val_loss: 0.2029 - val_dice_coefficient: 0.7971\n",
      "Epoch 211/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0682 - dice_coefficient: 0.9318 - val_loss: 0.2106 - val_dice_coefficient: 0.7894\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 212/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0684 - dice_coefficient: 0.9316 - val_loss: 0.1932 - val_dice_coefficient: 0.8068\n",
      "Epoch 213/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0678 - dice_coefficient: 0.9322 - val_loss: 0.1891 - val_dice_coefficient: 0.8109\n",
      "Epoch 214/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0671 - dice_coefficient: 0.9329 - val_loss: 0.1994 - val_dice_coefficient: 0.8006\n",
      "Epoch 215/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0672 - dice_coefficient: 0.9328 - val_loss: 0.1910 - val_dice_coefficient: 0.8090\n",
      "Epoch 216/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0672 - dice_coefficient: 0.9328 - val_loss: 0.2038 - val_dice_coefficient: 0.7962\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 217/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0671 - dice_coefficient: 0.9329 - val_loss: 0.1950 - val_dice_coefficient: 0.8050\n",
      "Epoch 218/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0680 - dice_coefficient: 0.9320 - val_loss: 0.1886 - val_dice_coefficient: 0.8114\n",
      "Epoch 219/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0673 - dice_coefficient: 0.9327 - val_loss: 0.2082 - val_dice_coefficient: 0.7918\n",
      "Epoch 220/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0662 - dice_coefficient: 0.9338 - val_loss: 0.1911 - val_dice_coefficient: 0.8089\n",
      "Epoch 221/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0675 - dice_coefficient: 0.9325 - val_loss: 0.1926 - val_dice_coefficient: 0.8074\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 222/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0671 - dice_coefficient: 0.9329 - val_loss: 0.1885 - val_dice_coefficient: 0.8115\n",
      "Epoch 223/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0660 - dice_coefficient: 0.9340 - val_loss: 0.1891 - val_dice_coefficient: 0.8109\n",
      "Epoch 224/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0661 - dice_coefficient: 0.9339 - val_loss: 0.1995 - val_dice_coefficient: 0.8005\n",
      "Epoch 225/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0655 - dice_coefficient: 0.9345 - val_loss: 0.2004 - val_dice_coefficient: 0.7996\n",
      "Epoch 226/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0666 - dice_coefficient: 0.9334 - val_loss: 0.1877 - val_dice_coefficient: 0.8123\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 227/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0665 - dice_coefficient: 0.9335 - val_loss: 0.1929 - val_dice_coefficient: 0.8071\n",
      "Epoch 228/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0666 - dice_coefficient: 0.9334 - val_loss: 0.2068 - val_dice_coefficient: 0.7932\n",
      "Epoch 229/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0660 - dice_coefficient: 0.9340 - val_loss: 0.1881 - val_dice_coefficient: 0.8119\n",
      "Epoch 230/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0657 - dice_coefficient: 0.9343 - val_loss: 0.1879 - val_dice_coefficient: 0.8121\n",
      "Epoch 231/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0663 - dice_coefficient: 0.9337 - val_loss: 0.1895 - val_dice_coefficient: 0.8105\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 232/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0646 - dice_coefficient: 0.9354 - val_loss: 0.1935 - val_dice_coefficient: 0.8065\n",
      "Epoch 233/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0643 - dice_coefficient: 0.9357 - val_loss: 0.1844 - val_dice_coefficient: 0.8156\n",
      "Epoch 234/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0649 - dice_coefficient: 0.9351 - val_loss: 0.2014 - val_dice_coefficient: 0.7986\n",
      "Epoch 235/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0642 - dice_coefficient: 0.9358 - val_loss: 0.2037 - val_dice_coefficient: 0.7963\n",
      "Epoch 236/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0646 - dice_coefficient: 0.9354 - val_loss: 0.1901 - val_dice_coefficient: 0.8099\n",
      "Epoch 237/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0637 - dice_coefficient: 0.9363 - val_loss: 0.2002 - val_dice_coefficient: 0.7998\n",
      "Epoch 238/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0636 - dice_coefficient: 0.9364 - val_loss: 0.1869 - val_dice_coefficient: 0.8131\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 239/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0638 - dice_coefficient: 0.9362 - val_loss: 0.1903 - val_dice_coefficient: 0.8097\n",
      "Epoch 240/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0639 - dice_coefficient: 0.9361 - val_loss: 0.1862 - val_dice_coefficient: 0.8138\n",
      "Epoch 241/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0640 - dice_coefficient: 0.9360 - val_loss: 0.2149 - val_dice_coefficient: 0.7851\n",
      "Epoch 242/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0646 - dice_coefficient: 0.9354 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 243/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0652 - dice_coefficient: 0.9348 - val_loss: 0.2094 - val_dice_coefficient: 0.7906\n",
      "Epoch 244/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0640 - dice_coefficient: 0.9360 - val_loss: 0.1887 - val_dice_coefficient: 0.8113\n",
      "Epoch 245/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0641 - dice_coefficient: 0.9359 - val_loss: 0.1910 - val_dice_coefficient: 0.8090\n",
      "Epoch 246/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0628 - dice_coefficient: 0.9372 - val_loss: 0.2063 - val_dice_coefficient: 0.7937\n",
      "Epoch 247/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0640 - dice_coefficient: 0.9360 - val_loss: 0.1893 - val_dice_coefficient: 0.8107\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 248/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0633 - dice_coefficient: 0.9367 - val_loss: 0.1923 - val_dice_coefficient: 0.8077\n",
      "Epoch 249/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0634 - dice_coefficient: 0.9366 - val_loss: 0.1964 - val_dice_coefficient: 0.8036\n",
      "Epoch 250/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0621 - dice_coefficient: 0.9379 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "TRAIN: (61,) TEST: (21,)\n",
      "Train on 61 samples, validate on 21 samples\n",
      "Epoch 1/250\n",
      "61/61 [==============================] - 36s 587ms/step - loss: 0.7824 - dice_coefficient: 0.2176 - val_loss: 0.8623 - val_dice_coefficient: 0.1377\n",
      "Epoch 2/250\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.4397 - dice_coefficient: 0.5603 - val_loss: 0.5670 - val_dice_coefficient: 0.4330\n",
      "Epoch 3/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.3044 - dice_coefficient: 0.6956 - val_loss: 0.6975 - val_dice_coefficient: 0.3025\n",
      "Epoch 4/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.2604 - dice_coefficient: 0.7396 - val_loss: 0.6450 - val_dice_coefficient: 0.3550\n",
      "Epoch 5/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.2416 - dice_coefficient: 0.7584 - val_loss: 0.3799 - val_dice_coefficient: 0.6201\n",
      "Epoch 6/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.2239 - dice_coefficient: 0.7761 - val_loss: 0.5648 - val_dice_coefficient: 0.4352\n",
      "Epoch 7/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.2153 - dice_coefficient: 0.7847 - val_loss: 0.4976 - val_dice_coefficient: 0.5024\n",
      "Epoch 8/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1938 - dice_coefficient: 0.8062 - val_loss: 0.3350 - val_dice_coefficient: 0.6650\n",
      "Epoch 9/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1777 - dice_coefficient: 0.8223 - val_loss: 0.4799 - val_dice_coefficient: 0.5201\n",
      "Epoch 10/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1650 - dice_coefficient: 0.8350 - val_loss: 0.6747 - val_dice_coefficient: 0.3253\n",
      "Epoch 11/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1654 - dice_coefficient: 0.8346 - val_loss: 0.4616 - val_dice_coefficient: 0.5384\n",
      "Epoch 12/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1605 - dice_coefficient: 0.8395 - val_loss: 0.4114 - val_dice_coefficient: 0.5886\n",
      "Epoch 13/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1533 - dice_coefficient: 0.8467 - val_loss: 0.3267 - val_dice_coefficient: 0.6733\n",
      "Epoch 14/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1505 - dice_coefficient: 0.8495 - val_loss: 0.3125 - val_dice_coefficient: 0.6875\n",
      "Epoch 15/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.1450 - dice_coefficient: 0.8550 - val_loss: 0.2521 - val_dice_coefficient: 0.7479\n",
      "Epoch 16/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1431 - dice_coefficient: 0.8569 - val_loss: 0.2983 - val_dice_coefficient: 0.7017\n",
      "Epoch 17/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1383 - dice_coefficient: 0.8617 - val_loss: 0.2575 - val_dice_coefficient: 0.7425\n",
      "Epoch 18/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1345 - dice_coefficient: 0.8655 - val_loss: 0.2541 - val_dice_coefficient: 0.7459\n",
      "Epoch 19/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1353 - dice_coefficient: 0.8647 - val_loss: 0.2641 - val_dice_coefficient: 0.7359\n",
      "Epoch 20/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1352 - dice_coefficient: 0.8648 - val_loss: 0.2697 - val_dice_coefficient: 0.7303\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 21/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.1266 - dice_coefficient: 0.8734 - val_loss: 0.2313 - val_dice_coefficient: 0.7687\n",
      "Epoch 22/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1233 - dice_coefficient: 0.8767 - val_loss: 0.2408 - val_dice_coefficient: 0.7592\n",
      "Epoch 23/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1219 - dice_coefficient: 0.8781 - val_loss: 0.2184 - val_dice_coefficient: 0.7816\n",
      "Epoch 24/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1228 - dice_coefficient: 0.8772 - val_loss: 0.2030 - val_dice_coefficient: 0.7970\n",
      "Epoch 25/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1208 - dice_coefficient: 0.8792 - val_loss: 0.2031 - val_dice_coefficient: 0.7969\n",
      "Epoch 26/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1185 - dice_coefficient: 0.8815 - val_loss: 0.2063 - val_dice_coefficient: 0.7937\n",
      "Epoch 27/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1169 - dice_coefficient: 0.8831 - val_loss: 0.2452 - val_dice_coefficient: 0.7548\n",
      "Epoch 28/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1177 - dice_coefficient: 0.8823 - val_loss: 0.2142 - val_dice_coefficient: 0.7858\n",
      "Epoch 29/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1135 - dice_coefficient: 0.8865 - val_loss: 0.2074 - val_dice_coefficient: 0.7926\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 30/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1123 - dice_coefficient: 0.8877 - val_loss: 0.2011 - val_dice_coefficient: 0.7989\n",
      "Epoch 31/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1123 - dice_coefficient: 0.8877 - val_loss: 0.1975 - val_dice_coefficient: 0.8025\n",
      "Epoch 32/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1119 - dice_coefficient: 0.8881 - val_loss: 0.2087 - val_dice_coefficient: 0.7913\n",
      "Epoch 33/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1078 - dice_coefficient: 0.8922 - val_loss: 0.2058 - val_dice_coefficient: 0.7942\n",
      "Epoch 34/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1071 - dice_coefficient: 0.8929 - val_loss: 0.2105 - val_dice_coefficient: 0.7895\n",
      "Epoch 35/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1068 - dice_coefficient: 0.8932 - val_loss: 0.2052 - val_dice_coefficient: 0.7948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1059 - dice_coefficient: 0.8941 - val_loss: 0.2070 - val_dice_coefficient: 0.7930\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 37/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1039 - dice_coefficient: 0.8961 - val_loss: 0.1979 - val_dice_coefficient: 0.8021\n",
      "Epoch 38/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1031 - dice_coefficient: 0.8969 - val_loss: 0.2039 - val_dice_coefficient: 0.7961\n",
      "Epoch 39/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1026 - dice_coefficient: 0.8974 - val_loss: 0.2034 - val_dice_coefficient: 0.7966\n",
      "Epoch 40/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1036 - dice_coefficient: 0.8964 - val_loss: 0.2065 - val_dice_coefficient: 0.7935\n",
      "Epoch 41/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.1022 - dice_coefficient: 0.8978 - val_loss: 0.1928 - val_dice_coefficient: 0.8072\n",
      "Epoch 42/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1020 - dice_coefficient: 0.8980 - val_loss: 0.1961 - val_dice_coefficient: 0.8039\n",
      "Epoch 43/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1000 - dice_coefficient: 0.9000 - val_loss: 0.1969 - val_dice_coefficient: 0.8031\n",
      "Epoch 44/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1006 - dice_coefficient: 0.8994 - val_loss: 0.1953 - val_dice_coefficient: 0.8047\n",
      "Epoch 45/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0994 - dice_coefficient: 0.9006 - val_loss: 0.1956 - val_dice_coefficient: 0.8044\n",
      "Epoch 46/250\n",
      "61/61 [==============================] - 15s 239ms/step - loss: 0.0995 - dice_coefficient: 0.9005 - val_loss: 0.1972 - val_dice_coefficient: 0.8028\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 47/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0991 - dice_coefficient: 0.9009 - val_loss: 0.1942 - val_dice_coefficient: 0.8058\n",
      "Epoch 48/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0986 - dice_coefficient: 0.9014 - val_loss: 0.1942 - val_dice_coefficient: 0.8058\n",
      "Epoch 49/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0982 - dice_coefficient: 0.9018 - val_loss: 0.1918 - val_dice_coefficient: 0.8082\n",
      "Epoch 50/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0981 - dice_coefficient: 0.9019 - val_loss: 0.1923 - val_dice_coefficient: 0.8077\n",
      "Epoch 51/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0973 - dice_coefficient: 0.9027 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "Epoch 52/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0980 - dice_coefficient: 0.9020 - val_loss: 0.1911 - val_dice_coefficient: 0.8089\n",
      "Epoch 53/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0976 - dice_coefficient: 0.9024 - val_loss: 0.1958 - val_dice_coefficient: 0.8042\n",
      "Epoch 54/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0972 - dice_coefficient: 0.9028 - val_loss: 0.1933 - val_dice_coefficient: 0.8067\n",
      "Epoch 55/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0966 - dice_coefficient: 0.9034 - val_loss: 0.1968 - val_dice_coefficient: 0.8032\n",
      "Epoch 56/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0962 - dice_coefficient: 0.9038 - val_loss: 0.1956 - val_dice_coefficient: 0.8044\n",
      "Epoch 57/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0952 - dice_coefficient: 0.9048 - val_loss: 0.1954 - val_dice_coefficient: 0.8046\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 58/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0954 - dice_coefficient: 0.9046 - val_loss: 0.1929 - val_dice_coefficient: 0.8071\n",
      "Epoch 59/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0958 - dice_coefficient: 0.9042 - val_loss: 0.1900 - val_dice_coefficient: 0.8100\n",
      "Epoch 60/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0953 - dice_coefficient: 0.9047 - val_loss: 0.1914 - val_dice_coefficient: 0.8086\n",
      "Epoch 61/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0944 - dice_coefficient: 0.9056 - val_loss: 0.1989 - val_dice_coefficient: 0.8011\n",
      "Epoch 62/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0945 - dice_coefficient: 0.9055 - val_loss: 0.1993 - val_dice_coefficient: 0.8007\n",
      "Epoch 63/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0949 - dice_coefficient: 0.9051 - val_loss: 0.1967 - val_dice_coefficient: 0.8033\n",
      "Epoch 64/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0937 - dice_coefficient: 0.9063 - val_loss: 0.1960 - val_dice_coefficient: 0.8040\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 65/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0940 - dice_coefficient: 0.9060 - val_loss: 0.1980 - val_dice_coefficient: 0.8020\n",
      "Epoch 66/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0938 - dice_coefficient: 0.9062 - val_loss: 0.1987 - val_dice_coefficient: 0.8013\n",
      "Epoch 67/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0928 - dice_coefficient: 0.9072 - val_loss: 0.1989 - val_dice_coefficient: 0.8011\n",
      "Epoch 68/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0925 - dice_coefficient: 0.9075 - val_loss: 0.1968 - val_dice_coefficient: 0.8032\n",
      "Epoch 69/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0929 - dice_coefficient: 0.9071 - val_loss: 0.1953 - val_dice_coefficient: 0.8047\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 70/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0929 - dice_coefficient: 0.9071 - val_loss: 0.2011 - val_dice_coefficient: 0.7989\n",
      "Epoch 71/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0930 - dice_coefficient: 0.9070 - val_loss: 0.1970 - val_dice_coefficient: 0.8030\n",
      "Epoch 72/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0926 - dice_coefficient: 0.9074 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "Epoch 73/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0938 - dice_coefficient: 0.9062 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "Epoch 74/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0921 - dice_coefficient: 0.9079 - val_loss: 0.1937 - val_dice_coefficient: 0.8063\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 75/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0906 - dice_coefficient: 0.9094 - val_loss: 0.1914 - val_dice_coefficient: 0.8086\n",
      "Epoch 76/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0911 - dice_coefficient: 0.9089 - val_loss: 0.2041 - val_dice_coefficient: 0.7959\n",
      "Epoch 77/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0901 - dice_coefficient: 0.9099 - val_loss: 0.1962 - val_dice_coefficient: 0.8038\n",
      "Epoch 78/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0899 - dice_coefficient: 0.9101 - val_loss: 0.1924 - val_dice_coefficient: 0.8076\n",
      "Epoch 79/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0892 - dice_coefficient: 0.9108 - val_loss: 0.1886 - val_dice_coefficient: 0.8114\n",
      "Epoch 80/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0903 - dice_coefficient: 0.9097 - val_loss: 0.1913 - val_dice_coefficient: 0.8087\n",
      "Epoch 81/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0897 - dice_coefficient: 0.9103 - val_loss: 0.1916 - val_dice_coefficient: 0.8084\n",
      "Epoch 82/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0894 - dice_coefficient: 0.9106 - val_loss: 0.1911 - val_dice_coefficient: 0.8089\n",
      "Epoch 83/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0883 - dice_coefficient: 0.9117 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "Epoch 84/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0888 - dice_coefficient: 0.9112 - val_loss: 0.1908 - val_dice_coefficient: 0.8092\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 85/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0896 - dice_coefficient: 0.9104 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "Epoch 86/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0877 - dice_coefficient: 0.9123 - val_loss: 0.1919 - val_dice_coefficient: 0.8081\n",
      "Epoch 87/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0879 - dice_coefficient: 0.9121 - val_loss: 0.1966 - val_dice_coefficient: 0.8034\n",
      "Epoch 88/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0870 - dice_coefficient: 0.9130 - val_loss: 0.1962 - val_dice_coefficient: 0.8038\n",
      "Epoch 89/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0883 - dice_coefficient: 0.9117 - val_loss: 0.1938 - val_dice_coefficient: 0.8062\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 90/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0873 - dice_coefficient: 0.9127 - val_loss: 0.1873 - val_dice_coefficient: 0.8127\n",
      "Epoch 91/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0873 - dice_coefficient: 0.9127 - val_loss: 0.1903 - val_dice_coefficient: 0.8097\n",
      "Epoch 92/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0878 - dice_coefficient: 0.9122 - val_loss: 0.1971 - val_dice_coefficient: 0.8029\n",
      "Epoch 93/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0865 - dice_coefficient: 0.9135 - val_loss: 0.1970 - val_dice_coefficient: 0.8030\n",
      "Epoch 94/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0868 - dice_coefficient: 0.9132 - val_loss: 0.1919 - val_dice_coefficient: 0.8081\n",
      "Epoch 95/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0881 - dice_coefficient: 0.9119 - val_loss: 0.1943 - val_dice_coefficient: 0.8057\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 96/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0864 - dice_coefficient: 0.9136 - val_loss: 0.1885 - val_dice_coefficient: 0.8115\n",
      "Epoch 97/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0861 - dice_coefficient: 0.9139 - val_loss: 0.1966 - val_dice_coefficient: 0.8034\n",
      "Epoch 98/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0853 - dice_coefficient: 0.9147 - val_loss: 0.1995 - val_dice_coefficient: 0.8005\n",
      "Epoch 99/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0856 - dice_coefficient: 0.9144 - val_loss: 0.1913 - val_dice_coefficient: 0.8087\n",
      "Epoch 100/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0853 - dice_coefficient: 0.9147 - val_loss: 0.1842 - val_dice_coefficient: 0.8158\n",
      "Epoch 101/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0854 - dice_coefficient: 0.9146 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 102/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0855 - dice_coefficient: 0.9145 - val_loss: 0.1902 - val_dice_coefficient: 0.8098\n",
      "Epoch 103/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0852 - dice_coefficient: 0.9148 - val_loss: 0.1888 - val_dice_coefficient: 0.8112\n",
      "Epoch 104/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0851 - dice_coefficient: 0.9149 - val_loss: 0.1859 - val_dice_coefficient: 0.8141\n",
      "Epoch 105/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0847 - dice_coefficient: 0.9153 - val_loss: 0.1884 - val_dice_coefficient: 0.8116\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 106/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0836 - dice_coefficient: 0.9164 - val_loss: 0.1951 - val_dice_coefficient: 0.8049\n",
      "Epoch 107/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0850 - dice_coefficient: 0.9150 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 108/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0833 - dice_coefficient: 0.9167 - val_loss: 0.1928 - val_dice_coefficient: 0.8072\n",
      "Epoch 109/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0838 - dice_coefficient: 0.9162 - val_loss: 0.1888 - val_dice_coefficient: 0.8112\n",
      "Epoch 110/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0836 - dice_coefficient: 0.9164 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 111/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0827 - dice_coefficient: 0.9173 - val_loss: 0.1913 - val_dice_coefficient: 0.8087\n",
      "Epoch 112/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0833 - dice_coefficient: 0.9167 - val_loss: 0.1955 - val_dice_coefficient: 0.8045\n",
      "Epoch 113/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0821 - dice_coefficient: 0.9179 - val_loss: 0.1957 - val_dice_coefficient: 0.8043\n",
      "Epoch 114/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0826 - dice_coefficient: 0.9174 - val_loss: 0.1892 - val_dice_coefficient: 0.8108\n",
      "Epoch 115/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0818 - dice_coefficient: 0.9182 - val_loss: 0.1911 - val_dice_coefficient: 0.8089\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 116/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0817 - dice_coefficient: 0.9183 - val_loss: 0.1879 - val_dice_coefficient: 0.8121\n",
      "Epoch 117/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0812 - dice_coefficient: 0.9188 - val_loss: 0.1945 - val_dice_coefficient: 0.8055\n",
      "Epoch 118/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0812 - dice_coefficient: 0.9188 - val_loss: 0.1878 - val_dice_coefficient: 0.8122\n",
      "Epoch 119/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0817 - dice_coefficient: 0.9183 - val_loss: 0.1895 - val_dice_coefficient: 0.8105\n",
      "Epoch 120/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0804 - dice_coefficient: 0.9196 - val_loss: 0.1875 - val_dice_coefficient: 0.8125\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 121/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0805 - dice_coefficient: 0.9195 - val_loss: 0.1981 - val_dice_coefficient: 0.8019\n",
      "Epoch 122/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0800 - dice_coefficient: 0.9200 - val_loss: 0.1942 - val_dice_coefficient: 0.8058\n",
      "Epoch 123/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0794 - dice_coefficient: 0.9206 - val_loss: 0.1914 - val_dice_coefficient: 0.8086\n",
      "Epoch 124/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0798 - dice_coefficient: 0.9202 - val_loss: 0.1889 - val_dice_coefficient: 0.8111\n",
      "Epoch 125/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0797 - dice_coefficient: 0.9203 - val_loss: 0.1944 - val_dice_coefficient: 0.8056\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 126/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0796 - dice_coefficient: 0.9204 - val_loss: 0.1923 - val_dice_coefficient: 0.8077\n",
      "Epoch 127/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0798 - dice_coefficient: 0.9202 - val_loss: 0.1884 - val_dice_coefficient: 0.8116\n",
      "Epoch 128/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0807 - dice_coefficient: 0.9193 - val_loss: 0.1971 - val_dice_coefficient: 0.8029\n",
      "Epoch 129/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0792 - dice_coefficient: 0.9208 - val_loss: 0.1943 - val_dice_coefficient: 0.8057\n",
      "Epoch 130/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0792 - dice_coefficient: 0.9208 - val_loss: 0.1913 - val_dice_coefficient: 0.8087\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 131/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0792 - dice_coefficient: 0.9208 - val_loss: 0.1993 - val_dice_coefficient: 0.8007\n",
      "Epoch 132/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1907 - val_dice_coefficient: 0.8093\n",
      "Epoch 133/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1888 - val_dice_coefficient: 0.8112\n",
      "Epoch 134/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0785 - dice_coefficient: 0.9215 - val_loss: 0.1877 - val_dice_coefficient: 0.8123\n",
      "Epoch 135/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1927 - val_dice_coefficient: 0.8073\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 136/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0780 - dice_coefficient: 0.9220 - val_loss: 0.1899 - val_dice_coefficient: 0.8101\n",
      "Epoch 137/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0779 - dice_coefficient: 0.9221 - val_loss: 0.1945 - val_dice_coefficient: 0.8055\n",
      "Epoch 138/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1951 - val_dice_coefficient: 0.8049\n",
      "Epoch 139/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0774 - dice_coefficient: 0.9226 - val_loss: 0.1900 - val_dice_coefficient: 0.8100\n",
      "Epoch 140/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0766 - dice_coefficient: 0.9234 - val_loss: 0.1942 - val_dice_coefficient: 0.8058\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 141/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0775 - dice_coefficient: 0.9225 - val_loss: 0.1962 - val_dice_coefficient: 0.8038\n",
      "Epoch 142/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0762 - dice_coefficient: 0.9238 - val_loss: 0.1893 - val_dice_coefficient: 0.8107\n",
      "Epoch 143/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0759 - dice_coefficient: 0.9241 - val_loss: 0.1934 - val_dice_coefficient: 0.8066\n",
      "Epoch 144/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0764 - dice_coefficient: 0.9236 - val_loss: 0.1896 - val_dice_coefficient: 0.8104\n",
      "Epoch 145/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0774 - dice_coefficient: 0.9226 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 146/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0765 - dice_coefficient: 0.9235 - val_loss: 0.1876 - val_dice_coefficient: 0.8124\n",
      "Epoch 147/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0757 - dice_coefficient: 0.9243 - val_loss: 0.1885 - val_dice_coefficient: 0.8115\n",
      "Epoch 148/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0759 - dice_coefficient: 0.9241 - val_loss: 0.1994 - val_dice_coefficient: 0.8006\n",
      "Epoch 149/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0770 - dice_coefficient: 0.9230 - val_loss: 0.2210 - val_dice_coefficient: 0.7790\n",
      "Epoch 150/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0762 - dice_coefficient: 0.9238 - val_loss: 0.1871 - val_dice_coefficient: 0.8129\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 151/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0758 - dice_coefficient: 0.9242 - val_loss: 0.1901 - val_dice_coefficient: 0.8099\n",
      "Epoch 152/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0754 - dice_coefficient: 0.9246 - val_loss: 0.1842 - val_dice_coefficient: 0.8158\n",
      "Epoch 153/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0760 - dice_coefficient: 0.9240 - val_loss: 0.1876 - val_dice_coefficient: 0.8124\n",
      "Epoch 154/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0763 - dice_coefficient: 0.9237 - val_loss: 0.1918 - val_dice_coefficient: 0.8082\n",
      "Epoch 155/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0760 - dice_coefficient: 0.9240 - val_loss: 0.1917 - val_dice_coefficient: 0.8083\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 156/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0753 - dice_coefficient: 0.9247 - val_loss: 0.1907 - val_dice_coefficient: 0.8093\n",
      "Epoch 157/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0745 - dice_coefficient: 0.9255 - val_loss: 0.1915 - val_dice_coefficient: 0.8085\n",
      "Epoch 158/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0738 - dice_coefficient: 0.9262 - val_loss: 0.2018 - val_dice_coefficient: 0.7982\n",
      "Epoch 159/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0739 - dice_coefficient: 0.9261 - val_loss: 0.1925 - val_dice_coefficient: 0.8075\n",
      "Epoch 160/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0740 - dice_coefficient: 0.9260 - val_loss: 0.1975 - val_dice_coefficient: 0.8025\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 161/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0741 - dice_coefficient: 0.9259 - val_loss: 0.1946 - val_dice_coefficient: 0.8054\n",
      "Epoch 162/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0744 - dice_coefficient: 0.9256 - val_loss: 0.1920 - val_dice_coefficient: 0.8080\n",
      "Epoch 163/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0736 - dice_coefficient: 0.9264 - val_loss: 0.1909 - val_dice_coefficient: 0.8091\n",
      "Epoch 164/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0729 - dice_coefficient: 0.9271 - val_loss: 0.1879 - val_dice_coefficient: 0.8121\n",
      "Epoch 165/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1914 - val_dice_coefficient: 0.8086\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 166/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1911 - val_dice_coefficient: 0.8089\n",
      "Epoch 167/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0733 - dice_coefficient: 0.9267 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "Epoch 168/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1934 - val_dice_coefficient: 0.8066\n",
      "Epoch 169/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0728 - dice_coefficient: 0.9272 - val_loss: 0.1968 - val_dice_coefficient: 0.8032\n",
      "Epoch 170/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0724 - dice_coefficient: 0.9276 - val_loss: 0.1868 - val_dice_coefficient: 0.8132\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 171/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0714 - dice_coefficient: 0.9286 - val_loss: 0.1887 - val_dice_coefficient: 0.8113\n",
      "Epoch 172/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0727 - dice_coefficient: 0.9273 - val_loss: 0.1867 - val_dice_coefficient: 0.8133\n",
      "Epoch 173/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0711 - dice_coefficient: 0.9289 - val_loss: 0.1898 - val_dice_coefficient: 0.8102\n",
      "Epoch 174/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0719 - dice_coefficient: 0.9281 - val_loss: 0.1897 - val_dice_coefficient: 0.8103\n",
      "Epoch 175/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0713 - dice_coefficient: 0.9287 - val_loss: 0.1861 - val_dice_coefficient: 0.8139\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 176/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0718 - dice_coefficient: 0.9282 - val_loss: 0.2111 - val_dice_coefficient: 0.7889\n",
      "Epoch 177/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0708 - dice_coefficient: 0.9292 - val_loss: 0.1920 - val_dice_coefficient: 0.8080\n",
      "Epoch 178/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0713 - dice_coefficient: 0.9287 - val_loss: 0.1899 - val_dice_coefficient: 0.8101\n",
      "Epoch 179/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0710 - dice_coefficient: 0.9290 - val_loss: 0.1869 - val_dice_coefficient: 0.8131\n",
      "Epoch 180/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0698 - dice_coefficient: 0.9302 - val_loss: 0.1924 - val_dice_coefficient: 0.8076\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 181/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0703 - dice_coefficient: 0.9297 - val_loss: 0.1854 - val_dice_coefficient: 0.8146\n",
      "Epoch 182/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0694 - dice_coefficient: 0.9306 - val_loss: 0.1869 - val_dice_coefficient: 0.8131\n",
      "Epoch 183/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0704 - dice_coefficient: 0.9296 - val_loss: 0.1884 - val_dice_coefficient: 0.8116\n",
      "Epoch 184/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0707 - dice_coefficient: 0.9293 - val_loss: 0.1923 - val_dice_coefficient: 0.8077\n",
      "Epoch 185/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0705 - dice_coefficient: 0.9295 - val_loss: 0.1897 - val_dice_coefficient: 0.8103\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 186/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0694 - dice_coefficient: 0.9306 - val_loss: 0.1937 - val_dice_coefficient: 0.8063\n",
      "Epoch 187/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0689 - dice_coefficient: 0.9311 - val_loss: 0.1872 - val_dice_coefficient: 0.8128\n",
      "Epoch 188/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0694 - dice_coefficient: 0.9306 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 189/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0686 - dice_coefficient: 0.9314 - val_loss: 0.1853 - val_dice_coefficient: 0.8147\n",
      "Epoch 190/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0681 - dice_coefficient: 0.9319 - val_loss: 0.1897 - val_dice_coefficient: 0.8103\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 191/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0689 - dice_coefficient: 0.9311 - val_loss: 0.2105 - val_dice_coefficient: 0.7895\n",
      "Epoch 192/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0684 - dice_coefficient: 0.9316 - val_loss: 0.1904 - val_dice_coefficient: 0.8096\n",
      "Epoch 193/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0682 - dice_coefficient: 0.9318 - val_loss: 0.1901 - val_dice_coefficient: 0.8099\n",
      "Epoch 194/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0678 - dice_coefficient: 0.9322 - val_loss: 0.1886 - val_dice_coefficient: 0.8114\n",
      "Epoch 195/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0675 - dice_coefficient: 0.9325 - val_loss: 0.1846 - val_dice_coefficient: 0.8154\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 196/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0686 - dice_coefficient: 0.9314 - val_loss: 0.1903 - val_dice_coefficient: 0.8097\n",
      "Epoch 197/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0675 - dice_coefficient: 0.9325 - val_loss: 0.1865 - val_dice_coefficient: 0.8135\n",
      "Epoch 198/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0674 - dice_coefficient: 0.9326 - val_loss: 0.1874 - val_dice_coefficient: 0.8126\n",
      "Epoch 199/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0673 - dice_coefficient: 0.9327 - val_loss: 0.1924 - val_dice_coefficient: 0.8076\n",
      "Epoch 200/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0677 - dice_coefficient: 0.9323 - val_loss: 0.1964 - val_dice_coefficient: 0.8036\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 201/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0682 - dice_coefficient: 0.9318 - val_loss: 0.1845 - val_dice_coefficient: 0.8155\n",
      "Epoch 202/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0673 - dice_coefficient: 0.9327 - val_loss: 0.1847 - val_dice_coefficient: 0.8153\n",
      "Epoch 203/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0670 - dice_coefficient: 0.9330 - val_loss: 0.1935 - val_dice_coefficient: 0.8065\n",
      "Epoch 204/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0672 - dice_coefficient: 0.9328 - val_loss: 0.1918 - val_dice_coefficient: 0.8082\n",
      "Epoch 205/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0675 - dice_coefficient: 0.9325 - val_loss: 0.1881 - val_dice_coefficient: 0.8119\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 206/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0663 - dice_coefficient: 0.9337 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "Epoch 207/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0672 - dice_coefficient: 0.9328 - val_loss: 0.1931 - val_dice_coefficient: 0.8069\n",
      "Epoch 208/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0665 - dice_coefficient: 0.9335 - val_loss: 0.1873 - val_dice_coefficient: 0.8127\n",
      "Epoch 209/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0668 - dice_coefficient: 0.9332 - val_loss: 0.1857 - val_dice_coefficient: 0.8143\n",
      "Epoch 210/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0654 - dice_coefficient: 0.9346 - val_loss: 0.1877 - val_dice_coefficient: 0.8123\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 211/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0662 - dice_coefficient: 0.9338 - val_loss: 0.1888 - val_dice_coefficient: 0.8112\n",
      "Epoch 212/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0662 - dice_coefficient: 0.9338 - val_loss: 0.1906 - val_dice_coefficient: 0.8094\n",
      "Epoch 213/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0661 - dice_coefficient: 0.9339 - val_loss: 0.1892 - val_dice_coefficient: 0.8108\n",
      "Epoch 214/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0663 - dice_coefficient: 0.9337 - val_loss: 0.1902 - val_dice_coefficient: 0.8098\n",
      "Epoch 215/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0665 - dice_coefficient: 0.9335 - val_loss: 0.1893 - val_dice_coefficient: 0.8107\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 216/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0652 - dice_coefficient: 0.9348 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "Epoch 217/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0647 - dice_coefficient: 0.9353 - val_loss: 0.1892 - val_dice_coefficient: 0.8108\n",
      "Epoch 218/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0651 - dice_coefficient: 0.9349 - val_loss: 0.1947 - val_dice_coefficient: 0.8053\n",
      "Epoch 219/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0642 - dice_coefficient: 0.9358 - val_loss: 0.1854 - val_dice_coefficient: 0.8146\n",
      "Epoch 220/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0650 - dice_coefficient: 0.9350 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 221/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0636 - dice_coefficient: 0.9364 - val_loss: 0.1854 - val_dice_coefficient: 0.8146\n",
      "Epoch 222/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0635 - dice_coefficient: 0.9365 - val_loss: 0.1927 - val_dice_coefficient: 0.8073\n",
      "Epoch 223/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0646 - dice_coefficient: 0.9354 - val_loss: 0.1869 - val_dice_coefficient: 0.8131\n",
      "Epoch 224/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0639 - dice_coefficient: 0.9361 - val_loss: 0.1875 - val_dice_coefficient: 0.8125\n",
      "Epoch 225/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0637 - dice_coefficient: 0.9363 - val_loss: 0.1877 - val_dice_coefficient: 0.8123\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 226/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0634 - dice_coefficient: 0.9366 - val_loss: 0.1918 - val_dice_coefficient: 0.8082\n",
      "Epoch 227/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0635 - dice_coefficient: 0.9365 - val_loss: 0.1874 - val_dice_coefficient: 0.8126\n",
      "Epoch 228/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0647 - dice_coefficient: 0.9353 - val_loss: 0.1872 - val_dice_coefficient: 0.8128\n",
      "Epoch 229/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0638 - dice_coefficient: 0.9362 - val_loss: 0.1855 - val_dice_coefficient: 0.8145\n",
      "Epoch 230/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0629 - dice_coefficient: 0.9371 - val_loss: 0.1851 - val_dice_coefficient: 0.8149\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 231/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0621 - dice_coefficient: 0.9379 - val_loss: 0.1836 - val_dice_coefficient: 0.8164\n",
      "Epoch 232/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0617 - dice_coefficient: 0.9383 - val_loss: 0.1852 - val_dice_coefficient: 0.8148\n",
      "Epoch 233/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0616 - dice_coefficient: 0.9384 - val_loss: 0.1869 - val_dice_coefficient: 0.8131\n",
      "Epoch 234/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0622 - dice_coefficient: 0.9378 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "Epoch 235/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0618 - dice_coefficient: 0.9382 - val_loss: 0.1993 - val_dice_coefficient: 0.8007\n",
      "Epoch 236/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0619 - dice_coefficient: 0.9381 - val_loss: 0.1893 - val_dice_coefficient: 0.8107\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 237/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0618 - dice_coefficient: 0.9382 - val_loss: 0.1836 - val_dice_coefficient: 0.8164\n",
      "Epoch 238/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0620 - dice_coefficient: 0.9380 - val_loss: 0.1876 - val_dice_coefficient: 0.8124\n",
      "Epoch 239/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0616 - dice_coefficient: 0.9384 - val_loss: 0.1942 - val_dice_coefficient: 0.8058\n",
      "Epoch 240/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0624 - dice_coefficient: 0.9376 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 241/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0612 - dice_coefficient: 0.9388 - val_loss: 0.1917 - val_dice_coefficient: 0.8083\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 242/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0613 - dice_coefficient: 0.9387 - val_loss: 0.1942 - val_dice_coefficient: 0.8058\n",
      "Epoch 243/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0617 - dice_coefficient: 0.9383 - val_loss: 0.1922 - val_dice_coefficient: 0.8078\n",
      "Epoch 244/250\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.0614 - dice_coefficient: 0.9386 - val_loss: 0.1874 - val_dice_coefficient: 0.8126\n",
      "Epoch 245/250\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0614 - dice_coefficient: 0.9386 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "Epoch 246/250\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0624 - dice_coefficient: 0.9376 - val_loss: 0.1903 - val_dice_coefficient: 0.8097\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 247/250\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0608 - dice_coefficient: 0.9392 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 248/250\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0603 - dice_coefficient: 0.9397 - val_loss: 0.1896 - val_dice_coefficient: 0.8104\n",
      "Epoch 249/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0601 - dice_coefficient: 0.9399 - val_loss: 0.1832 - val_dice_coefficient: 0.8168\n",
      "Epoch 250/250\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0599 - dice_coefficient: 0.9401 - val_loss: 0.1871 - val_dice_coefficient: 0.8129\n",
      "TRAIN: (62,) TEST: (20,)\n",
      "Train on 62 samples, validate on 20 samples\n",
      "Epoch 1/250\n",
      "62/62 [==============================] - 37s 602ms/step - loss: 0.8135 - dice_coefficient: 0.1865 - val_loss: 0.8721 - val_dice_coefficient: 0.1279\n",
      "Epoch 2/250\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.4981 - dice_coefficient: 0.5019 - val_loss: 0.7078 - val_dice_coefficient: 0.2922\n",
      "Epoch 3/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.3567 - dice_coefficient: 0.6433 - val_loss: 0.4481 - val_dice_coefficient: 0.5519\n",
      "Epoch 4/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.3213 - dice_coefficient: 0.6787 - val_loss: 0.4019 - val_dice_coefficient: 0.5981\n",
      "Epoch 5/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.2551 - dice_coefficient: 0.7449 - val_loss: 0.3578 - val_dice_coefficient: 0.6422\n",
      "Epoch 6/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.2272 - dice_coefficient: 0.7728 - val_loss: 0.4131 - val_dice_coefficient: 0.5869\n",
      "Epoch 7/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.2089 - dice_coefficient: 0.7911 - val_loss: 0.3283 - val_dice_coefficient: 0.6717\n",
      "Epoch 8/250\n",
      "62/62 [==============================] - 14s 228ms/step - loss: 0.2017 - dice_coefficient: 0.7983 - val_loss: 0.2521 - val_dice_coefficient: 0.7479\n",
      "Epoch 9/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1953 - dice_coefficient: 0.8047 - val_loss: 0.3264 - val_dice_coefficient: 0.6736\n",
      "Epoch 10/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1820 - dice_coefficient: 0.8180 - val_loss: 0.2965 - val_dice_coefficient: 0.7035\n",
      "Epoch 11/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1668 - dice_coefficient: 0.8332 - val_loss: 0.2762 - val_dice_coefficient: 0.7238\n",
      "Epoch 12/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1647 - dice_coefficient: 0.8353 - val_loss: 0.2617 - val_dice_coefficient: 0.7383\n",
      "Epoch 13/250\n",
      "62/62 [==============================] - 15s 247ms/step - loss: 0.1616 - dice_coefficient: 0.8384 - val_loss: 0.2384 - val_dice_coefficient: 0.7616\n",
      "Epoch 14/250\n",
      "62/62 [==============================] - 15s 234ms/step - loss: 0.1565 - dice_coefficient: 0.8435 - val_loss: 0.2387 - val_dice_coefficient: 0.7613\n",
      "Epoch 15/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1505 - dice_coefficient: 0.8495 - val_loss: 0.2347 - val_dice_coefficient: 0.7653\n",
      "Epoch 16/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1449 - dice_coefficient: 0.8551 - val_loss: 0.2154 - val_dice_coefficient: 0.7846\n",
      "Epoch 17/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1396 - dice_coefficient: 0.8604 - val_loss: 0.2231 - val_dice_coefficient: 0.7769\n",
      "Epoch 18/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1395 - dice_coefficient: 0.8605 - val_loss: 0.2181 - val_dice_coefficient: 0.7819\n",
      "Epoch 19/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1398 - dice_coefficient: 0.8602 - val_loss: 0.2056 - val_dice_coefficient: 0.7944\n",
      "Epoch 20/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1392 - dice_coefficient: 0.8608 - val_loss: 0.2472 - val_dice_coefficient: 0.7528\n",
      "Epoch 21/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1462 - dice_coefficient: 0.8538 - val_loss: 0.3903 - val_dice_coefficient: 0.6097\n",
      "Epoch 22/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1523 - dice_coefficient: 0.8477 - val_loss: 0.2081 - val_dice_coefficient: 0.7919\n",
      "Epoch 23/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1441 - dice_coefficient: 0.8559 - val_loss: 0.2113 - val_dice_coefficient: 0.7887\n",
      "Epoch 24/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1382 - dice_coefficient: 0.8618 - val_loss: 0.2266 - val_dice_coefficient: 0.7734\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 25/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.1331 - dice_coefficient: 0.8669 - val_loss: 0.1919 - val_dice_coefficient: 0.8081\n",
      "Epoch 26/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1243 - dice_coefficient: 0.8757 - val_loss: 0.2012 - val_dice_coefficient: 0.7988\n",
      "Epoch 27/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1217 - dice_coefficient: 0.8783 - val_loss: 0.2071 - val_dice_coefficient: 0.7929\n",
      "Epoch 28/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1195 - dice_coefficient: 0.8805 - val_loss: 0.1998 - val_dice_coefficient: 0.8002\n",
      "Epoch 29/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1182 - dice_coefficient: 0.8818 - val_loss: 0.2084 - val_dice_coefficient: 0.7916\n",
      "Epoch 30/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1179 - dice_coefficient: 0.8821 - val_loss: 0.2022 - val_dice_coefficient: 0.7978\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 31/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1152 - dice_coefficient: 0.8848 - val_loss: 0.1994 - val_dice_coefficient: 0.8006\n",
      "Epoch 32/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1130 - dice_coefficient: 0.8870 - val_loss: 0.1988 - val_dice_coefficient: 0.8012\n",
      "Epoch 33/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1119 - dice_coefficient: 0.8881 - val_loss: 0.1927 - val_dice_coefficient: 0.8073\n",
      "Epoch 34/250\n",
      "62/62 [==============================] - 14s 228ms/step - loss: 0.1107 - dice_coefficient: 0.8893 - val_loss: 0.1889 - val_dice_coefficient: 0.8111\n",
      "Epoch 35/250\n",
      "62/62 [==============================] - 14s 233ms/step - loss: 0.1114 - dice_coefficient: 0.8886 - val_loss: 0.2006 - val_dice_coefficient: 0.7994\n",
      "Epoch 36/250\n",
      "62/62 [==============================] - 14s 230ms/step - loss: 0.1090 - dice_coefficient: 0.8910 - val_loss: 0.2033 - val_dice_coefficient: 0.7967\n",
      "Epoch 37/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1085 - dice_coefficient: 0.8915 - val_loss: 0.1859 - val_dice_coefficient: 0.8141\n",
      "Epoch 38/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1079 - dice_coefficient: 0.8921 - val_loss: 0.1910 - val_dice_coefficient: 0.8090\n",
      "Epoch 39/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1069 - dice_coefficient: 0.8931 - val_loss: 0.1933 - val_dice_coefficient: 0.8067\n",
      "Epoch 40/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1061 - dice_coefficient: 0.8939 - val_loss: 0.1955 - val_dice_coefficient: 0.8045\n",
      "Epoch 41/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1063 - dice_coefficient: 0.8937 - val_loss: 0.1949 - val_dice_coefficient: 0.8051\n",
      "Epoch 42/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1059 - dice_coefficient: 0.8941 - val_loss: 0.1850 - val_dice_coefficient: 0.8150\n",
      "Epoch 43/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1040 - dice_coefficient: 0.8960 - val_loss: 0.1879 - val_dice_coefficient: 0.8121\n",
      "Epoch 44/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1029 - dice_coefficient: 0.8971 - val_loss: 0.1879 - val_dice_coefficient: 0.8121\n",
      "Epoch 45/250\n",
      "62/62 [==============================] - 14s 229ms/step - loss: 0.1039 - dice_coefficient: 0.8961 - val_loss: 0.1953 - val_dice_coefficient: 0.8047\n",
      "Epoch 46/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1048 - dice_coefficient: 0.8952 - val_loss: 0.1922 - val_dice_coefficient: 0.8078\n",
      "Epoch 47/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1042 - dice_coefficient: 0.8958 - val_loss: 0.2012 - val_dice_coefficient: 0.7988\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 48/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1021 - dice_coefficient: 0.8979 - val_loss: 0.1956 - val_dice_coefficient: 0.8044\n",
      "Epoch 49/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1009 - dice_coefficient: 0.8991 - val_loss: 0.1952 - val_dice_coefficient: 0.8048\n",
      "Epoch 50/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1000 - dice_coefficient: 0.9000 - val_loss: 0.1960 - val_dice_coefficient: 0.8040\n",
      "Epoch 51/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1001 - dice_coefficient: 0.8999 - val_loss: 0.1952 - val_dice_coefficient: 0.8048\n",
      "Epoch 52/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0995 - dice_coefficient: 0.9005 - val_loss: 0.1954 - val_dice_coefficient: 0.8046\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 53/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0992 - dice_coefficient: 0.9008 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "Epoch 54/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0981 - dice_coefficient: 0.9019 - val_loss: 0.1908 - val_dice_coefficient: 0.8092\n",
      "Epoch 55/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0977 - dice_coefficient: 0.9023 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 56/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0974 - dice_coefficient: 0.9026 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "Epoch 57/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0970 - dice_coefficient: 0.9030 - val_loss: 0.1916 - val_dice_coefficient: 0.8084\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 58/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0966 - dice_coefficient: 0.9034 - val_loss: 0.1977 - val_dice_coefficient: 0.8023\n",
      "Epoch 59/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0966 - dice_coefficient: 0.9034 - val_loss: 0.1951 - val_dice_coefficient: 0.8049\n",
      "Epoch 60/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0951 - dice_coefficient: 0.9049 - val_loss: 0.1900 - val_dice_coefficient: 0.8100\n",
      "Epoch 61/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0957 - dice_coefficient: 0.9043 - val_loss: 0.1882 - val_dice_coefficient: 0.8118\n",
      "Epoch 62/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0951 - dice_coefficient: 0.9049 - val_loss: 0.1907 - val_dice_coefficient: 0.8093\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 63/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0950 - dice_coefficient: 0.9050 - val_loss: 0.1934 - val_dice_coefficient: 0.8066\n",
      "Epoch 64/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0950 - dice_coefficient: 0.9050 - val_loss: 0.1935 - val_dice_coefficient: 0.8065\n",
      "Epoch 65/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0947 - dice_coefficient: 0.9053 - val_loss: 0.1902 - val_dice_coefficient: 0.8098\n",
      "Epoch 66/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0945 - dice_coefficient: 0.9055 - val_loss: 0.1884 - val_dice_coefficient: 0.8116\n",
      "Epoch 67/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0942 - dice_coefficient: 0.9058 - val_loss: 0.1875 - val_dice_coefficient: 0.8125\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 68/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0938 - dice_coefficient: 0.9062 - val_loss: 0.1865 - val_dice_coefficient: 0.8135\n",
      "Epoch 69/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0937 - dice_coefficient: 0.9063 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 70/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0947 - dice_coefficient: 0.9053 - val_loss: 0.1867 - val_dice_coefficient: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0926 - dice_coefficient: 0.9074 - val_loss: 0.1855 - val_dice_coefficient: 0.8145\n",
      "Epoch 72/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0928 - dice_coefficient: 0.9072 - val_loss: 0.1852 - val_dice_coefficient: 0.8148\n",
      "Epoch 73/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0918 - dice_coefficient: 0.9082 - val_loss: 0.1853 - val_dice_coefficient: 0.8147\n",
      "Epoch 74/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0929 - dice_coefficient: 0.9071 - val_loss: 0.1872 - val_dice_coefficient: 0.8128\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 75/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0918 - dice_coefficient: 0.9082 - val_loss: 0.1860 - val_dice_coefficient: 0.8140\n",
      "Epoch 76/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0918 - dice_coefficient: 0.9082 - val_loss: 0.1880 - val_dice_coefficient: 0.8120\n",
      "Epoch 77/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0911 - dice_coefficient: 0.9089 - val_loss: 0.1858 - val_dice_coefficient: 0.8142\n",
      "Epoch 78/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0926 - dice_coefficient: 0.9074 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "Epoch 79/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0916 - dice_coefficient: 0.9084 - val_loss: 0.1859 - val_dice_coefficient: 0.8141\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 80/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0917 - dice_coefficient: 0.9083 - val_loss: 0.1907 - val_dice_coefficient: 0.8093\n",
      "Epoch 81/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0921 - dice_coefficient: 0.9079 - val_loss: 0.1849 - val_dice_coefficient: 0.8151\n",
      "Epoch 82/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0911 - dice_coefficient: 0.9089 - val_loss: 0.1872 - val_dice_coefficient: 0.8128\n",
      "Epoch 83/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0912 - dice_coefficient: 0.9088 - val_loss: 0.1868 - val_dice_coefficient: 0.8132\n",
      "Epoch 84/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0896 - dice_coefficient: 0.9104 - val_loss: 0.1876 - val_dice_coefficient: 0.8124\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 85/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0896 - dice_coefficient: 0.9104 - val_loss: 0.1921 - val_dice_coefficient: 0.8079\n",
      "Epoch 86/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0904 - dice_coefficient: 0.9096 - val_loss: 0.1868 - val_dice_coefficient: 0.8132\n",
      "Epoch 87/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0907 - dice_coefficient: 0.9093 - val_loss: 0.1813 - val_dice_coefficient: 0.8187\n",
      "Epoch 88/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0905 - dice_coefficient: 0.9095 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "Epoch 89/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0891 - dice_coefficient: 0.9109 - val_loss: 0.1900 - val_dice_coefficient: 0.8100\n",
      "Epoch 90/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0890 - dice_coefficient: 0.9110 - val_loss: 0.1873 - val_dice_coefficient: 0.8127\n",
      "Epoch 91/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0893 - dice_coefficient: 0.9107 - val_loss: 0.1882 - val_dice_coefficient: 0.8118\n",
      "Epoch 92/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0887 - dice_coefficient: 0.9113 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 93/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0890 - dice_coefficient: 0.9110 - val_loss: 0.1828 - val_dice_coefficient: 0.8172\n",
      "Epoch 94/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0890 - dice_coefficient: 0.9110 - val_loss: 0.1910 - val_dice_coefficient: 0.8090\n",
      "Epoch 95/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0870 - dice_coefficient: 0.9130 - val_loss: 0.1868 - val_dice_coefficient: 0.8132\n",
      "Epoch 96/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0878 - dice_coefficient: 0.9122 - val_loss: 0.1874 - val_dice_coefficient: 0.8126\n",
      "Epoch 97/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0877 - dice_coefficient: 0.9123 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 98/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0878 - dice_coefficient: 0.9122 - val_loss: 0.1859 - val_dice_coefficient: 0.8141\n",
      "Epoch 99/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0874 - dice_coefficient: 0.9126 - val_loss: 0.1882 - val_dice_coefficient: 0.8118\n",
      "Epoch 100/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0875 - dice_coefficient: 0.9125 - val_loss: 0.1931 - val_dice_coefficient: 0.8069\n",
      "Epoch 101/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0866 - dice_coefficient: 0.9134 - val_loss: 0.1894 - val_dice_coefficient: 0.8106\n",
      "Epoch 102/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0871 - dice_coefficient: 0.9129 - val_loss: 0.1797 - val_dice_coefficient: 0.8203\n",
      "Epoch 103/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0878 - dice_coefficient: 0.9122 - val_loss: 0.1841 - val_dice_coefficient: 0.8159\n",
      "Epoch 104/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0866 - dice_coefficient: 0.9134 - val_loss: 0.1858 - val_dice_coefficient: 0.8142\n",
      "Epoch 105/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0869 - dice_coefficient: 0.9131 - val_loss: 0.1829 - val_dice_coefficient: 0.8171\n",
      "Epoch 106/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0866 - dice_coefficient: 0.9134 - val_loss: 0.1843 - val_dice_coefficient: 0.8157\n",
      "Epoch 107/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0854 - dice_coefficient: 0.9146 - val_loss: 0.1871 - val_dice_coefficient: 0.8129\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 108/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0850 - dice_coefficient: 0.9150 - val_loss: 0.1836 - val_dice_coefficient: 0.8164\n",
      "Epoch 109/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0855 - dice_coefficient: 0.9145 - val_loss: 0.1887 - val_dice_coefficient: 0.8113\n",
      "Epoch 110/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0857 - dice_coefficient: 0.9143 - val_loss: 0.1898 - val_dice_coefficient: 0.8102\n",
      "Epoch 111/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0855 - dice_coefficient: 0.9145 - val_loss: 0.1906 - val_dice_coefficient: 0.8094\n",
      "Epoch 112/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0845 - dice_coefficient: 0.9155 - val_loss: 0.1809 - val_dice_coefficient: 0.8191\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 113/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0847 - dice_coefficient: 0.9153 - val_loss: 0.1867 - val_dice_coefficient: 0.8133\n",
      "Epoch 114/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0841 - dice_coefficient: 0.9159 - val_loss: 0.1858 - val_dice_coefficient: 0.8142\n",
      "Epoch 115/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0844 - dice_coefficient: 0.9156 - val_loss: 0.1872 - val_dice_coefficient: 0.8128\n",
      "Epoch 116/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0841 - dice_coefficient: 0.9159 - val_loss: 0.1826 - val_dice_coefficient: 0.8174\n",
      "Epoch 117/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0837 - dice_coefficient: 0.9163 - val_loss: 0.1853 - val_dice_coefficient: 0.8147\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 118/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0835 - dice_coefficient: 0.9165 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 119/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0837 - dice_coefficient: 0.9163 - val_loss: 0.1873 - val_dice_coefficient: 0.8127\n",
      "Epoch 120/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0838 - dice_coefficient: 0.9162 - val_loss: 0.1883 - val_dice_coefficient: 0.8117\n",
      "Epoch 121/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0834 - dice_coefficient: 0.9166 - val_loss: 0.1870 - val_dice_coefficient: 0.8130\n",
      "Epoch 122/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0843 - dice_coefficient: 0.9157 - val_loss: 0.1914 - val_dice_coefficient: 0.8086\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 123/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0834 - dice_coefficient: 0.9166 - val_loss: 0.1912 - val_dice_coefficient: 0.8088\n",
      "Epoch 124/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0831 - dice_coefficient: 0.9169 - val_loss: 0.1830 - val_dice_coefficient: 0.8170\n",
      "Epoch 125/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0825 - dice_coefficient: 0.9175 - val_loss: 0.1830 - val_dice_coefficient: 0.8170\n",
      "Epoch 126/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0820 - dice_coefficient: 0.9180 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "Epoch 127/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0828 - dice_coefficient: 0.9172 - val_loss: 0.1867 - val_dice_coefficient: 0.8133\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 128/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0818 - dice_coefficient: 0.9182 - val_loss: 0.1839 - val_dice_coefficient: 0.8161\n",
      "Epoch 129/250\n",
      "62/62 [==============================] - 14s 232ms/step - loss: 0.0820 - dice_coefficient: 0.9180 - val_loss: 0.1852 - val_dice_coefficient: 0.8148\n",
      "Epoch 130/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0821 - dice_coefficient: 0.9179 - val_loss: 0.1816 - val_dice_coefficient: 0.8184\n",
      "Epoch 131/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0822 - dice_coefficient: 0.9178 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "Epoch 132/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0819 - dice_coefficient: 0.9181 - val_loss: 0.1810 - val_dice_coefficient: 0.8190\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 133/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0810 - dice_coefficient: 0.9190 - val_loss: 0.1862 - val_dice_coefficient: 0.8138\n",
      "Epoch 134/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0808 - dice_coefficient: 0.9192 - val_loss: 0.1836 - val_dice_coefficient: 0.8164\n",
      "Epoch 135/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0807 - dice_coefficient: 0.9193 - val_loss: 0.1820 - val_dice_coefficient: 0.8180\n",
      "Epoch 136/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0820 - dice_coefficient: 0.9180 - val_loss: 0.1862 - val_dice_coefficient: 0.8138\n",
      "Epoch 137/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0809 - dice_coefficient: 0.9191 - val_loss: 0.1831 - val_dice_coefficient: 0.8169\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 138/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0799 - dice_coefficient: 0.9201 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 139/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0798 - dice_coefficient: 0.9202 - val_loss: 0.1817 - val_dice_coefficient: 0.8183\n",
      "Epoch 140/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0801 - dice_coefficient: 0.9199 - val_loss: 0.1820 - val_dice_coefficient: 0.8180\n",
      "Epoch 141/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0796 - dice_coefficient: 0.9204 - val_loss: 0.1820 - val_dice_coefficient: 0.8180\n",
      "Epoch 142/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0797 - dice_coefficient: 0.9203 - val_loss: 0.1798 - val_dice_coefficient: 0.8202\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 143/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1826 - val_dice_coefficient: 0.8174\n",
      "Epoch 144/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0791 - dice_coefficient: 0.9209 - val_loss: 0.1796 - val_dice_coefficient: 0.8204\n",
      "Epoch 145/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0797 - dice_coefficient: 0.9203 - val_loss: 0.1834 - val_dice_coefficient: 0.8166\n",
      "Epoch 146/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1833 - val_dice_coefficient: 0.8167\n",
      "Epoch 147/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0787 - dice_coefficient: 0.9213 - val_loss: 0.1810 - val_dice_coefficient: 0.8190\n",
      "Epoch 148/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1835 - val_dice_coefficient: 0.8165\n",
      "Epoch 149/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1836 - val_dice_coefficient: 0.8164\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 150/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0783 - dice_coefficient: 0.9217 - val_loss: 0.1830 - val_dice_coefficient: 0.8170\n",
      "Epoch 151/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0784 - dice_coefficient: 0.9216 - val_loss: 0.1866 - val_dice_coefficient: 0.8134\n",
      "Epoch 152/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0781 - dice_coefficient: 0.9219 - val_loss: 0.1819 - val_dice_coefficient: 0.8181\n",
      "Epoch 153/250\n",
      "62/62 [==============================] - 15s 245ms/step - loss: 0.0778 - dice_coefficient: 0.9222 - val_loss: 0.1827 - val_dice_coefficient: 0.8173\n",
      "Epoch 154/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0778 - dice_coefficient: 0.9222 - val_loss: 0.1859 - val_dice_coefficient: 0.8141\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 155/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0776 - dice_coefficient: 0.9224 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "Epoch 156/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0774 - dice_coefficient: 0.9226 - val_loss: 0.1827 - val_dice_coefficient: 0.8173\n",
      "Epoch 157/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0773 - dice_coefficient: 0.9227 - val_loss: 0.1799 - val_dice_coefficient: 0.8201\n",
      "Epoch 158/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0783 - dice_coefficient: 0.9217 - val_loss: 0.1820 - val_dice_coefficient: 0.8180\n",
      "Epoch 159/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0762 - dice_coefficient: 0.9238 - val_loss: 0.1842 - val_dice_coefficient: 0.8158\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 160/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0773 - dice_coefficient: 0.9227 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "Epoch 161/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0771 - dice_coefficient: 0.9229 - val_loss: 0.1808 - val_dice_coefficient: 0.8192\n",
      "Epoch 162/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0765 - dice_coefficient: 0.9235 - val_loss: 0.1814 - val_dice_coefficient: 0.8186\n",
      "Epoch 163/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0762 - dice_coefficient: 0.9238 - val_loss: 0.1819 - val_dice_coefficient: 0.8181\n",
      "Epoch 164/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0759 - dice_coefficient: 0.9241 - val_loss: 0.1820 - val_dice_coefficient: 0.8180\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 165/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0761 - dice_coefficient: 0.9239 - val_loss: 0.1839 - val_dice_coefficient: 0.8161\n",
      "Epoch 166/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0760 - dice_coefficient: 0.9240 - val_loss: 0.1805 - val_dice_coefficient: 0.8195\n",
      "Epoch 167/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0758 - dice_coefficient: 0.9242 - val_loss: 0.1842 - val_dice_coefficient: 0.8158\n",
      "Epoch 168/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0754 - dice_coefficient: 0.9246 - val_loss: 0.1811 - val_dice_coefficient: 0.8189\n",
      "Epoch 169/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0752 - dice_coefficient: 0.9248 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 170/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0758 - dice_coefficient: 0.9242 - val_loss: 0.1826 - val_dice_coefficient: 0.8174\n",
      "Epoch 171/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0765 - dice_coefficient: 0.9235 - val_loss: 0.1831 - val_dice_coefficient: 0.8169\n",
      "Epoch 172/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0755 - dice_coefficient: 0.9245 - val_loss: 0.1808 - val_dice_coefficient: 0.8192\n",
      "Epoch 173/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0756 - dice_coefficient: 0.9244 - val_loss: 0.1844 - val_dice_coefficient: 0.8156\n",
      "Epoch 174/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0756 - dice_coefficient: 0.9244 - val_loss: 0.1818 - val_dice_coefficient: 0.8182\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 175/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0750 - dice_coefficient: 0.9250 - val_loss: 0.1856 - val_dice_coefficient: 0.8144\n",
      "Epoch 176/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0745 - dice_coefficient: 0.9255 - val_loss: 0.1800 - val_dice_coefficient: 0.8200\n",
      "Epoch 177/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0752 - dice_coefficient: 0.9248 - val_loss: 0.1840 - val_dice_coefficient: 0.8160\n",
      "Epoch 178/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0743 - dice_coefficient: 0.9257 - val_loss: 0.1845 - val_dice_coefficient: 0.8155\n",
      "Epoch 179/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0741 - dice_coefficient: 0.9259 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 180/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0744 - dice_coefficient: 0.9256 - val_loss: 0.1846 - val_dice_coefficient: 0.8154\n",
      "Epoch 181/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0734 - dice_coefficient: 0.9266 - val_loss: 0.1828 - val_dice_coefficient: 0.8172\n",
      "Epoch 182/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0735 - dice_coefficient: 0.9265 - val_loss: 0.1823 - val_dice_coefficient: 0.8177\n",
      "Epoch 183/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0732 - dice_coefficient: 0.9268 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 184/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0727 - dice_coefficient: 0.9273 - val_loss: 0.1800 - val_dice_coefficient: 0.8200\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 185/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0737 - dice_coefficient: 0.9263 - val_loss: 0.1775 - val_dice_coefficient: 0.8225\n",
      "Epoch 186/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0729 - dice_coefficient: 0.9271 - val_loss: 0.1835 - val_dice_coefficient: 0.8165\n",
      "Epoch 187/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0721 - dice_coefficient: 0.9279 - val_loss: 0.1819 - val_dice_coefficient: 0.8181\n",
      "Epoch 188/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1812 - val_dice_coefficient: 0.8188\n",
      "Epoch 189/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0721 - dice_coefficient: 0.9279 - val_loss: 0.1833 - val_dice_coefficient: 0.8167\n",
      "Epoch 190/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0719 - dice_coefficient: 0.9281 - val_loss: 0.1813 - val_dice_coefficient: 0.8187\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 191/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1827 - val_dice_coefficient: 0.8173\n",
      "Epoch 192/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0727 - dice_coefficient: 0.9273 - val_loss: 0.1835 - val_dice_coefficient: 0.8165\n",
      "Epoch 193/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0721 - dice_coefficient: 0.9279 - val_loss: 0.1849 - val_dice_coefficient: 0.8151\n",
      "Epoch 194/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0716 - dice_coefficient: 0.9284 - val_loss: 0.1827 - val_dice_coefficient: 0.8173\n",
      "Epoch 195/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0715 - dice_coefficient: 0.9285 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 196/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0719 - dice_coefficient: 0.9281 - val_loss: 0.1827 - val_dice_coefficient: 0.8173\n",
      "Epoch 197/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1848 - val_dice_coefficient: 0.8152\n",
      "Epoch 198/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0709 - dice_coefficient: 0.9291 - val_loss: 0.1849 - val_dice_coefficient: 0.8151\n",
      "Epoch 199/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0710 - dice_coefficient: 0.9290 - val_loss: 0.1828 - val_dice_coefficient: 0.8172\n",
      "Epoch 200/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0712 - dice_coefficient: 0.9288 - val_loss: 0.1868 - val_dice_coefficient: 0.8132\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 201/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0710 - dice_coefficient: 0.9290 - val_loss: 0.1795 - val_dice_coefficient: 0.8205\n",
      "Epoch 202/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0712 - dice_coefficient: 0.9288 - val_loss: 0.1808 - val_dice_coefficient: 0.8192\n",
      "Epoch 203/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0708 - dice_coefficient: 0.9292 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 204/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0713 - dice_coefficient: 0.9287 - val_loss: 0.1823 - val_dice_coefficient: 0.8177\n",
      "Epoch 205/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0709 - dice_coefficient: 0.9291 - val_loss: 0.1802 - val_dice_coefficient: 0.8198\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 206/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0708 - dice_coefficient: 0.9292 - val_loss: 0.1830 - val_dice_coefficient: 0.8170\n",
      "Epoch 207/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0701 - dice_coefficient: 0.9299 - val_loss: 0.1832 - val_dice_coefficient: 0.8168\n",
      "Epoch 208/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0703 - dice_coefficient: 0.9297 - val_loss: 0.1780 - val_dice_coefficient: 0.8220\n",
      "Epoch 209/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0696 - dice_coefficient: 0.9304 - val_loss: 0.1771 - val_dice_coefficient: 0.8229\n",
      "Epoch 210/250\n",
      "62/62 [==============================] - 14s 229ms/step - loss: 0.0696 - dice_coefficient: 0.9304 - val_loss: 0.1828 - val_dice_coefficient: 0.8172\n",
      "Epoch 211/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0695 - dice_coefficient: 0.9305 - val_loss: 0.1797 - val_dice_coefficient: 0.8203\n",
      "Epoch 212/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0693 - dice_coefficient: 0.9307 - val_loss: 0.1797 - val_dice_coefficient: 0.8203\n",
      "Epoch 213/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0691 - dice_coefficient: 0.9309 - val_loss: 0.1830 - val_dice_coefficient: 0.8170\n",
      "Epoch 214/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0691 - dice_coefficient: 0.9309 - val_loss: 0.1797 - val_dice_coefficient: 0.8203\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 215/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0682 - dice_coefficient: 0.9318 - val_loss: 0.1801 - val_dice_coefficient: 0.8199\n",
      "Epoch 216/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0690 - dice_coefficient: 0.9310 - val_loss: 0.1800 - val_dice_coefficient: 0.8200\n",
      "Epoch 217/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0694 - dice_coefficient: 0.9306 - val_loss: 0.1804 - val_dice_coefficient: 0.8196\n",
      "Epoch 218/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0693 - dice_coefficient: 0.9307 - val_loss: 0.1818 - val_dice_coefficient: 0.8182\n",
      "Epoch 219/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0687 - dice_coefficient: 0.9313 - val_loss: 0.1806 - val_dice_coefficient: 0.8194\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 220/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0684 - dice_coefficient: 0.9316 - val_loss: 0.1812 - val_dice_coefficient: 0.8188\n",
      "Epoch 221/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0688 - dice_coefficient: 0.9312 - val_loss: 0.1805 - val_dice_coefficient: 0.8195\n",
      "Epoch 222/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0680 - dice_coefficient: 0.9320 - val_loss: 0.1817 - val_dice_coefficient: 0.8183\n",
      "Epoch 223/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0692 - dice_coefficient: 0.9308 - val_loss: 0.1809 - val_dice_coefficient: 0.8191\n",
      "Epoch 224/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0683 - dice_coefficient: 0.9317 - val_loss: 0.1808 - val_dice_coefficient: 0.8192\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 225/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0676 - dice_coefficient: 0.9324 - val_loss: 0.1782 - val_dice_coefficient: 0.8218\n",
      "Epoch 226/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0677 - dice_coefficient: 0.9323 - val_loss: 0.1792 - val_dice_coefficient: 0.8208\n",
      "Epoch 227/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0677 - dice_coefficient: 0.9323 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "Epoch 228/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0678 - dice_coefficient: 0.9322 - val_loss: 0.1828 - val_dice_coefficient: 0.8172\n",
      "Epoch 229/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0669 - dice_coefficient: 0.9331 - val_loss: 0.1802 - val_dice_coefficient: 0.8198\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 230/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0666 - dice_coefficient: 0.9334 - val_loss: 0.1834 - val_dice_coefficient: 0.8166\n",
      "Epoch 231/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.0671 - dice_coefficient: 0.9329 - val_loss: 0.1799 - val_dice_coefficient: 0.8201\n",
      "Epoch 232/250\n",
      "62/62 [==============================] - 15s 234ms/step - loss: 0.0676 - dice_coefficient: 0.9324 - val_loss: 0.1807 - val_dice_coefficient: 0.8193\n",
      "Epoch 233/250\n",
      "62/62 [==============================] - 14s 229ms/step - loss: 0.0671 - dice_coefficient: 0.9329 - val_loss: 0.1823 - val_dice_coefficient: 0.8177\n",
      "Epoch 234/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0667 - dice_coefficient: 0.9333 - val_loss: 0.1800 - val_dice_coefficient: 0.8200\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 235/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0665 - dice_coefficient: 0.9335 - val_loss: 0.1812 - val_dice_coefficient: 0.8188\n",
      "Epoch 236/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0665 - dice_coefficient: 0.9335 - val_loss: 0.1791 - val_dice_coefficient: 0.8209\n",
      "Epoch 237/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0661 - dice_coefficient: 0.9339 - val_loss: 0.1810 - val_dice_coefficient: 0.8190\n",
      "Epoch 238/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0661 - dice_coefficient: 0.9339 - val_loss: 0.1785 - val_dice_coefficient: 0.8215\n",
      "Epoch 239/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0661 - dice_coefficient: 0.9339 - val_loss: 0.1797 - val_dice_coefficient: 0.8203\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 240/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0662 - dice_coefficient: 0.9338 - val_loss: 0.1806 - val_dice_coefficient: 0.8194\n",
      "Epoch 241/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0663 - dice_coefficient: 0.9337 - val_loss: 0.1846 - val_dice_coefficient: 0.8154\n",
      "Epoch 242/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0659 - dice_coefficient: 0.9341 - val_loss: 0.1778 - val_dice_coefficient: 0.8222\n",
      "Epoch 243/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0655 - dice_coefficient: 0.9345 - val_loss: 0.1827 - val_dice_coefficient: 0.8173\n",
      "Epoch 244/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0657 - dice_coefficient: 0.9343 - val_loss: 0.1808 - val_dice_coefficient: 0.8192\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 245/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0646 - dice_coefficient: 0.9354 - val_loss: 0.1793 - val_dice_coefficient: 0.8207\n",
      "Epoch 246/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0658 - dice_coefficient: 0.9342 - val_loss: 0.1825 - val_dice_coefficient: 0.8175\n",
      "Epoch 247/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0655 - dice_coefficient: 0.9345 - val_loss: 0.1822 - val_dice_coefficient: 0.8178\n",
      "Epoch 248/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.0646 - dice_coefficient: 0.9354 - val_loss: 0.1836 - val_dice_coefficient: 0.8164\n",
      "Epoch 249/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0652 - dice_coefficient: 0.9348 - val_loss: 0.1816 - val_dice_coefficient: 0.8184\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 250/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0650 - dice_coefficient: 0.9350 - val_loss: 0.1789 - val_dice_coefficient: 0.8211\n",
      "TRAIN: (62,) TEST: (20,)\n",
      "Train on 62 samples, validate on 20 samples\n",
      "Epoch 1/250\n",
      "62/62 [==============================] - 38s 613ms/step - loss: 0.8239 - dice_coefficient: 0.1761 - val_loss: 0.8789 - val_dice_coefficient: 0.1211\n",
      "Epoch 2/250\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.5373 - dice_coefficient: 0.4627 - val_loss: 0.8498 - val_dice_coefficient: 0.1502\n",
      "Epoch 3/250\n",
      "62/62 [==============================] - 14s 225ms/step - loss: 0.4095 - dice_coefficient: 0.5905 - val_loss: 0.5886 - val_dice_coefficient: 0.4114\n",
      "Epoch 4/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.3347 - dice_coefficient: 0.6653 - val_loss: 0.5756 - val_dice_coefficient: 0.4244\n",
      "Epoch 5/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.2758 - dice_coefficient: 0.7242 - val_loss: 0.3852 - val_dice_coefficient: 0.6148\n",
      "Epoch 6/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.2587 - dice_coefficient: 0.7413 - val_loss: 0.3148 - val_dice_coefficient: 0.6852\n",
      "Epoch 7/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.2322 - dice_coefficient: 0.7678 - val_loss: 0.4736 - val_dice_coefficient: 0.5264\n",
      "Epoch 8/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.2157 - dice_coefficient: 0.7843 - val_loss: 0.2847 - val_dice_coefficient: 0.7153\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1918 - dice_coefficient: 0.8082 - val_loss: 0.2647 - val_dice_coefficient: 0.7353\n",
      "Epoch 10/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1795 - dice_coefficient: 0.8205 - val_loss: 0.2169 - val_dice_coefficient: 0.7831\n",
      "Epoch 11/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1738 - dice_coefficient: 0.8262 - val_loss: 0.3518 - val_dice_coefficient: 0.6482\n",
      "Epoch 12/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1667 - dice_coefficient: 0.8333 - val_loss: 0.3152 - val_dice_coefficient: 0.6848\n",
      "Epoch 13/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1627 - dice_coefficient: 0.8373 - val_loss: 0.3063 - val_dice_coefficient: 0.6937\n",
      "Epoch 14/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1610 - dice_coefficient: 0.8390 - val_loss: 0.2312 - val_dice_coefficient: 0.7688\n",
      "Epoch 15/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1552 - dice_coefficient: 0.8448 - val_loss: 0.4390 - val_dice_coefficient: 0.5610\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 16/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1492 - dice_coefficient: 0.8508 - val_loss: 0.2280 - val_dice_coefficient: 0.7720\n",
      "Epoch 17/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1435 - dice_coefficient: 0.8565 - val_loss: 0.3326 - val_dice_coefficient: 0.6674\n",
      "Epoch 18/250\n",
      "62/62 [==============================] - 14s 226ms/step - loss: 0.1390 - dice_coefficient: 0.8610 - val_loss: 0.2672 - val_dice_coefficient: 0.7328\n",
      "Epoch 19/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1356 - dice_coefficient: 0.8644 - val_loss: 0.2017 - val_dice_coefficient: 0.7983\n",
      "Epoch 20/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1366 - dice_coefficient: 0.8634 - val_loss: 0.1959 - val_dice_coefficient: 0.8041\n",
      "Epoch 21/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1340 - dice_coefficient: 0.8660 - val_loss: 0.2502 - val_dice_coefficient: 0.7498\n",
      "Epoch 22/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1305 - dice_coefficient: 0.8695 - val_loss: 0.2468 - val_dice_coefficient: 0.7532\n",
      "Epoch 23/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1296 - dice_coefficient: 0.8704 - val_loss: 0.2247 - val_dice_coefficient: 0.7753\n",
      "Epoch 24/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1262 - dice_coefficient: 0.8738 - val_loss: 0.2147 - val_dice_coefficient: 0.7853\n",
      "Epoch 25/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1286 - dice_coefficient: 0.8714 - val_loss: 0.1913 - val_dice_coefficient: 0.8087\n",
      "Epoch 26/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1269 - dice_coefficient: 0.8731 - val_loss: 0.1955 - val_dice_coefficient: 0.8045\n",
      "Epoch 27/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1262 - dice_coefficient: 0.8738 - val_loss: 0.1917 - val_dice_coefficient: 0.8083\n",
      "Epoch 28/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1281 - dice_coefficient: 0.8719 - val_loss: 0.2109 - val_dice_coefficient: 0.7891\n",
      "Epoch 29/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1274 - dice_coefficient: 0.8726 - val_loss: 0.1885 - val_dice_coefficient: 0.8115\n",
      "Epoch 30/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1268 - dice_coefficient: 0.8732 - val_loss: 0.2017 - val_dice_coefficient: 0.7983\n",
      "Epoch 31/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1252 - dice_coefficient: 0.8748 - val_loss: 0.1829 - val_dice_coefficient: 0.8171\n",
      "Epoch 32/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1235 - dice_coefficient: 0.8765 - val_loss: 0.1864 - val_dice_coefficient: 0.8136\n",
      "Epoch 33/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1214 - dice_coefficient: 0.8786 - val_loss: 0.1991 - val_dice_coefficient: 0.8009\n",
      "Epoch 34/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1193 - dice_coefficient: 0.8807 - val_loss: 0.1926 - val_dice_coefficient: 0.8074\n",
      "Epoch 35/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1175 - dice_coefficient: 0.8825 - val_loss: 0.1821 - val_dice_coefficient: 0.8179\n",
      "Epoch 36/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1160 - dice_coefficient: 0.8840 - val_loss: 0.1788 - val_dice_coefficient: 0.8212\n",
      "Epoch 37/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1145 - dice_coefficient: 0.8855 - val_loss: 0.2221 - val_dice_coefficient: 0.7779\n",
      "Epoch 38/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1167 - dice_coefficient: 0.8833 - val_loss: 0.1821 - val_dice_coefficient: 0.8179\n",
      "Epoch 39/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1162 - dice_coefficient: 0.8838 - val_loss: 0.1787 - val_dice_coefficient: 0.8213\n",
      "Epoch 40/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1143 - dice_coefficient: 0.8857 - val_loss: 0.1973 - val_dice_coefficient: 0.8027\n",
      "Epoch 41/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1157 - dice_coefficient: 0.8843 - val_loss: 0.1843 - val_dice_coefficient: 0.8157\n",
      "Epoch 42/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1143 - dice_coefficient: 0.8857 - val_loss: 0.1786 - val_dice_coefficient: 0.8214\n",
      "Epoch 43/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1145 - dice_coefficient: 0.8855 - val_loss: 0.1746 - val_dice_coefficient: 0.8254\n",
      "Epoch 44/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1113 - dice_coefficient: 0.8887 - val_loss: 0.1732 - val_dice_coefficient: 0.8268\n",
      "Epoch 45/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1098 - dice_coefficient: 0.8902 - val_loss: 0.2385 - val_dice_coefficient: 0.7615\n",
      "Epoch 46/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1082 - dice_coefficient: 0.8918 - val_loss: 0.1890 - val_dice_coefficient: 0.8110\n",
      "Epoch 47/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1084 - dice_coefficient: 0.8916 - val_loss: 0.1974 - val_dice_coefficient: 0.8026\n",
      "Epoch 48/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1087 - dice_coefficient: 0.8913 - val_loss: 0.1745 - val_dice_coefficient: 0.8255\n",
      "Epoch 49/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1073 - dice_coefficient: 0.8927 - val_loss: 0.1767 - val_dice_coefficient: 0.8233\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 50/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1059 - dice_coefficient: 0.8941 - val_loss: 0.1749 - val_dice_coefficient: 0.8251\n",
      "Epoch 51/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1018 - dice_coefficient: 0.8982 - val_loss: 0.1755 - val_dice_coefficient: 0.8245\n",
      "Epoch 52/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.1006 - dice_coefficient: 0.8994 - val_loss: 0.1778 - val_dice_coefficient: 0.8222\n",
      "Epoch 53/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0994 - dice_coefficient: 0.9006 - val_loss: 0.1751 - val_dice_coefficient: 0.8249\n",
      "Epoch 54/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0983 - dice_coefficient: 0.9017 - val_loss: 0.1677 - val_dice_coefficient: 0.8323\n",
      "Epoch 55/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0983 - dice_coefficient: 0.9017 - val_loss: 0.1696 - val_dice_coefficient: 0.8304\n",
      "Epoch 56/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0984 - dice_coefficient: 0.9016 - val_loss: 0.1734 - val_dice_coefficient: 0.8266\n",
      "Epoch 57/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0967 - dice_coefficient: 0.9033 - val_loss: 0.1761 - val_dice_coefficient: 0.8239\n",
      "Epoch 58/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0965 - dice_coefficient: 0.9035 - val_loss: 0.1765 - val_dice_coefficient: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0973 - dice_coefficient: 0.9027 - val_loss: 0.1702 - val_dice_coefficient: 0.8298\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 60/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0961 - dice_coefficient: 0.9039 - val_loss: 0.1731 - val_dice_coefficient: 0.8269\n",
      "Epoch 61/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0941 - dice_coefficient: 0.9059 - val_loss: 0.1729 - val_dice_coefficient: 0.8271\n",
      "Epoch 62/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0945 - dice_coefficient: 0.9055 - val_loss: 0.1711 - val_dice_coefficient: 0.8289\n",
      "Epoch 63/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0931 - dice_coefficient: 0.9069 - val_loss: 0.1703 - val_dice_coefficient: 0.8297\n",
      "Epoch 64/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0926 - dice_coefficient: 0.9074 - val_loss: 0.1764 - val_dice_coefficient: 0.8236\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 65/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0926 - dice_coefficient: 0.9074 - val_loss: 0.1760 - val_dice_coefficient: 0.8240\n",
      "Epoch 66/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0918 - dice_coefficient: 0.9082 - val_loss: 0.1728 - val_dice_coefficient: 0.8272\n",
      "Epoch 67/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0914 - dice_coefficient: 0.9086 - val_loss: 0.1750 - val_dice_coefficient: 0.8250\n",
      "Epoch 68/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0911 - dice_coefficient: 0.9089 - val_loss: 0.1710 - val_dice_coefficient: 0.8290\n",
      "Epoch 69/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0905 - dice_coefficient: 0.9095 - val_loss: 0.1697 - val_dice_coefficient: 0.8303\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 70/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0901 - dice_coefficient: 0.9099 - val_loss: 0.1744 - val_dice_coefficient: 0.8256\n",
      "Epoch 71/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0908 - dice_coefficient: 0.9092 - val_loss: 0.1742 - val_dice_coefficient: 0.8258\n",
      "Epoch 72/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0896 - dice_coefficient: 0.9104 - val_loss: 0.1724 - val_dice_coefficient: 0.8276\n",
      "Epoch 73/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0905 - dice_coefficient: 0.9095 - val_loss: 0.1702 - val_dice_coefficient: 0.8298\n",
      "Epoch 74/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0894 - dice_coefficient: 0.9106 - val_loss: 0.1714 - val_dice_coefficient: 0.8286\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 75/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0891 - dice_coefficient: 0.9109 - val_loss: 0.1747 - val_dice_coefficient: 0.8253\n",
      "Epoch 76/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0885 - dice_coefficient: 0.9115 - val_loss: 0.1722 - val_dice_coefficient: 0.8278\n",
      "Epoch 77/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0890 - dice_coefficient: 0.9110 - val_loss: 0.1708 - val_dice_coefficient: 0.8292\n",
      "Epoch 78/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0887 - dice_coefficient: 0.9113 - val_loss: 0.1719 - val_dice_coefficient: 0.8281\n",
      "Epoch 79/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0883 - dice_coefficient: 0.9117 - val_loss: 0.1750 - val_dice_coefficient: 0.8250\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 80/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0885 - dice_coefficient: 0.9115 - val_loss: 0.1757 - val_dice_coefficient: 0.8243\n",
      "Epoch 81/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0882 - dice_coefficient: 0.9118 - val_loss: 0.1752 - val_dice_coefficient: 0.8248\n",
      "Epoch 82/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0883 - dice_coefficient: 0.9117 - val_loss: 0.1735 - val_dice_coefficient: 0.8265\n",
      "Epoch 83/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0875 - dice_coefficient: 0.9125 - val_loss: 0.1705 - val_dice_coefficient: 0.8295\n",
      "Epoch 84/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0873 - dice_coefficient: 0.9127 - val_loss: 0.1777 - val_dice_coefficient: 0.8223\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 85/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0876 - dice_coefficient: 0.9124 - val_loss: 0.1764 - val_dice_coefficient: 0.8236\n",
      "Epoch 86/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0869 - dice_coefficient: 0.9131 - val_loss: 0.1744 - val_dice_coefficient: 0.8256\n",
      "Epoch 87/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0866 - dice_coefficient: 0.9134 - val_loss: 0.1737 - val_dice_coefficient: 0.8263\n",
      "Epoch 88/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0867 - dice_coefficient: 0.9133 - val_loss: 0.1698 - val_dice_coefficient: 0.8302\n",
      "Epoch 89/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0862 - dice_coefficient: 0.9138 - val_loss: 0.1707 - val_dice_coefficient: 0.8293\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 90/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0857 - dice_coefficient: 0.9143 - val_loss: 0.1716 - val_dice_coefficient: 0.8284\n",
      "Epoch 91/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0855 - dice_coefficient: 0.9145 - val_loss: 0.1742 - val_dice_coefficient: 0.8258\n",
      "Epoch 92/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0857 - dice_coefficient: 0.9143 - val_loss: 0.1722 - val_dice_coefficient: 0.8278\n",
      "Epoch 93/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0854 - dice_coefficient: 0.9146 - val_loss: 0.1711 - val_dice_coefficient: 0.8289\n",
      "Epoch 94/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0857 - dice_coefficient: 0.9143 - val_loss: 0.1732 - val_dice_coefficient: 0.8268\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 95/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0855 - dice_coefficient: 0.9145 - val_loss: 0.1721 - val_dice_coefficient: 0.8279\n",
      "Epoch 96/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0847 - dice_coefficient: 0.9153 - val_loss: 0.1747 - val_dice_coefficient: 0.8253\n",
      "Epoch 97/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0850 - dice_coefficient: 0.9150 - val_loss: 0.1711 - val_dice_coefficient: 0.8289\n",
      "Epoch 98/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0854 - dice_coefficient: 0.9146 - val_loss: 0.1707 - val_dice_coefficient: 0.8293\n",
      "Epoch 99/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0853 - dice_coefficient: 0.9147 - val_loss: 0.1804 - val_dice_coefficient: 0.8196\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 100/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0852 - dice_coefficient: 0.9148 - val_loss: 0.1717 - val_dice_coefficient: 0.8283\n",
      "Epoch 101/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0852 - dice_coefficient: 0.9148 - val_loss: 0.1733 - val_dice_coefficient: 0.8267\n",
      "Epoch 102/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0845 - dice_coefficient: 0.9155 - val_loss: 0.1710 - val_dice_coefficient: 0.8290\n",
      "Epoch 103/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0850 - dice_coefficient: 0.9150 - val_loss: 0.1732 - val_dice_coefficient: 0.8268\n",
      "Epoch 104/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0837 - dice_coefficient: 0.9163 - val_loss: 0.1726 - val_dice_coefficient: 0.8274\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 105/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0834 - dice_coefficient: 0.9166 - val_loss: 0.1740 - val_dice_coefficient: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0836 - dice_coefficient: 0.9164 - val_loss: 0.1748 - val_dice_coefficient: 0.8252\n",
      "Epoch 107/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0835 - dice_coefficient: 0.9165 - val_loss: 0.1735 - val_dice_coefficient: 0.8265\n",
      "Epoch 108/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0832 - dice_coefficient: 0.9168 - val_loss: 0.1748 - val_dice_coefficient: 0.8252\n",
      "Epoch 109/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0823 - dice_coefficient: 0.9177 - val_loss: 0.1708 - val_dice_coefficient: 0.8292\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 110/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0837 - dice_coefficient: 0.9163 - val_loss: 0.1707 - val_dice_coefficient: 0.8293\n",
      "Epoch 111/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0829 - dice_coefficient: 0.9171 - val_loss: 0.1747 - val_dice_coefficient: 0.8253\n",
      "Epoch 112/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0832 - dice_coefficient: 0.9168 - val_loss: 0.1725 - val_dice_coefficient: 0.8275\n",
      "Epoch 113/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0826 - dice_coefficient: 0.9174 - val_loss: 0.1723 - val_dice_coefficient: 0.8277\n",
      "Epoch 114/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0822 - dice_coefficient: 0.9178 - val_loss: 0.1691 - val_dice_coefficient: 0.8309\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 115/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0821 - dice_coefficient: 0.9179 - val_loss: 0.1728 - val_dice_coefficient: 0.8272\n",
      "Epoch 116/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0815 - dice_coefficient: 0.9185 - val_loss: 0.1728 - val_dice_coefficient: 0.8272\n",
      "Epoch 117/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0825 - dice_coefficient: 0.9175 - val_loss: 0.1723 - val_dice_coefficient: 0.8277\n",
      "Epoch 118/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0815 - dice_coefficient: 0.9185 - val_loss: 0.1739 - val_dice_coefficient: 0.8261\n",
      "Epoch 119/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0804 - dice_coefficient: 0.9196 - val_loss: 0.1713 - val_dice_coefficient: 0.8287\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 120/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0809 - dice_coefficient: 0.9191 - val_loss: 0.1734 - val_dice_coefficient: 0.8266\n",
      "Epoch 121/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0806 - dice_coefficient: 0.9194 - val_loss: 0.1727 - val_dice_coefficient: 0.8273\n",
      "Epoch 122/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0812 - dice_coefficient: 0.9188 - val_loss: 0.1695 - val_dice_coefficient: 0.8305\n",
      "Epoch 123/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0805 - dice_coefficient: 0.9195 - val_loss: 0.1721 - val_dice_coefficient: 0.8279\n",
      "Epoch 124/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0812 - dice_coefficient: 0.9188 - val_loss: 0.1744 - val_dice_coefficient: 0.8256\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 125/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0802 - dice_coefficient: 0.9198 - val_loss: 0.1749 - val_dice_coefficient: 0.8251\n",
      "Epoch 126/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0803 - dice_coefficient: 0.9197 - val_loss: 0.1748 - val_dice_coefficient: 0.8252\n",
      "Epoch 127/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0805 - dice_coefficient: 0.9195 - val_loss: 0.1737 - val_dice_coefficient: 0.8263\n",
      "Epoch 128/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0801 - dice_coefficient: 0.9199 - val_loss: 0.1774 - val_dice_coefficient: 0.8226\n",
      "Epoch 129/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0793 - dice_coefficient: 0.9207 - val_loss: 0.1746 - val_dice_coefficient: 0.8254\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 130/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1725 - val_dice_coefficient: 0.8275\n",
      "Epoch 131/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1693 - val_dice_coefficient: 0.8307\n",
      "Epoch 132/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0792 - dice_coefficient: 0.9208 - val_loss: 0.1760 - val_dice_coefficient: 0.8240\n",
      "Epoch 133/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0797 - dice_coefficient: 0.9203 - val_loss: 0.1752 - val_dice_coefficient: 0.8248\n",
      "Epoch 134/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0795 - dice_coefficient: 0.9205 - val_loss: 0.1741 - val_dice_coefficient: 0.8259\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 135/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0789 - dice_coefficient: 0.9211 - val_loss: 0.1743 - val_dice_coefficient: 0.8257\n",
      "Epoch 136/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0786 - dice_coefficient: 0.9214 - val_loss: 0.1761 - val_dice_coefficient: 0.8239\n",
      "Epoch 137/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0790 - dice_coefficient: 0.9210 - val_loss: 0.1759 - val_dice_coefficient: 0.8241\n",
      "Epoch 138/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0791 - dice_coefficient: 0.9209 - val_loss: 0.1712 - val_dice_coefficient: 0.8288\n",
      "Epoch 139/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0788 - dice_coefficient: 0.9212 - val_loss: 0.1753 - val_dice_coefficient: 0.8247\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 140/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0779 - dice_coefficient: 0.9221 - val_loss: 0.1742 - val_dice_coefficient: 0.8258\n",
      "Epoch 141/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0786 - dice_coefficient: 0.9214 - val_loss: 0.1721 - val_dice_coefficient: 0.8279\n",
      "Epoch 142/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0788 - dice_coefficient: 0.9212 - val_loss: 0.1677 - val_dice_coefficient: 0.8323\n",
      "Epoch 143/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0781 - dice_coefficient: 0.9219 - val_loss: 0.1747 - val_dice_coefficient: 0.8253\n",
      "Epoch 144/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0779 - dice_coefficient: 0.9221 - val_loss: 0.1723 - val_dice_coefficient: 0.8277\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 145/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0777 - dice_coefficient: 0.9223 - val_loss: 0.1687 - val_dice_coefficient: 0.8313\n",
      "Epoch 146/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0775 - dice_coefficient: 0.9225 - val_loss: 0.1741 - val_dice_coefficient: 0.8259\n",
      "Epoch 147/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0774 - dice_coefficient: 0.9226 - val_loss: 0.1666 - val_dice_coefficient: 0.8334\n",
      "Epoch 148/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0773 - dice_coefficient: 0.9227 - val_loss: 0.1705 - val_dice_coefficient: 0.8295\n",
      "Epoch 149/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0763 - dice_coefficient: 0.9237 - val_loss: 0.1740 - val_dice_coefficient: 0.8260\n",
      "Epoch 150/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0761 - dice_coefficient: 0.9239 - val_loss: 0.1765 - val_dice_coefficient: 0.8235\n",
      "Epoch 151/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0765 - dice_coefficient: 0.9235 - val_loss: 0.1754 - val_dice_coefficient: 0.8246\n",
      "Epoch 152/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0756 - dice_coefficient: 0.9244 - val_loss: 0.1733 - val_dice_coefficient: 0.8267\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 153/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0759 - dice_coefficient: 0.9241 - val_loss: 0.1709 - val_dice_coefficient: 0.8291\n",
      "Epoch 154/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0751 - dice_coefficient: 0.9249 - val_loss: 0.1724 - val_dice_coefficient: 0.8276\n",
      "Epoch 155/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0756 - dice_coefficient: 0.9244 - val_loss: 0.1749 - val_dice_coefficient: 0.8251\n",
      "Epoch 156/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0764 - dice_coefficient: 0.9236 - val_loss: 0.1701 - val_dice_coefficient: 0.8299\n",
      "Epoch 157/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0769 - dice_coefficient: 0.9231 - val_loss: 0.1756 - val_dice_coefficient: 0.8244\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 158/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0756 - dice_coefficient: 0.9244 - val_loss: 0.1716 - val_dice_coefficient: 0.8284\n",
      "Epoch 159/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0746 - dice_coefficient: 0.9254 - val_loss: 0.1727 - val_dice_coefficient: 0.8273\n",
      "Epoch 160/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0752 - dice_coefficient: 0.9248 - val_loss: 0.1735 - val_dice_coefficient: 0.8265\n",
      "Epoch 161/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0752 - dice_coefficient: 0.9248 - val_loss: 0.1713 - val_dice_coefficient: 0.8287\n",
      "Epoch 162/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0753 - dice_coefficient: 0.9247 - val_loss: 0.1776 - val_dice_coefficient: 0.8224\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 163/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0751 - dice_coefficient: 0.9249 - val_loss: 0.1741 - val_dice_coefficient: 0.8259\n",
      "Epoch 164/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0754 - dice_coefficient: 0.9246 - val_loss: 0.1698 - val_dice_coefficient: 0.8302\n",
      "Epoch 165/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0749 - dice_coefficient: 0.9251 - val_loss: 0.1759 - val_dice_coefficient: 0.8241\n",
      "Epoch 166/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0744 - dice_coefficient: 0.9256 - val_loss: 0.1740 - val_dice_coefficient: 0.8260\n",
      "Epoch 167/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0741 - dice_coefficient: 0.9259 - val_loss: 0.1717 - val_dice_coefficient: 0.8283\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 168/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0736 - dice_coefficient: 0.9264 - val_loss: 0.1716 - val_dice_coefficient: 0.8284\n",
      "Epoch 169/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0737 - dice_coefficient: 0.9263 - val_loss: 0.1737 - val_dice_coefficient: 0.8263\n",
      "Epoch 170/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0737 - dice_coefficient: 0.9263 - val_loss: 0.1759 - val_dice_coefficient: 0.8241\n",
      "Epoch 171/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0737 - dice_coefficient: 0.9263 - val_loss: 0.1701 - val_dice_coefficient: 0.8299\n",
      "Epoch 172/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0734 - dice_coefficient: 0.9266 - val_loss: 0.1748 - val_dice_coefficient: 0.8252\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 173/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0730 - dice_coefficient: 0.9270 - val_loss: 0.1721 - val_dice_coefficient: 0.8279\n",
      "Epoch 174/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0731 - dice_coefficient: 0.9269 - val_loss: 0.1751 - val_dice_coefficient: 0.8249\n",
      "Epoch 175/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0732 - dice_coefficient: 0.9268 - val_loss: 0.1738 - val_dice_coefficient: 0.8262\n",
      "Epoch 176/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0731 - dice_coefficient: 0.9269 - val_loss: 0.1765 - val_dice_coefficient: 0.8235\n",
      "Epoch 177/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0741 - dice_coefficient: 0.9259 - val_loss: 0.1724 - val_dice_coefficient: 0.8276\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 178/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0730 - dice_coefficient: 0.9270 - val_loss: 0.1764 - val_dice_coefficient: 0.8236\n",
      "Epoch 179/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0728 - dice_coefficient: 0.9272 - val_loss: 0.1708 - val_dice_coefficient: 0.8292\n",
      "Epoch 180/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0724 - dice_coefficient: 0.9276 - val_loss: 0.1758 - val_dice_coefficient: 0.8242\n",
      "Epoch 181/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0725 - dice_coefficient: 0.9275 - val_loss: 0.1712 - val_dice_coefficient: 0.8288\n",
      "Epoch 182/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0723 - dice_coefficient: 0.9277 - val_loss: 0.1730 - val_dice_coefficient: 0.8270\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 183/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0720 - dice_coefficient: 0.9280 - val_loss: 0.1690 - val_dice_coefficient: 0.8310\n",
      "Epoch 184/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0726 - dice_coefficient: 0.9274 - val_loss: 0.1753 - val_dice_coefficient: 0.8247\n",
      "Epoch 185/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0720 - dice_coefficient: 0.9280 - val_loss: 0.1707 - val_dice_coefficient: 0.8293\n",
      "Epoch 186/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0716 - dice_coefficient: 0.9284 - val_loss: 0.1699 - val_dice_coefficient: 0.8301\n",
      "Epoch 187/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0713 - dice_coefficient: 0.9287 - val_loss: 0.1717 - val_dice_coefficient: 0.8283\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 188/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0716 - dice_coefficient: 0.9284 - val_loss: 0.1727 - val_dice_coefficient: 0.8273\n",
      "Epoch 189/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0711 - dice_coefficient: 0.9289 - val_loss: 0.1708 - val_dice_coefficient: 0.8292\n",
      "Epoch 190/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0712 - dice_coefficient: 0.9288 - val_loss: 0.1732 - val_dice_coefficient: 0.8268\n",
      "Epoch 191/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0713 - dice_coefficient: 0.9287 - val_loss: 0.1732 - val_dice_coefficient: 0.8268\n",
      "Epoch 192/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0716 - dice_coefficient: 0.9284 - val_loss: 0.1737 - val_dice_coefficient: 0.8263\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 193/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0712 - dice_coefficient: 0.9288 - val_loss: 0.1735 - val_dice_coefficient: 0.8265\n",
      "Epoch 194/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0709 - dice_coefficient: 0.9291 - val_loss: 0.1767 - val_dice_coefficient: 0.8233\n",
      "Epoch 195/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0701 - dice_coefficient: 0.9299 - val_loss: 0.1744 - val_dice_coefficient: 0.8256\n",
      "Epoch 196/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0706 - dice_coefficient: 0.9294 - val_loss: 0.1715 - val_dice_coefficient: 0.8285\n",
      "Epoch 197/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0705 - dice_coefficient: 0.9295 - val_loss: 0.1713 - val_dice_coefficient: 0.8287\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 198/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0705 - dice_coefficient: 0.9295 - val_loss: 0.1699 - val_dice_coefficient: 0.8301\n",
      "Epoch 199/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0709 - dice_coefficient: 0.9291 - val_loss: 0.1725 - val_dice_coefficient: 0.8275\n",
      "Epoch 200/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0712 - dice_coefficient: 0.9288 - val_loss: 0.1746 - val_dice_coefficient: 0.8254\n",
      "Epoch 201/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0718 - dice_coefficient: 0.9282 - val_loss: 0.1724 - val_dice_coefficient: 0.8276\n",
      "Epoch 202/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0697 - dice_coefficient: 0.9303 - val_loss: 0.1743 - val_dice_coefficient: 0.8257\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 203/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0697 - dice_coefficient: 0.9303 - val_loss: 0.1714 - val_dice_coefficient: 0.8286\n",
      "Epoch 204/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0696 - dice_coefficient: 0.9304 - val_loss: 0.1734 - val_dice_coefficient: 0.8266\n",
      "Epoch 205/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0692 - dice_coefficient: 0.9308 - val_loss: 0.1725 - val_dice_coefficient: 0.8275\n",
      "Epoch 206/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0688 - dice_coefficient: 0.9312 - val_loss: 0.1703 - val_dice_coefficient: 0.8297\n",
      "Epoch 207/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0691 - dice_coefficient: 0.9309 - val_loss: 0.1705 - val_dice_coefficient: 0.8295\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 208/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0686 - dice_coefficient: 0.9314 - val_loss: 0.1717 - val_dice_coefficient: 0.8283\n",
      "Epoch 209/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0685 - dice_coefficient: 0.9315 - val_loss: 0.1702 - val_dice_coefficient: 0.8298\n",
      "Epoch 210/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0683 - dice_coefficient: 0.9317 - val_loss: 0.1723 - val_dice_coefficient: 0.8277\n",
      "Epoch 211/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0687 - dice_coefficient: 0.9313 - val_loss: 0.1731 - val_dice_coefficient: 0.8269\n",
      "Epoch 212/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0683 - dice_coefficient: 0.9317 - val_loss: 0.1701 - val_dice_coefficient: 0.8299\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 213/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0682 - dice_coefficient: 0.9318 - val_loss: 0.1689 - val_dice_coefficient: 0.8311\n",
      "Epoch 214/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0676 - dice_coefficient: 0.9324 - val_loss: 0.1738 - val_dice_coefficient: 0.8262\n",
      "Epoch 215/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0679 - dice_coefficient: 0.9321 - val_loss: 0.1699 - val_dice_coefficient: 0.8301\n",
      "Epoch 216/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0675 - dice_coefficient: 0.9325 - val_loss: 0.1733 - val_dice_coefficient: 0.8267\n",
      "Epoch 217/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0673 - dice_coefficient: 0.9327 - val_loss: 0.1689 - val_dice_coefficient: 0.8311\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 218/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0673 - dice_coefficient: 0.9327 - val_loss: 0.1727 - val_dice_coefficient: 0.8273\n",
      "Epoch 219/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0678 - dice_coefficient: 0.9322 - val_loss: 0.1713 - val_dice_coefficient: 0.8287\n",
      "Epoch 220/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0675 - dice_coefficient: 0.9325 - val_loss: 0.1743 - val_dice_coefficient: 0.8257\n",
      "Epoch 221/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0671 - dice_coefficient: 0.9329 - val_loss: 0.1742 - val_dice_coefficient: 0.8258\n",
      "Epoch 222/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0663 - dice_coefficient: 0.9337 - val_loss: 0.1723 - val_dice_coefficient: 0.8277\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 223/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0665 - dice_coefficient: 0.9335 - val_loss: 0.1696 - val_dice_coefficient: 0.8304\n",
      "Epoch 224/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0667 - dice_coefficient: 0.9333 - val_loss: 0.1735 - val_dice_coefficient: 0.8265\n",
      "Epoch 225/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0662 - dice_coefficient: 0.9338 - val_loss: 0.1727 - val_dice_coefficient: 0.8273\n",
      "Epoch 226/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0654 - dice_coefficient: 0.9346 - val_loss: 0.1758 - val_dice_coefficient: 0.8242\n",
      "Epoch 227/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0658 - dice_coefficient: 0.9342 - val_loss: 0.1696 - val_dice_coefficient: 0.8304\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 228/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0656 - dice_coefficient: 0.9344 - val_loss: 0.1727 - val_dice_coefficient: 0.8273\n",
      "Epoch 229/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0653 - dice_coefficient: 0.9347 - val_loss: 0.1719 - val_dice_coefficient: 0.8281\n",
      "Epoch 230/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0657 - dice_coefficient: 0.9343 - val_loss: 0.1733 - val_dice_coefficient: 0.8267\n",
      "Epoch 231/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0657 - dice_coefficient: 0.9343 - val_loss: 0.1734 - val_dice_coefficient: 0.8266\n",
      "Epoch 232/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0651 - dice_coefficient: 0.9349 - val_loss: 0.1715 - val_dice_coefficient: 0.8285\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 233/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0670 - dice_coefficient: 0.9330 - val_loss: 0.1738 - val_dice_coefficient: 0.8262\n",
      "Epoch 234/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0670 - dice_coefficient: 0.9330 - val_loss: 0.1710 - val_dice_coefficient: 0.8290\n",
      "Epoch 235/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0650 - dice_coefficient: 0.9350 - val_loss: 0.1730 - val_dice_coefficient: 0.8270\n",
      "Epoch 236/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0648 - dice_coefficient: 0.9352 - val_loss: 0.1729 - val_dice_coefficient: 0.8271\n",
      "Epoch 237/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0647 - dice_coefficient: 0.9353 - val_loss: 0.1723 - val_dice_coefficient: 0.8277\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 238/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0645 - dice_coefficient: 0.9355 - val_loss: 0.1745 - val_dice_coefficient: 0.8255\n",
      "Epoch 239/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0648 - dice_coefficient: 0.9352 - val_loss: 0.1704 - val_dice_coefficient: 0.8296\n",
      "Epoch 240/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0647 - dice_coefficient: 0.9353 - val_loss: 0.1694 - val_dice_coefficient: 0.8306\n",
      "Epoch 241/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0647 - dice_coefficient: 0.9353 - val_loss: 0.1720 - val_dice_coefficient: 0.8280\n",
      "Epoch 242/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0642 - dice_coefficient: 0.9358 - val_loss: 0.1711 - val_dice_coefficient: 0.8289\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 243/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0650 - dice_coefficient: 0.9350 - val_loss: 0.1695 - val_dice_coefficient: 0.8305\n",
      "Epoch 244/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0642 - dice_coefficient: 0.9358 - val_loss: 0.1729 - val_dice_coefficient: 0.8271\n",
      "Epoch 245/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0640 - dice_coefficient: 0.9360 - val_loss: 0.1744 - val_dice_coefficient: 0.8256\n",
      "Epoch 246/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0641 - dice_coefficient: 0.9359 - val_loss: 0.1729 - val_dice_coefficient: 0.8271\n",
      "Epoch 247/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0631 - dice_coefficient: 0.9369 - val_loss: 0.1765 - val_dice_coefficient: 0.8235\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 248/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0636 - dice_coefficient: 0.9364 - val_loss: 0.1746 - val_dice_coefficient: 0.8254\n",
      "Epoch 249/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0636 - dice_coefficient: 0.9364 - val_loss: 0.1736 - val_dice_coefficient: 0.8264\n",
      "Epoch 250/250\n",
      "62/62 [==============================] - 14s 227ms/step - loss: 0.0634 - dice_coefficient: 0.9366 - val_loss: 0.1713 - val_dice_coefficient: 0.8287\n"
     ]
    }
   ],
   "source": [
    "# Training Loop for pancreas model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "kf = KFold(n_splits=4, random_state=4)\n",
    "\n",
    "count = 0\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_train_morph, y_test_morph = xmorph[train_index], xmorph[test_index]\n",
    "    \n",
    "    model = unet_3d_ReLU_pancreas()\n",
    "    \n",
    "    c1        = ModelCheckpoint('./model_small3_'+str(count)+'.h5', monitor='val_loss', \n",
    "                         verbose=0, save_best_only=True, \n",
    "                         save_weights_only=False, mode='auto', period=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=0.001)\n",
    "    model.fit(x_train, y_train, batch_size=3, validation_data=(x_test, y_test), \n",
    "              callbacks=[c1,reduce_lr], epochs=250)\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dril/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "model = unet_3d_ReLU_pancreas()\n",
    "model.load_weights('./model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, random_state=4)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 80, 160, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(x_train, batch_size=3)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-988a0b6f834d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_coefficient_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_coefficient_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "s     = 15\n",
    "\n",
    "print(dice_coefficient_numpy(pred[index, :, :, :, 0].astype('float32'), y_train[index, :, :, :, 0].astype('float32')))\n",
    "print(dice_coefficient_numpy(pred[index, :, :, s, 0].astype('float32'), y_train[index, :, :, s, 0].astype('float32')))\n",
    "plt.imshow(np.concatenate([x_train[index, :, :,s, 0], pred[index, :, :, s, 0], y_train[index, :, :, s, 0]], axis=1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 160) (80, 160)\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import medial_axis\n",
    "\n",
    "skel, distance = medial_axis(y_train[index, :, :, s, 0], return_distance=True)\n",
    "print(skel.shape, distance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe81e86fc88>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.concatenate([skel, distance], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 80, 160, 80)\n"
     ]
    }
   ],
   "source": [
    "xmorph = []\n",
    "for i in range(len(x)):\n",
    "    body = np.zeros((80, 160, 80))\n",
    "    for j in range(80):\n",
    "        temp = y[i, :, :, j, 0]\n",
    "        skel, distance = medial_axis(temp, return_distance=True)\n",
    "        body[:, :, j]  = distance/20.0\n",
    "    xmorph.append(body)\n",
    "\n",
    "xmorph = np.array(xmorph)\n",
    "print(xmorph.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('xmorph.npy', xmorph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe81e61aac8>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADJCAYAAAA6q2k2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAWv0lEQVR4nO3de4yc1X3G8e9vd2d3vb7ErImJwW5NWkRCo8ZQN4FSVTSEBlIErZRE0ChFLRL/pG3SJgq4SL2plYha5VIppUEhCa0oJHGgsVCalLpBUaWKcgkhBOPgEAcWExaDwZf1emdnf/3jnDMz+3pm553dub34+Uird9/Lzhy/9hw/e95zMXdHRESKZ6jfBRARkeVRBS4iUlCqwEVECkoVuIhIQakCFxEpKFXgIiIFtaIK3MwuN7O9ZrbPzG7qVKFERKQ1W24/cDMbBn4EXAZMAQ8B17r7k50rnoiINDOygp99B7DP3Z8BMLO7gauBphX4qI35OKtX8JYiIqeeIxw66O5vzB5fSQV+FvBc3f4U8M7sRWZ2A3ADwDgTvNMuXcFbioicev7Ld/600fGVtIFbg2Mntce4+23uvt3dt5cYW8HbiYhIvZVU4FPAlrr9zcCBlRVHRETyWkkF/hBwjpmdbWajwDXArs4US0REWll2G7i7z5vZHwHfBoaBL7r7DztWMhERWdJKHmLi7t8EvtmhsoiISBs0ElNEpKBUgYuIFJQqcBGRglIFLiJSUKrARUQKShW4iEhBqQIXESkoVeAiIgWlClxEpKBUgYuIFJQqcBFpamTLZka2bO53MaQJVeAiIgXVcjIrM/sicCUw7e5vi8cmga8AW4H9wAfc/VD3iiki3dYoafvEeNNzAPPPTXW1TLK0PAn8y8DlmWM3Abvd/Rxgd9wXEZEeapnA3f27ZrY1c/hq4JL4/R3AA8CNHSyXiHRJszSd0nbltInqsYXSMABD5YlF1w4fmmn4WkrkvbXcNvAz3P0FgLjd2OxCM7vBzB42s4fLnFjm24mISNaKFnTIw91vA24DWGeTJy16LCKd1arXSKOkDbW0XV5Xqxbmx0PGG6qEj+5QOWxLmWSuRN4fy03gL5rZJoC4ne5ckUREJI/lJvBdwHXALXH7jY6VSETakk29zRJ2kk3aCyUL2+GwLU/Ucl15ddgOVcJ2eDZsUzIfmV0AWidyJfHuaJnAzewu4H+Bc81sysyuJ1Tcl5nZ08BlcV9ERHooTy+Ua5ucurTDZRE5Za1ktGM2cTdL2Ek2aVfG0/GwrYzVrp/PhPiREKwprw4/WzoWts0SeSk2rtb/+ZTGO0cjMUVECqrrvVBEpKadPth5ZRN3SsPZhF29PpO0U8r2eHxhtNZZLPuzlVVhO3zc4muE/WwiT1Kb+MjMbDt/JMlJCVxEpKCUwEV6ICXvvH2ws+3WS8m2aaeeI9mEnWSTdrUNvBT2vVRL4D5eWfSzldnww8MzMd1nEjnEfuLxfGoLT39uUM+UTlICFxEpKFXgIiIFpSYUkR5KTScnNoSnf80G0WQfHi6l2UPJyqpME8lIbBqJrR2pqSQ1kwyNhe3IyEL1tUfH5he91+xsKbzHeKg6UpPK6Cux3DOL/xwjsUmofjIsPdDsHCVwEZGCUgIX6ZL6LoPpIV56WJm6+s1Ohm2zFJ1Hs4eSlYmQpFPCttGwbxauS0k7pew142G20NHh2oPLNaOLZxB95Xgo2NHx8BvEsVdWxfccWlTuShzw087DWGmfEriISEEpgYv0QGr7Tt0Eq13+JmKb8dpw3Uld+0ZyzMDcpE17eCIk6/HxMgATY3MADMUEnpJ2StnrR48DsLZUa6NeMxzOVWLWmx4NBd3npwMwMzqWKacSdy8pgYuIFFSeRY23AP8CvAlYAG5z989qYWOR9qU24ZSwU5txeV1M3k3arZfSqk17clVokE4JeyTODbtqOCTzlLI3lI4BcHrpSPW1D82HUUHPHA+J+3C5je4x0nV5Evg88DF3fytwIfBhMzsPLWwsItJXeaaTfQFI618eMbM9wFloYWORjqm2Ia8LqXj1mpCKU7v1Ulq1aW8cD4l6Y0zWEzFxTwyF1143FK6b9dDH+8DcadXX/unsJAD7j2wAYProGgCOHAtJ3OdCBlTLd3+01QYeV6c/H3iQnAsba1FjEZHuyN0LxczWAF8HPuruh83y/Z+rRY1F2peS9y+uPwjUUnYjQxbavpu1aZ85Gh5NnTkStuuHQ5v4z+bfAMC+E28C4NkTIW1Pz66tvvarc6Gfd0rehw+H/YUjIa2PHI2TW2lwZV/kSuBmViJU3ne6+z3xsBY2FhHpozy9UAy4Hdjj7p+qO6WFjUV65Lw1LwAwPlQ+6VxK4Nk27cnhowBsjNsxC23kT5dDj5I9s2cBtR4mz8+sB+DgzOrqax+dDf280xwoKXmXXotLph0Ov4mnpdaGT4TfFFIiHyrrl+5uytOEcjHwIeAHZvZYPPbnhIr7q3GR42eB93eniCIi0kieXij/Q/OHzFrYWKQDhubjHCixV8fMiVGg1gb9clyl4VfX/ASAraWDtZ+NCXyUsF0bU/obhsJrvlQJ22bJu1kPE4DKTKgiLM46OJIWaojJe/S1cN3okbSQQyhDdXHjw6FP+vChmby3QtqgkZgiIgWluVBEeii1Cac24tR2nJYmS/Nrz50IH82jc6EN+mhcPfjwQrhw3GrzdG8bG1v0Hgcr4dzUfHiNZ+dDv+5WyTvbwwRO7mWSlk5L5U7Je9Ur4T1T4h4qx/lYYvK2ujnAtZRa5yiBi4gUlBK4SA+kJFrKzAdeXh22Q3Mh2Vo5zpUyH47PVcL1xyshFc8shLbxubrsdbAS+nunxD1dCb1JDsTknUZWNhtVmU3eqYcJNO9lEruYV9u8U/IuTYfRnpZZdUepuzuUwEVECkoVuIhIQakJRaRL6psN0vJqaXHfoYrHbThvaRWzOO7FPS52XN0ONdwCPHqicZPJdFwlIg2Nf3k2dEVs1XSSmk0gfzfB9NAyNZ2oyaQ3lMBFRApKCVykgJ6a21T9vlniToOAqgsRx2Hxx4+FB6HNkndK3bC8boLSO0rgIiIFpQQuUiCzCyE1P3bs56rHWiXuNBFVdlh86cjSw+Lh5OStboKDRQlcRKSg8kwnOw58FxiL1+909780s7OBu4FJ4FHgQ+7eev0nEVm2J46cCdTSNuRP3Gkiquyw+GzyTqkbmidvJe7BkCeBnwDe5e5vB7YBl5vZhcAngU/HRY0PAdd3r5giIpKVZzpZB47G3VL8cuBdwO/F43cAfwXc2vkiikhK3GmxhZS2of3E3WxYfLa9G5S8B13eJdWG42IO08D9wI+BV909/U1PEVaqb/SzWtRYRKQLcvVCcfcKsM3M1gP3Am9tdFmTn9WixiIr9PxrYQHitNhCStuw/MTdbFRlSt2g5D3o2uqF4u6vAg8AFwLrzSz9K9oMHOhs0UREZCl5eqG8ESi7+6tmtgp4N+EB5neA9xF6omhRY5EuKM+HdJ2dtyQttAArT9xafKG48jShbALuMLNhQmL/qrvfZ2ZPAneb2d8C3yOsXC8iIj2SpxfK48D5DY4/A7yjG4USkSDPjIGdTNyg1F0kGokpIlJQmgtFZIC1M2OgEvepRwlcRKSglMBFuiStwgPgE6H/9kJc1HhhOK60EzuTeOpUEpu2fS5kq9TbpJ0ZA5W4Tx1K4CIiBaUKXESkoNSEItIDldPClK/ldeEjV54I2akyFptSRkOTiJfCNg2PT4N0UlfBdqZ8TdRk8vqlBC4iUlBK4HJKSQ8W+5VKF0ohcVfCM03mQzCv7vtQ7BIYuw2m4fHVQTozi7sIgqZ8PZUpgYuIFJQSuLyu1HfdayR158te18nUml47vRe07j64UFqcvLPdBtPw+DRIJ3UVBCXvU5kSuIhIQeVO4HE2woeB5939Si1qLP3ULGmn1Jt6fWSlJDxUDufTYJelkntKtq3az7PJu7xxbfVcq94nQ+Ww32zATnawTiq3nNraSeAfAfbU7WtRYxGRPsqVwM1sM/DbwN8Bf2ZmhhY1lgEwf9bkov2UsFPiTb0+qudjG3R1wqdMIq+XTefN2s+TbPJOZQA4Phm+n1sb3j/b+6RVf++l+nqr7fvUlTeBfwb4BLAQ9zegRY1FRPoqz5JqVwLT7v6ImV2SDje4VIsaS1ctNTnUiQ1h2tWUsKttzeMsknp/lI6F8/PjYTtUqf3THCrHHiGZdJ5tP8/Kpv+UuqGWvOfC2sSU13n8mfheh+OCxE36e6uvtzSSpwnlYuAqM3svMA6sIyTy9WY2ElO4FjUWEemxPEuq7QB2AMQE/nF3/6CZfQ0taiw9VJ86UxqvpeGQwGcnQ5ItTyxua86qjIVteXVK4LVzqT06m85Tuq9P6/Wy6T+lbjg5eZffEN4w9fu2+P5D1W3qnRIOKHlLIyvpB34j4YHmPkKbuBY1FhHpobZGYrr7A8AD8XstaiwDqzQTEuxwfG6e+l2nRH5iQ0y4c+G41SXw1BMkm85T+3l9Wq+XzmffC2rJuzK+9IjLlP5TO7zIUjQSU0SkoDQXirwupMQ68dLieJxtly6nRD6zOCWnhAxQWRVfM5PO07wl1iSBV+c1GU1pu3au2s879n5Jr6ERl7ISSuAiIgWlBC6FlhLqWJPzqW/2SOybXZpJvVRiT5Fy6ilS6zFS7SmyNo5b88wlzZqn4/nh2diufaj2mqldPfXzTu3oKZm3GnGp3ifSiBK4iEhBqQIXESkoNaFIIWWneB3JLOSbpCH3acBPKdOkUvsI1M8OsXimiDToZmhtObymLz7vR2PzTJOugVB7SJmGyNcG6qSh9Go6kfYpgYuIFJQSuBRaq4SaTei1Zc7WZq+s+z77YDNOUhX3UhJfOBKG748cbZy8U+qGkx9S1i+JBrWHsUre0g4lcBGRglICl9e1bJJNibw0nY5kkzic3C4etj4cknaaBD/b5t1sMYZwTfMFGZYqr8hSlMBFRAoq75Jq+4EjQAWYd/ftZjYJfAXYCuwHPuDuh7pTTJHOyPZeyZPE07JsaYi9VZZu884uxhDeR71LpPPaSeC/6e7b3H173L8J2B0XNd4d90VEpEdW0gZ+NXBJ/P4OwjSzN66wPCI90TyJQ0rjaUGH6rSycXKr4ePhqlYTUdX3NFHylm7Im8Ad+E8ze8TMbojHznD3FwDidmOjH9SixiIi3ZE3gV/s7gfMbCNwv5k9lfcNtKixDLJsEofaqM3qaMkYpPNOAduqp4lIp+RK4O5+IG6ngXsJK/G8aGabAOJ2uvkriIhIp7VM4Ga2Ghhy9yPx+98C/gbYRVjM+Ba0qLGcAsYOxV4mx8K+poCVfsvThHIGcK+Zpev/zd2/ZWYPAV81s+uBZ4H3d6+YIiKS1bICj4sXv73B8ZeBS7tRKJFBkGYKTIsujMf+3SOzi/t5K3lLv2gkpohIQWkuFJGMNDNgmjs8yfbv1gyC0m9K4CIiBaUELsLi9JwdnZn6hWcTd6OfFeklJXARkYJSBS4iUlBqQhHJaLVgsppMZFAogYuIFJQSuEgTStoy6JTARUQKShW4iEhBqQIXESmoXBW4ma03s51m9pSZ7TGzi8xs0szuN7On4/a0bhdWRERq8ibwzwLfcve3EGYm3IMWNRYR6auWFbiZrQN+A7gdwN3n3P1VwqLGd8TL7gB+p1uFFBGRk+VJ4G8GXgK+ZGbfM7MvxJV5tKixiEgf5anAR4ALgFvd/XzgGG00l7j7be6+3d23lxhbZjFFRCQrTwU+BUy5+4NxfyehQteixiIifdSyAnf3nwHPmdm58dClwJPUFjUGLWosItJzeYfS/zFwp5mNAs8Af0Co/LWosYhIn+SqwN39MWB7g1Na1FhEpE80ElNEpKBUgYuIFJQqcBGRglIFLiJSUKrARUQKShW4iEhBqQIXESkoVeAiIgWlClxEpKBUgYuIFJQqcBGRglIFLiJSUHmWVDvXzB6r+zpsZh/VosYiIv2VZz7wve6+zd23Ab8CzAD3okWNRUT6qt0mlEuBH7v7T9GixiIifdVuBX4NcFf8Xosai4j0Ue4KPK7GcxXwtXbeQIsai4h0RzsJ/ArgUXd/Me5rUWMRkT5qpwK/llrzCWhRYxGRvspVgZvZBHAZcE/d4VuAy8zs6Xjuls4XT0REmsm7qPEMsCFz7GW0qLGISN9oJKaISEGpAhcRKShV4CIiBaUKXESkoFSBi4gUlCpwEZGCUgUuIlJQqsBFRApKFbiISEGpAhcRKShV4CIiBaUKXESkoFSBi4gUlCpwEZGCMnfv3ZuZvQQcAw727E2X73RUzk4pQhlB5ew0lbNzft7d35g92NMKHMDMHnb37T1902VQOTunCGUElbPTVM7uUxOKiEhBqQIXESmoflTgt/XhPZdD5eycIpQRVM5OUzm7rOdt4CIi0hlqQhERKShV4CIiBdWzCtzMLjezvWa2z8xu6tX7tmJmW8zsO2a2x8x+aGYficcnzex+M3s6bk/rd1kBzGzYzL5nZvfF/bPN7MFYzq+Y2egAlHG9me00s6fifb1oEO+nmf1p/Dt/wszuMrPxQbifZvZFM5s2syfqjjW8fxb8Y/xcPW5mF/S5nH8f/94fN7N7zWx93bkdsZx7zew9/Sxn3bmPm5mb2elxv2/3czl6UoGb2TDwOeAK4DzgWjM7rxfvncM88DF3fytwIfDhWLabgN3ufg6wO+4Pgo8Ae+r2Pwl8OpbzEHB9X0q12GeBb7n7W4C3E8o7UPfTzM4C/gTY7u5vA4aBaxiM+/ll4PLMsWb37wrgnPh1A3Brj8oIjct5P/A2d/9l4EfADoD4mboG+KX4M/8U64V+lRMz2wJcBjxbd7if97N97t71L+Ai4Nt1+zuAHb1472WU9RuEv9S9wKZ4bBOwdwDKtpnw4X0XcB9ghBFkI43uc5/KuA74CfEBed3xgbqfwFnAc8AkMBLv53sG5X4CW4EnWt0/4PPAtY2u60c5M+d+F7gzfr/oMw98G7ion+UEdhICxn7g9EG4n+1+9aoJJX1Ykql4bKCY2VbgfOBB4Ax3fwEgbjf2r2RVnwE+ASzE/Q3Aq+4+H/cH4b6+GXgJ+FJs6vmCma1mwO6nuz8P/AMhfb0AvAY8wuDdz6TZ/Rvkz9YfAv8Rvx+ocprZVcDz7v79zKmBKmcrvarArcGxgeq/aGZrgK8DH3X3w/0uT5aZXQlMu/sj9YcbXNrv+zoCXADc6u7nE+a+GZTmp6rYhnw1cDZwJrCa8OtzVr/vZyuD+G8AM7uZ0Dx5ZzrU4LK+lNPMJoCbgb9odLrBsb7fz2Z6VYFPAVvq9jcDB3r03i2ZWYlQed/p7vfEwy+a2aZ4fhMw3a/yRRcDV5nZfuBuQjPKZ4D1ZjYSrxmE+zoFTLn7g3F/J6FCH7T7+W7gJ+7+kruXgXuAX2Pw7mfS7P4N3GfLzK4DrgQ+6LEdgsEq5y8Q/uP+fvw8bQYeNbM3MVjlbKlXFfhDwDnxCf8o4WHGrh6995LMzIDbgT3u/qm6U7uA6+L31xHaxvvG3Xe4+2Z330q4f//t7h8EvgO8L142COX8GfCcmZ0bD10KPMmA3U9C08mFZjYR/w2kcg7U/azT7P7tAn4/9p64EHgtNbX0g5ldDtwIXOXuM3WndgHXmNmYmZ1NeEj4f/0oo7v/wN03uvvW+HmaAi6I/3YH6n621MOHCO8lPJX+MXBzvxv/68r164RfkR4HHotf7yW0L+8Gno7byX6Xta7MlwD3xe/fTPgg7AO+BowNQPm2AQ/He/rvwGmDeD+BvwaeAp4A/hUYG4T7CdxFaJcvEyqX65vdP8Kv/J+Ln6sfEHrV9LOc+whtyOmz9M91198cy7kXuKKf5cyc30/tIWbf7udyvjSUXkSkoDQSU0SkoFSBi4gUlCpwEZGCUgUuIlJQqsBFRApKFbiISEGpAhcRKaj/B87fHKc+9glQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xmorph[1, :, :, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "from skimage.data import binary_blobs\n",
    "\n",
    "data = binary_blobs(200, blob_size_fraction=.2, volume_fraction=.35, seed=1)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize_3d\n",
    "\n",
    "skeleton_lee = skeletonize_3d(y[0, :, :, :, 0])\n",
    "print(skeleton_lee.shape)\n",
    "\n",
    "skel, distance = medial_axis(y[0, :, :, 0], return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe81e4a7e80>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(skeleton_lee[40, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
