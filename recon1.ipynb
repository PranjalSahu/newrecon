{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "import copy\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback, TensorBoard\n",
    "from keras import backend as keras\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#import pylidc as pl\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import pymrt as mrt\n",
    "#import pymrt.geometry\n",
    "import ipyvolume as ipv\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from image_gen import ImageDataGenerator\n",
    "#from load_data import loadDataMontgomery, loadDataJSRT\n",
    "#from build_model import build_UNet2D_4L\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "from keras.layers import Convolution3D, Input, merge, RepeatVector, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import activations, initializers, regularizers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "#from keras.utils.np_utils import conv_output_length\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     2,
     91,
     143,
     192,
     263,
     344,
     374
    ]
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def unet_vanilla(input_size = (960,64,1)):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 256\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    \n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(4, 1))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "    up6   = Conv2D(filter4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (4,1))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    \n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = Conv2D(filter3, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    \n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    \n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9    = Conv2D(filter1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    #conv9  = BatchNormalization()(conv9)\n",
    "    conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9  = BatchNormalization()(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "    #conv10 = PReLU()(conv10)\n",
    "    \n",
    "    \n",
    "    #conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    #conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-3), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_vanilla1(input_size = (800,64,1)):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 1))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 1))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "    up6 = Conv2D(filter4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(filter3, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(filter2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(filter1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_dense(input_size = (960,64,1)):\n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    filter5 = 256\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    a1  = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
    "    a2  = MaxPooling2D(pool_size=(2, 2))(a1)\n",
    "    \n",
    "    a3  = Flatten()(a2)\n",
    "    b  = Dense(2400,   activation='relu', kernel_initializer = 'he_normal')(a3)\n",
    "    b  = BatchNormalization()(b)\n",
    "    \n",
    "    e  = Dense(4800,   activation='relu', kernel_initializer = 'he_normal')(b)\n",
    "    e  = BatchNormalization()(e)\n",
    "    \n",
    "    f  = Dense(4800,   activation='relu', kernel_initializer = 'he_normal')(e)\n",
    "    f  = BatchNormalization()(f)\n",
    "    \n",
    "    g  = Dense(4800,   activation='relu', kernel_initializer = 'he_normal')(f)\n",
    "    g  = BatchNormalization()(g)\n",
    "    \n",
    "    c  = Dense(2400,   activation='relu', kernel_initializer = 'he_normal')(g)\n",
    "    d  = Reshape([200, 12, 1])(c)  # Downsampled Sinogram which will go in loss function\n",
    "    \n",
    "    up1 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (1, 1))(d))\n",
    "    up1 = Concatenate()([up1, a2])\n",
    "    \n",
    "    up2 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(up1))\n",
    "    up2 = Concatenate()([up2, a1])\n",
    "    \n",
    "    up3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(up2))\n",
    "     \n",
    "    out = Conv2D(1, 1, activation = 'relu')(up3)\n",
    "\n",
    "    model = Model(input = inputs, output = [out, d])\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), \n",
    "                  loss = ['mean_absolute_error', 'mean_absolute_error'],\n",
    "                  loss_weights = [0.5, 0.5],\n",
    "                  metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "#a = unet_dense()\n",
    "#print(a.summary())\n",
    "\n",
    "def unet_3d_prelu(input_size = (104, 56, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    \n",
    "    zfilter = 40\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Add()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Add()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Add()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu2(input_size = (104, 56, 40, 1)):\n",
    "#def unet_3d_prelu2(input_size = (104, 24, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 128\n",
    "    \n",
    "    zfilter = 3\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, 3), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    #conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    #conv1 = ReLU()(conv1)\n",
    "    #conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, (3, 3, 3),  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, (3, 3, 10),  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, (3, 3, 5),  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Concatenate()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, (3, 3, 10),  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = Dropout(0.1)(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Concatenate()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = Dropout(0.1)(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Concatenate()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, 3),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = Dropout(0.1)(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    #merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "#     up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "#     up7 = ReLU()(up7)\n",
    "#     up7 = BatchNormalization()(up7)\n",
    "    \n",
    "#     up8 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "#     up8 = ReLU()(up8)\n",
    "#     up8 = BatchNormalization()(up8)\n",
    "    \n",
    "#     up8 = Add()([up8, merge1])\n",
    "    \n",
    "#     up9 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up8)\n",
    "#     up9 = ReLU()(up9)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(merge1)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0005), loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu1(input_size = (104, 56, 40, 1)):\n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    zfilter = 40\n",
    "    \n",
    "    model = load_model('/media/dril/ubuntudata/DBT-NEW/models/model2.h5', compile=False)\n",
    "    x     = model.layers[-3].output\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(x)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model1 = Model(input = model.input, output = conv9)\n",
    "    model1.compile(optimizer = Adam(lr = 0.0001), loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    model3 =  load_model('/media/dril/ubuntudata/DBT-NEW/models/model2.h5', compile=False)\n",
    "    \n",
    "    for i in range(len(model3.layers)-2):\n",
    "        if len(model3.layers[i].get_weights()) > 0:\n",
    "            model1.layers[i].set_weights(model3.layers[i].get_weights())\n",
    "    \n",
    "    return model1\n",
    "\n",
    "def bbox2_3D(img):\n",
    "\n",
    "    r = np.any(img, axis=(1, 2))\n",
    "    c = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax, zmin, zmax\n",
    "\n",
    "# For checking if weights are same or not of two networks\n",
    "\n",
    "# for i in range(40):\n",
    "#     w1 = model3.layers[i].get_weights()\n",
    "#     w2 = m2.layers[i].get_weights()\n",
    "    \n",
    "#     for j in range(len(w1)):\n",
    "#         print(i, np.all(w1[j] == w2[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For getting the shapes\n",
    "\n",
    "allshapesx = []\n",
    "allshapesy = []\n",
    "allshapesz = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    a = loadmat('/media/dril/ubuntudata/attenuation_values/'+str(i)+'.mat')\n",
    "    a = a['head']\n",
    "    b = copy.deepcopy(a)\n",
    "    a[a != 0 ] = 1\n",
    "    rmin, rmax, cmin, cmax, zmin, zmax = bbox2_3D(a)\n",
    "    b = b[rmin:rmax, cmin:cmax, zmin:zmax]\n",
    "    \n",
    "    allshapesx.append(b.shape[0])\n",
    "    allshapesy.append(b.shape[1])\n",
    "    allshapesz.append(b.shape[2])\n",
    "    \n",
    "    temp = int((800-b.shape[0])/2)\n",
    "    vol = b\n",
    "    vol = np.pad(b, ((temp, 800-temp-b.shape[0]), (320-b.shape[1], 0), (0, 448-b.shape[2])), \n",
    "                     'constant', constant_values=(0, 0))\n",
    "    vol = np.moveaxis(vol, [1, 2], [2, 1]).astype(np.single)\n",
    "\n",
    "    h = {}\n",
    "    h['head'] = vol\n",
    "    savemat('/media/dril/ubuntudata/attenuation_values_cropped/'+str(i)+'.mat', h,\n",
    "            do_compression=True)\n",
    "    print(i, vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New size will be 800, 320, 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 3D U-Net model\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    print(i)\n",
    "    #volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons/sart_cir_zero_'+str(i)+'.mat')\n",
    "    volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons-noise/fbp_'+str(i)+'_3_hann50.mat', verify_compressed_data_integrity=False)\n",
    "    voly = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/'+str(i)+'.mat')\n",
    "    \n",
    "    volx = volx['xfbp']\n",
    "    voly = voly['head']\n",
    "    \n",
    "    voly = ndimage.zoom(voly, 0.125, order=1).astype(np.single)\n",
    "    volx = ndimage.zoom(volx, 0.250, order=1).astype(np.single)\n",
    "    \n",
    "    if i <= 140:\n",
    "        trainx.append(np.expand_dims(volx, axis=-1))\n",
    "        trainy.append(np.expand_dims(voly, axis=-1))\n",
    "    else:\n",
    "        valx.append(np.expand_dims(volx,axis=-1))\n",
    "        valy.append(np.expand_dims(voly,axis=-1))\n",
    "\n",
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "valx   = np.array(valx)\n",
    "valy   = np.array(valy)\n",
    "\n",
    "trainx  = np.pad(trainx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "trainy  = np.pad(trainy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valx    = np.pad(valx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valy    = np.pad(valy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(valx.shape, valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 2D U-Net model for sinogram completion\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "slices_train = 31523\n",
    "slices_val   = 8133\n",
    "\n",
    "trainx  = np.zeros((slices_train, 960, 64, 1), dtype=np.single)\n",
    "trainy  = np.zeros((slices_train, 960, 64, 1), dtype=np.single)\n",
    "\n",
    "valx   = np.zeros((slices_val, 960, 64, 1), dtype=np.single)  # This is from sart\n",
    "valy   = np.zeros((slices_val, 960, 64, 1), dtype=np.single)\n",
    "\n",
    "\n",
    "count_train = 0\n",
    "count_val   = 0\n",
    "\n",
    "for i in range(1, 177):\n",
    "    x = loadmat('/media/dril/a19fa9b7-846c-45a0-be8c-ef93fea1e48c/gan-110-projections/g_noi_sart_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    #x = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/projections/g_noi_sart_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x = x['g_noi_nonoise']\n",
    "    \n",
    "    y = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/projections/g_noi_nonoise_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    #y = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/projections/g_noi_nonoise_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    y = y['g_noi_nonoise']\n",
    "    print(i, count_train, count_val)\n",
    "    \n",
    "    if i <= 140:\n",
    "        for j in range(0, 300):\n",
    "            tempx = x[:, j, :]\n",
    "            tempy = y[:, j, :]\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > 0:\n",
    "                trainx[count_train, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                trainy[count_train, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                count_train = count_train +1\n",
    "    else:\n",
    "        for j in range(0, 300):\n",
    "            tempx = x[:, j, :]\n",
    "            tempy = y[:, j, :]\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > 0:\n",
    "                valx[count_val, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                valy[count_val, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                count_val = count_val +1\n",
    "            \n",
    "print(trainx.shape, trainy.shape, valx.shape, valy.shape, count_train, count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 2D U-Net model for sinogram completion with higher resolution\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "train_slices = 23409\n",
    "val_slices   = 12138\n",
    "\n",
    "trainx  = np.zeros((train_slices, 1600, 48, 1), dtype=np.single)\n",
    "trainy  = np.zeros((train_slices, 1600, 48, 1), dtype=np.single)\n",
    "\n",
    "#valx   = np.zeros((int(10656/1), 1600, 48, 1), dtype=np.single)  # This is from sart\n",
    "#valy   = np.zeros((int(10656/1), 1600, 48, 1), dtype=np.single)\n",
    "\n",
    "valx   = np.zeros((val_slices, 1600, 48, 1), dtype=np.single)  # This is from sart\n",
    "valy   = np.zeros((val_slices, 1600, 48, 1), dtype=np.single)\n",
    "\n",
    "\n",
    "count_train = 0\n",
    "count_val   = 0\n",
    "\n",
    "less_than_train = []\n",
    "less_than_val   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    x = loadmat('/media/dril/Windows/gan-90-projections-higher/projections/g_noi_sart_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x = x['g_noi_nonoise']\n",
    "    \n",
    "    y = loadmat('/media/dril/Windows/gan-90-projections-higher/projections/g_noi_nonoise_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    y = y['g_noi_nonoise']\n",
    "    print(i, x.shape, y.shape)\n",
    "    \n",
    "    if i <= 140:\n",
    "        for j in range(0, 600):\n",
    "            tempx    = x[:, j, :]\n",
    "            tempy    = y[:, j, :]\n",
    "            tempdiff = tempy-tempx\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > 20000 and j%2 == 1:\n",
    "                less_than_train.append(np.count_nonzero(tempy.flatten()))\n",
    "                trainx[count_train, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                trainy[count_train, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                count_train = count_train +1\n",
    "    else:\n",
    "        for j in range(0, 600):\n",
    "            tempx    = x[:, j, :]\n",
    "            tempy    = y[:, j, :]\n",
    "            tempdiff = tempy-tempx\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > -1:\n",
    "                less_than_val.append(np.count_nonzero(tempy.flatten()))\n",
    "                \n",
    "                valx[count_val, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                valy[count_val, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                count_val = count_val +1\n",
    "            \n",
    "print(trainx.shape, trainy.shape, valx.shape, valy.shape, count_train, count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainy[:, :, 10:35, 0] = 0\n",
    "#valy[:, :, 10:35,   0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31523 samples, validate on 8133 samples\n",
      "Epoch 1/1500\n",
      "31523/31523 [==============================] - 600s 19ms/step - loss: 0.0023 - mean_squared_error: 4.4276e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.7870e-05\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00228, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.109777786\n",
      "Epoch 2/1500\n",
      "31523/31523 [==============================] - 625s 20ms/step - loss: 0.0022 - mean_squared_error: 4.0458e-05 - val_loss: 0.0026 - val_mean_squared_error: 5.9588e-05\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00228\n",
      "0.10908389\n",
      "Epoch 3/1500\n",
      "31523/31523 [==============================] - 638s 20ms/step - loss: 0.0022 - mean_squared_error: 4.0155e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.3956e-05\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00228 to 0.00224, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.106867425\n",
      "Epoch 4/1500\n",
      "31523/31523 [==============================] - 649s 21ms/step - loss: 0.0020 - mean_squared_error: 3.4808e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.1922e-05\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00224\n",
      "0.10646775\n",
      "Epoch 5/1500\n",
      "31523/31523 [==============================] - 650s 21ms/step - loss: 0.0020 - mean_squared_error: 3.4557e-05 - val_loss: 0.0031 - val_mean_squared_error: 1.8330e-04\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00224\n",
      "0.13875447\n",
      "Epoch 6/1500\n",
      "31523/31523 [==============================] - 649s 21ms/step - loss: 0.0020 - mean_squared_error: 3.3152e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.4353e-05\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00224 to 0.00223, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.109954305\n",
      "Epoch 7/1500\n",
      "31523/31523 [==============================] - 648s 21ms/step - loss: 0.0019 - mean_squared_error: 3.1403e-05 - val_loss: 0.0025 - val_mean_squared_error: 5.9611e-05\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00223\n",
      "0.099607214\n",
      "Epoch 8/1500\n",
      "31523/31523 [==============================] - 649s 21ms/step - loss: 0.0019 - mean_squared_error: 2.9376e-05 - val_loss: 0.0024 - val_mean_squared_error: 5.5789e-05\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00223\n",
      "0.10938356\n",
      "Epoch 9/1500\n",
      "31523/31523 [==============================] - 648s 21ms/step - loss: 0.0019 - mean_squared_error: 2.8871e-05 - val_loss: 0.0026 - val_mean_squared_error: 6.7042e-05\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00223\n",
      "0.09737947\n",
      "Epoch 10/1500\n",
      "31523/31523 [==============================] - 647s 21ms/step - loss: 0.0018 - mean_squared_error: 2.8604e-05 - val_loss: 0.0027 - val_mean_squared_error: 7.4795e-05\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00223\n",
      "0.10198385\n",
      "Epoch 11/1500\n",
      "31523/31523 [==============================] - 646s 20ms/step - loss: 0.0018 - mean_squared_error: 2.6667e-05 - val_loss: 0.0031 - val_mean_squared_error: 9.3688e-05\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00223\n",
      "0.18027611\n",
      "Epoch 12/1500\n",
      "31523/31523 [==============================] - 645s 20ms/step - loss: 0.0018 - mean_squared_error: 2.6344e-05 - val_loss: 0.0024 - val_mean_squared_error: 6.2335e-05\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00223\n",
      "0.10808281\n",
      "Epoch 13/1500\n",
      "31523/31523 [==============================] - 647s 21ms/step - loss: 0.0018 - mean_squared_error: 2.6262e-05 - val_loss: 0.0021 - val_mean_squared_error: 4.7347e-05\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00223 to 0.00210, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.08635047\n",
      "Epoch 14/1500\n",
      "31523/31523 [==============================] - 646s 20ms/step - loss: 0.0017 - mean_squared_error: 2.4744e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.4745e-05\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00210\n",
      "0.096437916\n",
      "Epoch 15/1500\n",
      "31523/31523 [==============================] - 646s 20ms/step - loss: 0.0017 - mean_squared_error: 2.3880e-05 - val_loss: 0.0026 - val_mean_squared_error: 5.9435e-05\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00210\n",
      "0.09661853\n",
      "Epoch 16/1500\n",
      "31523/31523 [==============================] - 646s 20ms/step - loss: 0.0017 - mean_squared_error: 2.3699e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.2282e-05\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00210 to 0.00209, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.09556524\n",
      "Epoch 17/1500\n",
      "31523/31523 [==============================] - 645s 20ms/step - loss: 0.0017 - mean_squared_error: 2.2956e-05 - val_loss: 0.0027 - val_mean_squared_error: 5.7307e-05\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00209\n",
      "0.09392298\n",
      "Epoch 18/1500\n",
      "31523/31523 [==============================] - 644s 20ms/step - loss: 0.0016 - mean_squared_error: 2.2328e-05 - val_loss: 0.0024 - val_mean_squared_error: 5.2802e-05\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00209\n",
      "0.090128876\n",
      "Epoch 19/1500\n",
      "31523/31523 [==============================] - 647s 21ms/step - loss: 0.0016 - mean_squared_error: 2.1488e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.0210e-05\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00209 to 0.00207, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.10138347\n",
      "Epoch 20/1500\n",
      "31523/31523 [==============================] - 647s 21ms/step - loss: 0.0016 - mean_squared_error: 2.1557e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.3363e-05\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00207\n",
      "0.08009887\n",
      "Epoch 21/1500\n",
      "31523/31523 [==============================] - 646s 20ms/step - loss: 0.0016 - mean_squared_error: 2.1240e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.0414e-05\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00207\n",
      "0.088195994\n",
      "Epoch 22/1500\n",
      "31523/31523 [==============================] - 647s 21ms/step - loss: 0.0016 - mean_squared_error: 2.0569e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.3776e-05\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00207\n",
      "0.082008354\n",
      "Epoch 23/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0016 - mean_squared_error: 2.0743e-05 - val_loss: 0.0021 - val_mean_squared_error: 6.4031e-05\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00207\n",
      "0.0992943\n",
      "Epoch 24/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0016 - mean_squared_error: 2.0271e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.3841e-05\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00207\n",
      "0.087756746\n",
      "Epoch 25/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0015 - mean_squared_error: 1.9473e-05 - val_loss: 0.0023 - val_mean_squared_error: 4.9672e-05\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00207\n",
      "0.10309983\n",
      "Epoch 26/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0015 - mean_squared_error: 1.9274e-05 - val_loss: 0.0021 - val_mean_squared_error: 4.9257e-05\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00207\n",
      "0.092923604\n",
      "Epoch 27/1500\n",
      "31523/31523 [==============================] - 636s 20ms/step - loss: 0.0015 - mean_squared_error: 1.8648e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.7940e-05\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00207 to 0.00204, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.08543181\n",
      "Epoch 28/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0015 - mean_squared_error: 1.8728e-05 - val_loss: 0.0023 - val_mean_squared_error: 8.8000e-05\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00204\n",
      "0.09655654\n",
      "Epoch 29/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0015 - mean_squared_error: 1.8545e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.9390e-05\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00204\n",
      "0.108292006\n",
      "Epoch 30/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0015 - mean_squared_error: 1.8415e-05 - val_loss: 0.0025 - val_mean_squared_error: 7.8026e-05\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00204\n",
      "0.10657897\n",
      "Epoch 31/1500\n",
      "31523/31523 [==============================] - 635s 20ms/step - loss: 0.0015 - mean_squared_error: 1.8689e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.0967e-05\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00204\n",
      "0.08536618\n",
      "Epoch 32/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0015 - mean_squared_error: 1.8041e-05 - val_loss: 0.0021 - val_mean_squared_error: 4.6919e-05\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00204\n",
      "0.0914687\n",
      "Epoch 33/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.8192e-05 - val_loss: 0.0027 - val_mean_squared_error: 7.5013e-05\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00204\n",
      "0.09270883\n",
      "Epoch 34/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0015 - mean_squared_error: 1.7793e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.0614e-05\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00204\n",
      "0.08204715\n",
      "Epoch 35/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.6955e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.6089e-05\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00204 to 0.00200, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.08153386\n",
      "Epoch 36/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0015 - mean_squared_error: 1.7556e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.5899e-05\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00200 to 0.00198, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.08782956\n",
      "Epoch 37/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.6839e-05 - val_loss: 0.0022 - val_mean_squared_error: 6.3486e-05\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00198\n",
      "0.10727379\n",
      "Epoch 38/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.6451e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.1870e-05\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00198\n",
      "0.08619426\n",
      "Epoch 39/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.6482e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.6434e-05\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00198\n",
      "0.08635032\n",
      "Epoch 40/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.6606e-05 - val_loss: 0.0024 - val_mean_squared_error: 5.3247e-05\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00198\n",
      "0.109119974\n",
      "Epoch 41/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5984e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.6514e-05\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00198\n",
      "0.07956843\n",
      "Epoch 42/1500\n",
      "31523/31523 [==============================] - 628s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5888e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.0993e-05\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00198\n",
      "0.08042493\n",
      "Epoch 43/1500\n",
      "31523/31523 [==============================] - 628s 20ms/step - loss: 0.0014 - mean_squared_error: 1.6185e-05 - val_loss: 0.0034 - val_mean_squared_error: 1.6036e-04\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00198\n",
      "0.11920619\n",
      "Epoch 44/1500\n",
      "31523/31523 [==============================] - 628s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5555e-05 - val_loss: 0.0021 - val_mean_squared_error: 4.8589e-05\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00198\n",
      "0.08188942\n",
      "Epoch 45/1500\n",
      "31523/31523 [==============================] - 628s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5855e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.3549e-05\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00198\n",
      "0.0834227\n",
      "Epoch 46/1500\n",
      "31523/31523 [==============================] - 628s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5423e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.5902e-05\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00198\n",
      "0.0819296\n",
      "Epoch 47/1500\n",
      "31523/31523 [==============================] - 628s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5731e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.6918e-05\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00198\n",
      "0.08745442\n",
      "Epoch 48/1500\n",
      "31523/31523 [==============================] - 627s 20ms/step - loss: 0.0013 - mean_squared_error: 1.4782e-05 - val_loss: 0.0024 - val_mean_squared_error: 5.4634e-05\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00198\n",
      "0.08862633\n",
      "Epoch 49/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0014 - mean_squared_error: 1.5236e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.6346e-05\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00198\n",
      "0.088165924\n",
      "Epoch 50/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0013 - mean_squared_error: 1.4721e-05 - val_loss: 0.0024 - val_mean_squared_error: 9.9580e-05\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00198\n",
      "0.099224\n",
      "Epoch 51/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0013 - mean_squared_error: 1.4916e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.4922e-05\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00198\n",
      "0.079760864\n",
      "Epoch 52/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0013 - mean_squared_error: 1.4991e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.0436e-05\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00198\n",
      "0.08557804\n",
      "Epoch 53/1500\n",
      "31523/31523 [==============================] - 610s 19ms/step - loss: 0.0013 - mean_squared_error: 1.4569e-05 - val_loss: 0.0023 - val_mean_squared_error: 9.9535e-05\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00198\n",
      "0.098804556\n",
      "Epoch 54/1500\n",
      "31523/31523 [==============================] - 597s 19ms/step - loss: 0.0013 - mean_squared_error: 1.4896e-05 - val_loss: 0.0023 - val_mean_squared_error: 8.5263e-05\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00198\n",
      "0.10071303\n",
      "Epoch 55/1500\n",
      "31523/31523 [==============================] - 598s 19ms/step - loss: 0.0013 - mean_squared_error: 1.4095e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.6879e-05\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00198 to 0.00198, saving model to /media/dril/ubuntudata/DBT-NEW/models/model-sinogram3-110-dril.h5\n",
      "0.08888504\n",
      "Epoch 56/1500\n",
      "31523/31523 [==============================] - 597s 19ms/step - loss: 0.0013 - mean_squared_error: 1.4368e-05 - val_loss: 0.0022 - val_mean_squared_error: 5.1966e-05\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00198\n",
      "0.07867988\n",
      "Epoch 57/1500\n",
      "31523/31523 [==============================] - 636s 20ms/step - loss: 0.0013 - mean_squared_error: 1.4326e-05 - val_loss: 0.0020 - val_mean_squared_error: 4.8168e-05\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00198\n",
      "0.08296346\n",
      "Epoch 58/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0013 - mean_squared_error: 1.3921e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.9259e-05\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00198\n",
      "0.09907155\n",
      "Epoch 59/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0013 - mean_squared_error: 1.4345e-05 - val_loss: 0.0023 - val_mean_squared_error: 5.1730e-05\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00198\n",
      "0.08161335\n",
      "Epoch 60/1500\n",
      "31523/31523 [==============================] - 629s 20ms/step - loss: 0.0013 - mean_squared_error: 1.3912e-05 - val_loss: 0.0021 - val_mean_squared_error: 5.4674e-05\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00198\n",
      "0.093589045\n",
      "Epoch 61/1500\n",
      "14584/31523 [============>.................] - ETA: 5:12 - loss: 0.0013 - mean_squared_error: 1.3746e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7fae1ced6ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m model.fit(trainx, trainy, validation_data=(valx, valy), \n\u001b[1;32m     32\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           epochs=1500, callbacks=[checkpoint,LossAndErrorPrintingCallback()])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For training the U-Net model\n",
    "\n",
    "# 31 is with L1 loss                             [0.002633739351092169,  5.250131192536668e-05]\n",
    "# 32 is with L2 loss                             [5.219619599067065e-05, 0.0026246307205545854]\n",
    "# 33 starts with 32 and then trains on odd lines [5.23863326888458e-05,  0.002626443004890068]\n",
    "\n",
    "checkpoint  = ModelCheckpoint(filepath='/media/dril/ubuntudata/DBT-NEW/models/model-sinogram4-110-dril.h5', \n",
    "                              monitor='val_loss', period=1, \n",
    "                              verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        index       = 2000\n",
    "        temp        = np.expand_dims(valx[index], axis=0)\n",
    "        temp_result = self.model.predict(temp)\n",
    "        a = temp[0, :, :, 0]\n",
    "        b = temp_result[0, :, :, 0]\n",
    "        c = valy[index, :, :, 0]\n",
    "        diff = np.abs(c-b)*100\n",
    "        print(np.mean(np.mean(diff)))\n",
    "        scipy.misc.imsave('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram1-110-dril-results/'+str(epoch)+'_diff.jpg', np.concatenate([diff.T, a.T], axis=0))\n",
    "        #print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "#unet_vanilla()\n",
    "model          = unet_vanilla()\n",
    "#model.load_weights('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram4-110-dril.h5')\n",
    "#\n",
    "#residual_train = trainx - trainy\n",
    "#residual_val   = valx   - valy\n",
    "\n",
    "model.fit(trainx, trainy, validation_data=(valx, valy), \n",
    "          batch_size=8, \n",
    "          epochs=1500, callbacks=[checkpoint,LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     39,
     93,
     131
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For training the GAN model\n",
    "\n",
    "img_size = (800, 48, 1)\n",
    "savepath = '/media/dril/ubuntudata/DBT-NEW/models/gan-model5/'\n",
    "\n",
    "class AdversarialAutoencoder():\n",
    "    def __init__(self):\n",
    "        self.optimizer  = Adam(0.0001)\n",
    "        self.clip_value = 0.01\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=self.optimizer, \n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        #self.discriminator.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/DBT_data/Results/vanilla-gan-weights-mse-0.1/discriminator_weights_8050.h5')\n",
    "        self.d_arr = []\n",
    "        self.g_arr = []\n",
    "        \n",
    "        # Build the encoder / decoder\n",
    "        self.generator      = self.build_generator()\n",
    "        img                 = Input(shape=img_size)\n",
    "        reconstructed_img   = self.generator(img)\n",
    "        \n",
    "        # For the adversarial_autoencoder model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator determines validity of the cleaned image\n",
    "        validity = self.discriminator(reconstructed_img)\n",
    "        \n",
    "        # The adversarial_autoencoder model  (stacked generator and discriminator)\n",
    "        self.adversarial_autoencoder = Model(img, [reconstructed_img, validity])\n",
    "        self.adversarial_autoencoder.compile(loss=['mean_absolute_error', 'mse'],\n",
    "            loss_weights=[0.99, 0.001],\n",
    "            optimizer=self.optimizer)\n",
    "        \n",
    "        self.generator.load_weights('/media/dril/ubuntudata/DBT-NEW/models/gan-model5/generator_weights_209700.h5')\n",
    "        self.discriminator.load_weights('/media/dril/ubuntudata/DBT-NEW/models/gan-model5/discriminator_weights_209700.h5')\n",
    "    \n",
    "    def build_generator(self):\n",
    "        input_size = (800, 48, 1)\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "\n",
    "        inputs = Input(input_size)\n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "        conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        #drop4 = conv4\n",
    "        drop4 = Dropout(0.2)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 1))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.2)(conv5)\n",
    "        #drop5 = conv5\n",
    "\n",
    "        up6    = Conv2D(filter4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(drop5))\n",
    "        merge6 = concatenate([drop4,up6], axis = 3)\n",
    "        conv6  = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6  = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7    = Conv2D(filter3, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = concatenate([conv3,up7], axis = 3)\n",
    "        conv7  = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7  = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8    = Conv2D(filter2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv7))\n",
    "        merge8 = concatenate([conv2,up8], axis = 3)\n",
    "        conv8  = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8  = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9    = Conv2D(filter1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = concatenate([conv1,up9], axis = 3)\n",
    "        conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "        \n",
    "        model = Model(input = inputs, output = conv10)\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        input_size = (800, 48, 1)\n",
    "\n",
    "        filter1 = 64 \n",
    "        filter2 = 128\n",
    "\n",
    "        inputs = Input(input_size)\n",
    "\n",
    "        input_top    = Lambda(lambda x: x[:, :, :10, 0])(inputs) \n",
    "        input_bottom = Lambda(lambda x: x[:, :, 35:, 0])(inputs)\n",
    "\n",
    "        new_input = Concatenate(axis=-1)([input_top, input_bottom])\n",
    "        new_input = Reshape([800, 23, 1])(new_input)\n",
    "        \n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(new_input) \n",
    "        pool1 = MaxPooling2D(pool_size=(2, 1))(conv1)\n",
    "\n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1) \n",
    "        conv1 = MaxPooling2D(pool_size=(2, 1))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1) \n",
    "        conv2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2) \n",
    "        conv2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2) \n",
    "        conv2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "\n",
    "        conv2 = Flatten()(conv2) \n",
    "        conv2 = Dense(512, activation='relu', kernel_initializer = 'he_normal')(conv2) \n",
    "        conv2 = Dense(128, activation='relu', kernel_initializer = 'he_normal')(conv2)\n",
    "        out   = Dense(1, activation='relu', kernel_initializer = 'he_normal')(conv2)\n",
    "\n",
    "        model = Model(input = inputs, output = out)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, epochs, batch_size=8, sampling=50, saveseed=5, startepoch=0, discriminator_epochs=5, log_sampling=1000):\n",
    "        global trainx\n",
    "        global trainy\n",
    "        global valx\n",
    "        global valy\n",
    "        \n",
    "        for epoch in range(startepoch, epochs):\n",
    "            # Train the discriminator 5 times\n",
    "            #print('Training Discriminator ', epoch)\n",
    "            \n",
    "            for itd in range(discriminator_epochs):\n",
    "                # Shuffle the dataset\n",
    "                random_index = np.random.randint(0, trainx.shape[0], batch_size)\n",
    "                \n",
    "                X_train = trainx[random_index]\n",
    "                Y_train = trainy[random_index]\n",
    "                \n",
    "                # Adversarial ground truths\n",
    "                valid = np.ones((batch_size,  1))\n",
    "                fake  = np.zeros((batch_size, 1))\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # get the noisy image and feed it into the generator\n",
    "                X_train_clean = self.generator.predict(X_train)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(Y_train, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(X_train_clean, fake)\n",
    "                d_loss      = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator\n",
    "            for itd in range(discriminator_epochs*10):\n",
    "                # Shuffle the dataset\n",
    "                random_index = np.random.randint(0, trainx.shape[0], batch_size)\n",
    "                \n",
    "                X_train = trainx[random_index]\n",
    "                Y_train = trainy[random_index]\n",
    "                \n",
    "                # Adversarial ground truths\n",
    "                valid = np.ones((batch_size,  1))\n",
    "                fake  = np.zeros((batch_size, 1))\n",
    "                g_loss = self.adversarial_autoencoder.train_on_batch(X_train, [Y_train, valid])\n",
    "            \n",
    "            #print(g_loss[0], g_loss[1], g_loss[2])\n",
    "            \n",
    "            self.d_arr.append(d_loss)\n",
    "            self.g_arr.append(g_loss)\n",
    "            \n",
    "            if epoch%sampling == 0 and epoch !=0:\n",
    "                result1 = self.generator.predict(valx, batch_size=4)\n",
    "                print('Mean L1 loss is ', np.mean(np.mean(np.abs(result1 - valy), axis=(1, 2, 3))))\n",
    "                self.generator.save_weights(savepath+'generator_weights_'+str(epoch)+'.h5')\n",
    "                self.discriminator.save_weights(savepath+'discriminator_weights_'+str(epoch)+'.h5')\n",
    "            \n",
    "            if epoch%log_sampling == 0:\n",
    "                print (\"%d [D loss: %f, mean_acc: %.2f%% real_acc: %.2f%% fake_acc: %.2f%%] [G loss: %f, L1: %f]\" % (epoch, d_loss[0], 100*d_loss[1], 100*d_loss_real[1], 100*d_loss_fake[1], g_loss[0], g_loss[1]))\n",
    "\n",
    "aae = AdversarialAutoencoder()\n",
    "aae.train(epochs=2000000, batch_size=8, \n",
    "          sampling=500, \n",
    "          saveseed=7590, \n",
    "          startepoch=209701, \n",
    "          discriminator_epochs=1,\n",
    "          log_sampling=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = aae.generator.predict(valx, batch_size=8)\n",
    "#print(a.shape, valy.shape)\n",
    "#result = a\n",
    "#print('Mean L1 loss is ', np.mean(np.mean(np.abs(result-valy), axis=(1, 2, 3))))\n",
    "epoch = 209700\n",
    "aae.generator.save_weights(savepath+'generator_weights_'+str(epoch)+'.h5')\n",
    "aae.discriminator.save_weights(savepath+'discriminator_weights_'+str(epoch)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8133/8133 [==============================] - 41s 5ms/step\n",
      "[0.0018616708284705172, 4.1579177295908704e-05]\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram2-110-dril.h5')\n",
    "result = model1.evaluate(valx, valy, batch_size=8)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00907218 7.0507317 0.0012867005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faab82e84e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x4320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(result))\n",
    "#print(index)\n",
    "t1 = valx[index, :, :, 0]\n",
    "t2 = result[index, :, :, 0]\n",
    "t3 = valy[index, :, :, 0]\n",
    "\n",
    "print( np.mean(np.abs(t1-t3)),  np.mean(np.abs(t1-t3))/np.mean(np.abs(t2-t3)), np.mean(np.abs(t2-t3)))\n",
    "\n",
    "plt.figure(figsize=(40, 60))\n",
    "#plt.imshow(np.concatenate([t1, t2, np.abs(t2-t1)*5, t4, np.abs(t4-t1)*5, t3, np.abs(t2-t3)*5, np.abs(t4-t3)*5], axis=-1).T, cmap='gray')\n",
    "#plt.imshow(np.concatenate([t1, t2, np.abs(t3-t1)*10, np.abs(t2-t3)*100], axis=-1).T, cmap='gray')\n",
    "plt.imshow(np.concatenate([np.abs(t3-t1)*10, np.abs(t2-t3)*10*np.mean(np.abs(t1-t3))/np.mean(np.abs(t2-t3))], axis=-1).T, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For getting the full projection from the sinogram for lower resolution 90 angle\n",
    "\n",
    "# Reading the original central projections\n",
    "valx_orig = np.zeros((36, 800, 300, 25), dtype=np.single) # These are the original noisy 25 projections\n",
    "counter   = 0\n",
    "for i in range(141, 177):\n",
    "    x_noise_orig = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/projections/g_noi_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x_noise_orig = x_noise_orig['g_noi']\n",
    "    print(i, x_noise_orig.shape)\n",
    "    temp         = x_noise_orig[:, :, 10:-10]\n",
    "    valx_orig[counter, :, :, :] = temp/5.0\n",
    "    counter = counter+1\n",
    "\n",
    "model  = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram21.h5')\n",
    "result = model.predict(valx, batch_size=16)\n",
    "\n",
    "result = result[:, :, :45, 0]\n",
    "valy   = valy[:, :, :45, 0]\n",
    "valx   = valx[:, :, :45, 0]\n",
    "valx   = valx[:, :, 10:-10]\n",
    "\n",
    "#valx   = valx_orig                # Replace the central projections\n",
    "\n",
    "print(valx.shape)\n",
    "\n",
    "result_25_full = np.zeros((36, 800, 300, 25), dtype=np.single)\n",
    "result_full    = np.zeros((36, 800, 300, 45), dtype=np.single)\n",
    "ground_full    = np.zeros((36, 800, 300, 45), dtype=np.single)\n",
    "\n",
    "valy_full   = []\n",
    "totalcount  = 0\n",
    "\n",
    "for i in range(36):\n",
    "    #result_25_full[i, :, :, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "    for j in range(300):\n",
    "        result_25_full[i, :, j, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "        result_full[i, :, j, :]    = result[totalcount, :, :]   # Prediction from the model, now replace the center 25 projections with original\n",
    "        ground_full[i, :, j, :]    = valy[totalcount, :, :]     # No noise projections \n",
    "        totalcount = totalcount+1\n",
    "\n",
    "# Replacing the central 25 projections\n",
    "print('Replacing the central 25 projections')\n",
    "result_full[:, :, :, 10:-10] = valx_orig[:, :, :, :]\n",
    "\n",
    "print('Converted to projections from line sinograms')\n",
    "print(result_full.shape, ground_full.shape)\n",
    "\n",
    "# Write to .mat file\n",
    "if(1):\n",
    "    for i in range(0, 36):\n",
    "        h1 = {}\n",
    "        h1['prediction']     = result_full[i]*5.0\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/predictions/model-sinogram21/'+str(i+1)+'_prediction.mat', h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['prediction_25']  = valx_orig[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/predictions/model-sinogram21/'+str(i+1)+'_input.mat',      h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['groundtruth']    = ground_full[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/predictions/model-sinogram21/'+str(i+1)+'_groundtruth.mat', h1, do_compression=True)\n",
    "\n",
    "print('Written to the disk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For getting the full projection from the sinogram for lower resolution 110 angle\n",
    "\n",
    "# Reading the original central projections\n",
    "valx_orig = np.zeros((36, 960, 300, 25), dtype=np.single) # These are the original noisy 25 projections\n",
    "counter   = 0\n",
    "for i in range(141, 177):\n",
    "    x_noise_orig = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/g_noi_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x_noise_orig = x_noise_orig['g_noi']\n",
    "    print(i, x_noise_orig.shape)\n",
    "    temp         = x_noise_orig[:, :, 15:-15]\n",
    "    valx_orig[counter, :, :, :] = temp/5.0\n",
    "    counter = counter+1\n",
    "\n",
    "model  = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram2-110-dril.h5')\n",
    "result = model.predict(valx, batch_size=16)\n",
    "\n",
    "result = result[:, :, 4:-5, 0]\n",
    "valy   = valy[:, :, 4:-5, 0]\n",
    "valx   = valx[:, :, 4:-5, 0]\n",
    "valx   = valx[:, :, 15:-15]\n",
    "\n",
    "#valx   = valx_orig                # Replace the central projections\n",
    "\n",
    "print(valx.shape)\n",
    "\n",
    "result_25_full = np.zeros((36, 960, 300, 25), dtype=np.single)\n",
    "result_full    = np.zeros((36, 960, 300, 55), dtype=np.single)\n",
    "ground_full    = np.zeros((36, 960, 300, 55), dtype=np.single)\n",
    "\n",
    "valy_full   = []\n",
    "totalcount  = 0\n",
    "\n",
    "for i in range(36):\n",
    "    #result_25_full[i, :, :, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "    for j in range(300):\n",
    "        result_25_full[i, :, j, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "        result_full[i, :, j, :]    = result[totalcount, :, :]   # Prediction from the model, now replace the center 25 projections with original\n",
    "        ground_full[i, :, j, :]    = valy[totalcount, :, :]     # No noise projections \n",
    "        totalcount = totalcount+1\n",
    "\n",
    "# Replacing the central 25 projections\n",
    "print('Replacing the central 25 projections')\n",
    "result_full[:, :, :, 15:-15] = valx_orig[:, :, :, :]\n",
    "\n",
    "print('Converted to projections from line sinograms')\n",
    "print(result_full.shape, ground_full.shape)\n",
    "\n",
    "# Write to .mat file\n",
    "if(1):\n",
    "    for i in range(0, 36):\n",
    "        h1 = {}\n",
    "        h1['prediction']     = result_full[i]*5.0\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/predictions/'+str(i+1)+'_prediction.mat', h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['prediction_25']  = valx_orig[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/predictions/'+str(i+1)+'_input.mat',      h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['groundtruth']    = ground_full[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/predictions/'+str(i+1)+'_groundtruth.mat', h1, do_compression=True)\n",
    "\n",
    "print('Written to the disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# For getting the full projection from the sinogram for higher resolution\n",
    "\n",
    "# Reading the original central projections\n",
    "valx_orig = np.zeros((36, 1600, 600, 25), dtype=np.single) # These are the original noisy 25 projections\n",
    "counter   = 0\n",
    "for i in range(141, 177):\n",
    "    x_noise_orig = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/projections/g_noi_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x_noise_orig = x_noise_orig['g_noi']\n",
    "    print(i, x_noise_orig.shape)\n",
    "    temp         = x_noise_orig[:, :, 10:-10]\n",
    "    valx_orig[counter, :, :, :] = temp/5.0\n",
    "    counter = counter+1\n",
    "\n",
    "model  = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram32-higher-dril.h5', compile=False)\n",
    "result = model.predict(valx, batch_size=16)\n",
    "\n",
    "result = result[:, :, :45, 0]\n",
    "valy   = valy[:, :, :45, 0]\n",
    "valx   = valx[:, :, :45, 0]\n",
    "valx   = valx[:, :, 10:-10]\n",
    "\n",
    "#valx   = valx_orig                # Replace the central projections\n",
    "\n",
    "print(valx.shape)\n",
    "\n",
    "result_25_full = np.zeros((36, 1600, 600, 25), dtype=np.single)\n",
    "result_full    = np.zeros((36, 1600, 600, 45), dtype=np.single)\n",
    "ground_full    = np.zeros((36, 1600, 600, 45), dtype=np.single)\n",
    "\n",
    "valy_full   = []\n",
    "totalcount  = 0\n",
    "\n",
    "for i in range(36):\n",
    "    #result_25_full[i, :, :, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "    for j in range(600):\n",
    "        result_25_full[i, :, j, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "        result_full[i, :, j, :]    = result[totalcount, :, :]   # Prediction from the model, now replace the center 25 projections with original\n",
    "        ground_full[i, :, j, :]    = valy[totalcount, :, :]     # No noise projections \n",
    "        totalcount = totalcount+1\n",
    "\n",
    "# Replacing the central 25 projections\n",
    "print('Replacing the central 25 projections')\n",
    "result_full[:, :, :, 10:-10] = valx_orig[:, :, :, :]\n",
    "\n",
    "print('Converted to projections from line sinograms')\n",
    "print(result_full.shape, ground_full.shape)\n",
    "\n",
    "# Write to .mat file\n",
    "if(1):\n",
    "    for i in range(0, 36):\n",
    "        h1 = {}\n",
    "        h1['prediction']     = result_full[i]*5.0\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/predictions/model-sinogram32-higher-dril/'+str(i+1)+'_prediction.mat', h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['prediction_25']  = valx_orig[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/predictions/model-sinogram32-higher-dril/'+str(i+1)+'_input.mat',      h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['groundtruth']    = ground_full[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/predictions/model-sinogram32-higher-dril/'+str(i+1)+'_groundtruth.mat', h1, do_compression=True)\n",
    "\n",
    "print('Written to the disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make total Model from slices and save the up-sampled output\n",
    "\n",
    "index   = 153#random.randint(0, 35)\n",
    "\n",
    "\n",
    "#volx = loadmat('/home/dril/newrecon/ReconDBT/xfbp.mat', verify_compressed_data_integrity=False)\n",
    "volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons-noise/fbp_'+str(index)+'_3_hann50.mat', verify_compressed_data_integrity=False)\n",
    "voly = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/'+str(index)+'.mat')  \n",
    "\n",
    "volx = volx['xfbp']\n",
    "voly = voly['head']\n",
    "b    = voly\n",
    "\n",
    "b    = volx#ndimage.zoom(volx, 0.50, order=1).astype(np.single)\n",
    "voly = ndimage.zoom(voly, 0.125, order=1).astype(np.single)\n",
    "volx = ndimage.zoom(volx, 0.250, order=1).astype(np.single)\n",
    "\n",
    "testitx = []\n",
    "testity = []\n",
    "\n",
    "gap_slice = 1\n",
    "for j in range(0, 36, gap_slice):\n",
    "    x = volx[:, j:j+20, :]\n",
    "    testitx.append(np.expand_dims(x, axis=-1))\n",
    "\n",
    "for j in range(0, 36, gap_slice):\n",
    "    y = voly[:, j:j+20, :]\n",
    "    testity.append(np.expand_dims(y, axis=-1))\n",
    "\n",
    "testitx = np.array(testitx)\n",
    "testity = np.array(testity)\n",
    "\n",
    "testitx  = np.pad(testitx, ((0,0), (2, 2), (2, 2), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "testity  = np.pad(testity, ((0,0), (2, 2), (2, 2), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "result = model.predict(testitx, batch_size=4)\n",
    "\n",
    "result  = result[:,  2:102, 2:22,  :, :]\n",
    "testitx = testitx[:, 2:102, 2:22,  :, :]\n",
    "testity = testity[:, 2:102, 2:22,  :, :]\n",
    "\n",
    "#print(testitx.shape, testity.shape, result.shape)\n",
    "\n",
    "# Joining the result to get the full volume from slice by slice results\n",
    "final_result = []\n",
    "for i in range(11):\n",
    "    final_result.append(result[0, :, i, :, 0])\n",
    "for i in range(0, len(result)):\n",
    "    temp = result[i, :, 10, :, 0]\n",
    "    final_result.append(result[i, :, 10, :, 0])\n",
    "for i in range(11, 20):\n",
    "    final_result.append(result[len(result)-1, :, i, :, 0])\n",
    "\n",
    "final_result  = np.array(final_result)\n",
    "final_result  = np.moveaxis(final_result, 0, 1)\n",
    "print(final_result.shape)\n",
    "\n",
    "# To save the upsampled low resolution deep learning model output\n",
    "a       = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/153.mat')\n",
    "a       = a['head']\n",
    "a       = ndimage.zoom(a, 0.5, order=1).astype(np.single)\n",
    "result1 = ndimage.zoom(final_result, 4, order=1).astype(np.single)\n",
    "h1         = {}\n",
    "h1['deep'] = result1.astype('single')\n",
    "\n",
    "\n",
    "diff_result = np.abs(result1-a)\n",
    "diff_result[diff_result < 0.5]   = 0\n",
    "diff_result[diff_result >= 0.5]  = 1\n",
    "h2            = {}\n",
    "h2['mask1']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "\n",
    "diff_result = np.abs(result1-a)\n",
    "diff_result[diff_result < 0.1]   = 0\n",
    "diff_result[diff_result >= 0.5]  = 0\n",
    "diff_result[diff_result >= 0.1]  = 1\n",
    "h3            = {}\n",
    "h3['mask2']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "\n",
    "diff_result = np.abs(result1-a)\n",
    "diff_result[diff_result >= 0.1]  = 0\n",
    "diff_result[(diff_result > 0.05) & (diff_result < 0.1)]  = 1\n",
    "diff_result[diff_result != 1]   = 0\n",
    "h4            = {}\n",
    "h4['mask3']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "a[a!=0]             = 1\n",
    "result1[result1!=0] = 1\n",
    "totalmask           = h2['mask1']+h3['mask2']+h4['mask3']\n",
    "totalmask[totalmask != 0] = 1\n",
    "\n",
    "diff_result = np.abs(totalmask - result1)\n",
    "diff_result[diff_result != 0]   = 1\n",
    "h5            = {}\n",
    "h5['mask4']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "\n",
    "# Uncomment this code to write the output\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50.mat',       h1, do_compression=True) # upsampled output\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask1.mat', h2, do_compression=True) # 0.5 <= error\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask2.mat', h3, do_compression=True) # 0.1 <= error <0.5\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask3.mat', h4, do_compression=True) # error < 0.1\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask4.mat', h5, do_compression=True) # rest mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
