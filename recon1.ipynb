{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback, TensorBoard\n",
    "from keras import backend as keras\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#import pylidc as pl\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import pymrt as mrt\n",
    "#import pymrt.geometry\n",
    "import ipyvolume as ipv\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from image_gen import ImageDataGenerator\n",
    "#from load_data import loadDataMontgomery, loadDataJSRT\n",
    "#from build_model import build_UNet2D_4L\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "from keras.layers import Convolution3D, Input, merge, RepeatVector, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import activations, initializers, regularizers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "#from keras.utils.np_utils import conv_output_length\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "code_folding": [
     2,
     66
    ]
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def unet_3d_prelu(input_size = (104, 56, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    \n",
    "    zfilter = 40\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Add()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Add()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Add()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def bbox2_3D(img):\n",
    "\n",
    "    r = np.any(img, axis=(1, 2))\n",
    "    c = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax, zmin, zmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For getting the shapes\n",
    "\n",
    "allshapesx = []\n",
    "allshapesy = []\n",
    "allshapesz = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    a = loadmat('/media/dril/ubuntudata/attenuation_values/'+str(i)+'.mat')\n",
    "    a = a['head']\n",
    "    b = copy.deepcopy(a)\n",
    "    a[a != 0 ] = 1\n",
    "    rmin, rmax, cmin, cmax, zmin, zmax = bbox2_3D(a)\n",
    "    b = b[rmin:rmax, cmin:cmax, zmin:zmax]\n",
    "    \n",
    "    allshapesx.append(b.shape[0])\n",
    "    allshapesy.append(b.shape[1])\n",
    "    allshapesz.append(b.shape[2])\n",
    "    \n",
    "    temp = int((800-b.shape[0])/2)\n",
    "    vol = b\n",
    "    vol = np.pad(b, ((temp, 800-temp-b.shape[0]), (320-b.shape[1], 0), (0, 448-b.shape[2])), \n",
    "                     'constant', constant_values=(0, 0))\n",
    "    vol = np.moveaxis(vol, [1, 2], [2, 1]).astype(np.single)\n",
    "\n",
    "    h = {}\n",
    "    h['head'] = vol\n",
    "    savemat('/media/dril/ubuntudata/attenuation_values_cropped/'+str(i)+'.mat', h,\n",
    "            do_compression=True)\n",
    "    print(i, vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New size will be 800, 320, 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 140\n",
      "36 36\n"
     ]
    }
   ],
   "source": [
    "# For reading the data for training the 3D U-Net model\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons/sart_cir_zero_'+str(i)+'.mat')\n",
    "    voly = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/'+str(i)+'.mat')\n",
    "    \n",
    "    volx = volx['xartt']\n",
    "    voly = voly['head']\n",
    "    \n",
    "    voly = ndimage.zoom(voly, 0.125, order=1).astype(np.single)\n",
    "    volx = ndimage.zoom(volx, 0.25, order=1).astype(np.single)\n",
    "    \n",
    "    if i <= 140:\n",
    "        trainx.append(np.expand_dims(volx, axis=-1))\n",
    "        trainy.append(np.expand_dims(voly, axis=-1))\n",
    "    else:\n",
    "        valx.append(np.expand_dims(volx,axis=-1))\n",
    "        valy.append(np.expand_dims(voly,axis=-1))\n",
    "\n",
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "valx   = np.array(valx)\n",
    "valy   = np.array(valy)\n",
    "\n",
    "trainx  = np.pad(trainx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "trainy  = np.pad(trainy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valx    = np.pad(valx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valy    = np.pad(valy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(valx.shape, valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/500\n",
      "140/140 [==============================] - 42s 298ms/step - loss: 0.0706 - mean_absolute_error: 0.1374 - val_loss: 0.0768 - val_mean_absolute_error: 0.1462\n",
      "Epoch 2/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0297 - mean_absolute_error: 0.0849 - val_loss: 0.0300 - val_mean_absolute_error: 0.0831\n",
      "Epoch 3/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0245 - mean_absolute_error: 0.0759 - val_loss: 0.0345 - val_mean_absolute_error: 0.0927\n",
      "Epoch 4/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0210 - mean_absolute_error: 0.0683 - val_loss: 0.0223 - val_mean_absolute_error: 0.0723\n",
      "Epoch 5/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0194 - mean_absolute_error: 0.0646 - val_loss: 0.0200 - val_mean_absolute_error: 0.0645\n",
      "Epoch 6/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0178 - mean_absolute_error: 0.0613 - val_loss: 0.0187 - val_mean_absolute_error: 0.0608\n",
      "Epoch 7/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0175 - mean_absolute_error: 0.0612 - val_loss: 0.0177 - val_mean_absolute_error: 0.0589\n",
      "Epoch 8/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0159 - mean_absolute_error: 0.0571 - val_loss: 0.0166 - val_mean_absolute_error: 0.0575\n",
      "Epoch 9/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0157 - mean_absolute_error: 0.0567 - val_loss: 0.0165 - val_mean_absolute_error: 0.0566\n",
      "Epoch 10/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0147 - mean_absolute_error: 0.0544 - val_loss: 0.0156 - val_mean_absolute_error: 0.0555\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.01556, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 11/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0154 - mean_absolute_error: 0.0563 - val_loss: 0.0170 - val_mean_absolute_error: 0.0589\n",
      "Epoch 12/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0141 - mean_absolute_error: 0.0548 - val_loss: 0.0138 - val_mean_absolute_error: 0.0503\n",
      "Epoch 13/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0126 - mean_absolute_error: 0.0510 - val_loss: 0.0139 - val_mean_absolute_error: 0.0550\n",
      "Epoch 14/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0125 - mean_absolute_error: 0.0507 - val_loss: 0.0151 - val_mean_absolute_error: 0.0571\n",
      "Epoch 15/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0118 - mean_absolute_error: 0.0492 - val_loss: 0.0125 - val_mean_absolute_error: 0.0467\n",
      "Epoch 16/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0117 - mean_absolute_error: 0.0486 - val_loss: 0.0122 - val_mean_absolute_error: 0.0476\n",
      "Epoch 17/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0111 - mean_absolute_error: 0.0468 - val_loss: 0.0133 - val_mean_absolute_error: 0.0510\n",
      "Epoch 18/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0117 - mean_absolute_error: 0.0489 - val_loss: 0.0128 - val_mean_absolute_error: 0.0502\n",
      "Epoch 19/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0109 - mean_absolute_error: 0.0464 - val_loss: 0.0116 - val_mean_absolute_error: 0.0454\n",
      "Epoch 20/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0105 - mean_absolute_error: 0.0450 - val_loss: 0.0137 - val_mean_absolute_error: 0.0466\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01556 to 0.01370, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 21/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0107 - mean_absolute_error: 0.0461 - val_loss: 0.0121 - val_mean_absolute_error: 0.0455\n",
      "Epoch 22/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0105 - mean_absolute_error: 0.0456 - val_loss: 0.0112 - val_mean_absolute_error: 0.0438\n",
      "Epoch 23/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0103 - mean_absolute_error: 0.0450 - val_loss: 0.0120 - val_mean_absolute_error: 0.0454\n",
      "Epoch 24/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0100 - mean_absolute_error: 0.0439 - val_loss: 0.0106 - val_mean_absolute_error: 0.0415\n",
      "Epoch 25/500\n",
      "140/140 [==============================] - 36s 258ms/step - loss: 0.0103 - mean_absolute_error: 0.0448 - val_loss: 0.0123 - val_mean_absolute_error: 0.0454\n",
      "Epoch 26/500\n",
      "140/140 [==============================] - 36s 258ms/step - loss: 0.0106 - mean_absolute_error: 0.0450 - val_loss: 0.0151 - val_mean_absolute_error: 0.0536\n",
      "Epoch 27/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0098 - mean_absolute_error: 0.0431 - val_loss: 0.0113 - val_mean_absolute_error: 0.0464\n",
      "Epoch 28/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0101 - mean_absolute_error: 0.0451 - val_loss: 0.0114 - val_mean_absolute_error: 0.0473\n",
      "Epoch 29/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0098 - mean_absolute_error: 0.0434 - val_loss: 0.0104 - val_mean_absolute_error: 0.0405\n",
      "Epoch 30/500\n",
      "140/140 [==============================] - 36s 258ms/step - loss: 0.0090 - mean_absolute_error: 0.0411 - val_loss: 0.0098 - val_mean_absolute_error: 0.0397\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01370 to 0.00980, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 31/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0091 - mean_absolute_error: 0.0414 - val_loss: 0.0105 - val_mean_absolute_error: 0.0405\n",
      "Epoch 32/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0089 - mean_absolute_error: 0.0407 - val_loss: 0.0104 - val_mean_absolute_error: 0.0439\n",
      "Epoch 33/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0085 - mean_absolute_error: 0.0394 - val_loss: 0.0103 - val_mean_absolute_error: 0.0395\n",
      "Epoch 34/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0090 - mean_absolute_error: 0.0412 - val_loss: 0.0108 - val_mean_absolute_error: 0.0428\n",
      "Epoch 35/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0088 - mean_absolute_error: 0.0405 - val_loss: 0.0094 - val_mean_absolute_error: 0.0374\n",
      "Epoch 36/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0091 - mean_absolute_error: 0.0409 - val_loss: 0.0097 - val_mean_absolute_error: 0.0393\n",
      "Epoch 37/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0087 - mean_absolute_error: 0.0403 - val_loss: 0.0097 - val_mean_absolute_error: 0.0391\n",
      "Epoch 38/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0087 - mean_absolute_error: 0.0404 - val_loss: 0.0090 - val_mean_absolute_error: 0.0374\n",
      "Epoch 39/500\n",
      "140/140 [==============================] - 35s 249ms/step - loss: 0.0083 - mean_absolute_error: 0.0386 - val_loss: 0.0110 - val_mean_absolute_error: 0.0443\n",
      "Epoch 40/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0080 - mean_absolute_error: 0.0381 - val_loss: 0.0093 - val_mean_absolute_error: 0.0375\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00980 to 0.00932, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 41/500\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 0.0081 - mean_absolute_error: 0.0385 - val_loss: 0.0087 - val_mean_absolute_error: 0.0353\n",
      "Epoch 42/500\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 0.0083 - mean_absolute_error: 0.0394 - val_loss: 0.0110 - val_mean_absolute_error: 0.0441\n",
      "Epoch 43/500\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 0.0080 - mean_absolute_error: 0.0381 - val_loss: 0.0091 - val_mean_absolute_error: 0.0382\n",
      "Epoch 44/500\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 0.0076 - mean_absolute_error: 0.0365 - val_loss: 0.0087 - val_mean_absolute_error: 0.0365\n",
      "Epoch 45/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0075 - mean_absolute_error: 0.0366 - val_loss: 0.0114 - val_mean_absolute_error: 0.0402\n",
      "Epoch 46/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 32s 231ms/step - loss: 0.0081 - mean_absolute_error: 0.0383 - val_loss: 0.0087 - val_mean_absolute_error: 0.0377\n",
      "Epoch 47/500\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 0.0084 - mean_absolute_error: 0.0388 - val_loss: 0.0124 - val_mean_absolute_error: 0.0465\n",
      "Epoch 48/500\n",
      "140/140 [==============================] - 32s 231ms/step - loss: 0.0075 - mean_absolute_error: 0.0363 - val_loss: 0.0105 - val_mean_absolute_error: 0.0406\n",
      "Epoch 49/500\n",
      "140/140 [==============================] - 32s 231ms/step - loss: 0.0074 - mean_absolute_error: 0.0364 - val_loss: 0.0089 - val_mean_absolute_error: 0.0366\n",
      "Epoch 50/500\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 0.0078 - mean_absolute_error: 0.0381 - val_loss: 0.0092 - val_mean_absolute_error: 0.0378\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00932 to 0.00916, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 51/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0076 - mean_absolute_error: 0.0369 - val_loss: 0.0091 - val_mean_absolute_error: 0.0367\n",
      "Epoch 52/500\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 0.0081 - mean_absolute_error: 0.0377 - val_loss: 0.0102 - val_mean_absolute_error: 0.0407\n",
      "Epoch 53/500\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 0.0080 - mean_absolute_error: 0.0377 - val_loss: 0.0082 - val_mean_absolute_error: 0.0375\n",
      "Epoch 54/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0075 - mean_absolute_error: 0.0366 - val_loss: 0.0083 - val_mean_absolute_error: 0.0337\n",
      "Epoch 55/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0071 - mean_absolute_error: 0.0358 - val_loss: 0.0079 - val_mean_absolute_error: 0.0345\n",
      "Epoch 56/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0072 - mean_absolute_error: 0.0359 - val_loss: 0.0100 - val_mean_absolute_error: 0.0389\n",
      "Epoch 57/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0071 - mean_absolute_error: 0.0355 - val_loss: 0.0080 - val_mean_absolute_error: 0.0336\n",
      "Epoch 58/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0069 - mean_absolute_error: 0.0349 - val_loss: 0.0080 - val_mean_absolute_error: 0.0352\n",
      "Epoch 59/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0066 - mean_absolute_error: 0.0339 - val_loss: 0.0075 - val_mean_absolute_error: 0.0338\n",
      "Epoch 60/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0066 - mean_absolute_error: 0.0339 - val_loss: 0.0077 - val_mean_absolute_error: 0.0345\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00916 to 0.00769, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 61/500\n",
      "140/140 [==============================] - 36s 258ms/step - loss: 0.0067 - mean_absolute_error: 0.0341 - val_loss: 0.0073 - val_mean_absolute_error: 0.0326\n",
      "Epoch 62/500\n",
      "140/140 [==============================] - 36s 258ms/step - loss: 0.0071 - mean_absolute_error: 0.0352 - val_loss: 0.0100 - val_mean_absolute_error: 0.0387\n",
      "Epoch 63/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0073 - mean_absolute_error: 0.0351 - val_loss: 0.0079 - val_mean_absolute_error: 0.0340\n",
      "Epoch 64/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0068 - mean_absolute_error: 0.0348 - val_loss: 0.0079 - val_mean_absolute_error: 0.0378\n",
      "Epoch 65/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0067 - mean_absolute_error: 0.0340 - val_loss: 0.0073 - val_mean_absolute_error: 0.0350\n",
      "Epoch 66/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0065 - mean_absolute_error: 0.0336 - val_loss: 0.0071 - val_mean_absolute_error: 0.0319\n",
      "Epoch 67/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0065 - mean_absolute_error: 0.0340 - val_loss: 0.0074 - val_mean_absolute_error: 0.0320\n",
      "Epoch 68/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0065 - mean_absolute_error: 0.0335 - val_loss: 0.0078 - val_mean_absolute_error: 0.0341\n",
      "Epoch 69/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0066 - mean_absolute_error: 0.0334 - val_loss: 0.0079 - val_mean_absolute_error: 0.0365\n",
      "Epoch 70/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0065 - mean_absolute_error: 0.0340 - val_loss: 0.0076 - val_mean_absolute_error: 0.0340\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00769 to 0.00759, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 71/500\n",
      "140/140 [==============================] - 36s 257ms/step - loss: 0.0062 - mean_absolute_error: 0.0331 - val_loss: 0.0071 - val_mean_absolute_error: 0.0328\n",
      "Epoch 72/500\n",
      "140/140 [==============================] - 35s 250ms/step - loss: 0.0062 - mean_absolute_error: 0.0325 - val_loss: 0.0069 - val_mean_absolute_error: 0.0331\n",
      "Epoch 73/500\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 0.0062 - mean_absolute_error: 0.0327 - val_loss: 0.0069 - val_mean_absolute_error: 0.0318\n",
      "Epoch 74/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0061 - mean_absolute_error: 0.0325 - val_loss: 0.0074 - val_mean_absolute_error: 0.0313\n",
      "Epoch 75/500\n",
      "140/140 [==============================] - 32s 232ms/step - loss: 0.0060 - mean_absolute_error: 0.0320 - val_loss: 0.0086 - val_mean_absolute_error: 0.0344\n",
      "Epoch 76/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0062 - mean_absolute_error: 0.0327 - val_loss: 0.0071 - val_mean_absolute_error: 0.0323\n",
      "Epoch 77/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0061 - mean_absolute_error: 0.0325 - val_loss: 0.0074 - val_mean_absolute_error: 0.0314\n",
      "Epoch 78/500\n",
      "140/140 [==============================] - 32s 231ms/step - loss: 0.0060 - mean_absolute_error: 0.0320 - val_loss: 0.0069 - val_mean_absolute_error: 0.0313\n",
      "Epoch 79/500\n",
      "140/140 [==============================] - 32s 231ms/step - loss: 0.0060 - mean_absolute_error: 0.0320 - val_loss: 0.0074 - val_mean_absolute_error: 0.0325\n",
      "Epoch 80/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0062 - mean_absolute_error: 0.0327 - val_loss: 0.0070 - val_mean_absolute_error: 0.0307\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00759 to 0.00704, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 81/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0060 - mean_absolute_error: 0.0317 - val_loss: 0.0071 - val_mean_absolute_error: 0.0303\n",
      "Epoch 82/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0061 - mean_absolute_error: 0.0324 - val_loss: 0.0073 - val_mean_absolute_error: 0.0326\n",
      "Epoch 83/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0063 - mean_absolute_error: 0.0337 - val_loss: 0.0071 - val_mean_absolute_error: 0.0319\n",
      "Epoch 84/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0062 - mean_absolute_error: 0.0326 - val_loss: 0.0085 - val_mean_absolute_error: 0.0343\n",
      "Epoch 85/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0061 - mean_absolute_error: 0.0320 - val_loss: 0.0081 - val_mean_absolute_error: 0.0389\n",
      "Epoch 86/500\n",
      "140/140 [==============================] - 32s 230ms/step - loss: 0.0060 - mean_absolute_error: 0.0322 - val_loss: 0.0078 - val_mean_absolute_error: 0.0331\n",
      "Epoch 87/500\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 0.0058 - mean_absolute_error: 0.0314 - val_loss: 0.0071 - val_mean_absolute_error: 0.0309\n",
      "Epoch 88/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0060 - mean_absolute_error: 0.0319 - val_loss: 0.0083 - val_mean_absolute_error: 0.0361\n",
      "Epoch 89/500\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 0.0057 - mean_absolute_error: 0.0310 - val_loss: 0.0074 - val_mean_absolute_error: 0.0328\n",
      "Epoch 90/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0057 - mean_absolute_error: 0.0308 - val_loss: 0.0069 - val_mean_absolute_error: 0.0321\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00704 to 0.00692, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0059 - mean_absolute_error: 0.0321 - val_loss: 0.0074 - val_mean_absolute_error: 0.0325\n",
      "Epoch 92/500\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 0.0060 - mean_absolute_error: 0.0317 - val_loss: 0.0071 - val_mean_absolute_error: 0.0321\n",
      "Epoch 93/500\n",
      "140/140 [==============================] - 33s 233ms/step - loss: 0.0056 - mean_absolute_error: 0.0306 - val_loss: 0.0068 - val_mean_absolute_error: 0.0319\n",
      "Epoch 94/500\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 0.0056 - mean_absolute_error: 0.0307 - val_loss: 0.0068 - val_mean_absolute_error: 0.0306\n",
      "Epoch 95/500\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 0.0060 - mean_absolute_error: 0.0323 - val_loss: 0.0068 - val_mean_absolute_error: 0.0307\n",
      "Epoch 96/500\n",
      "140/140 [==============================] - 33s 239ms/step - loss: 0.0058 - mean_absolute_error: 0.0316 - val_loss: 0.0067 - val_mean_absolute_error: 0.0306\n",
      "Epoch 97/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0057 - mean_absolute_error: 0.0315 - val_loss: 0.0064 - val_mean_absolute_error: 0.0289\n",
      "Epoch 98/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0057 - mean_absolute_error: 0.0307 - val_loss: 0.0066 - val_mean_absolute_error: 0.0297\n",
      "Epoch 99/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0064 - mean_absolute_error: 0.0330 - val_loss: 0.0097 - val_mean_absolute_error: 0.0389\n",
      "Epoch 100/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0063 - mean_absolute_error: 0.0326 - val_loss: 0.0079 - val_mean_absolute_error: 0.0344\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00692\n",
      "Epoch 101/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0057 - mean_absolute_error: 0.0309 - val_loss: 0.0091 - val_mean_absolute_error: 0.0369\n",
      "Epoch 102/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0059 - mean_absolute_error: 0.0315 - val_loss: 0.0064 - val_mean_absolute_error: 0.0300\n",
      "Epoch 103/500\n",
      "140/140 [==============================] - 35s 247ms/step - loss: 0.0055 - mean_absolute_error: 0.0302 - val_loss: 0.0062 - val_mean_absolute_error: 0.0298\n",
      "Epoch 104/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0065 - mean_absolute_error: 0.0328 - val_loss: 0.0084 - val_mean_absolute_error: 0.0356\n",
      "Epoch 105/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0062 - mean_absolute_error: 0.0333 - val_loss: 0.0075 - val_mean_absolute_error: 0.0327\n",
      "Epoch 106/500\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 0.0056 - mean_absolute_error: 0.0304 - val_loss: 0.0067 - val_mean_absolute_error: 0.0314\n",
      "Epoch 107/500\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 0.0056 - mean_absolute_error: 0.0308 - val_loss: 0.0066 - val_mean_absolute_error: 0.0318\n",
      "Epoch 108/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0054 - mean_absolute_error: 0.0301 - val_loss: 0.0074 - val_mean_absolute_error: 0.0337\n",
      "Epoch 109/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0054 - mean_absolute_error: 0.0300 - val_loss: 0.0062 - val_mean_absolute_error: 0.0303\n",
      "Epoch 110/500\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 0.0060 - mean_absolute_error: 0.0313 - val_loss: 0.0076 - val_mean_absolute_error: 0.0343\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00692\n",
      "Epoch 111/500\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 0.0058 - mean_absolute_error: 0.0310 - val_loss: 0.0067 - val_mean_absolute_error: 0.0337\n",
      "Epoch 112/500\n",
      "140/140 [==============================] - 33s 235ms/step - loss: 0.0053 - mean_absolute_error: 0.0300 - val_loss: 0.0063 - val_mean_absolute_error: 0.0305\n",
      "Epoch 113/500\n",
      "140/140 [==============================] - 33s 236ms/step - loss: 0.0055 - mean_absolute_error: 0.0305 - val_loss: 0.0066 - val_mean_absolute_error: 0.0303\n",
      "Epoch 114/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0055 - mean_absolute_error: 0.0306 - val_loss: 0.0063 - val_mean_absolute_error: 0.0296\n",
      "Epoch 115/500\n",
      "140/140 [==============================] - 32s 231ms/step - loss: 0.0053 - mean_absolute_error: 0.0296 - val_loss: 0.0090 - val_mean_absolute_error: 0.0345\n",
      "Epoch 116/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0054 - mean_absolute_error: 0.0296 - val_loss: 0.0061 - val_mean_absolute_error: 0.0288\n",
      "Epoch 117/500\n",
      "140/140 [==============================] - 34s 240ms/step - loss: 0.0054 - mean_absolute_error: 0.0300 - val_loss: 0.0082 - val_mean_absolute_error: 0.0347\n",
      "Epoch 118/500\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 0.0057 - mean_absolute_error: 0.0306 - val_loss: 0.0068 - val_mean_absolute_error: 0.0301\n",
      "Epoch 119/500\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 0.0052 - mean_absolute_error: 0.0293 - val_loss: 0.0060 - val_mean_absolute_error: 0.0293\n",
      "Epoch 120/500\n",
      "140/140 [==============================] - 32s 229ms/step - loss: 0.0053 - mean_absolute_error: 0.0297 - val_loss: 0.0063 - val_mean_absolute_error: 0.0280\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00692 to 0.00627, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 121/500\n",
      "140/140 [==============================] - 33s 234ms/step - loss: 0.0052 - mean_absolute_error: 0.0295 - val_loss: 0.0066 - val_mean_absolute_error: 0.0305\n",
      "Epoch 122/500\n",
      "140/140 [==============================] - 33s 238ms/step - loss: 0.0052 - mean_absolute_error: 0.0289 - val_loss: 0.0063 - val_mean_absolute_error: 0.0289\n",
      "Epoch 123/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0053 - mean_absolute_error: 0.0298 - val_loss: 0.0070 - val_mean_absolute_error: 0.0308\n",
      "Epoch 124/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0054 - mean_absolute_error: 0.0302 - val_loss: 0.0070 - val_mean_absolute_error: 0.0313\n",
      "Epoch 125/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0054 - mean_absolute_error: 0.0302 - val_loss: 0.0061 - val_mean_absolute_error: 0.0282\n",
      "Epoch 126/500\n",
      "140/140 [==============================] - 35s 253ms/step - loss: 0.0052 - mean_absolute_error: 0.0291 - val_loss: 0.0060 - val_mean_absolute_error: 0.0291\n",
      "Epoch 127/500\n",
      "140/140 [==============================] - 33s 232ms/step - loss: 0.0053 - mean_absolute_error: 0.0295 - val_loss: 0.0060 - val_mean_absolute_error: 0.0292\n",
      "Epoch 128/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0063 - mean_absolute_error: 0.0323 - val_loss: 0.0135 - val_mean_absolute_error: 0.0482\n",
      "Epoch 129/500\n",
      "140/140 [==============================] - 32s 228ms/step - loss: 0.0059 - mean_absolute_error: 0.0320 - val_loss: 0.0060 - val_mean_absolute_error: 0.0297\n",
      "Epoch 130/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0053 - mean_absolute_error: 0.0294 - val_loss: 0.0066 - val_mean_absolute_error: 0.0315\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00627\n",
      "Epoch 131/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0051 - mean_absolute_error: 0.0290 - val_loss: 0.0060 - val_mean_absolute_error: 0.0291\n",
      "Epoch 132/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0054 - mean_absolute_error: 0.0300 - val_loss: 0.0072 - val_mean_absolute_error: 0.0332\n",
      "Epoch 133/500\n",
      "140/140 [==============================] - 32s 227ms/step - loss: 0.0053 - mean_absolute_error: 0.0297 - val_loss: 0.0061 - val_mean_absolute_error: 0.0282\n",
      "Epoch 134/500\n",
      "140/140 [==============================] - 33s 237ms/step - loss: 0.0050 - mean_absolute_error: 0.0286 - val_loss: 0.0063 - val_mean_absolute_error: 0.0327\n",
      "Epoch 135/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0051 - mean_absolute_error: 0.0289 - val_loss: 0.0063 - val_mean_absolute_error: 0.0301\n",
      "Epoch 136/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0052 - mean_absolute_error: 0.0296 - val_loss: 0.0060 - val_mean_absolute_error: 0.0299\n",
      "Epoch 137/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0050 - mean_absolute_error: 0.0285 - val_loss: 0.0058 - val_mean_absolute_error: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0050 - mean_absolute_error: 0.0286 - val_loss: 0.0059 - val_mean_absolute_error: 0.0284\n",
      "Epoch 139/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0051 - mean_absolute_error: 0.0288 - val_loss: 0.0061 - val_mean_absolute_error: 0.0290\n",
      "Epoch 140/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0050 - mean_absolute_error: 0.0290 - val_loss: 0.0059 - val_mean_absolute_error: 0.0278\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00627 to 0.00592, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 141/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0052 - mean_absolute_error: 0.0293 - val_loss: 0.0059 - val_mean_absolute_error: 0.0287\n",
      "Epoch 142/500\n",
      "140/140 [==============================] - 36s 255ms/step - loss: 0.0049 - mean_absolute_error: 0.0282 - val_loss: 0.0061 - val_mean_absolute_error: 0.0300\n",
      "Epoch 143/500\n",
      "140/140 [==============================] - 36s 256ms/step - loss: 0.0050 - mean_absolute_error: 0.0285 - val_loss: 0.0062 - val_mean_absolute_error: 0.0282\n",
      "Epoch 144/500\n",
      "140/140 [==============================] - 34s 245ms/step - loss: 0.0051 - mean_absolute_error: 0.0294 - val_loss: 0.0058 - val_mean_absolute_error: 0.0278\n",
      "Epoch 145/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0049 - mean_absolute_error: 0.0284 - val_loss: 0.0057 - val_mean_absolute_error: 0.0273\n",
      "Epoch 146/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0051 - mean_absolute_error: 0.0292 - val_loss: 0.0060 - val_mean_absolute_error: 0.0279\n",
      "Epoch 147/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0049 - mean_absolute_error: 0.0278 - val_loss: 0.0055 - val_mean_absolute_error: 0.0268\n",
      "Epoch 148/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0049 - mean_absolute_error: 0.0280 - val_loss: 0.0060 - val_mean_absolute_error: 0.0276\n",
      "Epoch 149/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0050 - mean_absolute_error: 0.0283 - val_loss: 0.0062 - val_mean_absolute_error: 0.0322\n",
      "Epoch 150/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0049 - mean_absolute_error: 0.0282 - val_loss: 0.0058 - val_mean_absolute_error: 0.0281\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00592 to 0.00575, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 151/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0049 - mean_absolute_error: 0.0282 - val_loss: 0.0061 - val_mean_absolute_error: 0.0271\n",
      "Epoch 152/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0051 - mean_absolute_error: 0.0289 - val_loss: 0.0065 - val_mean_absolute_error: 0.0343\n",
      "Epoch 153/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0050 - mean_absolute_error: 0.0285 - val_loss: 0.0055 - val_mean_absolute_error: 0.0276\n",
      "Epoch 154/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0049 - mean_absolute_error: 0.0286 - val_loss: 0.0069 - val_mean_absolute_error: 0.0309\n",
      "Epoch 155/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0050 - mean_absolute_error: 0.0288 - val_loss: 0.0060 - val_mean_absolute_error: 0.0271\n",
      "Epoch 156/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0049 - mean_absolute_error: 0.0278 - val_loss: 0.0062 - val_mean_absolute_error: 0.0305\n",
      "Epoch 157/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0051 - mean_absolute_error: 0.0289 - val_loss: 0.0064 - val_mean_absolute_error: 0.0291\n",
      "Epoch 158/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0051 - mean_absolute_error: 0.0291 - val_loss: 0.0063 - val_mean_absolute_error: 0.0300\n",
      "Epoch 159/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0276 - val_loss: 0.0063 - val_mean_absolute_error: 0.0319\n",
      "Epoch 160/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0055 - mean_absolute_error: 0.0300 - val_loss: 0.0076 - val_mean_absolute_error: 0.0298\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00575\n",
      "Epoch 161/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0052 - mean_absolute_error: 0.0288 - val_loss: 0.0066 - val_mean_absolute_error: 0.0298\n",
      "Epoch 162/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0053 - mean_absolute_error: 0.0291 - val_loss: 0.0059 - val_mean_absolute_error: 0.0282\n",
      "Epoch 163/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0055 - mean_absolute_error: 0.0302 - val_loss: 0.0063 - val_mean_absolute_error: 0.0289\n",
      "Epoch 164/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0053 - mean_absolute_error: 0.0297 - val_loss: 0.0061 - val_mean_absolute_error: 0.0307\n",
      "Epoch 165/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0275 - val_loss: 0.0056 - val_mean_absolute_error: 0.0270\n",
      "Epoch 166/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0049 - mean_absolute_error: 0.0282 - val_loss: 0.0062 - val_mean_absolute_error: 0.0287\n",
      "Epoch 167/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0048 - mean_absolute_error: 0.0279 - val_loss: 0.0060 - val_mean_absolute_error: 0.0288\n",
      "Epoch 168/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0273 - val_loss: 0.0078 - val_mean_absolute_error: 0.0331\n",
      "Epoch 169/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0052 - mean_absolute_error: 0.0291 - val_loss: 0.0059 - val_mean_absolute_error: 0.0269\n",
      "Epoch 170/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0275 - val_loss: 0.0061 - val_mean_absolute_error: 0.0297\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00575\n",
      "Epoch 171/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0276 - val_loss: 0.0059 - val_mean_absolute_error: 0.0280\n",
      "Epoch 172/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0048 - mean_absolute_error: 0.0280 - val_loss: 0.0060 - val_mean_absolute_error: 0.0297\n",
      "Epoch 173/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0051 - mean_absolute_error: 0.0289 - val_loss: 0.0064 - val_mean_absolute_error: 0.0306\n",
      "Epoch 174/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0052 - mean_absolute_error: 0.0291 - val_loss: 0.0058 - val_mean_absolute_error: 0.0290\n",
      "Epoch 175/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0274 - val_loss: 0.0062 - val_mean_absolute_error: 0.0310\n",
      "Epoch 176/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0276 - val_loss: 0.0056 - val_mean_absolute_error: 0.0267\n",
      "Epoch 177/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0046 - mean_absolute_error: 0.0270 - val_loss: 0.0055 - val_mean_absolute_error: 0.0281\n",
      "Epoch 178/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0284 - val_loss: 0.0061 - val_mean_absolute_error: 0.0313\n",
      "Epoch 179/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0048 - mean_absolute_error: 0.0282 - val_loss: 0.0065 - val_mean_absolute_error: 0.0304\n",
      "Epoch 180/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0048 - mean_absolute_error: 0.0277 - val_loss: 0.0056 - val_mean_absolute_error: 0.0273\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00575 to 0.00564, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 181/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0049 - mean_absolute_error: 0.0279 - val_loss: 0.0073 - val_mean_absolute_error: 0.0325\n",
      "Epoch 182/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0050 - mean_absolute_error: 0.0283 - val_loss: 0.0062 - val_mean_absolute_error: 0.0282\n",
      "Epoch 183/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0048 - mean_absolute_error: 0.0279 - val_loss: 0.0058 - val_mean_absolute_error: 0.0282\n",
      "Epoch 184/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0271 - val_loss: 0.0057 - val_mean_absolute_error: 0.0277\n",
      "Epoch 185/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0048 - mean_absolute_error: 0.0287 - val_loss: 0.0055 - val_mean_absolute_error: 0.0264\n",
      "Epoch 186/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0274 - val_loss: 0.0055 - val_mean_absolute_error: 0.0273\n",
      "Epoch 187/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0273 - val_loss: 0.0063 - val_mean_absolute_error: 0.0281\n",
      "Epoch 188/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0271 - val_loss: 0.0059 - val_mean_absolute_error: 0.0277\n",
      "Epoch 189/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0274 - val_loss: 0.0061 - val_mean_absolute_error: 0.0296\n",
      "Epoch 190/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0278 - val_loss: 0.0057 - val_mean_absolute_error: 0.0287\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00564\n",
      "Epoch 191/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0048 - mean_absolute_error: 0.0282 - val_loss: 0.0067 - val_mean_absolute_error: 0.0299\n",
      "Epoch 192/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0272 - val_loss: 0.0055 - val_mean_absolute_error: 0.0258\n",
      "Epoch 193/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0044 - mean_absolute_error: 0.0264 - val_loss: 0.0055 - val_mean_absolute_error: 0.0273\n",
      "Epoch 194/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0271 - val_loss: 0.0055 - val_mean_absolute_error: 0.0288\n",
      "Epoch 195/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0044 - mean_absolute_error: 0.0262 - val_loss: 0.0059 - val_mean_absolute_error: 0.0295\n",
      "Epoch 196/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0046 - mean_absolute_error: 0.0273 - val_loss: 0.0056 - val_mean_absolute_error: 0.0282\n",
      "Epoch 197/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0270 - val_loss: 0.0056 - val_mean_absolute_error: 0.0275\n",
      "Epoch 198/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0276 - val_loss: 0.0055 - val_mean_absolute_error: 0.0266\n",
      "Epoch 199/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0047 - mean_absolute_error: 0.0274 - val_loss: 0.0055 - val_mean_absolute_error: 0.0273\n",
      "Epoch 200/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0048 - mean_absolute_error: 0.0279 - val_loss: 0.0062 - val_mean_absolute_error: 0.0323\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00564\n",
      "Epoch 201/500\n",
      "140/140 [==============================] - 34s 243ms/step - loss: 0.0050 - mean_absolute_error: 0.0287 - val_loss: 0.0059 - val_mean_absolute_error: 0.0273\n",
      "Epoch 202/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0051 - mean_absolute_error: 0.0286 - val_loss: 0.0064 - val_mean_absolute_error: 0.0312\n",
      "Epoch 203/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0274 - val_loss: 0.0054 - val_mean_absolute_error: 0.0262\n",
      "Epoch 204/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0275 - val_loss: 0.0055 - val_mean_absolute_error: 0.0281\n",
      "Epoch 205/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0275 - val_loss: 0.0054 - val_mean_absolute_error: 0.0260\n",
      "Epoch 206/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0268 - val_loss: 0.0056 - val_mean_absolute_error: 0.0258\n",
      "Epoch 207/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0270 - val_loss: 0.0054 - val_mean_absolute_error: 0.0260\n",
      "Epoch 208/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0267 - val_loss: 0.0056 - val_mean_absolute_error: 0.0283\n",
      "Epoch 209/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0276 - val_loss: 0.0054 - val_mean_absolute_error: 0.0266\n",
      "Epoch 210/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0050 - mean_absolute_error: 0.0288 - val_loss: 0.0060 - val_mean_absolute_error: 0.0293\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00564\n",
      "Epoch 211/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0050 - mean_absolute_error: 0.0287 - val_loss: 0.0065 - val_mean_absolute_error: 0.0284\n",
      "Epoch 212/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0267 - val_loss: 0.0055 - val_mean_absolute_error: 0.0272\n",
      "Epoch 213/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0048 - mean_absolute_error: 0.0278 - val_loss: 0.0057 - val_mean_absolute_error: 0.0274\n",
      "Epoch 214/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0274 - val_loss: 0.0056 - val_mean_absolute_error: 0.0284\n",
      "Epoch 215/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0276 - val_loss: 0.0056 - val_mean_absolute_error: 0.0284\n",
      "Epoch 216/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0269 - val_loss: 0.0058 - val_mean_absolute_error: 0.0296\n",
      "Epoch 217/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0276 - val_loss: 0.0054 - val_mean_absolute_error: 0.0273\n",
      "Epoch 218/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0263 - val_loss: 0.0060 - val_mean_absolute_error: 0.0263\n",
      "Epoch 219/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0264 - val_loss: 0.0053 - val_mean_absolute_error: 0.0259\n",
      "Epoch 220/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0263 - val_loss: 0.0053 - val_mean_absolute_error: 0.0257\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00564 to 0.00528, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 221/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0261 - val_loss: 0.0058 - val_mean_absolute_error: 0.0269\n",
      "Epoch 222/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0263 - val_loss: 0.0055 - val_mean_absolute_error: 0.0254\n",
      "Epoch 223/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0267 - val_loss: 0.0055 - val_mean_absolute_error: 0.0277\n",
      "Epoch 224/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0261 - val_loss: 0.0063 - val_mean_absolute_error: 0.0305\n",
      "Epoch 225/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0277 - val_loss: 0.0059 - val_mean_absolute_error: 0.0276\n",
      "Epoch 226/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0268 - val_loss: 0.0058 - val_mean_absolute_error: 0.0267\n",
      "Epoch 227/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0265 - val_loss: 0.0055 - val_mean_absolute_error: 0.0267\n",
      "Epoch 228/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0274 - val_loss: 0.0058 - val_mean_absolute_error: 0.0270\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0265 - val_loss: 0.0058 - val_mean_absolute_error: 0.0275\n",
      "Epoch 230/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0273 - val_loss: 0.0054 - val_mean_absolute_error: 0.0266\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00528\n",
      "Epoch 231/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0261 - val_loss: 0.0055 - val_mean_absolute_error: 0.0272\n",
      "Epoch 232/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0264 - val_loss: 0.0058 - val_mean_absolute_error: 0.0271\n",
      "Epoch 233/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0273 - val_loss: 0.0064 - val_mean_absolute_error: 0.0331\n",
      "Epoch 234/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0045 - mean_absolute_error: 0.0268 - val_loss: 0.0055 - val_mean_absolute_error: 0.0266\n",
      "Epoch 235/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0262 - val_loss: 0.0055 - val_mean_absolute_error: 0.0280\n",
      "Epoch 236/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0261 - val_loss: 0.0053 - val_mean_absolute_error: 0.0267\n",
      "Epoch 237/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0266 - val_loss: 0.0058 - val_mean_absolute_error: 0.0274\n",
      "Epoch 238/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0277 - val_loss: 0.0070 - val_mean_absolute_error: 0.0343\n",
      "Epoch 239/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0265 - val_loss: 0.0057 - val_mean_absolute_error: 0.0265\n",
      "Epoch 240/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0264 - val_loss: 0.0055 - val_mean_absolute_error: 0.0262\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00528\n",
      "Epoch 241/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0046 - mean_absolute_error: 0.0268 - val_loss: 0.0056 - val_mean_absolute_error: 0.0269\n",
      "Epoch 242/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0278 - val_loss: 0.0063 - val_mean_absolute_error: 0.0301\n",
      "Epoch 243/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0259 - val_loss: 0.0052 - val_mean_absolute_error: 0.0257\n",
      "Epoch 244/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0261 - val_loss: 0.0054 - val_mean_absolute_error: 0.0266\n",
      "Epoch 245/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0266 - val_loss: 0.0057 - val_mean_absolute_error: 0.0257\n",
      "Epoch 246/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0267 - val_loss: 0.0056 - val_mean_absolute_error: 0.0265\n",
      "Epoch 247/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0261 - val_loss: 0.0059 - val_mean_absolute_error: 0.0273\n",
      "Epoch 248/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0259 - val_loss: 0.0058 - val_mean_absolute_error: 0.0277\n",
      "Epoch 249/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0262 - val_loss: 0.0055 - val_mean_absolute_error: 0.0258\n",
      "Epoch 250/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0259 - val_loss: 0.0056 - val_mean_absolute_error: 0.0275\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00528\n",
      "Epoch 251/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0258 - val_loss: 0.0058 - val_mean_absolute_error: 0.0297\n",
      "Epoch 252/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0259 - val_loss: 0.0055 - val_mean_absolute_error: 0.0256\n",
      "Epoch 253/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0260 - val_loss: 0.0055 - val_mean_absolute_error: 0.0259\n",
      "Epoch 254/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0262 - val_loss: 0.0054 - val_mean_absolute_error: 0.0261\n",
      "Epoch 255/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0262 - val_loss: 0.0058 - val_mean_absolute_error: 0.0294\n",
      "Epoch 256/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0049 - mean_absolute_error: 0.0274 - val_loss: 0.0063 - val_mean_absolute_error: 0.0297\n",
      "Epoch 257/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0272 - val_loss: 0.0053 - val_mean_absolute_error: 0.0263\n",
      "Epoch 258/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0259 - val_loss: 0.0054 - val_mean_absolute_error: 0.0256\n",
      "Epoch 259/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0264 - val_loss: 0.0062 - val_mean_absolute_error: 0.0310\n",
      "Epoch 260/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0260 - val_loss: 0.0057 - val_mean_absolute_error: 0.0264\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00528\n",
      "Epoch 261/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0045 - mean_absolute_error: 0.0266 - val_loss: 0.0054 - val_mean_absolute_error: 0.0269\n",
      "Epoch 262/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0266 - val_loss: 0.0057 - val_mean_absolute_error: 0.0273\n",
      "Epoch 263/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0264 - val_loss: 0.0053 - val_mean_absolute_error: 0.0252\n",
      "Epoch 264/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0267 - val_loss: 0.0053 - val_mean_absolute_error: 0.0260\n",
      "Epoch 265/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0253 - val_loss: 0.0057 - val_mean_absolute_error: 0.0299\n",
      "Epoch 266/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0256 - val_loss: 0.0053 - val_mean_absolute_error: 0.0264\n",
      "Epoch 267/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0258 - val_loss: 0.0052 - val_mean_absolute_error: 0.0262\n",
      "Epoch 268/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0253 - val_loss: 0.0052 - val_mean_absolute_error: 0.0253\n",
      "Epoch 269/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0256 - val_loss: 0.0056 - val_mean_absolute_error: 0.0277\n",
      "Epoch 270/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0255 - val_loss: 0.0062 - val_mean_absolute_error: 0.0271\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00528\n",
      "Epoch 271/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0257 - val_loss: 0.0056 - val_mean_absolute_error: 0.0272\n",
      "Epoch 272/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0265 - val_loss: 0.0061 - val_mean_absolute_error: 0.0264\n",
      "Epoch 273/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0261 - val_loss: 0.0057 - val_mean_absolute_error: 0.0263\n",
      "Epoch 274/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0258 - val_loss: 0.0052 - val_mean_absolute_error: 0.0272\n",
      "Epoch 275/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0044 - mean_absolute_error: 0.0268 - val_loss: 0.0057 - val_mean_absolute_error: 0.0266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0251 - val_loss: 0.0053 - val_mean_absolute_error: 0.0264\n",
      "Epoch 277/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0251 - val_loss: 0.0059 - val_mean_absolute_error: 0.0290\n",
      "Epoch 278/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0040 - mean_absolute_error: 0.0253 - val_loss: 0.0051 - val_mean_absolute_error: 0.0259\n",
      "Epoch 279/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0259 - val_loss: 0.0056 - val_mean_absolute_error: 0.0258\n",
      "Epoch 280/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0260 - val_loss: 0.0062 - val_mean_absolute_error: 0.0323\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00528\n",
      "Epoch 281/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0253 - val_loss: 0.0055 - val_mean_absolute_error: 0.0285\n",
      "Epoch 282/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0253 - val_loss: 0.0062 - val_mean_absolute_error: 0.0277\n",
      "Epoch 283/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0260 - val_loss: 0.0056 - val_mean_absolute_error: 0.0275\n",
      "Epoch 284/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0041 - mean_absolute_error: 0.0259 - val_loss: 0.0057 - val_mean_absolute_error: 0.0257\n",
      "Epoch 285/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0264 - val_loss: 0.0057 - val_mean_absolute_error: 0.0265\n",
      "Epoch 286/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0041 - mean_absolute_error: 0.0255 - val_loss: 0.0056 - val_mean_absolute_error: 0.0259\n",
      "Epoch 287/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0254 - val_loss: 0.0051 - val_mean_absolute_error: 0.0251\n",
      "Epoch 288/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0252 - val_loss: 0.0052 - val_mean_absolute_error: 0.0259\n",
      "Epoch 289/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0258 - val_loss: 0.0055 - val_mean_absolute_error: 0.0257\n",
      "Epoch 290/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0246 - val_loss: 0.0054 - val_mean_absolute_error: 0.0274\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00528\n",
      "Epoch 291/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0246 - val_loss: 0.0051 - val_mean_absolute_error: 0.0253\n",
      "Epoch 292/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0262 - val_loss: 0.0064 - val_mean_absolute_error: 0.0292\n",
      "Epoch 293/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0047 - mean_absolute_error: 0.0271 - val_loss: 0.0062 - val_mean_absolute_error: 0.0290\n",
      "Epoch 294/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0251 - val_loss: 0.0057 - val_mean_absolute_error: 0.0279\n",
      "Epoch 295/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0248 - val_loss: 0.0053 - val_mean_absolute_error: 0.0267\n",
      "Epoch 296/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0256 - val_loss: 0.0058 - val_mean_absolute_error: 0.0280\n",
      "Epoch 297/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0251 - val_loss: 0.0056 - val_mean_absolute_error: 0.0261\n",
      "Epoch 298/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0041 - mean_absolute_error: 0.0259 - val_loss: 0.0056 - val_mean_absolute_error: 0.0278\n",
      "Epoch 299/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0247 - val_loss: 0.0054 - val_mean_absolute_error: 0.0266\n",
      "Epoch 300/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0249 - val_loss: 0.0056 - val_mean_absolute_error: 0.0273\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00528\n",
      "Epoch 301/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0042 - mean_absolute_error: 0.0261 - val_loss: 0.0052 - val_mean_absolute_error: 0.0248\n",
      "Epoch 302/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0242 - val_loss: 0.0053 - val_mean_absolute_error: 0.0262\n",
      "Epoch 303/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0241 - val_loss: 0.0052 - val_mean_absolute_error: 0.0253\n",
      "Epoch 304/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0247 - val_loss: 0.0054 - val_mean_absolute_error: 0.0255\n",
      "Epoch 305/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0250 - val_loss: 0.0055 - val_mean_absolute_error: 0.0273\n",
      "Epoch 306/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0251 - val_loss: 0.0051 - val_mean_absolute_error: 0.0251\n",
      "Epoch 307/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0248 - val_loss: 0.0055 - val_mean_absolute_error: 0.0272\n",
      "Epoch 308/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0250 - val_loss: 0.0058 - val_mean_absolute_error: 0.0292\n",
      "Epoch 309/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0254 - val_loss: 0.0054 - val_mean_absolute_error: 0.0256\n",
      "Epoch 310/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0041 - mean_absolute_error: 0.0252 - val_loss: 0.0052 - val_mean_absolute_error: 0.0270\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.00528 to 0.00522, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 311/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0040 - mean_absolute_error: 0.0251 - val_loss: 0.0053 - val_mean_absolute_error: 0.0247\n",
      "Epoch 312/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0254 - val_loss: 0.0055 - val_mean_absolute_error: 0.0251\n",
      "Epoch 313/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0242 - val_loss: 0.0052 - val_mean_absolute_error: 0.0248\n",
      "Epoch 314/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0249 - val_loss: 0.0052 - val_mean_absolute_error: 0.0265\n",
      "Epoch 315/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0246 - val_loss: 0.0055 - val_mean_absolute_error: 0.0256\n",
      "Epoch 316/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0250 - val_loss: 0.0062 - val_mean_absolute_error: 0.0304\n",
      "Epoch 317/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0253 - val_loss: 0.0060 - val_mean_absolute_error: 0.0280\n",
      "Epoch 318/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0247 - val_loss: 0.0052 - val_mean_absolute_error: 0.0253\n",
      "Epoch 319/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0250 - val_loss: 0.0053 - val_mean_absolute_error: 0.0252\n",
      "Epoch 320/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0245 - val_loss: 0.0052 - val_mean_absolute_error: 0.0255\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.00522 to 0.00515, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 321/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0247 - val_loss: 0.0061 - val_mean_absolute_error: 0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0247 - val_loss: 0.0055 - val_mean_absolute_error: 0.0263\n",
      "Epoch 323/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0245 - val_loss: 0.0053 - val_mean_absolute_error: 0.0261\n",
      "Epoch 324/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0242 - val_loss: 0.0053 - val_mean_absolute_error: 0.0250\n",
      "Epoch 325/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0249 - val_loss: 0.0056 - val_mean_absolute_error: 0.0279\n",
      "Epoch 326/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0243 - val_loss: 0.0056 - val_mean_absolute_error: 0.0284\n",
      "Epoch 327/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0243 - val_loss: 0.0056 - val_mean_absolute_error: 0.0271\n",
      "Epoch 328/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0040 - mean_absolute_error: 0.0255 - val_loss: 0.0062 - val_mean_absolute_error: 0.0264\n",
      "Epoch 329/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0043 - mean_absolute_error: 0.0261 - val_loss: 0.0056 - val_mean_absolute_error: 0.0280\n",
      "Epoch 330/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0246 - val_loss: 0.0052 - val_mean_absolute_error: 0.0254\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00515\n",
      "Epoch 331/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0248 - val_loss: 0.0051 - val_mean_absolute_error: 0.0254\n",
      "Epoch 332/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0250 - val_loss: 0.0054 - val_mean_absolute_error: 0.0277\n",
      "Epoch 333/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0038 - mean_absolute_error: 0.0247 - val_loss: 0.0052 - val_mean_absolute_error: 0.0247\n",
      "Epoch 334/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0246 - val_loss: 0.0052 - val_mean_absolute_error: 0.0260\n",
      "Epoch 335/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0247 - val_loss: 0.0052 - val_mean_absolute_error: 0.0247\n",
      "Epoch 336/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0245 - val_loss: 0.0051 - val_mean_absolute_error: 0.0248\n",
      "Epoch 337/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0244 - val_loss: 0.0055 - val_mean_absolute_error: 0.0275\n",
      "Epoch 338/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0246 - val_loss: 0.0053 - val_mean_absolute_error: 0.0250\n",
      "Epoch 339/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0243 - val_loss: 0.0054 - val_mean_absolute_error: 0.0249\n",
      "Epoch 340/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0240 - val_loss: 0.0058 - val_mean_absolute_error: 0.0282\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00515\n",
      "Epoch 341/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0241 - val_loss: 0.0054 - val_mean_absolute_error: 0.0263\n",
      "Epoch 342/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0249 - val_loss: 0.0053 - val_mean_absolute_error: 0.0253\n",
      "Epoch 343/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0246 - val_loss: 0.0059 - val_mean_absolute_error: 0.0317\n",
      "Epoch 344/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0040 - mean_absolute_error: 0.0250 - val_loss: 0.0059 - val_mean_absolute_error: 0.0289\n",
      "Epoch 345/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0246 - val_loss: 0.0060 - val_mean_absolute_error: 0.0259\n",
      "Epoch 346/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0238 - val_loss: 0.0051 - val_mean_absolute_error: 0.0261\n",
      "Epoch 347/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0239 - val_loss: 0.0051 - val_mean_absolute_error: 0.0245\n",
      "Epoch 348/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0236 - val_loss: 0.0052 - val_mean_absolute_error: 0.0252\n",
      "Epoch 349/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0239 - val_loss: 0.0051 - val_mean_absolute_error: 0.0249\n",
      "Epoch 350/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0239 - val_loss: 0.0052 - val_mean_absolute_error: 0.0242\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.00515 to 0.00515, saving model to /media/dril/ubuntudata/DBT-NEW/models/model2.h5\n",
      "Epoch 351/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0237 - val_loss: 0.0058 - val_mean_absolute_error: 0.0260\n",
      "Epoch 352/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0244 - val_loss: 0.0055 - val_mean_absolute_error: 0.0265\n",
      "Epoch 353/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0235 - val_loss: 0.0053 - val_mean_absolute_error: 0.0252\n",
      "Epoch 354/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0241 - val_loss: 0.0052 - val_mean_absolute_error: 0.0243\n",
      "Epoch 355/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0238 - val_loss: 0.0053 - val_mean_absolute_error: 0.0256\n",
      "Epoch 356/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0240 - val_loss: 0.0054 - val_mean_absolute_error: 0.0267\n",
      "Epoch 357/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0236 - val_loss: 0.0055 - val_mean_absolute_error: 0.0271\n",
      "Epoch 358/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0240 - val_loss: 0.0053 - val_mean_absolute_error: 0.0253\n",
      "Epoch 359/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0241 - val_loss: 0.0060 - val_mean_absolute_error: 0.0316\n",
      "Epoch 360/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0249 - val_loss: 0.0061 - val_mean_absolute_error: 0.0267\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.00515\n",
      "Epoch 361/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0244 - val_loss: 0.0051 - val_mean_absolute_error: 0.0251\n",
      "Epoch 362/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0244 - val_loss: 0.0052 - val_mean_absolute_error: 0.0243\n",
      "Epoch 363/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0241 - val_loss: 0.0064 - val_mean_absolute_error: 0.0302\n",
      "Epoch 364/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0241 - val_loss: 0.0057 - val_mean_absolute_error: 0.0264\n",
      "Epoch 365/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0236 - val_loss: 0.0059 - val_mean_absolute_error: 0.0253\n",
      "Epoch 366/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0241 - val_loss: 0.0054 - val_mean_absolute_error: 0.0254\n",
      "Epoch 367/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0237 - val_loss: 0.0054 - val_mean_absolute_error: 0.0260\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0237 - val_loss: 0.0052 - val_mean_absolute_error: 0.0251\n",
      "Epoch 369/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0036 - mean_absolute_error: 0.0239 - val_loss: 0.0051 - val_mean_absolute_error: 0.0248\n",
      "Epoch 370/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0035 - mean_absolute_error: 0.0233 - val_loss: 0.0054 - val_mean_absolute_error: 0.0263\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00515\n",
      "Epoch 371/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0035 - mean_absolute_error: 0.0230 - val_loss: 0.0055 - val_mean_absolute_error: 0.0278\n",
      "Epoch 372/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0038 - mean_absolute_error: 0.0243 - val_loss: 0.0052 - val_mean_absolute_error: 0.0251\n",
      "Epoch 373/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0039 - mean_absolute_error: 0.0244 - val_loss: 0.0055 - val_mean_absolute_error: 0.0266\n",
      "Epoch 374/500\n",
      "140/140 [==============================] - 34s 241ms/step - loss: 0.0036 - mean_absolute_error: 0.0237 - val_loss: 0.0055 - val_mean_absolute_error: 0.0251\n",
      "Epoch 375/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0239 - val_loss: 0.0055 - val_mean_absolute_error: 0.0257\n",
      "Epoch 376/500\n",
      "140/140 [==============================] - 34s 242ms/step - loss: 0.0037 - mean_absolute_error: 0.0244 - val_loss: 0.0065 - val_mean_absolute_error: 0.0340\n",
      "Epoch 377/500\n",
      "136/140 [============================>.] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0238"
     ]
    }
   ],
   "source": [
    "# For training the U-Net model\n",
    "\n",
    "checkpoint  = ModelCheckpoint(filepath='/media/dril/ubuntudata/DBT-NEW/models/model2.h5', \n",
    "                              monitor='val_loss', period=10, \n",
    "                              verbose=1, save_best_only=True, mode='min')\n",
    "model = unet_3d_prelu()\n",
    "model.fit(trainx, trainy, validation_data=(valx, valy), \n",
    "          batch_size=4, \n",
    "          epochs=500, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 104, 56, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(valx, batch_size=4)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cd4188320>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, 35)\n",
    "print(index)\n",
    "plt.imshow(np.concatenate([result[index, :, :, 20, 0], valx[index, :, :, 20, 0], valy[index, :, :, 20, 0]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ca8296860>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, 35)\n",
    "plt.imshow(np.concatenate([result[index, 50, :, :, 0], valx[index, 50, :, :, 0], valy[index, 50, :, :, 0]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
