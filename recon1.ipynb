{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback, TensorBoard\n",
    "from keras import backend as keras\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#import pylidc as pl\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import pymrt as mrt\n",
    "#import pymrt.geometry\n",
    "import ipyvolume as ipv\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from image_gen import ImageDataGenerator\n",
    "#from load_data import loadDataMontgomery, loadDataJSRT\n",
    "#from build_model import build_UNet2D_4L\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "from keras.layers import Convolution3D, Input, merge, RepeatVector, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import activations, initializers, regularizers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "#from keras.utils.np_utils import conv_output_length\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     2,
     147,
     177
    ]
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def unet_3d_prelu(input_size = (104, 56, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    \n",
    "    zfilter = 40\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Add()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Add()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Add()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu2(input_size = (56, 56, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    \n",
    "    zfilter = 3\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Add()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Add()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Add()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    \n",
    "    up8 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "    up8 = ReLU()(up8)\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    \n",
    "    up8 = Add()([up8, merge1])\n",
    "    \n",
    "    up9 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up8)\n",
    "    up9 = ReLU()(up9)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up9)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0002), loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu1(input_size = (104, 56, 40, 1)):\n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    zfilter = 40\n",
    "    \n",
    "    model = load_model('/media/dril/ubuntudata/DBT-NEW/models/model2.h5', compile=False)\n",
    "    x     = model.layers[-3].output\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(x)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model1 = Model(input = model.input, output = conv9)\n",
    "    model1.compile(optimizer = Adam(lr = 0.0001), loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    model3 =  load_model('/media/dril/ubuntudata/DBT-NEW/models/model2.h5', compile=False)\n",
    "    \n",
    "    for i in range(len(model3.layers)-2):\n",
    "        if len(model3.layers[i].get_weights()) > 0:\n",
    "            model1.layers[i].set_weights(model3.layers[i].get_weights())\n",
    "    \n",
    "    return model1\n",
    "\n",
    "def bbox2_3D(img):\n",
    "\n",
    "    r = np.any(img, axis=(1, 2))\n",
    "    c = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax, zmin, zmax\n",
    "\n",
    "# For checking if weights are same or not of two networks\n",
    "\n",
    "# for i in range(40):\n",
    "#     w1 = model3.layers[i].get_weights()\n",
    "#     w2 = m2.layers[i].get_weights()\n",
    "    \n",
    "#     for j in range(len(w1)):\n",
    "#         print(i, np.all(w1[j] == w2[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For getting the shapes\n",
    "\n",
    "allshapesx = []\n",
    "allshapesy = []\n",
    "allshapesz = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    a = loadmat('/media/dril/ubuntudata/attenuation_values/'+str(i)+'.mat')\n",
    "    a = a['head']\n",
    "    b = copy.deepcopy(a)\n",
    "    a[a != 0 ] = 1\n",
    "    rmin, rmax, cmin, cmax, zmin, zmax = bbox2_3D(a)\n",
    "    b = b[rmin:rmax, cmin:cmax, zmin:zmax]\n",
    "    \n",
    "    allshapesx.append(b.shape[0])\n",
    "    allshapesy.append(b.shape[1])\n",
    "    allshapesz.append(b.shape[2])\n",
    "    \n",
    "    temp = int((800-b.shape[0])/2)\n",
    "    vol = b\n",
    "    vol = np.pad(b, ((temp, 800-temp-b.shape[0]), (320-b.shape[1], 0), (0, 448-b.shape[2])), \n",
    "                     'constant', constant_values=(0, 0))\n",
    "    vol = np.moveaxis(vol, [1, 2], [2, 1]).astype(np.single)\n",
    "\n",
    "    h = {}\n",
    "    h['head'] = vol\n",
    "    savemat('/media/dril/ubuntudata/attenuation_values_cropped/'+str(i)+'.mat', h,\n",
    "            do_compression=True)\n",
    "    print(i, vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New size will be 800, 320, 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 3D U-Net model\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons/sart_cir_zero_'+str(i)+'.mat')\n",
    "    voly = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/'+str(i)+'.mat')\n",
    "    \n",
    "    volx = volx['xartt']\n",
    "    voly = voly['head']\n",
    "    \n",
    "    voly = ndimage.zoom(voly, 0.0625, order=1).astype(np.single)\n",
    "    volx = ndimage.zoom(volx, 0.125, order=1).astype(np.single)\n",
    "    \n",
    "    if i <= 140:\n",
    "        trainx.append(np.expand_dims(volx, axis=-1))\n",
    "        trainy.append(np.expand_dims(voly, axis=-1))\n",
    "    else:\n",
    "        valx.append(np.expand_dims(volx,axis=-1))\n",
    "        valy.append(np.expand_dims(voly,axis=-1))\n",
    "\n",
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "valx   = np.array(valx)\n",
    "valy   = np.array(valy)\n",
    "\n",
    "# trainx  = np.pad(trainx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "# trainy  = np.pad(trainy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "# valx    = np.pad(valx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "# valy    = np.pad(valy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(valx.shape, valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 3D U-Net model in small patches\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    print(i)\n",
    "    volx = loadmat('/media/pranjal/Backup/DBT-NEW/recons/sart_cir_zero_'+str(i)+'.mat')\n",
    "    voly = loadmat('/media/pranjal/Backup/DBT-NEW/attenuation_values_cropped/'+str(i)+'.mat')\n",
    "    \n",
    "    volx = volx['xartt']\n",
    "    voly = voly['head']\n",
    "    \n",
    "    voly = ndimage.zoom(voly, 0.125, order=1).astype(np.single)\n",
    "    volx = ndimage.zoom(volx, 0.250, order=1).astype(np.single)\n",
    "    \n",
    "    #print(volx.shape)\n",
    "    x1 = volx[:50, :, :]\n",
    "    x2 = volx[50:, :, :]\n",
    "    x3 = volx[25:75, :, :]\n",
    "    x4 = volx[35:85, :, :]\n",
    "    x5 = volx[15:65, :, :]\n",
    "\n",
    "    y1 = voly[:50, :, :]\n",
    "    y2 = voly[50:, :, :]\n",
    "    y3 = voly[25:75, :, :]\n",
    "    y4 = voly[35:85, :, :]\n",
    "    y5 = voly[15:65, :, :]\n",
    "        \n",
    "    if i <= 140:\n",
    "        trainx.append(np.expand_dims(x1, axis=-1))\n",
    "        trainx.append(np.expand_dims(x2, axis=-1))\n",
    "        trainx.append(np.expand_dims(x3, axis=-1))\n",
    "        trainx.append(np.expand_dims(x4, axis=-1))\n",
    "        trainx.append(np.expand_dims(x5, axis=-1))\n",
    "        \n",
    "        trainy.append(np.expand_dims(y1, axis=-1))\n",
    "        trainy.append(np.expand_dims(y2, axis=-1))\n",
    "        trainy.append(np.expand_dims(y3, axis=-1))\n",
    "        trainy.append(np.expand_dims(y4, axis=-1))\n",
    "        trainy.append(np.expand_dims(y5, axis=-1))\n",
    "    else:\n",
    "        valx.append(np.expand_dims(x1, axis=-1))\n",
    "        valx.append(np.expand_dims(x2, axis=-1))\n",
    "        valx.append(np.expand_dims(x3, axis=-1))\n",
    "        valx.append(np.expand_dims(x4, axis=-1))\n",
    "        valx.append(np.expand_dims(x5, axis=-1))\n",
    "        \n",
    "        valy.append(np.expand_dims(y1, axis=-1))\n",
    "        valy.append(np.expand_dims(y2, axis=-1))\n",
    "        valy.append(np.expand_dims(y3, axis=-1))\n",
    "        valy.append(np.expand_dims(y4, axis=-1))\n",
    "        valy.append(np.expand_dims(y5, axis=-1))\n",
    "\n",
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "valx   = np.array(valx)\n",
    "valy   = np.array(valy)\n",
    "\n",
    "trainx  = np.pad(trainx, ((0,0), (3, 3), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "trainy  = np.pad(trainy, ((0,0), (3, 3), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valx    = np.pad(valx, ((0,0), (3, 3), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valy    = np.pad(valy, ((0,0), (3, 3), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(valx.shape, valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 180 samples\n",
      "Epoch 1/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.1775 - mean_squared_error: 0.1816 - val_loss: 0.0820 - val_mean_squared_error: 0.0321\n",
      "Epoch 2/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0696 - mean_squared_error: 0.0256 - val_loss: 0.0598 - val_mean_squared_error: 0.0221\n",
      "Epoch 3/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0584 - mean_squared_error: 0.0205 - val_loss: 0.0509 - val_mean_squared_error: 0.0184\n",
      "Epoch 4/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0526 - mean_squared_error: 0.0177 - val_loss: 0.0539 - val_mean_squared_error: 0.0177\n",
      "Epoch 5/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0489 - mean_squared_error: 0.0162 - val_loss: 0.0508 - val_mean_squared_error: 0.0184\n",
      "Epoch 6/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0464 - mean_squared_error: 0.0151 - val_loss: 0.0413 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0426 - mean_squared_error: 0.0130 - val_loss: 0.0413 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0408 - mean_squared_error: 0.0122 - val_loss: 0.0380 - val_mean_squared_error: 0.0127\n",
      "Epoch 9/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0393 - mean_squared_error: 0.0115 - val_loss: 0.0371 - val_mean_squared_error: 0.0128\n",
      "Epoch 10/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0378 - mean_squared_error: 0.0109 - val_loss: 0.0370 - val_mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.03696, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 11/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0373 - mean_squared_error: 0.0108 - val_loss: 0.0356 - val_mean_squared_error: 0.0115\n",
      "Epoch 12/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0362 - mean_squared_error: 0.0102 - val_loss: 0.0357 - val_mean_squared_error: 0.0109\n",
      "Epoch 13/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0353 - mean_squared_error: 0.0098 - val_loss: 0.0344 - val_mean_squared_error: 0.0106\n",
      "Epoch 14/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0344 - mean_squared_error: 0.0095 - val_loss: 0.0338 - val_mean_squared_error: 0.0110\n",
      "Epoch 15/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0344 - mean_squared_error: 0.0095 - val_loss: 0.0337 - val_mean_squared_error: 0.0102\n",
      "Epoch 16/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0336 - mean_squared_error: 0.0091 - val_loss: 0.0333 - val_mean_squared_error: 0.0110\n",
      "Epoch 17/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0334 - mean_squared_error: 0.0090 - val_loss: 0.0325 - val_mean_squared_error: 0.0106\n",
      "Epoch 18/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0328 - mean_squared_error: 0.0089 - val_loss: 0.0323 - val_mean_squared_error: 0.0100\n",
      "Epoch 19/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0324 - mean_squared_error: 0.0088 - val_loss: 0.0348 - val_mean_squared_error: 0.0112\n",
      "Epoch 20/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0323 - mean_squared_error: 0.0086 - val_loss: 0.0315 - val_mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.03696 to 0.03152, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 21/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0312 - mean_squared_error: 0.0082 - val_loss: 0.0308 - val_mean_squared_error: 0.0094\n",
      "Epoch 22/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0312 - mean_squared_error: 0.0082 - val_loss: 0.0314 - val_mean_squared_error: 0.0099\n",
      "Epoch 23/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0303 - mean_squared_error: 0.0079 - val_loss: 0.0328 - val_mean_squared_error: 0.0103\n",
      "Epoch 24/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0309 - mean_squared_error: 0.0081 - val_loss: 0.0303 - val_mean_squared_error: 0.0092\n",
      "Epoch 25/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0296 - mean_squared_error: 0.0077 - val_loss: 0.0293 - val_mean_squared_error: 0.0091\n",
      "Epoch 26/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0297 - mean_squared_error: 0.0077 - val_loss: 0.0302 - val_mean_squared_error: 0.0094\n",
      "Epoch 27/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0298 - mean_squared_error: 0.0079 - val_loss: 0.0301 - val_mean_squared_error: 0.0093\n",
      "Epoch 28/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0301 - mean_squared_error: 0.0078 - val_loss: 0.0297 - val_mean_squared_error: 0.0092\n",
      "Epoch 29/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0293 - mean_squared_error: 0.0077 - val_loss: 0.0290 - val_mean_squared_error: 0.0090\n",
      "Epoch 30/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0290 - mean_squared_error: 0.0075 - val_loss: 0.0296 - val_mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.03152 to 0.02958, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 31/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0286 - mean_squared_error: 0.0074 - val_loss: 0.0298 - val_mean_squared_error: 0.0088\n",
      "Epoch 32/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0283 - mean_squared_error: 0.0073 - val_loss: 0.0301 - val_mean_squared_error: 0.0090\n",
      "Epoch 33/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0286 - mean_squared_error: 0.0073 - val_loss: 0.0289 - val_mean_squared_error: 0.0087\n",
      "Epoch 34/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0281 - mean_squared_error: 0.0073 - val_loss: 0.0296 - val_mean_squared_error: 0.0092\n",
      "Epoch 35/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0277 - mean_squared_error: 0.0071 - val_loss: 0.0289 - val_mean_squared_error: 0.0089\n",
      "Epoch 36/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0276 - mean_squared_error: 0.0071 - val_loss: 0.0295 - val_mean_squared_error: 0.0086\n",
      "Epoch 37/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0283 - mean_squared_error: 0.0072 - val_loss: 0.0283 - val_mean_squared_error: 0.0090\n",
      "Epoch 38/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0274 - mean_squared_error: 0.0070 - val_loss: 0.0281 - val_mean_squared_error: 0.0086\n",
      "Epoch 39/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0277 - mean_squared_error: 0.0070 - val_loss: 0.0279 - val_mean_squared_error: 0.0084\n",
      "Epoch 40/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0268 - mean_squared_error: 0.0068 - val_loss: 0.0282 - val_mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.02958 to 0.02818, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 41/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0267 - mean_squared_error: 0.0068 - val_loss: 0.0278 - val_mean_squared_error: 0.0085\n",
      "Epoch 42/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0268 - mean_squared_error: 0.0068 - val_loss: 0.0284 - val_mean_squared_error: 0.0088\n",
      "Epoch 43/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0266 - mean_squared_error: 0.0068 - val_loss: 0.0288 - val_mean_squared_error: 0.0087\n",
      "Epoch 44/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0267 - mean_squared_error: 0.0067 - val_loss: 0.0275 - val_mean_squared_error: 0.0085\n",
      "Epoch 45/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0271 - mean_squared_error: 0.0068 - val_loss: 0.0283 - val_mean_squared_error: 0.0085\n",
      "Epoch 46/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0263 - mean_squared_error: 0.0066 - val_loss: 0.0277 - val_mean_squared_error: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0265 - mean_squared_error: 0.0067 - val_loss: 0.0278 - val_mean_squared_error: 0.0085\n",
      "Epoch 48/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0270 - mean_squared_error: 0.0069 - val_loss: 0.0281 - val_mean_squared_error: 0.0088\n",
      "Epoch 49/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0260 - mean_squared_error: 0.0065 - val_loss: 0.0274 - val_mean_squared_error: 0.0084\n",
      "Epoch 50/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0257 - mean_squared_error: 0.0064 - val_loss: 0.0277 - val_mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.02818 to 0.02767, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 51/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0259 - mean_squared_error: 0.0065 - val_loss: 0.0278 - val_mean_squared_error: 0.0083\n",
      "Epoch 52/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0253 - mean_squared_error: 0.0063 - val_loss: 0.0276 - val_mean_squared_error: 0.0085\n",
      "Epoch 53/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0252 - mean_squared_error: 0.0063 - val_loss: 0.0267 - val_mean_squared_error: 0.0082\n",
      "Epoch 54/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0258 - mean_squared_error: 0.0064 - val_loss: 0.0268 - val_mean_squared_error: 0.0081\n",
      "Epoch 55/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0252 - mean_squared_error: 0.0063 - val_loss: 0.0270 - val_mean_squared_error: 0.0082\n",
      "Epoch 56/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0252 - mean_squared_error: 0.0063 - val_loss: 0.0268 - val_mean_squared_error: 0.0082\n",
      "Epoch 57/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.0256 - mean_squared_error: 0.0065 - val_loss: 0.0266 - val_mean_squared_error: 0.0082\n",
      "Epoch 58/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0250 - mean_squared_error: 0.0062 - val_loss: 0.0265 - val_mean_squared_error: 0.0080\n",
      "Epoch 59/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0247 - mean_squared_error: 0.0062 - val_loss: 0.0274 - val_mean_squared_error: 0.0082\n",
      "Epoch 60/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0246 - mean_squared_error: 0.0061 - val_loss: 0.0262 - val_mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02767 to 0.02620, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 61/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0246 - mean_squared_error: 0.0061 - val_loss: 0.0264 - val_mean_squared_error: 0.0079\n",
      "Epoch 62/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0244 - mean_squared_error: 0.0060 - val_loss: 0.0262 - val_mean_squared_error: 0.0079\n",
      "Epoch 63/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0255 - mean_squared_error: 0.0065 - val_loss: 0.0272 - val_mean_squared_error: 0.0082\n",
      "Epoch 64/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0246 - mean_squared_error: 0.0061 - val_loss: 0.0271 - val_mean_squared_error: 0.0086\n",
      "Epoch 65/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0244 - mean_squared_error: 0.0060 - val_loss: 0.0264 - val_mean_squared_error: 0.0082\n",
      "Epoch 66/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0238 - mean_squared_error: 0.0059 - val_loss: 0.0264 - val_mean_squared_error: 0.0078\n",
      "Epoch 67/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0241 - mean_squared_error: 0.0059 - val_loss: 0.0260 - val_mean_squared_error: 0.0081\n",
      "Epoch 68/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0245 - mean_squared_error: 0.0059 - val_loss: 0.0269 - val_mean_squared_error: 0.0080\n",
      "Epoch 69/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0239 - mean_squared_error: 0.0059 - val_loss: 0.0274 - val_mean_squared_error: 0.0078\n",
      "Epoch 70/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0240 - mean_squared_error: 0.0058 - val_loss: 0.0259 - val_mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02620 to 0.02594, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 71/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0236 - mean_squared_error: 0.0058 - val_loss: 0.0267 - val_mean_squared_error: 0.0083\n",
      "Epoch 72/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0235 - mean_squared_error: 0.0058 - val_loss: 0.0266 - val_mean_squared_error: 0.0080\n",
      "Epoch 73/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0237 - mean_squared_error: 0.0058 - val_loss: 0.0293 - val_mean_squared_error: 0.0087\n",
      "Epoch 74/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0237 - mean_squared_error: 0.0058 - val_loss: 0.0258 - val_mean_squared_error: 0.0077\n",
      "Epoch 75/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0233 - mean_squared_error: 0.0057 - val_loss: 0.0271 - val_mean_squared_error: 0.0079\n",
      "Epoch 76/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0234 - mean_squared_error: 0.0057 - val_loss: 0.0259 - val_mean_squared_error: 0.0079\n",
      "Epoch 77/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0236 - mean_squared_error: 0.0057 - val_loss: 0.0262 - val_mean_squared_error: 0.0080\n",
      "Epoch 78/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0233 - mean_squared_error: 0.0057 - val_loss: 0.0267 - val_mean_squared_error: 0.0079\n",
      "Epoch 79/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0232 - mean_squared_error: 0.0056 - val_loss: 0.0263 - val_mean_squared_error: 0.0080\n",
      "Epoch 80/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0233 - mean_squared_error: 0.0057 - val_loss: 0.0260 - val_mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02594\n",
      "Epoch 81/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0233 - mean_squared_error: 0.0057 - val_loss: 0.0256 - val_mean_squared_error: 0.0077\n",
      "Epoch 82/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0227 - mean_squared_error: 0.0055 - val_loss: 0.0257 - val_mean_squared_error: 0.0077\n",
      "Epoch 83/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0227 - mean_squared_error: 0.0055 - val_loss: 0.0261 - val_mean_squared_error: 0.0078\n",
      "Epoch 84/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0229 - mean_squared_error: 0.0055 - val_loss: 0.0262 - val_mean_squared_error: 0.0077\n",
      "Epoch 85/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0226 - mean_squared_error: 0.0055 - val_loss: 0.0257 - val_mean_squared_error: 0.0078\n",
      "Epoch 86/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0229 - mean_squared_error: 0.0055 - val_loss: 0.0272 - val_mean_squared_error: 0.0083\n",
      "Epoch 87/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0229 - mean_squared_error: 0.0055 - val_loss: 0.0255 - val_mean_squared_error: 0.0077\n",
      "Epoch 88/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0225 - mean_squared_error: 0.0054 - val_loss: 0.0253 - val_mean_squared_error: 0.0077\n",
      "Epoch 89/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0228 - mean_squared_error: 0.0054 - val_loss: 0.0262 - val_mean_squared_error: 0.0077\n",
      "Epoch 90/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0229 - mean_squared_error: 0.0054 - val_loss: 0.0258 - val_mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.02594 to 0.02576, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 91/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0222 - mean_squared_error: 0.0053 - val_loss: 0.0256 - val_mean_squared_error: 0.0076\n",
      "Epoch 92/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0221 - mean_squared_error: 0.0053 - val_loss: 0.0255 - val_mean_squared_error: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0225 - mean_squared_error: 0.0053 - val_loss: 0.0257 - val_mean_squared_error: 0.0078\n",
      "Epoch 94/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0225 - mean_squared_error: 0.0053 - val_loss: 0.0253 - val_mean_squared_error: 0.0077\n",
      "Epoch 95/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0222 - mean_squared_error: 0.0053 - val_loss: 0.0259 - val_mean_squared_error: 0.0077\n",
      "Epoch 96/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0222 - mean_squared_error: 0.0052 - val_loss: 0.0257 - val_mean_squared_error: 0.0078\n",
      "Epoch 97/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0220 - mean_squared_error: 0.0052 - val_loss: 0.0262 - val_mean_squared_error: 0.0078\n",
      "Epoch 98/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0219 - mean_squared_error: 0.0051 - val_loss: 0.0251 - val_mean_squared_error: 0.0075\n",
      "Epoch 99/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0218 - mean_squared_error: 0.0052 - val_loss: 0.0258 - val_mean_squared_error: 0.0077\n",
      "Epoch 100/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0219 - mean_squared_error: 0.0051 - val_loss: 0.0266 - val_mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02576\n",
      "Epoch 101/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0220 - mean_squared_error: 0.0052 - val_loss: 0.0254 - val_mean_squared_error: 0.0078\n",
      "Epoch 102/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0217 - mean_squared_error: 0.0051 - val_loss: 0.0257 - val_mean_squared_error: 0.0077\n",
      "Epoch 103/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0214 - mean_squared_error: 0.0050 - val_loss: 0.0252 - val_mean_squared_error: 0.0076\n",
      "Epoch 104/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0214 - mean_squared_error: 0.0050 - val_loss: 0.0254 - val_mean_squared_error: 0.0074\n",
      "Epoch 105/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0217 - mean_squared_error: 0.0050 - val_loss: 0.0254 - val_mean_squared_error: 0.0078\n",
      "Epoch 106/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0219 - mean_squared_error: 0.0050 - val_loss: 0.0261 - val_mean_squared_error: 0.0078\n",
      "Epoch 107/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0216 - mean_squared_error: 0.0050 - val_loss: 0.0252 - val_mean_squared_error: 0.0077\n",
      "Epoch 108/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0216 - mean_squared_error: 0.0050 - val_loss: 0.0254 - val_mean_squared_error: 0.0076\n",
      "Epoch 109/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0217 - mean_squared_error: 0.0051 - val_loss: 0.0251 - val_mean_squared_error: 0.0076\n",
      "Epoch 110/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0213 - mean_squared_error: 0.0049 - val_loss: 0.0250 - val_mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.02576 to 0.02503, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 111/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0210 - mean_squared_error: 0.0048 - val_loss: 0.0254 - val_mean_squared_error: 0.0075\n",
      "Epoch 112/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0209 - mean_squared_error: 0.0048 - val_loss: 0.0250 - val_mean_squared_error: 0.0075\n",
      "Epoch 113/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0210 - mean_squared_error: 0.0048 - val_loss: 0.0251 - val_mean_squared_error: 0.0076\n",
      "Epoch 114/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0211 - mean_squared_error: 0.0048 - val_loss: 0.0254 - val_mean_squared_error: 0.0076\n",
      "Epoch 115/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0212 - mean_squared_error: 0.0048 - val_loss: 0.0253 - val_mean_squared_error: 0.0075\n",
      "Epoch 116/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0209 - mean_squared_error: 0.0047 - val_loss: 0.0250 - val_mean_squared_error: 0.0074\n",
      "Epoch 117/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0211 - mean_squared_error: 0.0047 - val_loss: 0.0251 - val_mean_squared_error: 0.0075\n",
      "Epoch 118/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0206 - mean_squared_error: 0.0047 - val_loss: 0.0254 - val_mean_squared_error: 0.0075\n",
      "Epoch 119/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0207 - mean_squared_error: 0.0047 - val_loss: 0.0284 - val_mean_squared_error: 0.0083\n",
      "Epoch 120/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0211 - mean_squared_error: 0.0048 - val_loss: 0.0250 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02503 to 0.02502, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 121/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0208 - mean_squared_error: 0.0047 - val_loss: 0.0263 - val_mean_squared_error: 0.0077\n",
      "Epoch 122/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0206 - mean_squared_error: 0.0046 - val_loss: 0.0256 - val_mean_squared_error: 0.0076\n",
      "Epoch 123/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0204 - mean_squared_error: 0.0046 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 124/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0207 - mean_squared_error: 0.0046 - val_loss: 0.0259 - val_mean_squared_error: 0.0074\n",
      "Epoch 125/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.0210 - mean_squared_error: 0.0046 - val_loss: 0.0255 - val_mean_squared_error: 0.0075\n",
      "Epoch 126/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0205 - mean_squared_error: 0.0046 - val_loss: 0.0253 - val_mean_squared_error: 0.0075\n",
      "Epoch 127/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0204 - mean_squared_error: 0.0045 - val_loss: 0.0252 - val_mean_squared_error: 0.0078\n",
      "Epoch 128/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0203 - mean_squared_error: 0.0046 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 129/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0205 - mean_squared_error: 0.0045 - val_loss: 0.0262 - val_mean_squared_error: 0.0075\n",
      "Epoch 130/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0205 - mean_squared_error: 0.0045 - val_loss: 0.0250 - val_mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02502\n",
      "Epoch 131/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0201 - mean_squared_error: 0.0045 - val_loss: 0.0255 - val_mean_squared_error: 0.0074\n",
      "Epoch 132/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0200 - mean_squared_error: 0.0045 - val_loss: 0.0253 - val_mean_squared_error: 0.0077\n",
      "Epoch 133/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0203 - mean_squared_error: 0.0045 - val_loss: 0.0252 - val_mean_squared_error: 0.0077\n",
      "Epoch 134/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0201 - mean_squared_error: 0.0044 - val_loss: 0.0248 - val_mean_squared_error: 0.0075\n",
      "Epoch 135/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0200 - mean_squared_error: 0.0044 - val_loss: 0.0250 - val_mean_squared_error: 0.0075\n",
      "Epoch 136/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0200 - mean_squared_error: 0.0044 - val_loss: 0.0250 - val_mean_squared_error: 0.0076\n",
      "Epoch 137/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0202 - mean_squared_error: 0.0044 - val_loss: 0.0254 - val_mean_squared_error: 0.0079\n",
      "Epoch 138/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0200 - mean_squared_error: 0.0044 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 139/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0198 - mean_squared_error: 0.0044 - val_loss: 0.0250 - val_mean_squared_error: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0200 - mean_squared_error: 0.0043 - val_loss: 0.0251 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02502\n",
      "Epoch 141/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0210 - mean_squared_error: 0.0046 - val_loss: 0.0251 - val_mean_squared_error: 0.0077\n",
      "Epoch 142/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0201 - mean_squared_error: 0.0044 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 143/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0198 - mean_squared_error: 0.0043 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 144/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0197 - mean_squared_error: 0.0042 - val_loss: 0.0250 - val_mean_squared_error: 0.0074\n",
      "Epoch 145/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0198 - mean_squared_error: 0.0043 - val_loss: 0.0251 - val_mean_squared_error: 0.0074\n",
      "Epoch 146/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0195 - mean_squared_error: 0.0042 - val_loss: 0.0252 - val_mean_squared_error: 0.0075\n",
      "Epoch 147/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0201 - mean_squared_error: 0.0043 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 148/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0196 - mean_squared_error: 0.0042 - val_loss: 0.0248 - val_mean_squared_error: 0.0075\n",
      "Epoch 149/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0196 - mean_squared_error: 0.0042 - val_loss: 0.0251 - val_mean_squared_error: 0.0074\n",
      "Epoch 150/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0198 - mean_squared_error: 0.0042 - val_loss: 0.0256 - val_mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02502\n",
      "Epoch 151/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0201 - mean_squared_error: 0.0043 - val_loss: 0.0248 - val_mean_squared_error: 0.0075\n",
      "Epoch 152/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0042 - val_loss: 0.0259 - val_mean_squared_error: 0.0075\n",
      "Epoch 153/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0195 - mean_squared_error: 0.0042 - val_loss: 0.0249 - val_mean_squared_error: 0.0075\n",
      "Epoch 154/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0195 - mean_squared_error: 0.0042 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 155/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0041 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 156/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0192 - mean_squared_error: 0.0041 - val_loss: 0.0257 - val_mean_squared_error: 0.0076\n",
      "Epoch 157/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0195 - mean_squared_error: 0.0041 - val_loss: 0.0247 - val_mean_squared_error: 0.0077\n",
      "Epoch 158/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0041 - val_loss: 0.0248 - val_mean_squared_error: 0.0075\n",
      "Epoch 159/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0195 - mean_squared_error: 0.0042 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 160/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0041 - val_loss: 0.0253 - val_mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02502\n",
      "Epoch 161/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0196 - mean_squared_error: 0.0041 - val_loss: 0.0254 - val_mean_squared_error: 0.0073\n",
      "Epoch 162/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0192 - mean_squared_error: 0.0041 - val_loss: 0.0249 - val_mean_squared_error: 0.0075\n",
      "Epoch 163/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0041 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 164/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0191 - mean_squared_error: 0.0040 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 165/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0041 - val_loss: 0.0247 - val_mean_squared_error: 0.0075\n",
      "Epoch 166/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0191 - mean_squared_error: 0.0040 - val_loss: 0.0250 - val_mean_squared_error: 0.0074\n",
      "Epoch 167/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0040 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 168/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0190 - mean_squared_error: 0.0040 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 169/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0188 - mean_squared_error: 0.0039 - val_loss: 0.0250 - val_mean_squared_error: 0.0076\n",
      "Epoch 170/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0190 - mean_squared_error: 0.0040 - val_loss: 0.0250 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.02502 to 0.02496, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 171/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0192 - mean_squared_error: 0.0040 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 172/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0188 - mean_squared_error: 0.0039 - val_loss: 0.0249 - val_mean_squared_error: 0.0073\n",
      "Epoch 173/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0039 - val_loss: 0.0252 - val_mean_squared_error: 0.0074\n",
      "Epoch 174/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0040 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 175/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0039 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 176/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0039 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 177/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0040 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 178/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0187 - mean_squared_error: 0.0039 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 179/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0191 - mean_squared_error: 0.0039 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 180/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.0191 - mean_squared_error: 0.0040 - val_loss: 0.0249 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.02496 to 0.02489, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 181/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0188 - mean_squared_error: 0.0039 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 182/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0185 - mean_squared_error: 0.0038 - val_loss: 0.0251 - val_mean_squared_error: 0.0074\n",
      "Epoch 183/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0186 - mean_squared_error: 0.0038 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 184/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0187 - mean_squared_error: 0.0039 - val_loss: 0.0250 - val_mean_squared_error: 0.0073\n",
      "Epoch 185/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0186 - mean_squared_error: 0.0038 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 186/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0039 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 187/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0186 - mean_squared_error: 0.0038 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 188/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0184 - mean_squared_error: 0.0038 - val_loss: 0.0252 - val_mean_squared_error: 0.0075\n",
      "Epoch 189/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0185 - mean_squared_error: 0.0038 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 190/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0185 - mean_squared_error: 0.0038 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.02489 to 0.02460, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 191/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0187 - mean_squared_error: 0.0038 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 192/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0186 - mean_squared_error: 0.0038 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 193/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0184 - mean_squared_error: 0.0037 - val_loss: 0.0248 - val_mean_squared_error: 0.0075\n",
      "Epoch 194/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0183 - mean_squared_error: 0.0037 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 195/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0185 - mean_squared_error: 0.0037 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 196/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0184 - mean_squared_error: 0.0037 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 197/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0182 - mean_squared_error: 0.0037 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 198/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0184 - mean_squared_error: 0.0037 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 199/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0183 - mean_squared_error: 0.0037 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 200/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.0183 - mean_squared_error: 0.0037 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.02460 to 0.02448, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 201/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0186 - mean_squared_error: 0.0037 - val_loss: 0.0250 - val_mean_squared_error: 0.0075\n",
      "Epoch 202/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0186 - mean_squared_error: 0.0037 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 203/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0182 - mean_squared_error: 0.0037 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 204/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 205/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0182 - mean_squared_error: 0.0037 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 206/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0181 - mean_squared_error: 0.0037 - val_loss: 0.0249 - val_mean_squared_error: 0.0073\n",
      "Epoch 207/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0184 - mean_squared_error: 0.0037 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 208/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0182 - mean_squared_error: 0.0037 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 209/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0184 - mean_squared_error: 0.0037 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 210/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0181 - mean_squared_error: 0.0036 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.02448 to 0.02434, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 211/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0179 - mean_squared_error: 0.0036 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 212/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0179 - mean_squared_error: 0.0036 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 213/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0181 - mean_squared_error: 0.0036 - val_loss: 0.0250 - val_mean_squared_error: 0.0073\n",
      "Epoch 214/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0036 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 215/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0036 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 216/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0181 - mean_squared_error: 0.0036 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 217/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0181 - mean_squared_error: 0.0037 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 218/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0036 - val_loss: 0.0253 - val_mean_squared_error: 0.0075\n",
      "Epoch 219/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0036 - val_loss: 0.0247 - val_mean_squared_error: 0.0072\n",
      "Epoch 220/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0179 - mean_squared_error: 0.0036 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.02434\n",
      "Epoch 221/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0178 - mean_squared_error: 0.0036 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 222/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0178 - mean_squared_error: 0.0036 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 223/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0177 - mean_squared_error: 0.0035 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 224/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0036 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 225/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0181 - mean_squared_error: 0.0037 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 226/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0178 - mean_squared_error: 0.0035 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 227/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0177 - mean_squared_error: 0.0035 - val_loss: 0.0248 - val_mean_squared_error: 0.0075\n",
      "Epoch 228/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.0178 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 229/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0180 - mean_squared_error: 0.0036 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 230/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0178 - mean_squared_error: 0.0035 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.02434\n",
      "Epoch 231/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0176 - mean_squared_error: 0.0035 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 233/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0177 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 234/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0177 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 235/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0176 - mean_squared_error: 0.0035 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 236/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0177 - mean_squared_error: 0.0035 - val_loss: 0.0252 - val_mean_squared_error: 0.0075\n",
      "Epoch 237/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0177 - mean_squared_error: 0.0035 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 238/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0176 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 239/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0176 - mean_squared_error: 0.0035 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 240/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.02434\n",
      "Epoch 241/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0075\n",
      "Epoch 242/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 243/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 244/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 245/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 246/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 247/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 248/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0034 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 249/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 250/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0245 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.02434\n",
      "Epoch 251/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 252/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 253/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 254/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 255/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 256/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 257/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 258/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 259/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 260/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.02434\n",
      "Epoch 261/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 262/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 263/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0247 - val_mean_squared_error: 0.0075\n",
      "Epoch 264/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 265/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 266/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 267/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 268/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 269/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 270/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.02434\n",
      "Epoch 271/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 272/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 273/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 274/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 275/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0170 - mean_squared_error: 0.0034 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 276/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0033 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 277/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 278/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 279/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 280/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.02434 to 0.02415, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 281/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0171 - mean_squared_error: 0.0033 - val_loss: 0.0255 - val_mean_squared_error: 0.0075\n",
      "Epoch 282/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0171 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 283/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 284/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 285/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0246 - val_mean_squared_error: 0.0076\n",
      "Epoch 286/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0171 - mean_squared_error: 0.0033 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 287/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 288/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 289/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0174 - mean_squared_error: 0.0034 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 290/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.02415\n",
      "Epoch 291/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 292/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 293/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 294/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 295/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0252 - val_mean_squared_error: 0.0073\n",
      "Epoch 296/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 297/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 298/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 299/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 300/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.02415\n",
      "Epoch 301/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 302/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 303/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 304/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 305/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 306/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 307/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 308/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 309/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 310/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.02415\n",
      "Epoch 311/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 312/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 313/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0249 - val_mean_squared_error: 0.0073\n",
      "Epoch 314/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 315/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 316/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0247 - val_mean_squared_error: 0.0075\n",
      "Epoch 317/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0247 - val_mean_squared_error: 0.0076\n",
      "Epoch 318/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 319/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 320/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0250 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.02415\n",
      "Epoch 321/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 322/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 323/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "Epoch 324/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 325/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 327/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 328/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 329/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0254 - val_mean_squared_error: 0.0078\n",
      "Epoch 330/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.02415\n",
      "Epoch 331/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0249 - val_mean_squared_error: 0.0073\n",
      "Epoch 332/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 333/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 334/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 335/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 336/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0032 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 337/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 338/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 339/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 340/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.02415\n",
      "Epoch 341/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 342/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0032 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 343/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 344/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 345/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0032 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 346/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 347/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 348/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 349/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 350/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.02415\n",
      "Epoch 351/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 352/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 353/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 354/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 355/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 356/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 357/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 358/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 359/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 360/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.02415\n",
      "Epoch 361/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 362/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0241 - val_mean_squared_error: 0.0072\n",
      "Epoch 363/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 364/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 365/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 366/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 367/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 368/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 369/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 370/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.02415\n",
      "Epoch 371/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 372/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0251 - val_mean_squared_error: 0.0074\n",
      "Epoch 373/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 374/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 375/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 376/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 377/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 378/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 379/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0031 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 380/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.02415\n",
      "Epoch 381/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 382/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 383/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 384/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 385/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0252 - val_mean_squared_error: 0.0073\n",
      "Epoch 386/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0253 - val_mean_squared_error: 0.0076\n",
      "Epoch 387/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 388/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 389/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 390/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.02415\n",
      "Epoch 391/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0031 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 392/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 393/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 394/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 395/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 396/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 397/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 398/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0250 - val_mean_squared_error: 0.0073\n",
      "Epoch 399/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 400/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.02415\n",
      "Epoch 401/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 402/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 403/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 404/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 405/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0249 - val_mean_squared_error: 0.0075\n",
      "Epoch 406/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 407/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 408/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 409/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 410/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0249 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.02415\n",
      "Epoch 411/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0247 - val_mean_squared_error: 0.0075\n",
      "Epoch 412/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 413/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 414/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 415/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 416/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 417/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 418/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 419/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 420/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.02415\n",
      "Epoch 421/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 422/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 423/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 424/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 425/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0247 - val_mean_squared_error: 0.0075\n",
      "Epoch 426/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0072\n",
      "Epoch 427/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 428/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 429/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 430/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.02415\n",
      "Epoch 431/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 432/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 433/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 434/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 435/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 436/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0241 - val_mean_squared_error: 0.0072\n",
      "Epoch 437/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 438/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 439/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 440/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0157 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.02415\n",
      "Epoch 441/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 442/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 443/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 444/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0075\n",
      "Epoch 445/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 446/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 447/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0030 - val_loss: 0.0245 - val_mean_squared_error: 0.0072\n",
      "Epoch 448/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0159 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 449/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 450/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.02415\n",
      "Epoch 451/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 452/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 453/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 454/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 455/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 456/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 457/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 458/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0030 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 459/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0072\n",
      "Epoch 460/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.02415 to 0.02412, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 461/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 462/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 463/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 464/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 465/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 466/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 468/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 469/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 470/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0157 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.02412\n",
      "Epoch 471/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 472/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 473/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 474/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 475/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 476/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0158 - mean_squared_error: 0.0030 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 477/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 478/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 479/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 480/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.02412\n",
      "Epoch 481/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 482/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 483/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 484/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0074\n",
      "Epoch 485/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 486/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 487/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 488/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 489/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 490/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.02412\n",
      "Epoch 491/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 492/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 493/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 494/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 495/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 496/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 497/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 498/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 499/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 500/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00500: val_loss improved from 0.02412 to 0.02410, saving model to /media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5\n",
      "Epoch 501/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0154 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 502/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 503/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 504/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 505/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 506/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 507/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 508/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 509/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0156 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 510/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.02410\n",
      "Epoch 511/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 512/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 513/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 515/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0248 - val_mean_squared_error: 0.0074\n",
      "Epoch 516/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 517/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 518/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0029 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 519/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0029 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 520/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0248 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.02410\n",
      "Epoch 521/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 522/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 523/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 524/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0072\n",
      "Epoch 525/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 526/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 527/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 528/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 529/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0155 - mean_squared_error: 0.0029 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 530/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.02410\n",
      "Epoch 531/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 532/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 533/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 534/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 535/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 536/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 537/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 538/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 539/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 540/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.02410\n",
      "Epoch 541/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0250 - val_mean_squared_error: 0.0073\n",
      "Epoch 542/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 543/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 544/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 545/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 546/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0251 - val_mean_squared_error: 0.0074\n",
      "Epoch 547/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 548/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 549/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 550/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.02410\n",
      "Epoch 551/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 552/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 553/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 554/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0072\n",
      "Epoch 555/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 556/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 557/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 558/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 559/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 560/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.02410\n",
      "Epoch 561/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 562/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 563/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 564/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 565/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 566/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0246 - val_mean_squared_error: 0.0074\n",
      "Epoch 567/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 568/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 569/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 570/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.02410\n",
      "Epoch 571/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 572/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 573/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 574/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 575/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 576/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0074\n",
      "Epoch 577/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0153 - mean_squared_error: 0.0028 - val_loss: 0.0249 - val_mean_squared_error: 0.0073\n",
      "Epoch 578/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0072\n",
      "Epoch 579/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 580/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.02410\n",
      "Epoch 581/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 582/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 583/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0154 - mean_squared_error: 0.0029 - val_loss: 0.0245 - val_mean_squared_error: 0.0075\n",
      "Epoch 584/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 585/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 586/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0250 - val_mean_squared_error: 0.0074\n",
      "Epoch 587/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 588/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 589/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 590/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.02410\n",
      "Epoch 591/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 592/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 593/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 594/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0245 - val_mean_squared_error: 0.0072\n",
      "Epoch 595/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0028 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 596/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 597/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 598/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 599/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0074\n",
      "Epoch 600/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.02410\n",
      "Epoch 601/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 602/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0072\n",
      "Epoch 603/1500\n",
      "700/700 [==============================] - 23s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 604/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 605/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 606/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 607/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 608/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 609/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0250 - val_mean_squared_error: 0.0073\n",
      "Epoch 610/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.02410\n",
      "Epoch 611/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 612/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 613/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 614/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 615/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 616/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 617/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 618/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 619/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0072\n",
      "Epoch 620/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.02410\n",
      "Epoch 621/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 622/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 623/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 624/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 625/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 626/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 627/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 628/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 629/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 630/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0152 - mean_squared_error: 0.0027 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.02410\n",
      "Epoch 631/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 632/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0249 - val_mean_squared_error: 0.0074\n",
      "Epoch 633/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0150 - mean_squared_error: 0.0028 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 634/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 635/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0241 - val_mean_squared_error: 0.0072\n",
      "Epoch 636/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 637/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 638/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0245 - val_mean_squared_error: 0.0072\n",
      "Epoch 639/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 640/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0028 - val_loss: 0.0247 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.02410\n",
      "Epoch 641/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0246 - val_mean_squared_error: 0.0073\n",
      "Epoch 642/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 643/1500\n",
      "700/700 [==============================] - 22s 31ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0245 - val_mean_squared_error: 0.0073\n",
      "Epoch 644/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 645/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0072\n",
      "Epoch 646/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 647/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0240 - val_mean_squared_error: 0.0072\n",
      "Epoch 648/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0073\n",
      "Epoch 649/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 650/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.02410\n",
      "Epoch 651/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 652/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0151 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0072\n",
      "Epoch 653/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0244 - val_mean_squared_error: 0.0072\n",
      "Epoch 654/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 655/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0248 - val_mean_squared_error: 0.0073\n",
      "Epoch 656/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 657/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0148 - mean_squared_error: 0.0027 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 658/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 659/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0150 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "Epoch 660/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0243 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.02410\n",
      "Epoch 661/1500\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 662/1500\n",
      "700/700 [==============================] - 23s 33ms/step - loss: 0.0149 - mean_squared_error: 0.0027 - val_loss: 0.0247 - val_mean_squared_error: 0.0073\n",
      "Epoch 663/1500\n",
      "636/700 [==========================>...] - ETA: 1s - loss: 0.0150 - mean_squared_error: 0.0027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2c35b5c3fa79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model.fit(trainx, trainy, validation_data=(valx, valy), \n\u001b[1;32m      8\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           epochs=1500, callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For training the U-Net model\n",
    "\n",
    "checkpoint  = ModelCheckpoint(filepath='/media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5', \n",
    "                              monitor='val_loss', period=10, \n",
    "                              verbose=1, save_best_only=True, mode='min')\n",
    "model = unet_3d_prelu2()\n",
    "model.fit(trainx, trainy, validation_data=(valx, valy), \n",
    "          batch_size=4, \n",
    "          epochs=1500, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('/media/pranjal/Backup/DBT-NEW/models/model3.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 56, 56, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(valx, batch_size=4)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model1.predict(valx, batch_size=4)\n",
    "print(result1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa522360e48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, 35)\n",
    "print(index)\n",
    "slicenum = 20\n",
    "plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f29dc419550>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.concatenate([result1[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cd4188320>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, 35)\n",
    "print(index)\n",
    "plt.imshow(np.concatenate([result[index, :, :, 20, 0], valx[index, :, :, 20, 0], valy[index, :, :, 20, 0]], axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ca8296860>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, 35)\n",
    "plt.imshow(np.concatenate([result[index, 50, :, :, 0], valx[index, 50, :, :, 0], valy[index, 50, :, :, 0]], axis=-1), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
