{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the imports\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "import copy\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback, TensorBoard\n",
    "from keras import backend as keras\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "#from scipy.misc import imresize\n",
    "import pywt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline  \n",
    "\n",
    "import pywt\n",
    "#import hdf5storage\n",
    "\n",
    "import scipy.io as sio\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#import pylidc as pl\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "#import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage.io as io\n",
    "#from sklearn.decomposition import PCA\n",
    "import collections, numpy\n",
    "import warnings\n",
    "from scipy import ndimage, misc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import pymrt as mrt\n",
    "#import pymrt.geometry\n",
    "import ipyvolume as ipv\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from image_gen import ImageDataGenerator\n",
    "#from load_data import loadDataMontgomery, loadDataJSRT\n",
    "#from build_model import build_UNet2D_4L\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "import warnings\n",
    "from keras.layers import Convolution3D, Input, merge, RepeatVector, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import activations, initializers, regularizers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "#from keras.utils.np_utils import conv_output_length\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     2,
     153,
     183
=======
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     2,
     91,
     143,
     192,
     263,
     344,
     374
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
    ]
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def unet_vanilla(input_size = (960,64,1)):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 256\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    \n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(4, 1))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "    up6   = Conv2D(filter4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (4,1))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    \n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = Conv2D(filter3, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    \n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8    = Conv2D(filter2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    \n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9    = Conv2D(filter1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    \n",
    "    conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    #conv9  = BatchNormalization()(conv9)\n",
    "    conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9  = BatchNormalization()(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "    #conv10 = PReLU()(conv10)\n",
    "    \n",
    "    \n",
    "    #conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    #conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-3), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_vanilla1(input_size = (800,64,1)):\n",
    "    filter1 = 32\n",
    "    filter2 = 64\n",
    "    filter3 = 128\n",
    "    filter4 = 256\n",
    "    filter5 = 512\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 1))(conv3)\n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.2)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 1))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.2)(conv5)\n",
    "\n",
    "    up6 = Conv2D(filter4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(filter3, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(filter2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(filter1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'mean_absolute_error', metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_dense(input_size = (960,64,1)):\n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    filter5 = 256\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    a1  = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
    "    a2  = MaxPooling2D(pool_size=(2, 2))(a1)\n",
    "    \n",
    "    a3  = Flatten()(a2)\n",
    "    b  = Dense(2400,   activation='relu', kernel_initializer = 'he_normal')(a3)\n",
    "    b  = BatchNormalization()(b)\n",
    "    \n",
    "    e  = Dense(4800,   activation='relu', kernel_initializer = 'he_normal')(b)\n",
    "    e  = BatchNormalization()(e)\n",
    "    \n",
    "    f  = Dense(4800,   activation='relu', kernel_initializer = 'he_normal')(e)\n",
    "    f  = BatchNormalization()(f)\n",
    "    \n",
    "    g  = Dense(4800,   activation='relu', kernel_initializer = 'he_normal')(f)\n",
    "    g  = BatchNormalization()(g)\n",
    "    \n",
    "    c  = Dense(2400,   activation='relu', kernel_initializer = 'he_normal')(g)\n",
    "    d  = Reshape([200, 12, 1])(c)  # Downsampled Sinogram which will go in loss function\n",
    "    \n",
    "    up1 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (1, 1))(d))\n",
    "    up1 = Concatenate()([up1, a2])\n",
    "    \n",
    "    up2 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(up1))\n",
    "    up2 = Concatenate()([up2, a1])\n",
    "    \n",
    "    up3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2, 2))(up2))\n",
    "     \n",
    "    out = Conv2D(1, 1, activation = 'relu')(up3)\n",
    "\n",
    "    model = Model(input = inputs, output = [out, d])\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), \n",
    "                  loss = ['mean_absolute_error', 'mean_absolute_error'],\n",
    "                  loss_weights = [0.5, 0.5],\n",
    "                  metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "#a = unet_dense()\n",
    "#print(a.summary())\n",
    "\n",
    "def unet_3d_prelu(input_size = (104, 56, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    \n",
    "    zfilter = 40\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, 3,  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Add()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Add()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Add()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu2(input_size = (104, 56, 40, 1)):\n",
    "#def unet_3d_prelu2(input_size = (104, 24, 40, 1)):\n",
    "    \n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 128\n",
    "    \n",
    "    zfilter = 3\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv3D(filter1, (3, 3, 3), padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Dropout(0.1)(conv1)\n",
    "    conv1 = ReLU()(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    #conv1 = Conv3D(filter1, (3, 3, zfilter), padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    #conv1 = ReLU()(conv1)\n",
    "    #conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
    "    conv2 = Conv3D(filter2, (3, 3, 3),  padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Dropout(0.1)(conv2)\n",
    "    conv2 = ReLU()(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2)\n",
    "    conv3 = Conv3D(filter3, (3, 3, 10),  padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = ReLU()(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3)\n",
    "    conv4 = Conv3D(filter3, (3, 3, 5),  padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = ReLU()(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up3    = UpSampling3D(size = (2,2,2))(conv4)\n",
    "    merge3 = Concatenate()([up3, conv3])\n",
    "    merge3 = Conv3D(filter2, (3, 3, 10),  padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
    "    merge3 = Dropout(0.1)(merge3)\n",
    "    merge3 = ReLU()(merge3)\n",
    "    merge3 = BatchNormalization()(merge3)    \n",
    "    \n",
    "    up2    = UpSampling3D(size = (2,2,2))(merge3)\n",
    "    merge2 = Concatenate()([up2, conv2])\n",
    "    merge2 = Conv3D(filter1, 3,  padding = 'same', kernel_initializer = 'he_normal')(merge2)\n",
    "    merge2 = Dropout(0.1)(merge2)\n",
    "    merge2 = ReLU()(merge2)\n",
    "    merge2 = BatchNormalization()(merge2)    \n",
    "    \n",
    "    up1    = UpSampling3D(size = (2,2,2))(merge2)\n",
    "    merge1 = Concatenate()([up1, conv1])\n",
    "    merge1 = Conv3D(filter1, (3, 3, 3),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "    merge1 = Dropout(0.1)(merge1)\n",
    "    merge1 = ReLU()(merge1)\n",
    "    #merge1 = BatchNormalization()(merge1)    \n",
    "    \n",
    "#     up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(merge1)\n",
    "#     up7 = ReLU()(up7)\n",
    "#     up7 = BatchNormalization()(up7)\n",
    "    \n",
    "#     up8 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "#     up8 = ReLU()(up8)\n",
    "#     up8 = BatchNormalization()(up8)\n",
    "    \n",
    "#     up8 = Add()([up8, merge1])\n",
    "    \n",
    "#     up9 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up8)\n",
    "#     up9 = ReLU()(up9)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(merge1)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv9)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.0005), loss = 'mean_absolute_error', \n",
    "                  metrics = ['mse'])\n",
    "    return model\n",
    "\n",
    "def unet_3d_prelu1(input_size = (104, 56, 40, 1)):\n",
    "    filter1 = 16\n",
    "    filter2 = 32\n",
    "    filter3 = 64\n",
    "    filter4 = 128\n",
    "    zfilter = 40\n",
    "    \n",
    "    model = load_model('/media/dril/ubuntudata/DBT-NEW/models/model2.h5', compile=False)\n",
    "    x     = model.layers[-3].output\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(x)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    up7 = Conv3D(filter1, (3, 3, zfilter),  padding = 'same', kernel_initializer = 'he_normal')(up7)\n",
    "    up7 = ReLU()(up7)\n",
    "    \n",
    "    conv9 = Conv3D(1, 1, padding='same', kernel_initializer = 'he_normal')(up7)\n",
    "    conv9 = ReLU()(conv9)\n",
    "    \n",
    "    model1 = Model(input = model.input, output = conv9)\n",
    "    model1.compile(optimizer = Adam(lr = 0.0001), loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    model3 =  load_model('/media/dril/ubuntudata/DBT-NEW/models/model2.h5', compile=False)\n",
    "    \n",
    "    for i in range(len(model3.layers)-2):\n",
    "        if len(model3.layers[i].get_weights()) > 0:\n",
    "            model1.layers[i].set_weights(model3.layers[i].get_weights())\n",
    "    \n",
    "    return model1\n",
    "\n",
    "def bbox2_3D(img):\n",
    "\n",
    "    r = np.any(img, axis=(1, 2))\n",
    "    c = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return rmin, rmax, cmin, cmax, zmin, zmax\n",
    "\n",
    "# For checking if weights are same or not of two networks\n",
    "\n",
    "# for i in range(40):\n",
    "#     w1 = model3.layers[i].get_weights()\n",
    "#     w2 = m2.layers[i].get_weights()\n",
    "    \n",
    "#     for j in range(len(w1)):\n",
    "#         print(i, np.all(w1[j] == w2[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For getting the shapes\n",
    "\n",
    "allshapesx = []\n",
    "allshapesy = []\n",
    "allshapesz = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    a = loadmat('/media/dril/ubuntudata/attenuation_values/'+str(i)+'.mat')\n",
    "    a = a['head']\n",
    "    b = copy.deepcopy(a)\n",
    "    a[a != 0 ] = 1\n",
    "    rmin, rmax, cmin, cmax, zmin, zmax = bbox2_3D(a)\n",
    "    b = b[rmin:rmax, cmin:cmax, zmin:zmax]\n",
    "    \n",
    "    allshapesx.append(b.shape[0])\n",
    "    allshapesy.append(b.shape[1])\n",
    "    allshapesz.append(b.shape[2])\n",
    "    \n",
    "    temp = int((800-b.shape[0])/2)\n",
    "    vol = b\n",
    "    vol = np.pad(b, ((temp, 800-temp-b.shape[0]), (320-b.shape[1], 0), (0, 448-b.shape[2])), \n",
    "                     'constant', constant_values=(0, 0))\n",
    "    vol = np.moveaxis(vol, [1, 2], [2, 1]).astype(np.single)\n",
    "\n",
    "    h = {}\n",
    "    h['head'] = vol\n",
    "    savemat('/media/dril/ubuntudata/attenuation_values_cropped/'+str(i)+'.mat', h,\n",
    "            do_compression=True)\n",
    "    print(i, vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New size will be 800, 320, 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
<<<<<<< HEAD
    "collapsed": true
=======
    "scrolled": true
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 3D U-Net model\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    print(i)\n",
    "    #volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons/sart_cir_zero_'+str(i)+'.mat')\n",
    "    volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons-noise/fbp_'+str(i)+'_3_hann50.mat', verify_compressed_data_integrity=False)\n",
    "    voly = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/'+str(i)+'.mat')\n",
    "    \n",
    "    volx = volx['xfbp']\n",
    "    voly = voly['head']\n",
    "    \n",
    "    voly = ndimage.zoom(voly, 0.125, order=1).astype(np.single)\n",
    "    volx = ndimage.zoom(volx, 0.250, order=1).astype(np.single)\n",
    "    \n",
    "    if i <= 140:\n",
    "        trainx.append(np.expand_dims(volx, axis=-1))\n",
    "        trainy.append(np.expand_dims(voly, axis=-1))\n",
    "    else:\n",
    "        valx.append(np.expand_dims(volx,axis=-1))\n",
    "        valy.append(np.expand_dims(voly,axis=-1))\n",
    "\n",
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "valx   = np.array(valx)\n",
    "valy   = np.array(valy)\n",
    "\n",
    "trainx  = np.pad(trainx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "trainy  = np.pad(trainy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valx    = np.pad(valx, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "valy    = np.pad(valy, ((0,0), (2, 2), (0, 0), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "print(trainx.shape, trainy.shape)\n",
    "print(valx.shape, valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 2D U-Net model for sinogram completion\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "slices_train = 31523\n",
    "slices_val   = 8133\n",
    "\n",
    "trainx  = np.zeros((slices_train, 960, 64, 1), dtype=np.single)\n",
    "trainy  = np.zeros((slices_train, 960, 64, 1), dtype=np.single)\n",
    "\n",
    "valx   = np.zeros((slices_val, 960, 64, 1), dtype=np.single)  # This is from sart\n",
    "valy   = np.zeros((slices_val, 960, 64, 1), dtype=np.single)\n",
    "\n",
    "\n",
    "count_train = 0\n",
    "count_val   = 0\n",
    "\n",
    "for i in range(1, 177):\n",
<<<<<<< HEAD
    "    print(i)\n",
    "    volx = loadmat('/media/pranjal/Backup/DBT-NEW/recons/sart_cir_zero_'+str(i)+'.mat')\n",
    "    voly = loadmat('/media/pranjal/Backup/DBT-NEW/attenuation_values_cropped/'+str(i)+'.mat')\n",
=======
    "    x = loadmat('/media/dril/a19fa9b7-846c-45a0-be8c-ef93fea1e48c/gan-110-projections/g_noi_sart_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    #x = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/projections/g_noi_sart_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x = x['g_noi_nonoise']\n",
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
    "    \n",
    "    y = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/projections/g_noi_nonoise_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    #y = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/projections/g_noi_nonoise_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    y = y['g_noi_nonoise']\n",
    "    print(i, count_train, count_val)\n",
    "    \n",
    "    if i <= 140:\n",
    "        for j in range(0, 300):\n",
    "            tempx = x[:, j, :]\n",
    "            tempy = y[:, j, :]\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > 0:\n",
    "                trainx[count_train, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                trainy[count_train, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                count_train = count_train +1\n",
    "    else:\n",
    "        for j in range(0, 300):\n",
    "            tempx = x[:, j, :]\n",
    "            tempy = y[:, j, :]\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > 0:\n",
    "                valx[count_val, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                valy[count_val, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (4, 5)), 'constant', constant_values = (0, 0))\n",
    "                count_val = count_val +1\n",
    "            \n",
    "print(trainx.shape, trainy.shape, valx.shape, valy.shape, count_train, count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For reading the data for training the 2D U-Net model for sinogram completion with higher resolution\n",
    "\n",
    "trainx = []\n",
    "trainy = []\n",
    "valx   = []\n",
    "valy   = []\n",
    "\n",
    "train_slices = 23409\n",
    "val_slices   = 12138\n",
    "\n",
    "trainx  = np.zeros((train_slices, 1600, 48, 1), dtype=np.single)\n",
    "trainy  = np.zeros((train_slices, 1600, 48, 1), dtype=np.single)\n",
    "\n",
    "#valx   = np.zeros((int(10656/1), 1600, 48, 1), dtype=np.single)  # This is from sart\n",
    "#valy   = np.zeros((int(10656/1), 1600, 48, 1), dtype=np.single)\n",
    "\n",
    "valx   = np.zeros((val_slices, 1600, 48, 1), dtype=np.single)  # This is from sart\n",
    "valy   = np.zeros((val_slices, 1600, 48, 1), dtype=np.single)\n",
    "\n",
    "\n",
    "count_train = 0\n",
    "count_val   = 0\n",
    "\n",
    "less_than_train = []\n",
    "less_than_val   = []\n",
    "\n",
    "for i in range(1, 177):\n",
    "    x = loadmat('/media/dril/Windows/gan-90-projections-higher/projections/g_noi_sart_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x = x['g_noi_nonoise']\n",
    "    \n",
    "    y = loadmat('/media/dril/Windows/gan-90-projections-higher/projections/g_noi_nonoise_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    y = y['g_noi_nonoise']\n",
    "    print(i, x.shape, y.shape)\n",
    "    \n",
    "    if i <= 140:\n",
    "        for j in range(0, 600):\n",
    "            tempx    = x[:, j, :]\n",
    "            tempy    = y[:, j, :]\n",
    "            tempdiff = tempy-tempx\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > 20000 and j%2 == 1:\n",
    "                less_than_train.append(np.count_nonzero(tempy.flatten()))\n",
    "                trainx[count_train, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                trainy[count_train, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                count_train = count_train +1\n",
    "    else:\n",
    "        for j in range(0, 600):\n",
    "            tempx    = x[:, j, :]\n",
    "            tempy    = y[:, j, :]\n",
    "            tempdiff = tempy-tempx\n",
    "            \n",
    "            if np.count_nonzero(tempy.flatten()) > -1:\n",
    "                less_than_val.append(np.count_nonzero(tempy.flatten()))\n",
    "                \n",
    "                valx[count_val, :, :, 0]  = np.pad((tempx)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                valy[count_val, :, :, 0]  = np.pad((tempy)/5.0, ((0, 0), (0, 3)), 'constant', constant_values = (0, 0))\n",
    "                count_val = count_val +1\n",
    "            \n",
    "print(trainx.shape, trainy.shape, valx.shape, valy.shape, count_train, count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainy[:, :, 10:35, 0] = 0\n",
    "#valy[:, :, 10:35,   0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 180 samples\n",
      "Epoch 1/1500\n",
      "700/700 [==============================] - 14s 19ms/step - loss: 0.1036 - mean_squared_error: 0.0425 - val_loss: 0.1094 - val_mean_squared_error: 0.0503\n",
      "Epoch 2/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0693 - mean_squared_error: 0.0228 - val_loss: 0.0827 - val_mean_squared_error: 0.0376\n",
      "Epoch 3/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0605 - mean_squared_error: 0.0191 - val_loss: 0.0592 - val_mean_squared_error: 0.0222\n",
      "Epoch 4/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0538 - mean_squared_error: 0.0163 - val_loss: 0.0415 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0492 - mean_squared_error: 0.0144 - val_loss: 0.0448 - val_mean_squared_error: 0.0158\n",
      "Epoch 6/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0449 - mean_squared_error: 0.0127 - val_loss: 0.0432 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0424 - mean_squared_error: 0.0117 - val_loss: 0.0372 - val_mean_squared_error: 0.0129\n",
      "Epoch 8/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0396 - mean_squared_error: 0.0109 - val_loss: 0.0375 - val_mean_squared_error: 0.0121\n",
      "Epoch 9/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0366 - mean_squared_error: 0.0099 - val_loss: 0.0301 - val_mean_squared_error: 0.0094\n",
      "Epoch 10/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0345 - mean_squared_error: 0.0092 - val_loss: 0.0313 - val_mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.03126, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 11/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0323 - mean_squared_error: 0.0086 - val_loss: 0.0288 - val_mean_squared_error: 0.0092\n",
      "Epoch 12/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0303 - mean_squared_error: 0.0081 - val_loss: 0.0292 - val_mean_squared_error: 0.0096\n",
      "Epoch 13/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0286 - mean_squared_error: 0.0077 - val_loss: 0.0284 - val_mean_squared_error: 0.0094\n",
      "Epoch 14/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0277 - mean_squared_error: 0.0077 - val_loss: 0.0268 - val_mean_squared_error: 0.0090\n",
      "Epoch 15/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0264 - mean_squared_error: 0.0074 - val_loss: 0.0275 - val_mean_squared_error: 0.0089\n",
      "Epoch 16/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0265 - mean_squared_error: 0.0075 - val_loss: 0.0290 - val_mean_squared_error: 0.0099\n",
      "Epoch 17/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0258 - mean_squared_error: 0.0072 - val_loss: 0.0266 - val_mean_squared_error: 0.0087\n",
      "Epoch 18/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0252 - mean_squared_error: 0.0069 - val_loss: 0.0261 - val_mean_squared_error: 0.0084\n",
      "Epoch 19/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0250 - mean_squared_error: 0.0068 - val_loss: 0.0259 - val_mean_squared_error: 0.0085\n",
      "Epoch 20/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0245 - mean_squared_error: 0.0065 - val_loss: 0.0257 - val_mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.03126 to 0.02567, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 21/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0243 - mean_squared_error: 0.0065 - val_loss: 0.0254 - val_mean_squared_error: 0.0081\n",
      "Epoch 22/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0239 - mean_squared_error: 0.0063 - val_loss: 0.0254 - val_mean_squared_error: 0.0081\n",
      "Epoch 23/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0237 - mean_squared_error: 0.0062 - val_loss: 0.0251 - val_mean_squared_error: 0.0079\n",
      "Epoch 24/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0234 - mean_squared_error: 0.0061 - val_loss: 0.0257 - val_mean_squared_error: 0.0082\n",
      "Epoch 25/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0231 - mean_squared_error: 0.0060 - val_loss: 0.0250 - val_mean_squared_error: 0.0078\n",
      "Epoch 26/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0229 - mean_squared_error: 0.0059 - val_loss: 0.0253 - val_mean_squared_error: 0.0080\n",
      "Epoch 27/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0228 - mean_squared_error: 0.0058 - val_loss: 0.0252 - val_mean_squared_error: 0.0078\n",
      "Epoch 28/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0226 - mean_squared_error: 0.0057 - val_loss: 0.0255 - val_mean_squared_error: 0.0079\n",
      "Epoch 29/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0223 - mean_squared_error: 0.0056 - val_loss: 0.0250 - val_mean_squared_error: 0.0078\n",
      "Epoch 30/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0222 - mean_squared_error: 0.0055 - val_loss: 0.0252 - val_mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.02567 to 0.02524, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 31/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0219 - mean_squared_error: 0.0054 - val_loss: 0.0244 - val_mean_squared_error: 0.0077\n",
      "Epoch 32/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0218 - mean_squared_error: 0.0053 - val_loss: 0.0248 - val_mean_squared_error: 0.0077\n",
      "Epoch 33/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0218 - mean_squared_error: 0.0053 - val_loss: 0.0249 - val_mean_squared_error: 0.0079\n",
      "Epoch 34/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0216 - mean_squared_error: 0.0052 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "Epoch 35/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0213 - mean_squared_error: 0.0051 - val_loss: 0.0249 - val_mean_squared_error: 0.0079\n",
      "Epoch 36/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0211 - mean_squared_error: 0.0050 - val_loss: 0.0251 - val_mean_squared_error: 0.0080\n",
      "Epoch 37/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0210 - mean_squared_error: 0.0049 - val_loss: 0.0251 - val_mean_squared_error: 0.0078\n",
      "Epoch 38/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0211 - mean_squared_error: 0.0049 - val_loss: 0.0247 - val_mean_squared_error: 0.0078\n",
      "Epoch 39/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0234 - mean_squared_error: 0.0060 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 40/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0210 - mean_squared_error: 0.0050 - val_loss: 0.0245 - val_mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.02524 to 0.02455, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 41/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0206 - mean_squared_error: 0.0047 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "Epoch 42/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0204 - mean_squared_error: 0.0047 - val_loss: 0.0243 - val_mean_squared_error: 0.0076\n",
      "Epoch 43/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0203 - mean_squared_error: 0.0046 - val_loss: 0.0248 - val_mean_squared_error: 0.0077\n",
      "Epoch 44/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0203 - mean_squared_error: 0.0046 - val_loss: 0.0245 - val_mean_squared_error: 0.0076\n",
      "Epoch 45/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0202 - mean_squared_error: 0.0046 - val_loss: 0.0246 - val_mean_squared_error: 0.0077\n",
      "Epoch 46/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0201 - mean_squared_error: 0.0046 - val_loss: 0.0245 - val_mean_squared_error: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0199 - mean_squared_error: 0.0045 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "Epoch 48/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0200 - mean_squared_error: 0.0045 - val_loss: 0.0246 - val_mean_squared_error: 0.0077\n",
      "Epoch 49/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0199 - mean_squared_error: 0.0045 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 50/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0198 - mean_squared_error: 0.0044 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.02455 to 0.02440, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 51/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0197 - mean_squared_error: 0.0044 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 52/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0198 - mean_squared_error: 0.0044 - val_loss: 0.0249 - val_mean_squared_error: 0.0078\n",
      "Epoch 53/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0197 - mean_squared_error: 0.0044 - val_loss: 0.0245 - val_mean_squared_error: 0.0077\n",
      "Epoch 54/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0196 - mean_squared_error: 0.0044 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 55/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0195 - mean_squared_error: 0.0043 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 56/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0195 - mean_squared_error: 0.0043 - val_loss: 0.0245 - val_mean_squared_error: 0.0075\n",
      "Epoch 57/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0195 - mean_squared_error: 0.0043 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 58/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0194 - mean_squared_error: 0.0042 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "Epoch 59/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0193 - mean_squared_error: 0.0042 - val_loss: 0.0246 - val_mean_squared_error: 0.0075\n",
      "Epoch 60/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0193 - mean_squared_error: 0.0042 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02440 to 0.02431, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 61/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0192 - mean_squared_error: 0.0042 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "Epoch 62/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0191 - mean_squared_error: 0.0041 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 63/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0190 - mean_squared_error: 0.0041 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 64/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0190 - mean_squared_error: 0.0041 - val_loss: 0.0251 - val_mean_squared_error: 0.0078\n",
      "Epoch 65/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0190 - mean_squared_error: 0.0041 - val_loss: 0.0245 - val_mean_squared_error: 0.0076\n",
      "Epoch 66/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0189 - mean_squared_error: 0.0041 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 67/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0189 - mean_squared_error: 0.0041 - val_loss: 0.0249 - val_mean_squared_error: 0.0075\n",
      "Epoch 68/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0190 - mean_squared_error: 0.0041 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "Epoch 69/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0189 - mean_squared_error: 0.0041 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "Epoch 70/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0189 - mean_squared_error: 0.0041 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02431 to 0.02419, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 71/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0188 - mean_squared_error: 0.0040 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 72/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0188 - mean_squared_error: 0.0040 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 73/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0187 - mean_squared_error: 0.0040 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 74/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0188 - mean_squared_error: 0.0040 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 75/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0186 - mean_squared_error: 0.0040 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "Epoch 76/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0186 - mean_squared_error: 0.0039 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "Epoch 77/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0185 - mean_squared_error: 0.0039 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 78/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0186 - mean_squared_error: 0.0040 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 79/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0185 - mean_squared_error: 0.0039 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 80/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0184 - mean_squared_error: 0.0039 - val_loss: 0.0245 - val_mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02419\n",
      "Epoch 81/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0183 - mean_squared_error: 0.0039 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 82/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0183 - mean_squared_error: 0.0038 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 83/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0191 - mean_squared_error: 0.0042 - val_loss: 0.0253 - val_mean_squared_error: 0.0079\n",
      "Epoch 84/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0185 - mean_squared_error: 0.0039 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 85/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0182 - mean_squared_error: 0.0038 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 86/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0182 - mean_squared_error: 0.0038 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 87/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0182 - mean_squared_error: 0.0038 - val_loss: 0.0241 - val_mean_squared_error: 0.0075\n",
      "Epoch 88/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0181 - mean_squared_error: 0.0038 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 89/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0180 - mean_squared_error: 0.0038 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 90/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.02419 to 0.02388, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 91/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0181 - mean_squared_error: 0.0038 - val_loss: 0.0244 - val_mean_squared_error: 0.0075\n",
      "Epoch 92/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 94/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0244 - val_mean_squared_error: 0.0076\n",
      "Epoch 95/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0179 - mean_squared_error: 0.0037 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 96/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0179 - mean_squared_error: 0.0037 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 97/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0179 - mean_squared_error: 0.0037 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 98/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0242 - val_mean_squared_error: 0.0073\n",
      "Epoch 99/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0180 - mean_squared_error: 0.0037 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 100/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0179 - mean_squared_error: 0.0037 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02388\n",
      "Epoch 101/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0179 - mean_squared_error: 0.0037 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 102/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0178 - mean_squared_error: 0.0037 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 103/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0178 - mean_squared_error: 0.0037 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 104/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0178 - mean_squared_error: 0.0036 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 105/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0178 - mean_squared_error: 0.0037 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 106/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0179 - mean_squared_error: 0.0037 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 107/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0178 - mean_squared_error: 0.0036 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 108/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 109/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 110/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02388\n",
      "Epoch 111/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 112/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 113/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 114/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 115/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0075\n",
      "Epoch 116/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 117/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0075\n",
      "Epoch 118/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0240 - val_mean_squared_error: 0.0072\n",
      "Epoch 119/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0036 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 120/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02388\n",
      "Epoch 121/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 122/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 123/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0239 - val_mean_squared_error: 0.0072\n",
      "Epoch 124/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 125/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 126/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 127/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 128/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0176 - mean_squared_error: 0.0036 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 129/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 130/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0242 - val_mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02388\n",
      "Epoch 131/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 132/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 133/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0242 - val_mean_squared_error: 0.0075\n",
      "Epoch 134/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 135/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0175 - mean_squared_error: 0.0035 - val_loss: 0.0241 - val_mean_squared_error: 0.0075\n",
      "Epoch 136/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0174 - mean_squared_error: 0.0035 - val_loss: 0.0243 - val_mean_squared_error: 0.0076\n",
      "Epoch 137/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0174 - mean_squared_error: 0.0035 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 138/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0174 - mean_squared_error: 0.0035 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 139/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0072\n",
      "Epoch 140/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02388\n",
      "Epoch 141/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 142/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0174 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 143/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0174 - mean_squared_error: 0.0035 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 144/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 145/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 146/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 147/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 148/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0243 - val_mean_squared_error: 0.0075\n",
      "Epoch 149/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0174 - mean_squared_error: 0.0035 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 150/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02388\n",
      "Epoch 151/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0241 - val_mean_squared_error: 0.0075\n",
      "Epoch 152/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 153/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 154/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0241 - val_mean_squared_error: 0.0075\n",
      "Epoch 155/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0035 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 156/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 157/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 158/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0241 - val_mean_squared_error: 0.0074\n",
      "Epoch 159/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 160/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.02388 to 0.02367, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 161/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 162/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 163/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 164/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 165/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 166/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 167/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 168/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0172 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 169/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 170/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02367\n",
      "Epoch 171/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 172/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 173/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 174/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 175/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 176/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 177/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 178/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 179/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 180/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02367\n",
      "Epoch 181/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 182/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 183/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 184/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 185/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 186/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0034 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 188/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 189/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0171 - mean_squared_error: 0.0034 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 190/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02367\n",
      "Epoch 191/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 192/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 193/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 194/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 195/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 196/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 197/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 198/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 199/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 200/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.02367 to 0.02366, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 201/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0034 - val_loss: 0.0240 - val_mean_squared_error: 0.0075\n",
      "Epoch 202/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 203/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 204/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 205/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 206/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0241 - val_mean_squared_error: 0.0073\n",
      "Epoch 207/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0074\n",
      "Epoch 208/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 209/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 210/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.02366\n",
      "Epoch 211/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 212/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0242 - val_mean_squared_error: 0.0074\n",
      "Epoch 213/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 214/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 215/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 216/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 217/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 218/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0072\n",
      "Epoch 219/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 220/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0170 - mean_squared_error: 0.0033 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.02366 to 0.02341, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 221/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 222/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 223/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 224/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 225/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 226/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 227/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 228/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 229/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 230/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.02341\n",
      "Epoch 231/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0074\n",
      "Epoch 232/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0169 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 233/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 234/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0240 - val_mean_squared_error: 0.0073\n",
      "Epoch 235/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 236/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0243 - val_mean_squared_error: 0.0074\n",
      "Epoch 237/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 238/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 239/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 240/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.02341\n",
      "Epoch 241/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0033 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 242/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 243/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 244/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 245/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 246/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 247/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 248/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0032 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 249/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 250/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.02341\n",
      "Epoch 251/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 252/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 253/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 254/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0168 - mean_squared_error: 0.0033 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 255/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 256/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 257/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 258/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 259/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 260/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.02341\n",
      "Epoch 261/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 262/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 263/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 264/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 265/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 266/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 267/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 268/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 269/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 270/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.02341\n",
      "Epoch 271/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 272/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 273/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 274/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 275/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 276/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 277/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 278/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 279/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 280/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.02341\n",
      "Epoch 281/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0074\n",
      "Epoch 282/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 283/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 284/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 285/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 286/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 287/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 288/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 289/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 290/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.02341\n",
      "Epoch 291/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 292/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 293/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 294/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 295/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 296/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 297/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 298/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 299/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 300/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0167 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.02341\n",
      "Epoch 301/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0074\n",
      "Epoch 302/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 303/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 304/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0070\n",
      "Epoch 305/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0239 - val_mean_squared_error: 0.0072\n",
      "Epoch 306/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 307/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 308/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 309/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 310/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.02341\n",
      "Epoch 311/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 312/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 313/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 314/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 315/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0240 - val_mean_squared_error: 0.0075\n",
      "Epoch 316/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 317/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 318/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 319/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0070\n",
      "Epoch 320/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.02341\n",
      "Epoch 321/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 322/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 323/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 324/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 325/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 326/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 327/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 328/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 329/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 330/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.02341\n",
      "Epoch 331/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 332/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 333/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 334/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 335/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 336/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 337/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 338/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0070\n",
      "Epoch 339/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 340/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.02341\n",
      "Epoch 341/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 342/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 343/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 344/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 345/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0166 - mean_squared_error: 0.0032 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 346/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 347/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 348/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 349/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 350/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.02341\n",
      "Epoch 351/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 352/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 353/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 354/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 355/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 356/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 357/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 358/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 359/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 360/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.02341\n",
      "Epoch 361/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 362/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 363/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 364/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0233 - val_mean_squared_error: 0.0070\n",
      "Epoch 365/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 366/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 367/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 368/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 369/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 370/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.02341\n",
      "Epoch 371/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 372/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 373/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 374/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 375/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 376/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 377/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 378/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 379/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 380/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.02341\n",
      "Epoch 381/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 382/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 383/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0072\n",
      "Epoch 384/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 385/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 386/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 387/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 388/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 389/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 390/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0165 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.02341\n",
      "Epoch 391/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 392/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 393/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 394/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 395/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 396/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 397/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 398/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 399/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 400/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.02341\n",
      "Epoch 401/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 402/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 403/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 404/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 405/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0072\n",
      "Epoch 406/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0240 - val_mean_squared_error: 0.0074\n",
      "Epoch 407/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 408/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 409/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 410/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0164 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.02341\n",
      "Epoch 411/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 412/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 413/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 414/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 415/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 416/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 417/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 418/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 419/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 420/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.02341\n",
      "Epoch 421/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0072\n",
      "Epoch 422/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 423/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 424/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 425/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0071\n",
      "Epoch 426/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 427/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 428/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 429/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0070\n",
      "Epoch 430/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0238 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.02341\n",
      "Epoch 431/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 432/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 433/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 434/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 435/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 436/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 437/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 438/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 439/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 440/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.02341 to 0.02337, saving model to /media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5\n",
      "Epoch 441/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 442/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 443/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 444/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 445/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 446/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 447/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 448/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 449/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 450/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.02337\n",
      "Epoch 451/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 452/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0070\n",
      "Epoch 453/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 454/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 455/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 456/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 457/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 458/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 459/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 460/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.02337\n",
      "Epoch 461/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 462/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 463/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 464/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0031 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "Epoch 465/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 466/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 467/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 468/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 469/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 470/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.02337\n",
      "Epoch 471/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 472/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 473/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 474/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0072\n",
      "Epoch 475/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 476/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 477/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 478/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 479/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 480/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.02337\n",
      "Epoch 481/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 482/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 483/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 484/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 485/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0072\n",
      "Epoch 486/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 487/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 488/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 489/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 490/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0240 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.02337\n",
      "Epoch 491/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0163 - mean_squared_error: 0.0031 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 492/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0072\n",
      "Epoch 493/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 494/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 495/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 496/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 497/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 498/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0073\n",
      "Epoch 499/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 500/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.02337\n",
      "Epoch 501/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 502/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0233 - val_mean_squared_error: 0.0070\n",
      "Epoch 503/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 504/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 505/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 506/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 507/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 508/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 509/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 510/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.02337\n",
      "Epoch 511/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 512/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 513/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 514/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 515/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 516/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0233 - val_mean_squared_error: 0.0070\n",
      "Epoch 517/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 518/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 519/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 520/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.02337\n",
      "Epoch 521/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 522/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 523/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 524/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 525/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 526/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 527/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 528/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 529/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 530/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.02337\n",
      "Epoch 531/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0073\n",
      "Epoch 532/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 533/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0073\n",
      "Epoch 534/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 535/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 536/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 537/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 538/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0071\n",
      "Epoch 539/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 540/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.02337\n",
      "Epoch 541/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 542/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 543/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 544/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 545/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 546/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 547/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 548/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 549/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0071\n",
      "Epoch 550/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.02337\n",
      "Epoch 551/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 552/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 553/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 554/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 555/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 556/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 557/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "Epoch 558/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 559/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0162 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 560/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.02337\n",
      "Epoch 561/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0070\n",
      "Epoch 562/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0072\n",
      "Epoch 563/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0234 - val_mean_squared_error: 0.0071\n",
      "Epoch 564/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 565/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0072\n",
      "Epoch 566/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 567/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0236 - val_mean_squared_error: 0.0071\n",
      "Epoch 568/1500\n",
      "700/700 [==============================] - 12s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0238 - val_mean_squared_error: 0.0073\n",
      "Epoch 569/1500\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.0161 - mean_squared_error: 0.0030 - val_loss: 0.0235 - val_mean_squared_error: 0.0071\n",
      "Epoch 570/1500\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.0160 - mean_squared_error: 0.0030 - val_loss: 0.0239 - val_mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.02337\n",
      "Epoch 571/1500\n",
      "404/700 [================>.............] - ETA: 5s - loss: 0.0158 - mean_squared_error: 0.0030"
     ]
    }
   ],
   "source": [
    "# For training the U-Net model\n",
    "\n",
    "checkpoint  = ModelCheckpoint(filepath='/media/pranjal/Backup/DBT-NEW/models/model10-cewit.h5', \n",
    "                              monitor='val_loss', period=10, \n",
=======
   "outputs": [],
   "source": [
    "# For training the U-Net model\n",
    "\n",
    "# 31 is with L1 loss                             [0.002633739351092169,  5.250131192536668e-05]\n",
    "# 32 is with L2 loss                             [5.219619599067065e-05, 0.0026246307205545854]\n",
    "# 33 starts with 32 and then trains on odd lines [5.23863326888458e-05,  0.002626443004890068]\n",
    "\n",
    "checkpoint  = ModelCheckpoint(filepath='/media/dril/ubuntudata/DBT-NEW/models/model-sinogram4-110-dril.h5', \n",
    "                              monitor='val_loss', period=1, \n",
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
    "                              verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        index       = 2000\n",
    "        temp        = np.expand_dims(valx[index], axis=0)\n",
    "        temp_result = self.model.predict(temp)\n",
    "        a = temp[0, :, :, 0]\n",
    "        b = temp_result[0, :, :, 0]\n",
    "        c = valy[index, :, :, 0]\n",
    "        diff = np.abs(c-b)*100\n",
    "        print(np.mean(np.mean(diff)))\n",
    "        scipy.misc.imsave('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram1-110-dril-results/'+str(epoch)+'_diff.jpg', np.concatenate([diff.T, a.T], axis=0))\n",
    "        #print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "#unet_vanilla()\n",
    "model          = unet_vanilla()\n",
    "#model.load_weights('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram4-110-dril.h5')\n",
    "#\n",
    "#residual_train = trainx - trainy\n",
    "#residual_val   = valx   - valy\n",
    "\n",
    "model.fit(trainx, trainy, validation_data=(valx, valy), \n",
    "          batch_size=8, \n",
    "          epochs=1500, callbacks=[checkpoint,LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/media/pranjal/Backup/DBT-NEW/models/model9-cewit.h5', compile=False)"
=======
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     39,
     93,
     131
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For training the GAN model\n",
    "\n",
    "img_size = (800, 48, 1)\n",
    "savepath = '/media/dril/ubuntudata/DBT-NEW/models/gan-model5/'\n",
    "\n",
    "class AdversarialAutoencoder():\n",
    "    def __init__(self):\n",
    "        self.optimizer  = Adam(0.0001)\n",
    "        self.clip_value = 0.01\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=self.optimizer, \n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        #self.discriminator.load_weights('/media/pranjal/de24af8d-2361-4ea2-a07a-1801b54488d9/DBT_data/Results/vanilla-gan-weights-mse-0.1/discriminator_weights_8050.h5')\n",
    "        self.d_arr = []\n",
    "        self.g_arr = []\n",
    "        \n",
    "        # Build the encoder / decoder\n",
    "        self.generator      = self.build_generator()\n",
    "        img                 = Input(shape=img_size)\n",
    "        reconstructed_img   = self.generator(img)\n",
    "        \n",
    "        # For the adversarial_autoencoder model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator determines validity of the cleaned image\n",
    "        validity = self.discriminator(reconstructed_img)\n",
    "        \n",
    "        # The adversarial_autoencoder model  (stacked generator and discriminator)\n",
    "        self.adversarial_autoencoder = Model(img, [reconstructed_img, validity])\n",
    "        self.adversarial_autoencoder.compile(loss=['mean_absolute_error', 'mse'],\n",
    "            loss_weights=[0.99, 0.001],\n",
    "            optimizer=self.optimizer)\n",
    "        \n",
    "        self.generator.load_weights('/media/dril/ubuntudata/DBT-NEW/models/gan-model5/generator_weights_209700.h5')\n",
    "        self.discriminator.load_weights('/media/dril/ubuntudata/DBT-NEW/models/gan-model5/discriminator_weights_209700.h5')\n",
    "    \n",
    "    def build_generator(self):\n",
    "        input_size = (800, 48, 1)\n",
    "        \n",
    "        filter1 = 32\n",
    "        filter2 = 64\n",
    "        filter3 = 128\n",
    "        filter4 = 256\n",
    "        filter5 = 512\n",
    "\n",
    "        inputs = Input(input_size)\n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "        conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        conv3 = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        #drop4 = conv4\n",
    "        drop4 = Dropout(0.2)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 1))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(filter5, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.2)(conv5)\n",
    "        #drop5 = conv5\n",
    "\n",
    "        up6    = Conv2D(filter4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(drop5))\n",
    "        merge6 = concatenate([drop4,up6], axis = 3)\n",
    "        conv6  = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6  = Conv2D(filter4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7    = Conv2D(filter3, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = concatenate([conv3,up7], axis = 3)\n",
    "        conv7  = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7  = Conv2D(filter3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8    = Conv2D(filter2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,1))(conv7))\n",
    "        merge8 = concatenate([conv2,up8], axis = 3)\n",
    "        conv8  = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8  = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9    = Conv2D(filter1, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = concatenate([conv1,up9], axis = 3)\n",
    "        conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9  = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'relu')(conv9)\n",
    "        \n",
    "        model = Model(input = inputs, output = conv10)\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        input_size = (800, 48, 1)\n",
    "\n",
    "        filter1 = 64 \n",
    "        filter2 = 128\n",
    "\n",
    "        inputs = Input(input_size)\n",
    "\n",
    "        input_top    = Lambda(lambda x: x[:, :, :10, 0])(inputs) \n",
    "        input_bottom = Lambda(lambda x: x[:, :, 35:, 0])(inputs)\n",
    "\n",
    "        new_input = Concatenate(axis=-1)([input_top, input_bottom])\n",
    "        new_input = Reshape([800, 23, 1])(new_input)\n",
    "        \n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(new_input) \n",
    "        pool1 = MaxPooling2D(pool_size=(2, 1))(conv1)\n",
    "\n",
    "        conv1 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1) \n",
    "        conv1 = MaxPooling2D(pool_size=(2, 1))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(filter1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1) \n",
    "        conv2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2) \n",
    "        conv2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "\n",
    "        conv2 = Conv2D(filter2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2) \n",
    "        conv2 = MaxPooling2D(pool_size=(2, 1))(conv2)\n",
    "\n",
    "        conv2 = Flatten()(conv2) \n",
    "        conv2 = Dense(512, activation='relu', kernel_initializer = 'he_normal')(conv2) \n",
    "        conv2 = Dense(128, activation='relu', kernel_initializer = 'he_normal')(conv2)\n",
    "        out   = Dense(1, activation='relu', kernel_initializer = 'he_normal')(conv2)\n",
    "\n",
    "        model = Model(input = inputs, output = out)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, epochs, batch_size=8, sampling=50, saveseed=5, startepoch=0, discriminator_epochs=5, log_sampling=1000):\n",
    "        global trainx\n",
    "        global trainy\n",
    "        global valx\n",
    "        global valy\n",
    "        \n",
    "        for epoch in range(startepoch, epochs):\n",
    "            # Train the discriminator 5 times\n",
    "            #print('Training Discriminator ', epoch)\n",
    "            \n",
    "            for itd in range(discriminator_epochs):\n",
    "                # Shuffle the dataset\n",
    "                random_index = np.random.randint(0, trainx.shape[0], batch_size)\n",
    "                \n",
    "                X_train = trainx[random_index]\n",
    "                Y_train = trainy[random_index]\n",
    "                \n",
    "                # Adversarial ground truths\n",
    "                valid = np.ones((batch_size,  1))\n",
    "                fake  = np.zeros((batch_size, 1))\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # get the noisy image and feed it into the generator\n",
    "                X_train_clean = self.generator.predict(X_train)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(Y_train, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(X_train_clean, fake)\n",
    "                d_loss      = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator\n",
    "            for itd in range(discriminator_epochs*10):\n",
    "                # Shuffle the dataset\n",
    "                random_index = np.random.randint(0, trainx.shape[0], batch_size)\n",
    "                \n",
    "                X_train = trainx[random_index]\n",
    "                Y_train = trainy[random_index]\n",
    "                \n",
    "                # Adversarial ground truths\n",
    "                valid = np.ones((batch_size,  1))\n",
    "                fake  = np.zeros((batch_size, 1))\n",
    "                g_loss = self.adversarial_autoencoder.train_on_batch(X_train, [Y_train, valid])\n",
    "            \n",
    "            #print(g_loss[0], g_loss[1], g_loss[2])\n",
    "            \n",
    "            self.d_arr.append(d_loss)\n",
    "            self.g_arr.append(g_loss)\n",
    "            \n",
    "            if epoch%sampling == 0 and epoch !=0:\n",
    "                result1 = self.generator.predict(valx, batch_size=4)\n",
    "                print('Mean L1 loss is ', np.mean(np.mean(np.abs(result1 - valy), axis=(1, 2, 3))))\n",
    "                self.generator.save_weights(savepath+'generator_weights_'+str(epoch)+'.h5')\n",
    "                self.discriminator.save_weights(savepath+'discriminator_weights_'+str(epoch)+'.h5')\n",
    "            \n",
    "            if epoch%log_sampling == 0:\n",
    "                print (\"%d [D loss: %f, mean_acc: %.2f%% real_acc: %.2f%% fake_acc: %.2f%%] [G loss: %f, L1: %f]\" % (epoch, d_loss[0], 100*d_loss[1], 100*d_loss_real[1], 100*d_loss_fake[1], g_loss[0], g_loss[1]))\n",
    "\n",
    "aae = AdversarialAutoencoder()\n",
    "aae.train(epochs=2000000, batch_size=8, \n",
    "          sampling=500, \n",
    "          saveseed=7590, \n",
    "          startepoch=209701, \n",
    "          discriminator_epochs=1,\n",
    "          log_sampling=20)"
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('/media/pranjal/Backup/DBT-NEW/models/model3.h5', compile=False)"
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = aae.generator.predict(valx, batch_size=8)\n",
    "#print(a.shape, valy.shape)\n",
    "#result = a\n",
    "#print('Mean L1 loss is ', np.mean(np.mean(np.abs(result-valy), axis=(1, 2, 3))))\n",
    "epoch = 209700\n",
    "aae.generator.save_weights(savepath+'generator_weights_'+str(epoch)+'.h5')\n",
    "aae.discriminator.save_weights(savepath+'discriminator_weights_'+str(epoch)+'.h5')"
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 10,
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(180, 56, 56, 40, 1)\n"
=======
      "8133/8133 [==============================] - 41s 5ms/step\n",
      "[0.0018616708284705172, 4.1579177295908704e-05]\n"
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
     ]
    }
   ],
   "source": [
    "model1 = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram2-110-dril.h5')\n",
    "result = model1.evaluate(valx, valy, batch_size=8)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model1.predict(valx, batch_size=4)\n",
    "print(result1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ea54834c498e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mslicenum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslicenum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslicenum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslicenum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "index = random.randint(0, 35)\n",
    "print(index)\n",
    "slicenum = 20\n",
    "plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')\n",
    "#plt.imshow(np.concatenate([result[index, :, :, slicenum, 0], valx[index, :, :, slicenum, 0], valy[index, :, :, slicenum, 0]], axis=-1), cmap='gray')"
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00907218 7.0507317 0.0012867005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faab82e84e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x4320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(result))\n",
    "#print(index)\n",
    "t1 = valx[index, :, :, 0]\n",
    "t2 = result[index, :, :, 0]\n",
    "t3 = valy[index, :, :, 0]\n",
    "\n",
    "print( np.mean(np.abs(t1-t3)),  np.mean(np.abs(t1-t3))/np.mean(np.abs(t2-t3)), np.mean(np.abs(t2-t3)))\n",
    "\n",
    "plt.figure(figsize=(40, 60))\n",
    "#plt.imshow(np.concatenate([t1, t2, np.abs(t2-t1)*5, t4, np.abs(t4-t1)*5, t3, np.abs(t2-t3)*5, np.abs(t4-t3)*5], axis=-1).T, cmap='gray')\n",
    "#plt.imshow(np.concatenate([t1, t2, np.abs(t3-t1)*10, np.abs(t2-t3)*100], axis=-1).T, cmap='gray')\n",
    "plt.imshow(np.concatenate([np.abs(t3-t1)*10, np.abs(t2-t3)*10*np.mean(np.abs(t1-t3))/np.mean(np.abs(t2-t3))], axis=-1).T, cmap='gray')"
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f29dc419550>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   "source": [
    "# For getting the full projection from the sinogram for lower resolution 90 angle\n",
    "\n",
    "# Reading the original central projections\n",
    "valx_orig = np.zeros((36, 800, 300, 25), dtype=np.single) # These are the original noisy 25 projections\n",
    "counter   = 0\n",
    "for i in range(141, 177):\n",
    "    x_noise_orig = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/projections/g_noi_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x_noise_orig = x_noise_orig['g_noi']\n",
    "    print(i, x_noise_orig.shape)\n",
    "    temp         = x_noise_orig[:, :, 10:-10]\n",
    "    valx_orig[counter, :, :, :] = temp/5.0\n",
    "    counter = counter+1\n",
    "\n",
    "model  = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram21.h5')\n",
    "result = model.predict(valx, batch_size=16)\n",
    "\n",
    "result = result[:, :, :45, 0]\n",
    "valy   = valy[:, :, :45, 0]\n",
    "valx   = valx[:, :, :45, 0]\n",
    "valx   = valx[:, :, 10:-10]\n",
    "\n",
    "#valx   = valx_orig                # Replace the central projections\n",
    "\n",
    "print(valx.shape)\n",
    "\n",
    "result_25_full = np.zeros((36, 800, 300, 25), dtype=np.single)\n",
    "result_full    = np.zeros((36, 800, 300, 45), dtype=np.single)\n",
    "ground_full    = np.zeros((36, 800, 300, 45), dtype=np.single)\n",
    "\n",
    "valy_full   = []\n",
    "totalcount  = 0\n",
    "\n",
    "for i in range(36):\n",
    "    #result_25_full[i, :, :, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "    for j in range(300):\n",
    "        result_25_full[i, :, j, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "        result_full[i, :, j, :]    = result[totalcount, :, :]   # Prediction from the model, now replace the center 25 projections with original\n",
    "        ground_full[i, :, j, :]    = valy[totalcount, :, :]     # No noise projections \n",
    "        totalcount = totalcount+1\n",
    "\n",
    "# Replacing the central 25 projections\n",
    "print('Replacing the central 25 projections')\n",
    "result_full[:, :, :, 10:-10] = valx_orig[:, :, :, :]\n",
    "\n",
    "print('Converted to projections from line sinograms')\n",
    "print(result_full.shape, ground_full.shape)\n",
    "\n",
    "# Write to .mat file\n",
    "if(1):\n",
    "    for i in range(0, 36):\n",
    "        h1 = {}\n",
    "        h1['prediction']     = result_full[i]*5.0\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/predictions/model-sinogram21/'+str(i+1)+'_prediction.mat', h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['prediction_25']  = valx_orig[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/predictions/model-sinogram21/'+str(i+1)+'_input.mat',      h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['groundtruth']    = ground_full[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections/predictions/model-sinogram21/'+str(i+1)+'_groundtruth.mat', h1, do_compression=True)\n",
    "\n",
    "print('Written to the disk')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cd4188320>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   "source": [
    "# For getting the full projection from the sinogram for lower resolution 110 angle\n",
    "\n",
    "# Reading the original central projections\n",
    "valx_orig = np.zeros((36, 960, 300, 25), dtype=np.single) # These are the original noisy 25 projections\n",
    "counter   = 0\n",
    "for i in range(141, 177):\n",
    "    x_noise_orig = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/g_noi_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x_noise_orig = x_noise_orig['g_noi']\n",
    "    print(i, x_noise_orig.shape)\n",
    "    temp         = x_noise_orig[:, :, 15:-15]\n",
    "    valx_orig[counter, :, :, :] = temp/5.0\n",
    "    counter = counter+1\n",
    "\n",
    "model  = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram2-110-dril.h5')\n",
    "result = model.predict(valx, batch_size=16)\n",
    "\n",
    "result = result[:, :, 4:-5, 0]\n",
    "valy   = valy[:, :, 4:-5, 0]\n",
    "valx   = valx[:, :, 4:-5, 0]\n",
    "valx   = valx[:, :, 15:-15]\n",
    "\n",
    "#valx   = valx_orig                # Replace the central projections\n",
    "\n",
    "print(valx.shape)\n",
    "\n",
    "result_25_full = np.zeros((36, 960, 300, 25), dtype=np.single)\n",
    "result_full    = np.zeros((36, 960, 300, 55), dtype=np.single)\n",
    "ground_full    = np.zeros((36, 960, 300, 55), dtype=np.single)\n",
    "\n",
    "valy_full   = []\n",
    "totalcount  = 0\n",
    "\n",
    "for i in range(36):\n",
    "    #result_25_full[i, :, :, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "    for j in range(300):\n",
    "        result_25_full[i, :, j, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "        result_full[i, :, j, :]    = result[totalcount, :, :]   # Prediction from the model, now replace the center 25 projections with original\n",
    "        ground_full[i, :, j, :]    = valy[totalcount, :, :]     # No noise projections \n",
    "        totalcount = totalcount+1\n",
    "\n",
    "# Replacing the central 25 projections\n",
    "print('Replacing the central 25 projections')\n",
    "result_full[:, :, :, 15:-15] = valx_orig[:, :, :, :]\n",
    "\n",
    "print('Converted to projections from line sinograms')\n",
    "print(result_full.shape, ground_full.shape)\n",
    "\n",
    "# Write to .mat file\n",
    "if(1):\n",
    "    for i in range(0, 36):\n",
    "        h1 = {}\n",
    "        h1['prediction']     = result_full[i]*5.0\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/predictions/'+str(i+1)+'_prediction.mat', h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['prediction_25']  = valx_orig[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/predictions/'+str(i+1)+'_input.mat',      h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['groundtruth']    = ground_full[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-110-projections/predictions/'+str(i+1)+'_groundtruth.mat', h1, do_compression=True)\n",
    "\n",
    "print('Written to the disk')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ca8296860>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# For getting the full projection from the sinogram for higher resolution\n",
    "\n",
    "# Reading the original central projections\n",
    "valx_orig = np.zeros((36, 1600, 600, 25), dtype=np.single) # These are the original noisy 25 projections\n",
    "counter   = 0\n",
    "for i in range(141, 177):\n",
    "    x_noise_orig = loadmat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/projections/g_noi_'+str(i)+'.mat', verify_compressed_data_integrity=False)\n",
    "    x_noise_orig = x_noise_orig['g_noi']\n",
    "    print(i, x_noise_orig.shape)\n",
    "    temp         = x_noise_orig[:, :, 10:-10]\n",
    "    valx_orig[counter, :, :, :] = temp/5.0\n",
    "    counter = counter+1\n",
    "\n",
    "model  = load_model('/media/dril/ubuntudata/DBT-NEW/models/model-sinogram32-higher-dril.h5', compile=False)\n",
    "result = model.predict(valx, batch_size=16)\n",
    "\n",
    "result = result[:, :, :45, 0]\n",
    "valy   = valy[:, :, :45, 0]\n",
    "valx   = valx[:, :, :45, 0]\n",
    "valx   = valx[:, :, 10:-10]\n",
    "\n",
    "#valx   = valx_orig                # Replace the central projections\n",
    "\n",
    "print(valx.shape)\n",
    "\n",
    "result_25_full = np.zeros((36, 1600, 600, 25), dtype=np.single)\n",
    "result_full    = np.zeros((36, 1600, 600, 45), dtype=np.single)\n",
    "ground_full    = np.zeros((36, 1600, 600, 45), dtype=np.single)\n",
    "\n",
    "valy_full   = []\n",
    "totalcount  = 0\n",
    "\n",
    "for i in range(36):\n",
    "    #result_25_full[i, :, :, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "    for j in range(600):\n",
    "        result_25_full[i, :, j, :] = valx[totalcount, :, :]     # Coming from sart\n",
    "        result_full[i, :, j, :]    = result[totalcount, :, :]   # Prediction from the model, now replace the center 25 projections with original\n",
    "        ground_full[i, :, j, :]    = valy[totalcount, :, :]     # No noise projections \n",
    "        totalcount = totalcount+1\n",
    "\n",
    "# Replacing the central 25 projections\n",
    "print('Replacing the central 25 projections')\n",
    "result_full[:, :, :, 10:-10] = valx_orig[:, :, :, :]\n",
    "\n",
    "print('Converted to projections from line sinograms')\n",
    "print(result_full.shape, ground_full.shape)\n",
    "\n",
    "# Write to .mat file\n",
    "if(1):\n",
    "    for i in range(0, 36):\n",
    "        h1 = {}\n",
    "        h1['prediction']     = result_full[i]*5.0\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/predictions/model-sinogram32-higher-dril/'+str(i+1)+'_prediction.mat', h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['prediction_25']  = valx_orig[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/predictions/model-sinogram32-higher-dril/'+str(i+1)+'_input.mat',      h1, do_compression=True)\n",
    "        \n",
    "        h1 = {}\n",
    "        h1['groundtruth']    = ground_full[i]\n",
    "        savemat('/media/dril/ubuntudata/DBT-NEW/gan-90-projections-higher/predictions/model-sinogram32-higher-dril/'+str(i+1)+'_groundtruth.mat', h1, do_compression=True)\n",
    "\n",
    "print('Written to the disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
>>>>>>> d582a282923b97425a8440d6ea007f2132821ccd
   "source": [
    "# Make total Model from slices and save the up-sampled output\n",
    "\n",
    "index   = 153#random.randint(0, 35)\n",
    "\n",
    "\n",
    "#volx = loadmat('/home/dril/newrecon/ReconDBT/xfbp.mat', verify_compressed_data_integrity=False)\n",
    "volx = loadmat('/media/dril/ubuntudata/DBT-NEW/recons-noise/fbp_'+str(index)+'_3_hann50.mat', verify_compressed_data_integrity=False)\n",
    "voly = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/'+str(index)+'.mat')  \n",
    "\n",
    "volx = volx['xfbp']\n",
    "voly = voly['head']\n",
    "b    = voly\n",
    "\n",
    "b    = volx#ndimage.zoom(volx, 0.50, order=1).astype(np.single)\n",
    "voly = ndimage.zoom(voly, 0.125, order=1).astype(np.single)\n",
    "volx = ndimage.zoom(volx, 0.250, order=1).astype(np.single)\n",
    "\n",
    "testitx = []\n",
    "testity = []\n",
    "\n",
    "gap_slice = 1\n",
    "for j in range(0, 36, gap_slice):\n",
    "    x = volx[:, j:j+20, :]\n",
    "    testitx.append(np.expand_dims(x, axis=-1))\n",
    "\n",
    "for j in range(0, 36, gap_slice):\n",
    "    y = voly[:, j:j+20, :]\n",
    "    testity.append(np.expand_dims(y, axis=-1))\n",
    "\n",
    "testitx = np.array(testitx)\n",
    "testity = np.array(testity)\n",
    "\n",
    "testitx  = np.pad(testitx, ((0,0), (2, 2), (2, 2), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "testity  = np.pad(testity, ((0,0), (2, 2), (2, 2), (0, 0), (0, 0)), 'constant', constant_values = (0, 0))\n",
    "\n",
    "result = model.predict(testitx, batch_size=4)\n",
    "\n",
    "result  = result[:,  2:102, 2:22,  :, :]\n",
    "testitx = testitx[:, 2:102, 2:22,  :, :]\n",
    "testity = testity[:, 2:102, 2:22,  :, :]\n",
    "\n",
    "#print(testitx.shape, testity.shape, result.shape)\n",
    "\n",
    "# Joining the result to get the full volume from slice by slice results\n",
    "final_result = []\n",
    "for i in range(11):\n",
    "    final_result.append(result[0, :, i, :, 0])\n",
    "for i in range(0, len(result)):\n",
    "    temp = result[i, :, 10, :, 0]\n",
    "    final_result.append(result[i, :, 10, :, 0])\n",
    "for i in range(11, 20):\n",
    "    final_result.append(result[len(result)-1, :, i, :, 0])\n",
    "\n",
    "final_result  = np.array(final_result)\n",
    "final_result  = np.moveaxis(final_result, 0, 1)\n",
    "print(final_result.shape)\n",
    "\n",
    "# To save the upsampled low resolution deep learning model output\n",
    "a       = loadmat('/media/dril/ubuntudata/DBT-NEW/attenuation_values_cropped/153.mat')\n",
    "a       = a['head']\n",
    "a       = ndimage.zoom(a, 0.5, order=1).astype(np.single)\n",
    "result1 = ndimage.zoom(final_result, 4, order=1).astype(np.single)\n",
    "h1         = {}\n",
    "h1['deep'] = result1.astype('single')\n",
    "\n",
    "\n",
    "diff_result = np.abs(result1-a)\n",
    "diff_result[diff_result < 0.5]   = 0\n",
    "diff_result[diff_result >= 0.5]  = 1\n",
    "h2            = {}\n",
    "h2['mask1']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "\n",
    "diff_result = np.abs(result1-a)\n",
    "diff_result[diff_result < 0.1]   = 0\n",
    "diff_result[diff_result >= 0.5]  = 0\n",
    "diff_result[diff_result >= 0.1]  = 1\n",
    "h3            = {}\n",
    "h3['mask2']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "\n",
    "diff_result = np.abs(result1-a)\n",
    "diff_result[diff_result >= 0.1]  = 0\n",
    "diff_result[(diff_result > 0.05) & (diff_result < 0.1)]  = 1\n",
    "diff_result[diff_result != 1]   = 0\n",
    "h4            = {}\n",
    "h4['mask3']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "a[a!=0]             = 1\n",
    "result1[result1!=0] = 1\n",
    "totalmask           = h2['mask1']+h3['mask2']+h4['mask3']\n",
    "totalmask[totalmask != 0] = 1\n",
    "\n",
    "diff_result = np.abs(totalmask - result1)\n",
    "diff_result[diff_result != 0]   = 1\n",
    "h5            = {}\n",
    "h5['mask4']   = diff_result.astype('single')\n",
    "print(np.count_nonzero(diff_result.flatten()))\n",
    "\n",
    "\n",
    "# Uncomment this code to write the output\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50.mat',       h1, do_compression=True) # upsampled output\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask1.mat', h2, do_compression=True) # 0.5 <= error\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask2.mat', h3, do_compression=True) # 0.1 <= error <0.5\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask3.mat', h4, do_compression=True) # error < 0.1\n",
    "savemat('/media/dril/ubuntudata/DBT-NEW/deeplearning_output/'+str(153)+'_3_hann50_mask4.mat', h5, do_compression=True) # rest mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
